<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 68]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.SD](#cs.SD) [Total: 9]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [An Empirical Analysis of Discrete Unit Representations in Speech Language Modeling Pre-training](https://arxiv.org/abs/2509.05359)
*Yanis Labrak,Richard Dufour,Mickaël Rouvier*

Main category: cs.CL

TL;DR: 本文系统研究语音语言模型中离散单元表示的优化策略，探讨模型架构、数据表示和训练鲁棒性对语音建模预训练的影响，发现最优离散化策略随模型容量变化，并揭示了聚类数据选择对模型鲁棒性的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究如何在持续预训练阶段优化语音语言模型的离散单元表示，将现有预训练语言模型适配到语音模态，探索模型架构、数据表示和训练鲁棒性的影响。

Method: 通过系统实验考察语音编码器和聚类粒度在不同模型规模下的作用，分析聚类分布和音素对齐，研究离散词汇表的有效使用，并探索聚类数据选择对模型鲁棒性的影响。

Result: 发现最优离散化策略随模型容量而变化，揭示了语言和副语言模式，证明了离散化训练与目标应用领域匹配的重要性。

Conclusion: 语音语言模型的离散单元表示优化需要根据模型容量选择适当策略，聚类数据选择对模型鲁棒性至关重要，领域匹配是成功应用的关键因素。

Abstract: This paper investigates discrete unit representations in Speech Language
Models (SLMs), focusing on optimizing speech modeling during continual
pre-training. In this paper, we systematically examine how model architecture,
data representation, and training robustness influence the pre-training stage
in which we adapt existing pre-trained language models to the speech modality.
Our experiments highlight the role of speech encoders and clustering
granularity across different model scales, showing how optimal discretization
strategies vary with model capacity. By examining cluster distribution and
phonemic alignments, we investigate the effective use of discrete vocabulary,
uncovering both linguistic and paralinguistic patterns. Additionally, we
explore the impact of clustering data selection on model robustness,
highlighting the importance of domain matching between discretization training
and target applications.

</details>


### [2] [Beyond ROUGE: N-Gram Subspace Features for LLM Hallucination Detection](https://arxiv.org/abs/2509.05360)
*Jerry Li,Evangelos Papalexakis*

Main category: cs.CL

TL;DR: 提出基于N-Gram频率张量的新方法检测LLM幻觉，通过张量分解提取特征并训练MLP分类器，在HaluEval数据集上表现优于传统基线方法


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法（如ROUGE、BERTScore等）缺乏足够的语义深度来有效检测LLM生成的幻觉内容，需要更丰富的语义结构表示方法

Method: 构建N-Gram频率张量捕获共现模式，应用张量分解提取各模态奇异值作为特征，训练多层感知机(MLP)二元分类器进行幻觉检测

Result: 在HaluEval数据集上评估，相比传统基线方法有显著改进，与最先进的LLM法官方法相比具有竞争力

Conclusion: 基于N-Gram张量的方法能够更好地捕捉语义结构，为LLM幻觉检测提供了有效的解决方案，在检测准确性和语义理解方面都有提升

Abstract: Large Language Models (LLMs) have demonstrated effectiveness across a wide
variety of tasks involving natural language, however, a fundamental problem of
hallucinations still plagues these models, limiting their trustworthiness in
generating consistent, truthful information. Detecting hallucinations has
quickly become an important topic, with various methods such as uncertainty
estimation, LLM Judges, retrieval augmented generation (RAG), and consistency
checks showing promise. Many of these methods build upon foundational metrics,
such as ROUGE, BERTScore, or Perplexity, which often lack the semantic depth
necessary to detect hallucinations effectively. In this work, we propose a
novel approach inspired by ROUGE that constructs an N-Gram frequency tensor
from LLM-generated text. This tensor captures richer semantic structure by
encoding co-occurrence patterns, enabling better differentiation between
factual and hallucinated content. We demonstrate this by applying tensor
decomposition methods to extract singular values from each mode and use these
as input features to train a multi-layer perceptron (MLP) binary classifier for
hallucinations. Our method is evaluated on the HaluEval dataset and
demonstrates significant improvements over traditional baselines, as well as
competitive performance against state-of-the-art LLM judges.

</details>


### [3] [A Lightweight Framework for Trigger-Guided LoRA-Based Self-Adaptation in LLMs](https://arxiv.org/abs/2509.05385)
*Jiacheng Wei,Faguo Wu,Xiao Zhang*

Main category: cs.CL

TL;DR: SAGE是一个触发引导的动态微调框架，能够在推理时实现自适应更新，通过检测推理失败、聚类异常样本和动态优化参数来提升大语言模型的持续学习能力。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在推理时无法持续适应和学习新数据的局限性，使模型能够在测试时进行动态知识更新。

Method: 将复杂推理任务分解为原子子任务，包含三个核心模块：触发模块（实时检测推理失败）、触发缓冲模块（使用HDBSCAN聚类异常样本并进行稳定性检查和相似性合并）、Lora存储模块（通过适配器池动态优化参数更新以实现知识保留）。

Result: SAGE在原子推理子任务上表现出优秀的准确性、鲁棒性和稳定性，通过测试时的动态知识更新取得了良好效果。

Conclusion: SAGE框架有效解决了大语言模型在推理时持续学习的挑战，为实时自适应推理提供了可行的解决方案。

Abstract: Large language models are unable to continuously adapt and learn from new
data during reasoning at inference time. To address this limitation, we propose
that complex reasoning tasks be decomposed into atomic subtasks and introduce
SAGE, a trigger-guided dynamic fine-tuning framework that enables adaptive
updates during reasoning at inference time. SAGE consists of three key
components: (1) a Trigger module that detects reasoning failures through
multiple evaluation metrics in real time; (2) a Trigger Buffer module that
clusters anomaly samples using a streaming clustering process with HDBSCAN,
followed by stability checks and similarity-based merging; and (3) a Lora Store
module that dynamically optimizes parameter updates with an adapter pool for
knowledge retention. Evaluation results show that SAGE demonstrates excellent
accuracy, robustness, and stability on the atomic reasoning subtask through
dynamic knowledge updating during test time.

</details>


### [4] [Talk Isn't Always Cheap: Understanding Failure Modes in Multi-Agent Debate](https://arxiv.org/abs/2509.05396)
*Andrea Wynn,Harsh Satija,Gillian Hadfield*

Main category: cs.CL

TL;DR: 多智能体辩论有时反而有害，特别是在能力不同的智能体群体中，可能导致准确率下降而非提升


<details>
  <summary>Details</summary>
Motivation: 探索模型能力多样性如何影响多智能体辩论的动态和结果，发现现有研究只关注同质群体而忽略了异质性的影响

Method: 通过一系列实验研究多智能体辩论，分析不同能力模型之间的交互动态

Result: 辩论可能导致准确率随时间下降，即使更强模型占多数；模型经常从正确答案转向错误答案，倾向于达成一致而非挑战错误推理

Conclusion: 多智能体辩论存在重要失败模式，当智能体既无激励也无足够能力抵抗有说服力但错误的推理时，简单的辩论应用可能导致性能下降

Abstract: While multi-agent debate has been proposed as a promising strategy for
improving AI reasoning ability, we find that debate can sometimes be harmful
rather than helpful. The prior work has exclusively focused on debates within
homogeneous groups of agents, whereas we explore how diversity in model
capabilities influences the dynamics and outcomes of multi-agent interactions.
Through a series of experiments, we demonstrate that debate can lead to a
decrease in accuracy over time -- even in settings where stronger (i.e., more
capable) models outnumber their weaker counterparts. Our analysis reveals that
models frequently shift from correct to incorrect answers in response to peer
reasoning, favoring agreement over challenging flawed reasoning. These results
highlight important failure modes in the exchange of reasons during multi-agent
debate, suggesting that naive applications of debate may cause performance
degradation when agents are neither incentivized nor adequately equipped to
resist persuasive but incorrect reasoning.

</details>


### [5] [No Translation Needed: Forecasting Quality from Fertility and Metadata](https://arxiv.org/abs/2509.05425)
*Jessica M. Lundin,Ada Zhang,David Adelani,Cody Carroll*

Main category: cs.CL

TL;DR: 使用语言类型学特征和词汇生成率等简单特征，可以在不运行翻译系统的情况下准确预测GPT-4o在FLORES-200语言对中的翻译质量（ChrF分数）。


<details>
  <summary>Details</summary>
Motivation: 探索如何在不实际运行翻译系统的情况下，仅依靠基础语言特征预测翻译质量，以提高多语言评估的效率。

Method: 采用梯度提升模型，使用词汇生成率比例、词汇数量和语言元数据（语言语系、文字系统、地区）作为特征，在FLORES-200语言对中预测GPT-4o的翻译质量。

Result: 模型表现良好，多语言到英语翻译的R²为0.66，英语到多语言翻译的R²为0.72。特征重要性分析显示，语言类型学因素对翻译到英语的预测影响更大，而词汇生成率在翻译到多样化目标语言时作用更重要。

Conclusion: 翻译质量受到词汇层面的生成率和更广泛的语言类型学因素的共同影响，这为多语言评估和质量估测提供了新的见解。

Abstract: We show that translation quality can be predicted with surprising accuracy
\textit{without ever running the translation system itself}. Using only a
handful of features, token fertility ratios, token counts, and basic linguistic
metadata (language family, script, and region), we can forecast ChrF scores for
GPT-4o translations across 203 languages in the FLORES-200 benchmark. Gradient
boosting models achieve favorable performance ($R^{2}=0.66$ for
XX$\rightarrow$English and $R^{2}=0.72$ for English$\rightarrow$XX). Feature
importance analyses reveal that typological factors dominate predictions into
English, while fertility plays a larger role for translations into diverse
target languages. These findings suggest that translation quality is shaped by
both token-level fertility and broader linguistic typology, offering new
insights for multilingual evaluation and quality estimation.

</details>


### [6] [Direct-Scoring NLG Evaluators Can Use Pairwise Comparisons Too](https://arxiv.org/abs/2509.05440)
*Logan Lawrence,Ashton Williamson,Alexander Shelton*

Main category: cs.CL

TL;DR: 这篇论文提出了一种直接评分方法，通过使用合成摘要来模拟成对比排序，解决了传统成对比方法无法赋予绝对分数的问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型被广泛用于自动评估自由形式内容，需要能够赋予绝对分数的评估方法，这对需要阈值处理的应用场景至关重要。

Method: 使用合成摘要来模拟成对比机器排序，实现直接评分方法，能够给单个摘要赋予绝对分数。

Result: 在SummEval、TopicalChat和HANNA评测基准上，方法表现与最先进的成对比评估器相当（相关系数分别为+0.03、-0.03、+0.05）。

Conclusion: 该直接评分方法使用合成摘要模拟成对比排序，在保持与成对比方法相符的样本级相关性能的同时，还能提供绝对分数评估能力。

Abstract: As large-language models have been increasingly used as automatic raters for
evaluating free-form content, including document summarization, dialog, and
story generation, work has been dedicated to evaluating such models by
measuring their correlations with human judgment. For \textit{sample-level}
performance, methods which operate by using pairwise comparisons between
machine-generated text perform well but often lack the ability to assign
absolute scores to individual summaries, an ability crucial for use cases that
require thresholding. In this work, we propose a direct-scoring method which
uses synthetic summaries to act as pairwise machine rankings at test time. We
show that our method performs comparably to state-of-the-art pairwise
evaluators in terms of axis-averaged sample-level correlations on the SummEval
(\textbf{+0.03}), TopicalChat (\textbf{-0.03}), and HANNA (\textbf{+0.05})
meta-evaluation benchmarks, and release the synthetic in-context summaries as
data to facilitate future work.

</details>


### [7] [From Staff Messages to Actionable Insights: A Multi-Stage LLM Classification Framework for Healthcare Analytics](https://arxiv.org/abs/2509.05484)
*Hajar Sakai,Yi-En Tseng,Mohammadsadegh Mikaeili,Joshua Bosire,Franziska Jovin*

Main category: cs.CL

TL;DR: 这篇论文提出了一种基于大语言模型的多阶段框架，用于分析医院呼叫中心的员工消息，进行主题识别和多类分类，最佳模型准确率达到79.2%。


<details>
  <summary>Details</summary>
Motivation: 医院呼叫中心产生大量员工消息数据，但传统监督学习需要注解数据和深度训练，大语言模型提供了更高效的健康分析方案。

Method: 设计了多阶段LLM框架，评估了推理模型、通用模型和轻量模型多种LLM类型，并结合数据安全措施和HIPAA合规要求。

Result: o3模型表现最佳，达到78.4%权重F1分数和79.2%准确率，其次是gpt-5（75.3% F1分数和76.2%准确率）。输出集成到可视化决策支持工具中。

Conclusion: 该方法能够高效利用员工消息数据，识别导航员培训机会，支持改善患者体验和护理质量，为健康领域提供了一种计算效率更高的分析方案。

Abstract: Hospital call centers serve as the primary contact point for patients within
a hospital system. They also generate substantial volumes of staff messages as
navigators process patient requests and communicate with the hospital offices
following the established protocol restrictions and guidelines. This
continuously accumulated large amount of text data can be mined and processed
to retrieve insights; however, traditional supervised learning approaches
require annotated data, extensive training, and model tuning. Large Language
Models (LLMs) offer a paradigm shift toward more computationally efficient
methodologies for healthcare analytics. This paper presents a multi-stage
LLM-based framework that identifies staff message topics and classifies
messages by their reasons in a multi-class fashion. In the process, multiple
LLM types, including reasoning, general-purpose, and lightweight models, were
evaluated. The best-performing model was o3, achieving 78.4% weighted F1-score
and 79.2% accuracy, followed closely by gpt-5 (75.3% Weighted F1-score and
76.2% accuracy). The proposed methodology incorporates data security measures
and HIPAA compliance requirements essential for healthcare environments. The
processed LLM outputs are integrated into a visualization decision support tool
that transforms the staff messages into actionable insights accessible to
healthcare professionals. This approach enables more efficient utilization of
the collected staff messaging data, identifies navigator training
opportunities, and supports improved patient experience and care quality.

</details>


### [8] [The Token Tax: Systematic Bias in Multilingual Tokenization](https://arxiv.org/abs/2509.05486)
*Jessica M. Lundin,Ada Zhang,Nihal Karim,Hamza Louzan,Victor Wei,David Adelani,Cody Carroll*

Main category: cs.CL

TL;DR: 研究表明词汇切分效率低下对形态复杂的低资源语言不利，词汇生育率（tokens/word）能可靠预测模型准确率，高生育率导致准确率下降，推理模型表现更优，词汇膨胀带来四倍训练成本增加。


<details>
  <summary>Details</summary>
Motivation: 评估词汇切分效率对非洲语言处理的影响，揭示词汇生育率与模型准确率的关系，以及由此产生的计算资源不平等问题。

Method: 在AfriMMLU数据集（9,000个多选题，5个科目，16种非洲语言）上评估10个大语言模型，分析词汇生育率与准确率的关联。

Result: 词汇生育率可靠预测准确率，高生育率导致低准确率；推理模型（DeepSeek, o1）在所有语言中表现优于非推理模型；词汇数量翻倍导致训练成本和时间增加四倍。

Conclusion: 需要开发形态学感知的词汇切分方法、公平定价策略和多语言基准测试，以实现更公平的自然语言处理。

Abstract: Tokenization inefficiency imposes structural disadvantages on morphologically
complex, low-resource languages, inflating compute resources and depressing
accuracy. We evaluate 10 large language models (LLMs) on AfriMMLU (9,000 MCQA
items; 5 subjects; 16 African languages) and show that fertility (tokens/word)
reliably predicts accuracy. Higher fertility consistently predicts lower
accuracy across all models and subjects. We further find that reasoning models
(DeepSeek, o1) consistently outperform non-reasoning peers across high and low
resource languages in the AfriMMLU dataset, narrowing accuracy gaps observed in
prior generations. Finally, translating token inflation to economics, a
doubling in tokens results in quadrupled training cost and time, underscoring
the token tax faced by many languages. These results motivate morphologically
aware tokenization, fair pricing, and multilingual benchmarks for equitable
natural language processing (NLP).

</details>


### [9] [Biomedical Literature Q&A System Using Retrieval-Augmented Generation (RAG)](https://arxiv.org/abs/2509.05505)
*Mansi Garg,Lee-Chi Wang,Bhavesh Ghanchi,Sanjana Dumpala,Shreyash Kakde,Yen Chih Chen*

Main category: cs.CL

TL;DR: 基于RAG架构的生物医学文献问答系统，整合多源医学信息，通过语义检索和微调语言模型生成准确回答，在乳腺癌文献评估中显示显著效果提升


<details>
  <summary>Details</summary>
Motivation: 解决传统健康搜索引擎的不足和公众获取生物医学研究的滞后问题，改善基于证据的医学信息获取

Method: 使用MiniLM语义嵌入和FAISS向量搜索的检索管道，配合QLoRA优化的Mistral-7B-v0.3语言模型进行答案生成，整合PubMed文章、问答数据集和医学百科全书

Result: 在BERTScore(F1)评估中，相比基线模型在事实一致性和语义相关性方面有显著改进，特别是在乳腺癌领域的域对齐检索中表现出色

Conclusion: RAG增强的语言模型有潜力弥合复杂生物医学文献与可访问公共卫生知识之间的差距，为多语言适配、隐私保护推理和个性化医疗AI系统的未来发展铺平道路

Abstract: This work presents a Biomedical Literature Question Answering (Q&A) system
based on a Retrieval-Augmented Generation (RAG) architecture, designed to
improve access to accurate, evidence-based medical information. Addressing the
shortcomings of conventional health search engines and the lag in public access
to biomedical research, the system integrates diverse sources, including PubMed
articles, curated Q&A datasets, and medical encyclopedias ,to retrieve relevant
information and generate concise, context-aware responses. The retrieval
pipeline uses MiniLM-based semantic embeddings and FAISS vector search, while
answer generation is performed by a fine-tuned Mistral-7B-v0.3 language model
optimized using QLoRA for efficient, low-resource training. The system supports
both general medical queries and domain-specific tasks, with a focused
evaluation on breast cancer literature demonstrating the value of
domain-aligned retrieval. Empirical results, measured using BERTScore (F1),
show substantial improvements in factual consistency and semantic relevance
compared to baseline models. The findings underscore the potential of
RAG-enhanced language models to bridge the gap between complex biomedical
literature and accessible public health knowledge, paving the way for future
work on multilingual adaptation, privacy-preserving inference, and personalized
medical AI systems.

</details>


### [10] [Using Contrastive Learning to Improve Two-Way Reasoning in Large Language Models: The Obfuscation Task as a Case Study](https://arxiv.org/abs/2509.05553)
*Serge Lionel Nikiema,Jordan Samhi,Micheline Bénédicte Moumoula,Albérick Euraste Djiré,Abdoul Kader Kaboré,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.CL

TL;DR: 该研究提出双向推理作为测试AI真正理解的标准，发现现有模型存在认知专门化问题，并开发了对比微调(CFT)方法成功实现双向推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决AI领域一个根本问题：大型语言模型是真正理解概念还是仅仅识别模式。研究者认为真正的理解应该自然允许可逆性，即能够双向应用转换而无需反向训练。

Method: 提出双向推理测试框架，开发对比微调(CFT)方法，使用三种示例类型：保持语义的正例、不同语义的负例、正向混淆示例，旨在培养深层理解而非表面模式识别。

Result: 实验证明CFT成功实现了双向推理，在保持正向任务能力的同时获得了强大的反向性能，解决了认知专门化问题。

Conclusion: 双向推理既可作为评估真正理解的理论框架，也可作为开发更强大AI系统的实用训练方法，CFT证明了无需显式反向训练即可自然发展反向能力。

Abstract: This research addresses a fundamental question in AI: whether large language
models truly understand concepts or simply recognize patterns. The authors
propose bidirectional reasoning,the ability to apply transformations in both
directions without being explicitly trained on the reverse direction, as a test
for genuine understanding. They argue that true comprehension should naturally
allow reversibility. For example, a model that can change a variable name like
userIndex to i should also be able to infer that i represents a user index
without reverse training. The researchers tested current language models and
discovered what they term cognitive specialization: when models are fine-tuned
on forward tasks, their performance on those tasks improves, but their ability
to reason bidirectionally becomes significantly worse. To address this issue,
they developed Contrastive Fine-Tuning (CFT), which trains models using three
types of examples: positive examples that maintain semantic meaning, negative
examples with different semantics, and forward-direction obfuscation examples.
This approach aims to develop deeper understanding rather than surface-level
pattern recognition and allows reverse capabilities to develop naturally
without explicit reverse training. Their experiments demonstrated that CFT
successfully achieved bidirectional reasoning, enabling strong reverse
performance while maintaining forward task capabilities. The authors conclude
that bidirectional reasoning serves both as a theoretical framework for
assessing genuine understanding and as a practical training approach for
developing more capable AI systems.

</details>


### [11] [Ad hoc conventions generalize to new referents](https://arxiv.org/abs/2509.05566)
*Anya Ji,Claire Augusta Bergey,Ron Eliav,Yoav Artzi,Robert D. Hawkins*

Main category: cs.CL

TL;DR: 研究发现人们在建立新的共享命名系统时，会通过概念协调实现泛化，而非仅仅建立任意的标签关联


<details>
  <summary>Details</summary>
Motivation: 探讨人们如何谈论从未讨论过的事物，检验两种对立观点：是建立任意标签关联还是通过概念协调实现语义空间重塑

Method: 使用KiloGram数据集的302对参与者进行双人交流研究，通过重复交流建立指称惯例后，测量对未讨论图像的描述一致性

Result: 发现了强烈的泛化证据：伙伴间的对齐度相对于前测标签显著增加；泛化随视觉相似度非线性衰减（符合Shepard定律）；在不同可命名性水平的图像上都表现稳健

Conclusion: 临时约定不是任意标签，而是反映了真正的概念协调，这对指称理论和设计更自适应的语言代理具有重要意义

Abstract: How do people talk about things they've never talked about before? One view
suggests that a new shared naming system establishes an arbitrary link to a
specific target, like proper names that cannot extend beyond their bearers. An
alternative view proposes that forming a shared way of describing objects
involves broader conceptual alignment, reshaping each individual's semantic
space in ways that should generalize to new referents. We test these competing
accounts in a dyadic communication study (N=302) leveraging the
recently-released KiloGram dataset containing over 1,000 abstract tangram
images. After pairs of participants coordinated on referential conventions for
one set of images through repeated communication, we measured the extent to
which their descriptions aligned for undiscussed images. We found strong
evidence for generalization: partners showed increased alignment relative to
their pre-test labels. Generalization also decayed nonlinearly with visual
similarity (consistent with Shepard's law) and was robust across levels of the
images' nameability. These findings suggest that ad hoc conventions are not
arbitrary labels but reflect genuine conceptual coordination, with implications
for theories of reference and the design of more adaptive language agents.

</details>


### [12] [Mitigating Spurious Correlations Between Question and Answer via Chain-of-Thought Correctness Perception Distillation](https://arxiv.org/abs/2509.05602)
*Hongyan Xie,Yitong Yao,Yikun Ban,Zixuan Huang,Deqing Wang,Zhenhe Wu,Haoxiang Su,Chao Wang,Shuangyong Song,Xuelong Li*

Main category: cs.CL

TL;DR: CoPeD方法通过引入正确性感知任务设置和加权损失函数，提升小语言模型从大语言模型生成的思维链数据中学习推理质量，减少噪声推理的影响


<details>
  <summary>Details</summary>
Motivation: 大语言模型生成的思维链数据可能包含噪声推理，这些推理要么无法支持答案，要么对答案预测没有额外贡献，导致小语言模型学习到虚假的相关性，影响推理质量

Method: 提出Chain-of-Thought Correctness Perception Distillation (CoPeD)：1) 正确性感知任务设置，鼓励学生模型基于正确推理预测答案并修正错误推理；2) 正确性感知加权损失，根据推理和答案的联合损失动态调整训练样本权重

Result: 实验表明CoPeD在分布内和分布外基准推理数据集上都有效

Conclusion: CoPeD通过改进任务设置和数据利用方式，有效提升了学生模型的推理质量，使其能够更好地从大语言模型生成的思维链数据中学习

Abstract: Large language models (LLMs) excel at reasoning tasks but are expensive to
deploy. Thus small language models (SLMs) are fine-tuned on CoT data generated
by LLMs to copy LLMs' abilities. However, these CoT data may include noisy
rationales that either fail to substantiate the answers or contribute no
additional information to support answer prediction, which leads SLMs to
capture spurious correlations between questions and answers and compromise the
quality of reasoning. In this work, we propose Chain-of-Thought Correctness
Perception Distillation (CoPeD), which aims to improve the reasoning quality of
the student model from the perspectives of task setting and data utilization.
Firstly, we introduce a correctness-aware task setting that encourages the
student model to predict answers based on correct rationales and revise them
when they are incorrect. This setting improves the faithfulness of reasoning
and allows the model to learn from its mistakes. Then, we propose a
Correctness-Aware Weighted loss, which dynamically adjusts the contribution of
each training instance based on the combined loss of the rationale and the
answer. This strategy encourages the model to focus more on samples where the
rationale offers stronger support for the correct answer. Experiments have
shown that CoPeD is effective on both in-distribution (IND) and
out-of-distribution (OOD) benchmark reasoning datasets.

</details>


### [13] [Icon$^{2}$: Aligning Large Language Models Using Self-Synthetic Preference Data via Inherent Regulation](https://arxiv.org/abs/2509.05605)
*Qiyuan Chen,Hongsen Huang,Qian Shao,Jiahe Chen,Jintai Chen,Hongxia Xu,Renjie Hua,Ren Chuan,Jian Wu*

Main category: cs.CL

TL;DR: Icon²方法通过利用LLM表示空间的固有调节机制，构建高质量偏好数据集，显著提升对齐效果并降低计算成本


<details>
  <summary>Details</summary>
Motivation: 传统偏好数据集构建方法存在分布不匹配和计算开销大的问题，需要更高效且针对性的解决方案

Method: 提取层级方向向量编码人类偏好，基于固有一致性过滤自合成指令，在解码时应用双向固有控制来生成具有明确对齐区分的响应对

Result: Llama3-8B和Qwen2-7B在AlpacaEval 2.0和Arena-Hard上平均胜率分别提升13.89%和13.45%，计算成本降低高达48.1%

Conclusion: Icon²通过利用LLM表示空间的固有调节，实现了高效且高质量的偏好数据集构建，为LLM对齐提供了新的有效途径

Abstract: Large Language Models (LLMs) require high quality preference datasets to
align with human preferences. However, conventional methods for constructing
such datasets face significant challenges: reliance on pre-collected
instructions often leads to distribution mismatches with target models, while
the need for sampling multiple stochastic responses introduces substantial
computational overhead. In this work, we explore a paradigm shift by leveraging
inherent regulation of LLMs' representation space for efficient and tailored
preference dataset construction, named Icon$^{2}$. Specifically, it first
extracts layer-wise direction vectors to encode sophisticated human preferences
and then uses these vectors to filter self-synthesized instructions based on
their inherent consistency. During decoding, bidirectional inherent control is
applied to steer token representations, enabling the precise generation of
response pairs with clear alignment distinctions. Experimental results
demonstrate significant improvements in both alignment and efficiency.
Llama3-8B and Qwen2-7B achieve an average win rate improvement of 13.89% on
AlpacaEval 2.0 and 13.45% on Arena-Hard, while reducing computational costs by
up to 48.1%.

</details>


### [14] [Beyond Keywords: Driving Generative Search Engine Optimization with Content-Centric Agents](https://arxiv.org/abs/2509.05607)
*Qiyuan Chen,Jiahe Chen,Hongsen Huang,Qian Shao,Jintai Chen,Renjie Hua,Hongxia Xu,Ruijia Wu,Ren Chuan,Jian Wu*

Main category: cs.CL

TL;DR: 这篇论文提出了一个结构化的生成式搜索引擎优化(GSEO)框架，包括大规模标准测试集CC-GSEO-Bench和自动化的多代理系统，以系统性评估和优化内容对生成式答案的影响力。


<details>
  <summary>Details</summary>
Motivation: 传统的排名基于搜索向生成式搜索引擎的转变使得传统SEO指标失效，必须开发新方法来理解、测量和优化内容对合成答案的影响。

Method: 构建了CC-GSEO-Bench大规模标准测试集，提出多维度评估框架系统性量化内容影响力，设计了新题的多代理系统通过协作分析-修订-评估流程自动化内容策略精炼。

Result: 实验分析揭示了内容影响力的新动态特征，为内容创作者提供了可操作的策略，并为未来GSEO研究建立了有理论基础的基础。

Conclusion: 该框架成功解决了生成式搜索引擎优化的挑战，通过结构化的方法论和自动化工具为内容创作者提供了实用的优化手段，为该领域的研究开启了新方向。

Abstract: The paradigm shift from traditional ranked-based search to Generative Search
Engines has rendered conventional SEO metrics obsolete, creating an urgent need
to understand, measure, and optimize for content influence on synthesized
answers. This paper introduces a comprehensive, end-to-end framework for
Generative Search Engine Optimization (GSEO) to address this challenge. We make
two primary contributions. First, we construct CC-GSEO-Bench, a large-scale,
content-centric benchmark, and propose a multi-dimensional evaluation framework
that systematically quantifies influence, moving beyond surface-level
attribution to assess substantive semantic impact. Second, we design a novel
multi-agent system that operationalizes this framework, automating the
strategic refinement of content through a collaborative analyze-revise-evaluate
workflow. Our empirical analysis using this framework reveals novel insights
into the dynamics of content influence, offering actionable strategies for
creators and establishing a principled foundation for future GSEO research.

</details>


### [15] [Enhancing the Robustness of Contextual ASR to Varying Biasing Information Volumes Through Purified Semantic Correlation Joint Modeling](https://arxiv.org/abs/2509.05908)
*Yue Gu,Zhihao Du,Ying Shi,Shiliang Zhang,Qian Chen,Jiqing Han*

Main category: cs.CL

TL;DR: 提出PSC-Joint方法，通过多粒度语义相关性联合建模，从偏置列表中筛选最相关信息，解决跨注意力机制在长偏置列表下性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于跨注意力的上下文ASR模型在处理长偏置列表时性能下降，因为只有少量偏置信息与特定ASR中间表示真正相关。

Method: 提出纯化语义相关性联合建模(PSC-Joint)，定义并计算列表级、短语级和词级三个粒度的语义相关性，通过联合建模突出最相关偏置信息，并采用分组竞争策略的纯化机制降低计算成本。

Result: 在AISHELL-1和KeSpeech数据集上，相比基线方法，平均相对F1分数分别提升21.34%和28.46%，在不同长度的偏置列表上均表现优异。

Conclusion: PSC-Joint方法能有效识别和整合最相关的偏置信息，缓解偏置信息量变化对上下文ASR的影响，显著提升识别性能。

Abstract: Recently, cross-attention-based contextual automatic speech recognition (ASR)
models have made notable advancements in recognizing personalized biasing
phrases. However, the effectiveness of cross-attention is affected by
variations in biasing information volume, especially when the length of the
biasing list increases significantly. We find that, regardless of the length of
the biasing list, only a limited amount of biasing information is most relevant
to a specific ASR intermediate representation. Therefore, by identifying and
integrating the most relevant biasing information rather than the entire
biasing list, we can alleviate the effects of variations in biasing information
volume for contextual ASR. To this end, we propose a purified semantic
correlation joint modeling (PSC-Joint) approach. In PSC-Joint, we define and
calculate three semantic correlations between the ASR intermediate
representations and biasing information from coarse to fine: list-level,
phrase-level, and token-level. Then, the three correlations are jointly modeled
to produce their intersection, so that the most relevant biasing information
across various granularities is highlighted and integrated for contextual
recognition. In addition, to reduce the computational cost introduced by the
joint modeling of three semantic correlations, we also propose a purification
mechanism based on a grouped-and-competitive strategy to filter out irrelevant
biasing phrases. Compared with baselines, our PSC-Joint approach achieves
average relative F1 score improvements of up to 21.34% on AISHELL-1 and 28.46%
on KeSpeech, across biasing lists of varying lengths.

</details>


### [16] [New Insights into Optimal Alignment of Acoustic and Linguistic Representations for Knowledge Transfer in ASR](https://arxiv.org/abs/2509.05609)
*Xugang Lu,Peng Shen,Yu Tsao,Hisashi Kawai*

Main category: cs.CL

TL;DR: 本文提出了一种基于不平衡最优传输的声学-语言表示对齐方法，将ASR中的跨模态对齐视为检测问题，通过软部分匹配处理分布不匹配和结构不对称性。


<details>
  <summary>Details</summary>
Motivation: 声学和语言表示的对齐是ASR知识迁移中的核心挑战，存在固有的结构不对称性（多对一、一对多）和冗余/噪声帧问题，需要高精度、高召回率的对齐方法。

Method: 采用不平衡最优传输模型，显式处理分布不匹配和结构不对称性，实现声学与语言模态间的软部分匹配，确保每个语言标记至少对应一个声学观测，同时允许灵活的probabilistic映射。

Result: 在基于CTC的ASR系统和预训练语言模型的知识迁移实验中，该方法能够灵活控制匹配程度，有效提升了ASR性能。

Conclusion: 将声学-语言对齐视为检测问题，并通过不平衡最优传输方法处理结构不对称性，为ASR知识迁移提供了有效的对齐解决方案。

Abstract: Aligning acoustic and linguistic representations is a central challenge to
bridge the pre-trained models in knowledge transfer for automatic speech
recognition (ASR). This alignment is inherently structured and asymmetric:
while multiple consecutive acoustic frames typically correspond to a single
linguistic token (many-to-one), certain acoustic transition regions may relate
to multiple adjacent tokens (one-to-many). Moreover, acoustic sequences often
include frames with no linguistic counterpart, such as background noise or
silence may lead to imbalanced matching conditions. In this work, we take a new
insight to regard alignment and matching as a detection problem, where the goal
is to identify meaningful correspondences with high precision and recall
ensuring full coverage of linguistic tokens while flexibly handling redundant
or noisy acoustic frames in transferring linguistic knowledge for ASR. Based on
this new insight, we propose an unbalanced optimal transport-based alignment
model that explicitly handles distributional mismatch and structural
asymmetries with soft and partial matching between acoustic and linguistic
modalities. Our method ensures that every linguistic token is grounded in at
least one acoustic observation, while allowing for flexible, probabilistic
mappings from acoustic to linguistic units. We evaluate our proposed model with
experiments on an CTC-based ASR system with a pre-trained language model for
knowledge transfer. Experimental results demonstrate the effectiveness of our
approach in flexibly controlling degree of matching and hence to improve ASR
performance.

</details>


### [17] [From Joy to Fear: A Benchmark of Emotion Estimation in Pop Song Lyrics](https://arxiv.org/abs/2509.05617)
*Shay Dahary,Avi Edana,Alexander Apartsin,Yehudit Aperstein*

Main category: cs.CL

TL;DR: 论文研究了歌词的多标签情感归因任务，通过构建人工标注数据集评估了零样本LLM和微调BERT模型在预测六种基本情感强度方面的表现。


<details>
  <summary>Details</summary>
Motivation: 歌词的情感内容对听众体验和音乐偏好有重要影响，需要可靠的方法来识别和分析歌词中的复杂情感。

Method: 构建人工标注数据集（采用平均意见分方法），评估零样本大语言模型性能，并微调BERT模型进行多标签情感分数预测。

Result: 实验结果显示零样本和微调模型在捕捉歌词细腻情感内容方面各有优势和局限，LLM在创意文本情感识别方面具有潜力。

Conclusion: 研究为基于情感的音乐信息检索应用提供了模型选择策略的见解，标注数据集已公开可用。

Abstract: The emotional content of song lyrics plays a pivotal role in shaping listener
experiences and influencing musical preferences. This paper investigates the
task of multi-label emotional attribution of song lyrics by predicting six
emotional intensity scores corresponding to six fundamental emotions. A
manually labeled dataset is constructed using a mean opinion score (MOS)
approach, which aggregates annotations from multiple human raters to ensure
reliable ground-truth labels. Leveraging this dataset, we conduct a
comprehensive evaluation of several publicly available large language models
(LLMs) under zero-shot scenarios. Additionally, we fine-tune a BERT-based model
specifically for predicting multi-label emotion scores. Experimental results
reveal the relative strengths and limitations of zero-shot and fine-tuned
models in capturing the nuanced emotional content of lyrics. Our findings
highlight the potential of LLMs for emotion recognition in creative texts,
providing insights into model selection strategies for emotion-based music
information retrieval applications. The labeled dataset is available at
https://github.com/LLM-HITCS25S/LyricsEmotionAttribution.

</details>


### [18] [Few-Shot Query Intent Detection via Relation-Aware Prompt Learning](https://arxiv.org/abs/2509.05635)
*Liang Zhang,Yuan Li,Shijie Zhang,Zheng Zhang,Xitong Li*

Main category: cs.CL

TL;DR: SAID是一个新颖的框架，首次统一整合文本和关系结构信息进行模型预训练，通过查询自适应注意力网络实现细粒度知识迁移，在少样本意图检测任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有意图检测方法主要关注文本数据，忽略了对话系统中关键的结构信息（如查询-查询关系和查询-回答关系），导致无法有效捕捉对话的结构特征。

Method: 提出SAID框架，统一整合文本和关系结构信息进行预训练；设计查询自适应注意力网络(QueryAdapt)，在关系标记级别生成意图特定的关系标记，实现细粒度知识迁移。

Result: 在两个真实世界数据集上的大量实验结果表明，SAID显著优于最先进的方法。

Conclusion: SAID通过有效整合文本和结构信息，在少样本意图检测任务上取得了显著改进，证明了结构信息在对话系统意图检测中的重要性。

Abstract: Intent detection is a crucial component of modern conversational systems,
since accurately identifying user intent at the beginning of a conversation is
essential for generating effective responses. Recent efforts have focused on
studying this problem under a challenging few-shot scenario. These approaches
primarily leverage large-scale unlabeled dialogue text corpora to pretrain
language models through various pretext tasks, followed by fine-tuning for
intent detection with very limited annotations. Despite the improvements
achieved, existing methods have predominantly focused on textual data,
neglecting to effectively capture the crucial structural information inherent
in conversational systems, such as the query-query relation and query-answer
relation. To address this gap, we propose SAID, a novel framework that
integrates both textual and relational structure information in a unified
manner for model pretraining for the first time. Building on this framework, we
further propose a novel mechanism, the query-adaptive attention network
(QueryAdapt), which operates at the relation token level by generating
intent-specific relation tokens from well-learned query-query and query-answer
relations explicitly, enabling more fine-grained knowledge transfer. Extensive
experimental results on two real-world datasets demonstrate that SAID
significantly outperforms state-of-the-art methods.

</details>


### [19] [LM-Searcher: Cross-domain Neural Architecture Search with LLMs via Unified Numerical Encoding](https://arxiv.org/abs/2509.05657)
*Yuxuan Hu,Jihao Liu,Ke Wang,Jinliang Zhen,Weikang Shi,Manyuan Zhang,Qi Dou,Rui Liu,Aojun Zhou,Hongsheng Li*

Main category: cs.CL

TL;DR: LM-Searcher是一个基于大语言模型的跨领域神经架构搜索框架，通过通用数值编码NCode和排名任务重定义，无需领域特定调优即可实现高性能架构搜索。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的神经架构搜索方法严重依赖提示工程和领域特定调优，限制了其在实际应用中的实用性和可扩展性。

Method: 提出NCode通用数值字符串表示法编码神经架构，将NAS问题重新定义为排名任务，使用基于剪枝的子空间采样策略生成指令调优样本训练LLM。

Result: 在领域内（如图像分类CNN）和跨领域（如分割和生成的LoRA配置）任务中都取得了有竞争力的性能。

Conclusion: LM-Searcher为灵活和可泛化的基于LLM的架构搜索建立了新范式，具有很好的跨领域适应性。

Abstract: Recent progress in Large Language Models (LLMs) has opened new avenues for
solving complex optimization problems, including Neural Architecture Search
(NAS). However, existing LLM-driven NAS approaches rely heavily on prompt
engineering and domain-specific tuning, limiting their practicality and
scalability across diverse tasks. In this work, we propose LM-Searcher, a novel
framework that leverages LLMs for cross-domain neural architecture optimization
without the need for extensive domain-specific adaptation. Central to our
approach is NCode, a universal numerical string representation for neural
architectures, which enables cross-domain architecture encoding and search. We
also reformulate the NAS problem as a ranking task, training LLMs to select
high-performing architectures from candidate pools using instruction-tuning
samples derived from a novel pruning-based subspace sampling strategy. Our
curated dataset, encompassing a wide range of architecture-performance pairs,
encourages robust and transferable learning. Comprehensive experiments
demonstrate that LM-Searcher achieves competitive performance in both in-domain
(e.g., CNNs for image classification) and out-of-domain (e.g., LoRA
configurations for segmentation and generation) tasks, establishing a new
paradigm for flexible and generalizable LLM-based architecture search. The
datasets and models will be released at https://github.com/Ashone3/LM-Searcher.

</details>


### [20] [Cross-Question Method Reuse in Large Language Models: From Word-Level Prediction to Rational Logical-Layer Reasoning](https://arxiv.org/abs/2509.05660)
*Hong Su*

Main category: cs.CL

TL;DR: 本文提出了一种扩展方法重用范围的新方法，能够处理相似度低或具有隐藏相似性的问题，通过分离问题和解决方案，引导LLM专注于解决方案迁移而非问题识别。


<details>
  <summary>Details</summary>
Motivation: 现有方法重用技术通常要求问题高度相似，限制了应用范围。本文旨在扩展方法重用，使其能够处理相似度低或具有隐藏相似性的问题，实现更广泛的问题间方法重用。

Method: 首先将问题和解决方案分离，而不是直接将问题-解决方案对输入LLM。然后引导LLM将解决方案适配到新的相关问题上，专注于解决方案迁移而非问题识别。该方法还扩展到仅共享部分特征或隐藏特征的问题。

Result: 实验验证表明，该范围扩展方法提高了筛选出可重用解决方案的概率，从而提升了跨问题方法重用的有效性。

Conclusion: 通过分离问题和解决方案并专注于解决方案迁移，该方法成功扩展了方法重用的范围，能够处理低相似度和隐藏相似性的问题，为跨问题方法重用提供了更有效的解决方案。

Abstract: Large language models (LLMs) have been widely applied to assist in finding
solutions for diverse questions. Prior work has proposed representing a method
as a pair of a question and its corresponding solution, enabling method reuse.
However, existing approaches typically require the questions to be highly
similar. In this paper, we extend the scope of method reuse to address
questions with low similarity or with hidden similarities that are not
explicitly observable. For questions that are similar in a general-specific
sense (i.e., broader or narrower in scope), we propose to first separate the
question and solution, rather than directly feeding the pair to the LLM. The
LLM is then guided to adapt the solution to new but related questions, allowing
it to focus on solution transfer rather than question recognition. Furthermore,
we extend this approach to cases where questions only share partial features or
hidden characteristics. This enables cross-question method reuse beyond
conventional similarity constraints. Experimental verification shows that our
scope-extension approach increases the probability of filtering out reusable
solutions, thereby improving the effectiveness of cross-question method reuse.

</details>


### [21] [Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian](https://arxiv.org/abs/2509.05668)
*Michael Hoffmann,Jophin John,Stefan Schweter,Gokul Ramakrishnan,Hoi-Fong Mak,Alice Zhang,Dmitry Gaynullin,Nicolay J. Hammer*

Main category: cs.CL

TL;DR: Llama-GENBA-10B是一个10B参数的三语基础模型，基于Llama 3.1-8B构建，针对英语、德语和巴伐利亚语进行持续预训练，旨在解决大语言模型中的英语中心偏见问题。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型中的英语中心偏见，为德语NLP社区提供支持，并促进低资源语言巴伐利亚语的发展。

Method: 在164B tokens（82B英语、82B德语、80M巴伐利亚语）上进行持续预训练，创建统一的分词器，优化架构和语言比例超参数，建立首个标准化三语评估套件。

Result: 模型在三语跨语言性能上表现强劲，微调版本在巴伐利亚语上超越Apertus-8B-2509和gemma-2-9b，成为该语言类别中的最佳模型，同时在英语上优于EuroLLM，在德语上与EuroLLM相当。

Conclusion: 该研究为整合低资源语言的包容性基础模型提供了蓝图，证明了大规模多语言预训练的效率，并记录了能源使用情况。

Abstract: We present Llama-GENBA-10B, a trilingual foundation model addressing
English-centric bias in large language models. Built on Llama 3.1-8B and scaled
to 10B parameters, Llama-GENBA-10B is continuously pretrained on 164B tokens
(82B English, 82B German, and 80M Bavarian), balancing resources while
preventing English dominance. Targeted at the German NLP community, the model
also promotes Bavarian as a low-resource language. Development tackled four
challenges: (1) curating a multilingual corpus despite Bavarian scarcity, (2)
creating a unified tokenizer for English, German, and Bavarian, (3) optimizing
architecture and language-ratio hyperparameters for cross-lingual transfer, and
(4) establishing the first standardized trilingual evaluation suite by
translating German benchmarks into Bavarian. Evaluations show that
Llama-GENBA-10B achieves strong cross-lingual performance, with the fine-tuned
variant surpassing Apertus-8B-2509 and gemma-2-9b in Bavarian and establishing
itself as the best model in its class for this language, while also
outperforming EuroLLM in English and matching its results in German. Training
on the Cerebras CS-2 demonstrated efficient large-scale multilingual
pretraining with documented energy use, offering a blueprint for inclusive
foundation models that integrate low-resource languages.

</details>


### [22] [Revealing the Numeracy Gap: An Empirical Investigation of Text Embedding Models](https://arxiv.org/abs/2509.05691)
*Ningyuan Deng,Hanyu Duan,Yixuan Tang,Yi Yang*

Main category: cs.CL

TL;DR: 嵌入模型在数值细节理解方面表现差强，尤其在金融领域的数值信息编码能力不足


<details>
  <summary>Details</summary>
Motivation: 当前嵌入模型的评测通常涉及不需要理解细微数值信息的任务，而在金融、医疗等领域中数值精确性至关重要

Method: 使用金融上下文的合成数据，评估13个广泛使用的文本嵌入模型的数值编码能力

Result: 模型普遍在准确捕捉数值细节方面表现差强，无法区分类似2%和20%这种重要数值差异

Conclusion: 当前嵌入模型在数值理解能力上存在显著缺陷，需要进一步研究提升模型的数值处理能力以支持更多应用领域

Abstract: Text embedding models are widely used in natural language processing
applications. However, their capability is often benchmarked on tasks that do
not require understanding nuanced numerical information in text. As a result,
it remains unclear whether current embedding models can precisely encode
numerical content, such as numbers, into embeddings. This question is critical
because embedding models are increasingly applied in domains where numbers
matter, such as finance and healthcare. For example, Company X's market share
grew by 2\% should be interpreted very differently from Company X's market
share grew by 20\%, even though both indicate growth in market share. This
study aims to examine whether text embedding models can capture such nuances.
Using synthetic data in a financial context, we evaluate 13 widely used text
embedding models and find that they generally struggle to capture numerical
details accurately. Our further analyses provide deeper insights into embedding
numeracy, informing future research to strengthen embedding model-based NLP
systems with improved capacity for handling numerical content.

</details>


### [23] [A Survey of the State-of-the-Art in Conversational Question Answering Systems](https://arxiv.org/abs/2509.05716)
*Manoj Madushanka Perera,Adnan Mahmood,Kasun Eranda Wijethilake,Fahmida Islam,Maryam Tahermazandarani,Quan Z. Sheng*

Main category: cs.CL

TL;DR: 这是一份关于对话式问答系统(ConvQA)的综述性论文，详细分析了该领域的现状、核心组件、先进技术和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 对话式问答系统在多个领域发挥着关键作用，需要维持语境相关和论述连贯性。本文通过综述形式提供对该领域最新进展的全面分析。

Method: 论文首先检视ConvQA系统的核心组件（历史选择、问题理解、答案预测），进而研究使用加强学习、对比学习、迁移学习等先进技术来提高系统性能。还分析了大语言模型的影响，并给出了主要的ConvQA数据集。

Result: 本文对对话式问答领域进行了全面的分析，为研究人员提供了完整的技术概览。通过研究核心组件、先进学习技术和大语言模型的应用，展示了该领域的发展趋势和成果。

Conclusion: 这份综述为对话式问答领域提供了丰富的视角和见解，指明了未来研究的方向，对推动该领域的进一步发展具有重要意义。

Abstract: Conversational Question Answering (ConvQA) systems have emerged as a pivotal
area within Natural Language Processing (NLP) by driving advancements that
enable machines to engage in dynamic and context-aware conversations. These
capabilities are increasingly being applied across various domains, i.e.,
customer support, education, legal, and healthcare where maintaining a coherent
and relevant conversation is essential. Building on recent advancements, this
survey provides a comprehensive analysis of the state-of-the-art in ConvQA.
This survey begins by examining the core components of ConvQA systems, i.e.,
history selection, question understanding, and answer prediction, highlighting
their interplay in ensuring coherence and relevance in multi-turn
conversations. It further investigates the use of advanced machine learning
techniques, including but not limited to, reinforcement learning, contrastive
learning, and transfer learning to improve ConvQA accuracy and efficiency. The
pivotal role of large language models, i.e., RoBERTa, GPT-4, Gemini 2.0 Flash,
Mistral 7B, and LLaMA 3, is also explored, thereby showcasing their impact
through data scalability and architectural advancements. Additionally, this
survey presents a comprehensive analysis of key ConvQA datasets and concludes
by outlining open research directions. Overall, this work offers a
comprehensive overview of the ConvQA landscape and provides valuable insights
to guide future advancements in the field.

</details>


### [24] [Exploring Subjective Tasks in Farsi: A Survey Analysis and Evaluation of Language Models](https://arxiv.org/abs/2509.05719)
*Donya Rooein,Flor Miriam Plaza-del-Arco,Debora Nozza,Dirk Hovy*

Main category: cs.CL

TL;DR: 这篇论文对法尔语在主观性NLP任务中的真实资源状况进行了批判性分析，发现虽然数字文本数量明上增长，但数据集质量、公开性和人口统计信息的缺乏仍使得法尔语在情感分析、情绪分析和毒性检测任务中面临重大挑战，模型预测结果极不稳定。


<details>
  <summary>Details</summary>
Motivation: 虽然法尔语在官方数据上被归类为"中等资源语言"（8过127亿使用者，维基百科超130万篇文章），但研究者认为这种分类并不能准确反映语言在NLP主观性任务中的真实资源状况。

Method: 研究对110篇关于法尔语主观性任务的公开出版物进行了系统评估，重点分析了情感分析、情绪分析和毒性检测三个关键领域的数据集可用性、质量和人口统计信息完整性。

Result: 研究发现：1）公开可用数据集极其缺乏；2）现有数据集缺少关键人口统计因素（如年龄、性别），这些因素对准确建模语言主观性至关重要；3）使用少量可用数据集评估预测模型时，结果在不同数据集和模型间显示出极大的不稳定性。

Conclusion: 线上文本数据的纯量增长不能有效改善语言在NLP领域的发展前景。语言资源的评估应考虑数据质量、公开性、以及包含人口统计信息的完整性，而不仅仅是数据量的表面数字。

Abstract: Given Farsi's speaker base of over 127 million people and the growing
availability of digital text, including more than 1.3 million articles on
Wikipedia, it is considered a middle-resource language. However, this label
quickly crumbles when the situation is examined more closely. We focus on three
subjective tasks (Sentiment Analysis, Emotion Analysis, and Toxicity Detection)
and find significant challenges in data availability and quality, despite the
overall increase in data availability. We review 110 publications on subjective
tasks in Farsi and observe a lack of publicly available datasets. Furthermore,
existing datasets often lack essential demographic factors, such as age and
gender, that are crucial for accurately modeling subjectivity in language. When
evaluating prediction models using the few available datasets, the results are
highly unstable across both datasets and models. Our findings indicate that the
volume of data is insufficient to significantly improve a language's prospects
in NLP.

</details>


### [25] [QCSE: A Pretrained Quantum Context-Sensitive Word Embedding for Natural Language Processing](https://arxiv.org/abs/2509.05729)
*Charles M. Varmantchaonala,Niclas GÖtting,Nils-Erik SchÜtte,Jean Louis E. K. Fendji,Christopher Gies*

Main category: cs.CL

TL;DR: 量子自然语言处理模型QCSE，通过5种上下文矩阵计算方法实现上下文敏感的量子词嵌入，在Fulani和英语语料上验证了量子系统在NLP中的表达能力和对低资源语言的潜力。


<details>
  <summary>Details</summary>
Motivation: 利用量子计算的独特性质来编码和理解自然语言的复杂性，解决传统NLP在上下文敏感性和语言资源不均衡方面的挑战。

Method: 提出QCSE预训练量子上下文敏感嵌入模型，采用5种创新的上下文矩阵计算方法（指数衰减、正弦调制、相位移、哈希变换等）来创建基于语境的词表示。

Result: 模型成功捕捆了上下文敏感性，并利用量子系统的表达能力来表示丰富的语境信息。在Fulani（低资源非洲语言）和英语语料上都取得了良好效果。

Conclusion: 这项工作展示了量子计算在NLP中的强大潜力，为应对真实世界语言挑战开启了新途径，尤其是在处理低资源语言方面。

Abstract: Quantum Natural Language Processing (QNLP) offers a novel approach to
encoding and understanding the complexity of natural languages through the
power of quantum computation. This paper presents a pretrained quantum
context-sensitive embedding model, called QCSE, that captures context-sensitive
word embeddings, leveraging the unique properties of quantum systems to learn
contextual relationships in languages. The model introduces quantum-native
context learning, enabling the utilization of quantum computers for linguistic
tasks. Central to the proposed approach are innovative context matrix
computation methods, designed to create unique, representations of words based
on their surrounding linguistic context. Five distinct methods are proposed and
tested for computing the context matrices, incorporating techniques such as
exponential decay, sinusoidal modulation, phase shifts, and hash-based
transformations. These methods ensure that the quantum embeddings retain
context sensitivity, thereby making them suitable for downstream language tasks
where the expressibility and properties of quantum systems are valuable
resources. To evaluate the effectiveness of the model and the associated
context matrix methods, evaluations are conducted on both a Fulani corpus, a
low-resource African language, dataset of small size and an English corpus of
slightly larger size. The results demonstrate that QCSE not only captures
context sensitivity but also leverages the expressibility of quantum systems
for representing rich, context-aware language information. The use of Fulani
further highlights the potential of QNLP to mitigate the problem of lack of
data for this category of languages. This work underscores the power of quantum
computation in natural language processing (NLP) and opens new avenues for
applying QNLP to real-world linguistic challenges across various tasks and
domains.

</details>


### [26] [Enhancing Factual Accuracy and Citation Generation in LLMs via Multi-Stage Self-Verification](https://arxiv.org/abs/2509.05741)
*Fernando Gabriela García,Qiyang Shi,Zilin Feng*

Main category: cs.CL

TL;DR: VeriFact-CoT是一种新颖的方法，通过事实验证-反思-引用整合的多阶段机制，解决LLMs在生成复杂事实敏感内容时的幻觉和缺乏可信引用源问题。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在生成复杂事实敏感内容时普遍存在的幻觉问题和缺乏可信引用源的问题，提高生成内容的客观准确性、可信度和可追溯性。

Method: 采用多阶段的'事实验证-反思-引用整合'机制，使LLMs能够批判性地自我检查和修订其中间推理步骤和最终答案。

Result: 显著提高了生成输出的客观准确性、可信度和可追溯性，使LLMs在需要高保真度的应用中更加可靠。

Conclusion: VeriFact-CoT方法有效增强了LLMs在科学研究、新闻报道和法律咨询等高要求应用中的可靠性，通过自我验证和引用整合机制解决了幻觉和可信度问题。

Abstract: This research introduces VeriFact-CoT (Verified Factual Chain-of-Thought), a
novel method designed to address the pervasive issues of hallucination and the
absence of credible citation sources in Large Language Models (LLMs) when
generating complex, fact-sensitive content. By incorporating a multi-stage
mechanism of 'fact verification-reflection-citation integration,' VeriFact-CoT
empowers LLMs to critically self-examine and revise their intermediate
reasoning steps and final answers. This process significantly enhances the
objective accuracy, trustworthiness, and traceability of the generated outputs,
making LLMs more reliable for applications demanding high fidelity such as
scientific research, news reporting, and legal consultation.

</details>


### [27] [LatinX: Aligning a Multilingual TTS Model with Direct Preference Optimization](https://arxiv.org/abs/2509.05863)
*Luis Felipe Chary,Miguel Arjona Ramirez*

Main category: cs.CL

TL;DR: LatinX是一个多语言文本转语音模型，用于级联语音翻译，能够在跨语言时保持源说话人身份。该模型采用三阶段训练方法，包括预训练、监督微调和DPO对齐，在英语和罗曼语系语言上表现优异。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在跨语言语音翻译中保持说话人身份的多语言TTS模型，解决现有系统在说话人相似性保持方面的不足。

Method: 使用12层仅解码器Transformer架构，分三阶段训练：文本到音频映射预训练、零样本语音克隆监督微调、基于WER和说话人相似性指标的DPO对齐。

Result: LatinX模型在DPO训练后持续降低词错误率(WER)并改善客观相似性指标。人工评估显示其感知说话人相似性优于强基线XTTSv2，但揭示了客观与主观测量之间的差距。

Conclusion: LatinX在多语言语音翻译中有效保持说话人身份，未来工作需要平衡偏好信号和开发低延迟架构。

Abstract: We present LatinX, a multilingual text-to-speech (TTS) model for cascaded
speech-to-speech translation that preserves the source speaker's identity
across languages. LatinX is a 12-layer decoder-only Transformer trained in
three stages: (i) pre-training for text-to-audio mapping, (ii) supervised
fine-tuning for zero-shot voice cloning, and (iii) alignment with Direct
Preference Optimization (DPO) using automatically labeled pairs based on Word
Error Rate (WER) and speaker-similarity metrics. Trained on English and Romance
languages with emphasis on Portuguese, LatinX with DPO consistently reduces WER
and improves objective similarity over the fine-tuned baseline. Human
evaluations further indicate stronger perceived speaker similarity than a
strong baseline (XTTSv2), revealing gaps between objective and subjective
measures. We provide cross-lingual analyses and discuss balanced preference
signals and lower-latency architectures as future work.

</details>


### [28] [ZhiFangDanTai: Fine-tuning Graph-based Retrieval-Augmented Generation Model for Traditional Chinese Medicine Formula](https://arxiv.org/abs/2509.05867)
*ZiXuan Zhang,Bowen Hao,Yingjie Li,Hongzhi Yin*

Main category: cs.CL

TL;DR: 提出了ZhiFangDanTai框架，结合图检索增强生成(GraphRAG)和LLM微调技术，用于生成更全面的中医方剂解释，包括君臣佐使、功效、禁忌等详细信息。


<details>
  <summary>Details</summary>
Motivation: 现有中医方剂模型缺乏全面的分析结果，如完整的方剂组成和详细解释。现有数据集缺乏足够细节信息，限制了模型输出的深度。

Method: 结合GraphRAG检索结构化中医知识并合成简洁摘要，同时构建增强的指令数据集来提高LLM整合检索信息的能力。提供了理论证明显示该方法能减少泛化误差和幻觉率。

Result: 在收集数据集和临床数据集上的实验结果表明，ZhiFangDanTai相比最先进模型取得了显著改进。

Conclusion: 提出的框架有效解决了中医方剂分析中信息不全面的问题，通过知识检索和模型微调的结合提高了生成质量，模型已开源。

Abstract: Traditional Chinese Medicine (TCM) formulas play a significant role in
treating epidemics and complex diseases. Existing models for TCM utilize
traditional algorithms or deep learning techniques to analyze formula
relationships, yet lack comprehensive results, such as complete formula
compositions and detailed explanations. Although recent efforts have used TCM
instruction datasets to fine-tune Large Language Models (LLMs) for explainable
formula generation, existing datasets lack sufficient details, such as the
roles of the formula's sovereign, minister, assistant, courier; efficacy;
contraindications; tongue and pulse diagnosis-limiting the depth of model
outputs. To address these challenges, we propose ZhiFangDanTai, a framework
combining Graph-based Retrieval-Augmented Generation (GraphRAG) with LLM
fine-tuning. ZhiFangDanTai uses GraphRAG to retrieve and synthesize structured
TCM knowledge into concise summaries, while also constructing an enhanced
instruction dataset to improve LLMs' ability to integrate retrieved
information. Furthermore, we provide novel theoretical proofs demonstrating
that integrating GraphRAG with fine-tuning techniques can reduce generalization
error and hallucination rates in the TCM formula task. Experimental results on
both collected and clinical datasets demonstrate that ZhiFangDanTai achieves
significant improvements over state-of-the-art models. Our model is
open-sourced at https://huggingface.co/tczzx6/ZhiFangDanTai1.0.

</details>


### [29] [MedFactEval and MedAgentBrief: A Framework and Workflow for Generating and Evaluating Factual Clinical Summaries](https://arxiv.org/abs/2509.05878)
*François Grolleau,Emily Alsentzer,Timothy Keyes,Philip Chung,Akshay Swaminathan,Asad Aali,Jason Hom,Tridu Huynh,Thomas Lew,April S. Liang,Weihan Chu,Natasha Z. Steele,Christina F. Lin,Jingkun Yang,Kameron C. Black,Stephen P. Ma,Fateme N. Haredasht,Nigam H. Shah,Kevin Schulman,Jonathan H. Chen*

Main category: cs.CL

TL;DR: MedFactEval框架通过LLM陪审团评估临床文本事实准确性，MedAgentBrief工作流生成高质量出院摘要，两者结合为临床AI部署提供全面解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成临床文本事实准确性评估的规模化问题，专家评审无法满足持续质量保证的需求。

Method: MedFactEval框架：临床医生定义关键事实，LLM陪审团多模型多数投票评估；MedAgentBrief：模型无关的多步骤工作流生成出院摘要。

Result: LLM陪审团与7名医生专家组达成几乎完美一致（Cohen's kappa=81%），统计上不劣于单个专家（kappa=67%，P<0.001）。

Conclusion: 提供了稳健的评估框架和高性能生成工作流，推动生成式AI在临床工作流中的负责任部署。

Abstract: Evaluating factual accuracy in Large Language Model (LLM)-generated clinical
text is a critical barrier to adoption, as expert review is unscalable for the
continuous quality assurance these systems require. We address this challenge
with two complementary contributions. First, we introduce MedFactEval, a
framework for scalable, fact-grounded evaluation where clinicians define
high-salience key facts and an "LLM Jury"--a multi-LLM majority vote--assesses
their inclusion in generated summaries. Second, we present MedAgentBrief, a
model-agnostic, multi-step workflow designed to generate high-quality, factual
discharge summaries. To validate our evaluation framework, we established a
gold-standard reference using a seven-physician majority vote on
clinician-defined key facts from inpatient cases. The MedFactEval LLM Jury
achieved almost perfect agreement with this panel (Cohen's kappa=81%), a
performance statistically non-inferior to that of a single human expert
(kappa=67%, P < 0.001). Our work provides both a robust evaluation framework
(MedFactEval) and a high-performing generation workflow (MedAgentBrief),
offering a comprehensive approach to advance the responsible deployment of
generative AI in clinical workflows.

</details>


### [30] [Let's Roleplay: Examining LLM Alignment in Collaborative Dialogues](https://arxiv.org/abs/2509.05882)
*Abhijnan Nath,Carine Graff,Nikhil Krishnaswamy*

Main category: cs.CL

TL;DR: 本文研究不同对齐方法对LLM代理在多轮多方协作中作为合作伙伴的有效性影响，提出了摩擦代理干预机制和反事实评估框架，发现摩擦感知方法在促进共识达成和任务正确性方面显著优于常见对齐基线。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型成为人类协作伙伴，需要确保其在多轮交互中的行为可预测且可靠。现有对齐技术主要针对单用户场景，无法适应长期多方交互的动态特性。

Method: 使用角色扮演方法评估不同训练方式的摩擦代理在协作任务对话中的干预效果，提出反事实评估框架量化摩擦干预对群体协作轨迹和信念对齐的影响。

Result: 摩擦感知方法在帮助群体达成共识（共同认可的任务相关命题）和任务结果正确性方面显著优于常见对齐基线方法。

Conclusion: 针对多轮多方协作场景设计的专门对齐方法比通用对齐技术更有效，摩擦代理干预机制能够有效促进群体审议决策和共识形成。

Abstract: As Large Language Models (LLMs) integrate into diverse workflows, they are
increasingly being considered "collaborators" with humans. If such AI
collaborators are to be reliable, their behavior over multiturn interactions
must be predictable, validated and verified before deployment. Common alignment
techniques are typically developed under simplified single-user settings and do
not account for the dynamics of long-horizon multiparty interactions. This
paper examines how different alignment methods affect LLM agents' effectiveness
as partners in multiturn, multiparty collaborations. We study this question
through the lens of friction agents that intervene in group dialogues to
encourage the collaborative group to slow down and reflect upon their reasoning
for deliberative decision-making. Using a roleplay methodology, we evaluate
interventions from differently-trained friction agents in collaborative task
conversations. We propose a novel counterfactual evaluation framework that
quantifies how friction interventions change the trajectory of group
collaboration and belief alignment. Our results show that a friction-aware
approach significantly outperforms common alignment baselines in helping both
convergence to a common ground, or agreed-upon task-relevant propositions, and
correctness of task outcomes.

</details>


### [31] [Accelerating Large Language Model Inference via Early-Exiting Algorithms](https://arxiv.org/abs/2509.05915)
*Sangmin Bae*

Main category: cs.CL

TL;DR: 这篇论文通过算法与架构的协同设计，解决了大语言模型中适应性计算与系统效率的冲突，实现了效率与性能的最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 大语言模型部署面临高计算成本，早期退出等适应性计算方法虽能节省计算，但在批处理推理中反而导致系统瓶颈，影响吞吐量。

Method: 1）提出高效并行解码机制减少过默计算开销
2）采用深度参数共享架构减缓同步问题
3）开发统一框架，通过轻量路由器动态分配最佳递归深度

Result: 建立了效率与性能的新帕紅托前沿，在单个模型内同时优化了适应性计算和参数效率。

Conclusion: 通过算法与架构的协同设计，成功解决了动态推理中的效率瓶颈，为大语言模型的高效部署提供了可行方案。

Abstract: Large language models have achieved remarkable capabilities, but their
practical deployment is hindered by significant computational costs. While
adaptive computation methods like early-exiting promise to reduce these costs,
they introduce a fundamental conflict: the per-token dynamism intended to save
computation often creates system-level bottlenecks that can paradoxically
reduce throughput in batched inference. This dissertation resolves this
conflict by co-designing adaptive algorithms and model architectures to strike
an optimal balance between dynamism and efficiency. To this end, our work first
addresses critical sources of overhead in conventional early-exiting by
proposing an efficient parallel decoding mechanism. We then show that deep
parameter sharing provides an architectural foundation that not only yields
compact, parameter-efficient models but also inherently mitigates the critical
synchronization issues affecting dynamic inference. Finally, this work presents
a unified framework where lightweight routers are pretrained to dynamically
assign an optimal recursion depth for each token. This approach establishes a
new Pareto frontier between efficiency and performance by effectively
optimizing for both adaptive computation and parameter efficiency within a
single model.

</details>


### [32] [KatotohananQA: Evaluating Truthfulness of Large Language Models in Filipino](https://arxiv.org/abs/2509.06065)
*Lorenzo Alfred Nery,Ronald Dawson Catignas,Thomas James Tiam-Lee*

Main category: cs.CL

TL;DR: KatotohananQA是TruthfulQA基准的菲律宾语翻译版本，用于评估大语言模型在低资源语言中的真实性表现。研究发现英语和菲律宾语之间存在显著性能差距，新型OpenAI模型在多语言鲁棒性方面表现较好，但不同问题类型存在差异。


<details>
  <summary>Details</summary>
Motivation: 当前LLM真实性基准主要针对英语，缺乏对低资源语言的评估，这限制了LLM在多语言环境中的可靠应用。

Method: 将TruthfulQA基准翻译成菲律宾语(KatotohananQA)，使用二元选择框架评估7个免费专有模型，比较英语和菲律宾语版本的表现。

Result: 发现英语和菲律宾语真实性存在显著性能差距；新型OpenAI模型(GPT-5和GPT-5 mini)展现较强的多语言鲁棒性；不同问题类型、类别和主题在多语言迁移中的鲁棒性存在差异。

Conclusion: 需要进行更广泛的多语言评估以确保LLM使用的公平性和可靠性，某些问题类型在多语言转换中表现较弱，需要特别关注。

Abstract: Large Language Models (LLMs) achieve remarkable performance across various
tasks, but their tendency to produce hallucinations limits reliable adoption.
Benchmarks such as TruthfulQA have been developed to measure truthfulness, yet
they are primarily available in English, leaving a gap in evaluating LLMs in
low-resource languages. To address this, we present KatotohananQA, a Filipino
translation of the TruthfulQA benchmark. Seven free-tier proprietary models
were assessed using a binary-choice framework. Findings show a significant
performance gap between English and Filipino truthfulness, with newer OpenAI
models (GPT-5 and GPT-5 mini) demonstrating strong multilingual robustness.
Results also reveal disparities across question characteristics, suggesting
that some question types, categories, and topics are less robust to
multilingual transfer which highlight the need for broader multilingual
evaluation to ensure fairness and reliability in LLM usage.

</details>


### [33] [Multimodal Fine-grained Context Interaction Graph Modeling for Conversational Speech Synthesis](https://arxiv.org/abs/2509.06074)
*Zhenqi Jia,Rui Liu,Berrak Sisman,Haizhou Li*

Main category: cs.CL

TL;DR: 提出MFCIG-CSS系统，通过构建多模态细粒度对话交互图来提升对话语音合成的韵律自然性


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了多模态对话历史中细粒度的语义和韵律交互建模，而这些信息对于生成自然韵律的对话语音至关重要

Method: 构建两个专门的多模态细粒度对话交互图：语义交互图和韵律交互图，编码词级语义、韵律及其对后续话语影响的交互特征

Result: 在DailyTalk数据集上的实验表明，MFCIG-CSS在韵律表现力方面优于所有基线模型

Conclusion: 提出的多模态细粒度上下文交互图方法能有效提升对话语音合成的韵律自然性，证明了细粒度交互建模的重要性

Abstract: Conversational Speech Synthesis (CSS) aims to generate speech with natural
prosody by understanding the multimodal dialogue history (MDH). The latest work
predicts the accurate prosody expression of the target utterance by modeling
the utterance-level interaction characteristics of MDH and the target
utterance. However, MDH contains fine-grained semantic and prosody knowledge at
the word level. Existing methods overlook the fine-grained semantic and
prosodic interaction modeling. To address this gap, we propose MFCIG-CSS, a
novel Multimodal Fine-grained Context Interaction Graph-based CSS system. Our
approach constructs two specialized multimodal fine-grained dialogue
interaction graphs: a semantic interaction graph and a prosody interaction
graph. These two interaction graphs effectively encode interactions between
word-level semantics, prosody, and their influence on subsequent utterances in
MDH. The encoded interaction features are then leveraged to enhance synthesized
speech with natural conversational prosody. Experiments on the DailyTalk
dataset demonstrate that MFCIG-CSS outperforms all baseline models in terms of
prosodic expressiveness. Code and speech samples are available at
https://github.com/AI-S2-Lab/MFCIG-CSS.

</details>


### [34] [Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge](https://arxiv.org/abs/2509.06079)
*Hao Liang,Ruitao Wu,Bohan Zeng,Junbo Niu,Wentao Zhang,Bin Dong*

Main category: cs.CL

TL;DR: 提出了一种caption辅助的多模态推理框架，在ICML 2025 AI for Math Workshop挑战赛中获第一名，并在MathVerse几何推理基准上验证了泛化能力


<details>
  <summary>Details</summary>
Motivation: 解决多模态推理的挑战，弥补文本推理模型在视觉-文本多模态场景中的性能差距

Method: caption辅助的推理框架，有效桥接视觉和文本模态

Result: 在SeePhys挑战赛中获第一名，在MathVerse几何推理基准上表现出良好的泛化性能

Conclusion: 该方法在多模态推理任务中表现出有效性和鲁棒性，具有很好的泛化能力

Abstract: Multimodal reasoning remains a fundamental challenge in artificial
intelligence. Despite substantial advances in text-based reasoning, even
state-of-the-art models such as GPT-o3 struggle to maintain strong performance
in multimodal scenarios. To address this gap, we introduce a caption-assisted
reasoning framework that effectively bridges visual and textual modalities. Our
approach achieved 1st place in the ICML 2025 AI for Math Workshop \& Challenge
2: SeePhys, highlighting its effectiveness and robustness. Furthermore, we
validate its generalization on the MathVerse benchmark for geometric reasoning,
demonstrating the versatility of our method. Our code is publicly available at
https://github.com/OpenDCAI/SciReasoner.

</details>


### [35] [Orthogonal Low-rank Adaptation in Lie Groups for Continual Learning of Large Language Models](https://arxiv.org/abs/2509.06100)
*Kefan Cao,Shuaicheng Wu*

Main category: cs.CL

TL;DR: OLieRA是一种新的LLM连续学习方法，通过李群理论和乘法更新来保持参数几何结构，同时在任务子空间应用正交约束，解决了传统方法破坏参数几何结构的问题。


<details>
  <summary>Details</summary>
Motivation: 现有参数正则化方法（如O-LoRA和N-LoRA）虽然通过强制低秩子空间正交性来缓解任务干扰，但忽视了传统加性微调会破坏LLM参数固有几何结构的问题，限制了性能。

Method: 提出OLieRA方法，引入李群理论到LLM微调中：利用乘法更新来保持参数几何结构，同时对任务子空间应用正交约束。

Result: 实验表明OLieRA在标准连续学习基准上达到最先进结果，在大量任务设置中保持顶级性能。

Conclusion: 保持参数几何结构对于LLM连续学习至关重要，OLieRA通过结合李群理论和正交约束，有效缓解了灾难性遗忘问题。

Abstract: Large language models (LLMs) are prone to catastrophic forgetting in
sequential multi-task settings. Parameter regularization methods such as O-LoRA
and N-LoRA alleviate task interference by enforcing low-rank subspace
orthogonality, but they overlook the fact that conventional additive
fine-tuning disrupts the intrinsic geometric structure of LLM parameters,
limiting performance. Our key insight is that the parameter space of LLMs
possesses a geometric structure, which must be preserved in addition to
enforcing orthogonality. Based on this, we propose Orthogonal Low-rank
Adaptation in Lie Groups (OLieRA), which introduces Lie group theory into LLM
fine-tuning: leveraging multiplicative updates to preserve parameter geometry
while applying orthogonality constraints to task subspaces. Experiments
demonstrate that OLieRA achieves state-of-the-art results on the Standard CL
benchmark and remains among the top-performing methods in the Large Number of
Tasks setting.

</details>


### [36] [Benchmarking Gender and Political Bias in Large Language Models](https://arxiv.org/abs/2509.06164)
*Jinrui Yang,Xudong Han,Timothy Baldwin*

Main category: cs.CL

TL;DR: EuroParlVote是一个用于评估大语言模型在政治敏感语境中表现的新基准，包含欧洲议会辩论演讲与投票结果的关联数据，揭示了LLMs在性别分类和投票预测任务中存在的系统性偏见。


<details>
  <summary>Details</summary>
Motivation: 为了评估大语言模型在政治敏感环境中的表现，特别是在涉及性别、政治立场等敏感属性时的偏见问题，需要建立一个专门的数据集和评估框架。

Method: 构建EuroParlVote数据集，包含欧洲议会辩论演讲、投票结果和议员人口统计信息，并在两个任务上评估最先进的LLMs：性别分类和投票预测。

Result: 发现LLMs经常将女性议员错误分类为男性，在模拟女性演讲者投票时准确率降低；政治立场上偏向中间派，在极左和极右团体上表现较差；GPT-4o等专有模型在鲁棒性和公平性方面优于开源模型。

Conclusion: LLMs在政治敏感语境中存在系统性偏见，需要更多研究来确保NLP技术在政治环境中的公平性和问责制，EuroParlVote数据集为此类研究提供了支持。

Abstract: We introduce EuroParlVote, a novel benchmark for evaluating large language
models (LLMs) in politically sensitive contexts. It links European Parliament
debate speeches to roll-call vote outcomes and includes rich demographic
metadata for each Member of the European Parliament (MEP), such as gender, age,
country, and political group. Using EuroParlVote, we evaluate state-of-the-art
LLMs on two tasks -- gender classification and vote prediction -- revealing
consistent patterns of bias. We find that LLMs frequently misclassify female
MEPs as male and demonstrate reduced accuracy when simulating votes for female
speakers. Politically, LLMs tend to favor centrist groups while underperforming
on both far-left and far-right ones. Proprietary models like GPT-4o outperform
open-weight alternatives in terms of both robustness and fairness. We release
the EuroParlVote dataset, code, and demo to support future research on fairness
and accountability in NLP within political contexts.

</details>


### [37] [Understanding the Influence of Synthetic Data for Text Embedders](https://arxiv.org/abs/2509.06184)
*Jacob Mitchell Springer,Vaibhav Adlakha,Siva Reddy,Aditi Raghunathan,Marius Mosbach*

Main category: cs.CL

TL;DR: 本文研究了合成数据在文本嵌入模型中的作用，发现合成数据的改善效果局限且存在任务间的交易下降。


<details>
  <summary>Details</summary>
Motivation: 当前通用文本嵌入器的发展依靠大量合成数据训练，但缺乏公开的合成数据集阻碍了对其演化机制的研究。

Method: 首先重现并公开采用Wang等人的Mistral-E5合成数据集，然后系统分析合成数据在不同任务上的演化效果。

Result: 合成数据能够一致提升性能，但改善效果很局限且仅在特定数据集上显现，同时存在任务间的性能交易下降。

Conclusion: 当前的合成数据方法在构建通用嵌入器方面存在局限性，训练合成数据并不能弥补任务间的性能差异。

Abstract: Recent progress in developing general purpose text embedders has been driven
by training on ever-growing corpora of synthetic LLM-generated data.
Nonetheless, no publicly available synthetic dataset exists, posing a barrier
to studying its role for generalization. To address this issue, we first
reproduce and publicly release the synthetic data proposed by Wang et al.
(Mistral-E5). Our synthetic data is high quality and leads to consistent
improvements in performance. Next, we critically examine where exactly
synthetic data improves model generalization. Our analysis reveals that
benefits from synthetic data are sparse and highly localized to individual
datasets. Moreover, we observe trade-offs between the performance on different
categories and data that benefits one task, degrades performance on another.
Our findings highlight the limitations of current synthetic data approaches for
building general-purpose embedders and challenge the notion that training on
synthetic data leads to more robust embedding models across tasks.

</details>


### [38] [Augmented Fine-Tuned LLMs for Enhanced Recruitment Automation](https://arxiv.org/abs/2509.06196)
*Mohamed T. Younes,Omar Walid,Khaled Shaban,Ali Hamdi,Mai Hassan*

Main category: cs.CL

TL;DR: 本文提出了一种基于精调大语言模型的新题招聘自动化方法，通过合成数据集和结构化JSON格式提高了招聘任务的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决通用大语言模型在招聘任务中的局限性，提高合胜者与职位的匹配准确度，以改善招聘工作流程。

Method: 使用合成数据集和DeepSeek解析的简历数据，都转换为标准化JSON格式，对LLMs进行专门为招聘任务设计的精调训练。

Result: 精调后的Phi-4模型在F1分数上达到90.62%，在准确匹配、F1分数、BLEU分数、ROUGE分数和整体相似度等指标上显著超越基础模型和其他最先进LLMs。

Conclusion: 研究证明了精调LLMs在招聘自动化中的强大潜力，能够通过提供更准确的合胜者-职位匹配来革命招聘工作流程。

Abstract: This paper presents a novel approach to recruitment automation. Large
Language Models (LLMs) were fine-tuned to improve accuracy and efficiency.
Building upon our previous work on the Multilayer Large Language Model-Based
Robotic Process Automation Applicant Tracking (MLAR) system . This work
introduces a novel methodology. Training fine-tuned LLMs specifically tuned for
recruitment tasks. The proposed framework addresses the limitations of generic
LLMs by creating a synthetic dataset that uses a standardized JSON format. This
helps ensure consistency and scalability. In addition to the synthetic data
set, the resumes were parsed using DeepSeek, a high-parameter LLM. The resumes
were parsed into the same structured JSON format and placed in the training
set. This will help improve data diversity and realism. Through
experimentation, we demonstrate significant improvements in performance
metrics, such as exact match, F1 score, BLEU score, ROUGE score, and overall
similarity compared to base models and other state-of-the-art LLMs. In
particular, the fine-tuned Phi-4 model achieved the highest F1 score of 90.62%,
indicating exceptional precision and recall in recruitment tasks. This study
highlights the potential of fine-tuned LLMs. Furthermore, it will revolutionize
recruitment workflows by providing more accurate candidate-job matching.

</details>


### [39] [MSLEF: Multi-Segment LLM Ensemble Finetuning in Recruitment](https://arxiv.org/abs/2509.06200)
*Omar Walid,Mohamed T. Younes,Khaled Shaban,Mai Hassan,Ali Hamdi*

Main category: cs.CL

TL;DR: MSLEF是一个多段集成框架，通过LLM微调提升简历解析性能，采用加权投票集成多个专门处理不同简历段的模型，显著优于单模型系统


<details>
  <summary>Details</summary>
Motivation: 解决招聘自动化中简历解析的准确性问题，克服单模型系统在处理多样化简历格式和结构时的局限性

Method: 采用分段感知架构，集成多个微调LLM（Gemma 9B、LLaMA 3.1 8B、Phi-4 14B），使用加权投票机制，Gemini-2.5-Flash作为复杂段的高级聚合器

Result: 在Exact Match、F1 score、BLEU、ROUGE和Recruitment Similarity等指标上显著提升，比最佳单模型在RS指标上高出+7%

Conclusion: MSLEF的分段感知设计增强了跨不同简历布局的泛化能力，使其高度适应真实招聘场景，确保精确可靠的候选人表示

Abstract: This paper presents MSLEF, a multi-segment ensemble framework that employs
LLM fine-tuning to enhance resume parsing in recruitment automation. It
integrates fine-tuned Large Language Models (LLMs) using weighted voting, with
each model specializing in a specific resume segment to boost accuracy.
Building on MLAR , MSLEF introduces a segment-aware architecture that leverages
field-specific weighting tailored to each resume part, effectively overcoming
the limitations of single-model systems by adapting to diverse formats and
structures. The framework incorporates Gemini-2.5-Flash LLM as a high-level
aggregator for complex sections and utilizes Gemma 9B, LLaMA 3.1 8B, and Phi-4
14B. MSLEF achieves significant improvements in Exact Match (EM), F1 score,
BLEU, ROUGE, and Recruitment Similarity (RS) metrics, outperforming the best
single model by up to +7% in RS. Its segment-aware design enhances
generalization across varied resume layouts, making it highly adaptable to
real-world hiring scenarios while ensuring precise and reliable candidate
representation.

</details>


### [40] [No Encore: Unlearning as Opt-Out in Music Generation](https://arxiv.org/abs/2509.06277)
*Jinju Kim,Taehan Kim,Abdul Waheed,Rita Singh*

Main category: cs.CL

TL;DR: 本文探讨了在文本到音乐生成模型中应用机器遗忘技术，以防止无意中使用受版权保护的内容，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: AI音乐生成系统存在利用受版权创作的风险，引发伦理和法律担忧，需要防止无意中使用创意内容。

Method: 将现有的机器遗忘方法应用于预训练的文本到音乐基线模型，分析其在遗忘预训练数据集方面的有效性。

Result: 提供了关于在音乐生成中应用遗忘技术挑战的初步见解，为未来研究奠定基础。

Conclusion: 机器遗忘技术在音乐生成模型中具有应用潜力，但需要进一步研究来解决相关挑战。

Abstract: AI music generation is rapidly emerging in the creative industries, enabling
intuitive music generation from textual descriptions. However, these systems
pose risks in exploitation of copyrighted creations, raising ethical and legal
concerns. In this paper, we present preliminary results on the first
application of machine unlearning techniques from an ongoing research to
prevent inadvertent usage of creative content. Particularly, we explore
existing methods in machine unlearning to a pre-trained Text-to-Music (TTM)
baseline and analyze their efficacy in unlearning pre-trained datasets without
harming model performance. Through our experiments, we provide insights into
the challenges of applying unlearning in music generation, offering a
foundational analysis for future works on the application of unlearning for
music generative models.

</details>


### [41] [Mask-GCG: Are All Tokens in Adversarial Suffixes Necessary for Jailbreak Attacks?](https://arxiv.org/abs/2509.06350)
*Junjie Mu,Zonghao Ying,Zhekui Fan,Zonglei Jing,Yaoyuan Zhang,Zhengmin Yu,Wenxin Zhang,Quanchen Zou,Xiangzheng Zhang*

Main category: cs.CL

TL;DR: Mask-GCG是一种针对大型语言模型越狱攻击的改进方法，通过可学习的token掩码机制识别后缀中高影响力token，修剪低影响力token来减少冗余和计算开销，同时保持攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的GCG越狱攻击方法使用固定长度的后缀，但其中可能存在冗余token未被探索，导致计算效率低下。

Method: 提出Mask-GCG方法，使用可学习的token掩码来识别后缀中高影响力token位置，增加这些位置的更新概率，同时修剪低影响力token，减少梯度空间大小。

Result: 实验表明后缀中大多数token对攻击成功有重要贡献，修剪少量低影响力token不会影响损失值或攻击成功率，揭示了LLM提示中的token冗余现象。

Conclusion: 该方法为从越狱攻击角度开发高效和可解释的LLM提供了见解，能够降低计算开销并缩短成功攻击时间。

Abstract: Jailbreak attacks on Large Language Models (LLMs) have demonstrated various
successful methods whereby attackers manipulate models into generating harmful
responses that they are designed to avoid. Among these, Greedy Coordinate
Gradient (GCG) has emerged as a general and effective approach that optimizes
the tokens in a suffix to generate jailbreakable prompts. While several
improved variants of GCG have been proposed, they all rely on fixed-length
suffixes. However, the potential redundancy within these suffixes remains
unexplored. In this work, we propose Mask-GCG, a plug-and-play method that
employs learnable token masking to identify impactful tokens within the suffix.
Our approach increases the update probability for tokens at high-impact
positions while pruning those at low-impact positions. This pruning not only
reduces redundancy but also decreases the size of the gradient space, thereby
lowering computational overhead and shortening the time required to achieve
successful attacks compared to GCG. We evaluate Mask-GCG by applying it to the
original GCG and several improved variants. Experimental results show that most
tokens in the suffix contribute significantly to attack success, and pruning a
minority of low-impact tokens does not affect the loss values or compromise the
attack success rate (ASR), thereby revealing token redundancy in LLM prompts.
Our findings provide insights for developing efficient and interpretable LLMs
from the perspective of jailbreak attacks.

</details>


### [42] [PL-CA: A Parametric Legal Case Augmentation Framework](https://arxiv.org/abs/2509.06356)
*Ao Chang,Yubo Chen,Jun Zhao*

Main category: cs.CL

TL;DR: PL-CA提出参数化RAG框架，将法律知识编码为参数向量并集成到LLM中，缓解上下文窗口限制，同时构建专家标注的多任务法律数据集验证效果。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法直接将检索文档注入模型上下文，受限于有限的上下文窗口，导致计算开销大且注意力分散，影响下游任务性能。现有基准缺乏专家标注且只关注单一任务，无法反映真实法律场景需求。

Method: 提出参数化RAG(P-RAG)框架，对语料知识进行数据增强并编码为参数向量，通过LoRA将参数化知识集成到LLM的前馈网络中，缓解模型上下文压力。构建包含2000+专家标注实例的多任务法律数据集。

Result: 实验结果表明，该方法在减少长上下文开销的同时，在下游任务上保持与传统RAG相当的竞争性能。

Conclusion: PL-CA通过参数化知识集成有效解决了传统RAG的上下文限制问题，为法律领域的高要求知识应用提供了更高效的解决方案。

Abstract: Conventional RAG is considered one of the most effective methods for
addressing model knowledge insufficiency and hallucination, particularly in the
judicial domain that requires high levels of knowledge rigor, logical
consistency, and content integrity. However, the conventional RAG method only
injects retrieved documents directly into the model's context, which severely
constrains models due to their limited context windows and introduces
additional computational overhead through excessively long contexts, thereby
disrupting models' attention and degrading performance on downstream tasks.
Moreover, many existing benchmarks lack expert annotation and focus solely on
individual downstream tasks while real-world legal scenarios consist of
multiple mixed legal tasks, indicating conventional benchmarks' inadequacy for
reflecting models' true capabilities. To address these limitations, we propose
PL-CA, which introduces a parametric RAG (P-RAG) framework to perform data
augmentation on corpus knowledge and encode this legal knowledge into
parametric vectors, and then integrates this parametric knowledge into the
LLM's feed-forward networks (FFN) via LoRA, thereby alleviating models' context
pressure. Additionally, we also construct a multi-task legal dataset comprising
more than 2000 training and test instances, which are all expert-annotated and
manually verified. We conduct our experiments on our dataset, and the
experimental results demonstrate that our method reduces the overhead
associated with excessively long contexts while maintaining competitive
performance on downstream tasks compared to conventional RAG. Our code and
dataset are provided in the appendix.

</details>


### [43] [Do LLMs exhibit the same commonsense capabilities across languages?](https://arxiv.org/abs/2509.06401)
*Ivan Martínez-Murillo,Elena Lloret,Paloma Moreda,Albert Gatt*

Main category: cs.CL

TL;DR: 本文提出了MULTICOM多语言常识生成基准，评估LLMs在英语、西班牙语、荷兰语和瓦伦西亚语中的常识生成能力，发现英语表现最佳，低资源语言表现较差。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在多语言环境下的常识生成能力，填补现有研究在多语言常识生成评估方面的空白。

Method: 构建MULTICOM基准数据集（扩展COCOTEROS到4种语言），评估多个开源LLM（LLaMA、Qwen、Gemma等），结合自动指标、LLM-as-a-judge方法和人工标注进行综合评估。

Result: 英语表现最优，低资源语言（如瓦伦西亚语）表现显著较差；上下文支持对低资源语言有一定帮助但效果不一。

Conclusion: 当前LLMs在多语言常识生成方面存在明显局限，特别是在低资源语言上表现不佳，需要进一步改进。

Abstract: This paper explores the multilingual commonsense generation abilities of
Large Language Models (LLMs). To facilitate this investigation, we introduce
MULTICOM, a novel benchmark that extends the COCOTEROS dataset to four
languages: English, Spanish, Dutch, and Valencian. The task involves generating
a commonsensical sentence that includes a given triplet of words. We evaluate a
range of open-source LLMs, including LLaMA, Qwen, Gemma, EuroLLM, and
Salamandra, on this benchmark. Our evaluation combines automatic metrics,
LLM-as-a-judge approaches (using Prometheus and JudgeLM), and human
annotations. Results consistently show superior performance in English, with
significantly lower performance in less-resourced languages. While contextual
support yields mixed results, it tends to benefit underrepresented languages.
These findings underscore the current limitations of LLMs in multilingual
commonsense generation. The dataset is publicly available at
https://huggingface.co/datasets/gplsi/MULTICOM.

</details>


### [44] [WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents](https://arxiv.org/abs/2509.06501)
*Junteng Liu,Yunji Li,Chi Zhang,Jingyang Li,Aili Chen,Ke Ji,Weiyu Cheng,Zijia Wu,Chengyu Du,Qidi Xu,Jiayuan Song,Zhengmao Zhu,Wenhu Chen,Pengyu Zhao,Junxian He*

Main category: cs.CL

TL;DR: WebExplorer是一个8B参数的网络代理模型，通过创新的数据生成方法和强化学习训练，在复杂信息检索任务中实现了最先进的性能，甚至超越了更大规模的模型。


<details>
  <summary>Details</summary>
Motivation: 现有开源网络代理在复杂任务上的信息检索能力有限，且缺乏透明实现，主要挑战在于缺乏具有挑战性的信息检索数据。

Method: 提出WebExplorer系统化数据生成方法，使用基于模型的探索和迭代式长到短查询演化，创建需要多步推理和复杂网络导航的查询-答案对。通过监督微调和强化学习训练支持128K上下文长度和100个工具调用轮次的模型。

Result: WebExplorer-8B在多个信息检索基准测试中达到同规模最佳性能，在BrowseComp-en/zh上超越WebSailor-72B，在WebWalkerQA和FRAMES上达到100B参数以下模型的最佳性能，同时在HLE基准测试中展现出强泛化能力。

Conclusion: 该方法为长视野网络代理的发展提供了实用路径，证明了通过高质量数据生成和强化学习训练，较小模型也能在复杂网络导航任务中取得卓越性能。

Abstract: The paradigm of Large Language Models (LLMs) has increasingly shifted toward
agentic applications, where web browsing capabilities are fundamental for
retrieving information from diverse online sources. However, existing
open-source web agents either demonstrate limited information-seeking abilities
on complex tasks or lack transparent implementations. In this work, we identify
that the key challenge lies in the scarcity of challenging data for information
seeking. To address this limitation, we introduce WebExplorer: a systematic
data generation approach using model-based exploration and iterative,
long-to-short query evolution. This method creates challenging query-answer
pairs that require multi-step reasoning and complex web navigation. By
leveraging our curated high-quality dataset, we successfully develop advanced
web agent WebExplorer-8B through supervised fine-tuning followed by
reinforcement learning. Our model supports 128K context length and up to 100
tool calling turns, enabling long-horizon problem solving. Across diverse
information-seeking benchmarks, WebExplorer-8B achieves the state-of-the-art
performance at its scale. Notably, as an 8B-sized model, WebExplorer-8B is able
to effectively search over an average of 16 turns after RL training, achieving
higher accuracy than WebSailor-72B on BrowseComp-en/zh and attaining the best
performance among models up to 100B parameters on WebWalkerQA and FRAMES.
Beyond these information-seeking tasks, our model also achieves strong
generalization on the HLE benchmark even though it is only trained on
knowledge-intensive QA data. These results highlight our approach as a
practical path toward long-horizon web agents.

</details>


### [45] [Crown, Frame, Reverse: Layer-Wise Scaling Variants for LLM Pre-Training](https://arxiv.org/abs/2509.06518)
*Andrei Baroian,Kasper Notebomer*

Main category: cs.CL

TL;DR: 这篇论文探索了Transformer模型的层次缩放技术，通过三种新的LWS变体（Framed、Reverse、Crown）重新分配FFN宽度和注意力头数，在固定参数预算下实现了更好的性能而不影响训练速度。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer模型使用均匀的层大小，忽略了不同深度层在功能角色和计算需求上的差异性。需要探索更灵活的层次缩放策略来提升模型效能。

Method: 提出三种新的层次缩放（LWS）变体：Framed、Reverse和Crown。通过二点或三点线性插值重新分配FFN宽度和注意力头数，在预训练阶段实施。在固定180M参数预算和5B标签的训练数据上进行系统性对比实验。

Result: 所有模型都能收敛到相似的损失值，且都比相同成本的均匀基准模型表现更好。训练速度没有实质性下降。

Conclusion: 这项工作是预训练阶段层次架构设计的初步探索，未来需要在更大规模的标签和参数上扩展实验以全面评估其潜力。

Abstract: Transformer-based language models traditionally use uniform (isotropic) layer
sizes, yet they ignore the diverse functional roles that different depths can
play and their computational capacity needs. Building on Layer-Wise Scaling
(LWS) and pruning literature, we introduce three new LWS variants - Framed,
Reverse, and Crown - that redistribute FFN widths and attention heads via two
or three-point linear interpolation in the pre-training stage. We present the
first systematic ablation of LWS and its variants, on a fixed budget of 180M
parameters, trained on 5B tokens. All models converge to similar losses and
achieve better performance compared to an equal-cost isotropic baseline,
without a substantial decrease in training throughput. This work represents an
initial step into the design space of layer-wise architectures for
pre-training, but future work should scale experiments to orders of magnitude
more tokens and parameters to fully assess their potential.

</details>


### [46] [LAMDAS: LLM as an Implicit Classifier for Domain-specific Data Selection](https://arxiv.org/abs/2509.06524)
*Jian Wu,Hang Yu,Bingchang Liu,Wenjie Yang,Peng Di,Jianguo Li,Yue Zhang*

Main category: cs.CL

TL;DR: LAMDAS利用预训练大语言模型作为隐式分类器，通过单类分类方法从大量未标注数据中高效选择高质量领域数据，显著提升微调效果并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 领域适配中高质量标注数据稀缺，而大量未标注数据直接使用会引入噪声。现有数据选择方法难以同时保证准确性和效率。

Method: 将数据选择重构为单类分类问题，利用预训练LLM作为隐式分类器，基于小规模参考数据集识别属于目标领域的候选数据，避免显式特征工程和计算密集型优化。

Result: 实验表明LAMDAS仅使用少量数据就超越全数据训练效果，在多种场景下优于9个SOTA基线方法，在性能增益和计算效率之间达到最佳平衡。

Conclusion: LAMDAS提供了一种高效准确的领域数据选择方法，解决了LLM领域适配中的数据质量瓶颈问题，具有重要的实践价值。

Abstract: Adapting large language models (LLMs) to specific domains often faces a
critical bottleneck: the scarcity of high-quality, human-curated data. While
large volumes of unchecked data are readily available, indiscriminately using
them for fine-tuning risks introducing noise and degrading performance.
Strategic data selection is thus crucial, requiring a method that is both
accurate and efficient. Existing approaches, categorized as similarity-based
and direct optimization methods, struggle to simultaneously achieve these
goals. In this paper, we introduce LAMDAS (LLM As an iMplicit classifier for
domain-specific DAta Selection), a novel approach that leverages the
pre-trained LLM itself as an implicit classifier, thereby bypassing explicit
feature engineering and computationally intensive optimization process. LAMDAS
reframes data selection as a one-class classification problem, identifying
candidate data that "belongs" to the target domain defined by a small reference
dataset. Extensive experimental results demonstrate that LAMDAS not only
exceeds the performance of full-data training using a fraction of the data but
also outperforms nine state-of-the-art (SOTA) baselines under various
scenarios. Furthermore, LAMDAS achieves the most compelling balance between
performance gains and computational efficiency compared to all evaluated
baselines.

</details>


### [47] [SLiNT: Structure-aware Language Model with Injection and Contrastive Training for Knowledge Graph Completion](https://arxiv.org/abs/2509.06531)
*Mengxue Yang,Chun Yang,Jiaqi Zhu,Jiafan Li,Jingqi Zhang,Yuyang Li,Ying Li*

Main category: cs.CL

TL;DR: SLiNT是一个结构感知的语言模型框架，通过注入知识图谱结构信息和对比学习来解决链接预测中的结构稀疏性和语义模糊性问题


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在知识图谱链接预测中虽然具有强大的生成推理能力，但对结构信号的利用有限，导致结构稀疏和语义模糊问题，特别是在不完整或零样本设置下

Method: 提出SLiNT框架：1) 结构引导邻域增强(SGNE)检索伪邻居丰富稀疏实体；2) 动态硬对比学习(DHCL)通过插值硬正负样本来解决实体级模糊性；3) 梯度解耦双重注入(GDDI)进行令牌级结构感知干预同时保持核心LLM参数

Result: 在WN18RR和FB15k-237数据集上的实验表明，SLiNT相比基于嵌入和基于生成的基线方法取得了优越或竞争性的性能

Conclusion: SLiNT证明了结构感知表示学习对于可扩展知识图谱补全的有效性，通过结合LLM的生成能力和知识图谱的结构信息来提升链接预测性能

Abstract: Link prediction in knowledge graphs requires integrating structural
information and semantic context to infer missing entities. While large
language models offer strong generative reasoning capabilities, their limited
exploitation of structural signals often results in structural sparsity and
semantic ambiguity, especially under incomplete or zero-shot settings. To
address these challenges, we propose SLiNT (Structure-aware Language model with
Injection and coNtrastive Training), a modular framework that injects
knowledge-graph-derived structural context into a frozen LLM backbone with
lightweight LoRA-based adaptation for robust link prediction. Specifically,
Structure-Guided Neighborhood Enhancement (SGNE) retrieves pseudo-neighbors to
enrich sparse entities and mitigate missing context; Dynamic Hard Contrastive
Learning (DHCL) introduces fine-grained supervision by interpolating hard
positives and negatives to resolve entity-level ambiguity; and
Gradient-Decoupled Dual Injection (GDDI) performs token-level structure-aware
intervention while preserving the core LLM parameters. Experiments on WN18RR
and FB15k-237 show that SLiNT achieves superior or competitive performance
compared with both embedding-based and generation-based baselines,
demonstrating the effectiveness of structure-aware representation learning for
scalable knowledge graph completion.

</details>


### [48] [HAVE: Head-Adaptive Gating and ValuE Calibration for Hallucination Mitigation in Large Language Models](https://arxiv.org/abs/2509.06596)
*Xin Tong,Zhi Lin,Jingya Wang,Bo Jin*

Main category: cs.CL

TL;DR: HAVE是一个无需微调的参数自由解码框架，通过头自适应门控和价值校准来解决LLM幻觉问题，在多个QA基准测试中有效减少幻觉并优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在检索增强或长上下文生成中经常产生幻觉，即使相关证据存在。这源于两个问题：头重要性被视为输入无关的，原始注意力权重不能很好反映每个token的真实贡献。

Method: HAVE框架包含头自适应门控（对注意力头进行实例级软重加权）和价值校准（通过价值向量大小增强注意力来近似写回贡献），通过轻量级不确定性缩放策略将token级证据与语言模型分布融合。

Result: 在多个QA基准测试和不同LLM家族上的实验表明，HAVE持续减少幻觉并优于包括DAGCD在内的强基线方法，且开销适中。

Conclusion: HAVE框架透明、可复现，能够轻松集成到现成的LLM中，在现实场景中推进可信赖的生成。

Abstract: Large Language Models (LLMs) often produce hallucinations in
retrieval-augmented or long-context generation, even when relevant evidence is
present. This stems from two issues: head importance is treated as
input-agnostic, and raw attention weights poorly reflect each token's true
contribution. We present HAVE (Head-Adaptive Gating and ValuE Calibration), a
parameter-free decoding framework that directly addresses both challenges. HAVE
introduces head-adaptive gating, which performs instance-level soft reweighing
of attention heads, and value calibration, which augments attention with the
magnitude of value vectors to approximate write-back contribution. Together,
these modules construct token-level evidence aligned with model updates and
fuse it with the LM distribution through a lightweight uncertainty-scaled
policy. HAVE requires no finetuning and operates in a single forward pass,
making it efficient and broadly applicable. Experiments across multiple QA
benchmarks and LLM families demonstrate that HAVE consistently reduces
hallucinations and outperforms strong baselines, including DAGCD, with modest
overhead. The framework is transparent, reproducible, and readily integrates
with off-the-shelf LLMs, advancing trustworthy generation in real-world
settings.

</details>


### [49] [Guided Decoding and Its Critical Role in Retrieval-Augmented Generation](https://arxiv.org/abs/2509.06631)
*Özgür Uğur,Musa Yılmaz,Esra Şavirdi,Özay Ezerceli,Mahmut El Huseyni,Selva Taş,Reyhan Bayraktar*

Main category: cs.CL

TL;DR: 本研究比较了三种引导解码方法（Outlines、XGrammar、LM Format Enforcer）在不同多轮提示设置下的性能，发现在RAG系统中多轮交互对引导解码有显著影响，并揭示了意外的性能变化。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在各种应用中的集成，需要确保输出符合预期格式并减少幻觉。RAG系统中的一个关键挑战是保证输出与期望格式对齐同时最小化幻觉。

Method: 研究比较了三种引导解码方法（Outlines、XGrammar、LM Format Enforcer），在不同多轮提示设置（0轮、1轮、2轮）下进行评估，通过成功率、幻觉率和输出质量等指标进行分析。

Result: 研究结果揭示了多轮交互如何影响引导解码，发现了意外的性能变化，这些发现可以为特定用例的方法选择提供信息。

Conclusion: 这项工作推进了对RAG系统中结构化输出生成的理解，为大语言模型部署提供了理论见解和实践指导。

Abstract: The integration of Large Language Models (LLMs) into various applications has
driven the need for structured and reliable responses. A key challenge in
Retrieval-Augmented Generation (RAG) systems is ensuring that outputs align
with expected formats while minimizing hallucinations. This study examines the
role of guided decoding in RAG systems, comparing three methods, Outlines,
XGrammar, and LM Format Enforcer, across different multi-turn prompting setups
(0-turn, 1-turn, and 2-turn). By evaluating success rates, hallucination rates,
and output quality, we provide insights into their performance and
applicability. Our findings reveal how multi-turn interactions influence guided
decoding, uncovering unexpected performance variations that can inform method
selection for specific use cases. This work advances the understanding of
structured output generation in RAG systems, offering both theoretical insights
and practical guidance for LLM deployment.

</details>


### [50] [Modelling Intertextuality with N-gram Embeddings](https://arxiv.org/abs/2509.06637)
*Yi Xing*

Main category: cs.CL

TL;DR: 提出了一种基于文本嵌入和n-gram比较的量化互文性分析模型，通过成对比较和平均计算来评估文本间的互文关系，并在验证实验中证明了方法的有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 互文性是文学研究中的核心概念，但传统分析方法难以进行大规模量化研究。本文旨在开发一种可扩展的定量模型，以实现对文本间互文关系的系统性分析和网络化洞察。

Method: 使用文本嵌入技术，对两个文本的n-gram进行成对比较，然后平均计算结果作为整体互文性指标。该方法支持大规模文本分析。

Result: 在4个已知互文性程度的文本上验证了方法的有效性，并在267个多样化文本上进行了可扩展性测试，证明了方法的效率和准确性。网络分析还揭示了中心性和社区结构。

Conclusion: 该方法成功捕捉和量化了互文关系，为文学研究提供了可扩展的定量分析工具，网络分析进一步验证了方法在揭示文本间复杂关系方面的成功。

Abstract: Intertextuality is a central tenet in literary studies. It refers to the
intricate links between literary texts that are created by various types of
references. This paper proposes a new quantitative model of intertextuality to
enable scalable analysis and network-based insights: perform pairwise
comparisons of the embeddings of n-grams from two texts and average their
results as the overall intertextuality. Validation on four texts with known
degrees of intertextuality, alongside a scalability test on 267 diverse texts,
demonstrates the method's effectiveness and efficiency. Network analysis
further reveals centrality and community structures, affirming the approach's
success in capturing and quantifying intertextual relationships.

</details>


### [51] [Domain-Aware RAG: MoL-Enhanced RL for Efficient Training and Scalable Retrieval](https://arxiv.org/abs/2509.06650)
*Hao Lin,Peitong Xie,Jingxue Chen,Jie Lin,Qingkun Tang,Qianchun Lu*

Main category: cs.CL

TL;DR: MoLER是一个基于混合损失增强强化学习的领域感知RAG方法，通过两阶段训练优化检索性能，在基准数据集上达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统在粗排序优化中难以平衡领域知识学习和查询增强，导致检索性能不佳。

Method: 采用两阶段流程：1）使用混合损失（MoL）进行持续预训练，平衡领域知识和通用语言能力；2）使用组相对策略优化（GRPO）进行强化学习，优化查询和段落生成以最大化文档召回率。创新性地提出多查询单段落后融合（MSLF）策略降低计算开销。

Result: 在基准数据集上的广泛实验表明，MoLER显著优于基线方法，实现了最先进的性能。

Conclusion: MoLER填补了RAG系统的知识鸿沟，能够在专业领域实现鲁棒且可扩展的检索。

Abstract: Retrieval-Augmented Generation (RAG) systems rely heavily on the retrieval
stage, particularly the coarse-ranking process. Existing coarse-ranking
optimization approaches often struggle to balance domain-specific knowledge
learning with query enhencement, resulting in suboptimal retrieval performance.
To address this challenge, we propose MoLER, a domain-aware RAG method that
uses MoL-Enhanced Reinforcement Learning to optimize retrieval. MoLER has a
two-stage pipeline: a continual pre-training (CPT) phase using a Mixture of
Losses (MoL) to balance domain-specific knowledge with general language
capabilities, and a reinforcement learning (RL) phase leveraging Group Relative
Policy Optimization (GRPO) to optimize query and passage generation for
maximizing document recall. A key innovation is our Multi-query Single-passage
Late Fusion (MSLF) strategy, which reduces computational overhead during RL
training while maintaining scalable inference via Multi-query Multi-passage
Late Fusion (MMLF). Extensive experiments on benchmark datasets show that MoLER
achieves state-of-the-art performance, significantly outperforming baseline
methods. MoLER bridges the knowledge gap in RAG systems, enabling robust and
scalable retrieval in specialized domains.

</details>


### [52] [IntrEx: A Dataset for Modeling Engagement in Educational Conversations](https://arxiv.org/abs/2509.06652)
*Xingwei Tan,Mahathi Parvatham,Chiara Gambi,Gabriele Pergola*

Main category: cs.CL

TL;DR: IntrEx是首个针对教师-学生互动中趣味性和预期趣味性的大规模标注数据集，通过基于RLHF的比较标注方法，发现微调后的中小型LLM在预测教育对话趣味性方面优于GPT-4o等大型模型。


<details>
  <summary>Details</summary>
Motivation: 解决教育对话中维持学习者兴趣的挑战，填补对话层面语言特征如何驱动参与度的研究空白。

Method: 基于TSCC语料库构建IntrEx数据集，采用比较式评分方法，由100多名二语学习者进行序列级标注，研究LLM预测人类趣味性判断的能力。

Result: 微调后的7B/8B参数LLM在预测趣味性方面表现优于GPT-4o等大型专有模型，证明了专业数据集在教育参与度建模中的潜力。

Conclusion: 语言和认知因素（如具体性、可理解性和吸收度）显著影响教育对话的参与度，专业数据集能够有效提升LLM在教育场景中的参与度建模能力。

Abstract: Engagement and motivation are crucial for second-language acquisition, yet
maintaining learner interest in educational conversations remains a challenge.
While prior research has explored what makes educational texts interesting,
still little is known about the linguistic features that drive engagement in
conversations. To address this gap, we introduce IntrEx, the first large
dataset annotated for interestingness and expected interestingness in
teacher-student interactions. Built upon the Teacher-Student Chatroom Corpus
(TSCC), IntrEx extends prior work by incorporating sequence-level annotations,
allowing for the study of engagement beyond isolated turns to capture how
interest evolves over extended dialogues. We employ a rigorous annotation
process with over 100 second-language learners, using a comparison-based rating
approach inspired by reinforcement learning from human feedback (RLHF) to
improve agreement. We investigate whether large language models (LLMs) can
predict human interestingness judgments. We find that LLMs (7B/8B parameters)
fine-tuned on interestingness ratings outperform larger proprietary models like
GPT-4o, demonstrating the potential for specialised datasets to model
engagement in educational settings. Finally, we analyze how linguistic and
cognitive factors, such as concreteness, comprehensibility (readability), and
uptake, influence engagement in educational dialogues.

</details>


### [53] [ParCzech4Speech: A New Speech Corpus Derived from Czech Parliamentary Data](https://arxiv.org/abs/2509.06675)
*Vladislav Stankov,Matyáš Kopp,Ondřej Bojar*

Main category: cs.CL

TL;DR: ParCzech4Speech 1.0是ParCzech 4.0语料库的处理版本，专门用于语音建模任务，最大变体包含2,695小时数据，结合了捷克议会演讲录音和官方转录文本。


<details>
  <summary>Details</summary>
Motivation: 改进ParCzech 3.0语音识别版本，提取更多数据并提高对齐可靠性，为语音建模任务提供高质量数据集。

Method: 使用WhisperX和Wav2Vec 2.0进行自动音频-文本对齐处理，提供三种变体：句子分割版本、未分割版本和原始对齐版本。

Result: 成功创建了包含2,695小时语音数据的语料库，提供三种灵活变体，保持原始元数据，采用CC-BY许可发布。

Conclusion: ParCzech4Speech 1.0为自动语音识别和语音合成等任务提供了高质量、可靠的捷克语语音数据集，可通过LINDAT和Hugging Face获取。

Abstract: We introduce ParCzech4Speech 1.0, a processed version of the ParCzech 4.0
corpus, targeted at speech modeling tasks with the largest variant containing
2,695 hours. We combined the sound recordings of the Czech parliamentary
speeches with the official transcripts. The recordings were processed with
WhisperX and Wav2Vec 2.0 to extract automated audio-text alignment. Our
processing pipeline improves upon the ParCzech 3.0 speech recognition version
by extracting more data with higher alignment reliability. The dataset is
offered in three flexible variants: (1) sentence-segmented for automatic speech
recognition and speech synthesis tasks with clean boundaries, (2) unsegmented
preserving original utterance flow across sentences, and (3) a raw-alignment
for further custom refinement for other possible tasks. All variants maintain
the original metadata and are released under a permissive CC-BY license. The
dataset is available in the LINDAT repository, with the sentence-segmented and
unsegmented variants additionally available on Hugging Face.

</details>


### [54] [Will Annotators Disagree? Identifying Subjectivity in Value-Laden Arguments](https://arxiv.org/abs/2509.06704)
*Amir Homayounirad,Enrico Liscio,Tong Wang,Catholijn M. Jonker,Luciano C. Siebert*

Main category: cs.CL

TL;DR: 该论文研究如何识别论证中人类价值识别的主观性，发现直接主观性识别方法比通过价值预测推断主观性效果更好，能有效标记主观论证。


<details>
  <summary>Details</summary>
Motivation: 聚合多个标注为单一真实标签可能会掩盖标注者分歧的宝贵见解，特别是在主观性起关键作用的任务中。本文旨在识别论证中人类价值动机的主观性。

Method: 评估两种主要方法：通过价值预测推断主观性 vs 直接识别主观性。实验比较了对比损失与二元交叉熵损失的组合效果。

Result: 直接主观性识别显著提高了标记主观论证的模型性能。结合对比损失和二元交叉熵损失虽未提升性能，但减少了对每个标签主观性的依赖。

Conclusion: 提出的方法有助于识别个体可能有不同解释的论证，促进更细致的标注过程。

Abstract: Aggregating multiple annotations into a single ground truth label may hide
valuable insights into annotator disagreement, particularly in tasks where
subjectivity plays a crucial role. In this work, we explore methods for
identifying subjectivity in recognizing the human values that motivate
arguments. We evaluate two main approaches: inferring subjectivity through
value prediction vs. directly identifying subjectivity. Our experiments show
that direct subjectivity identification significantly improves the model
performance of flagging subjective arguments. Furthermore, combining
contrastive loss with binary cross-entropy loss does not improve performance
but reduces the dependency on per-label subjectivity. Our proposed methods can
help identify arguments that individuals may interpret differently, fostering a
more nuanced annotation process.

</details>


### [55] [Anchoring Refusal Direction: Mitigating Safety Risks in Tuning via Projection Constraint](https://arxiv.org/abs/2509.06795)
*Yanrui Du,Fenglei Fan,Sendong Zhao,Jiawei Cao,Qika Lin,Kai He,Ting Liu,Bing Qin,Mengling Feng*

Main category: cs.CL

TL;DR: 该研究发现指令微调会导致LLM拒绝方向偏移，提出ProCon方法通过投影约束损失和温身策略有效减少安全风险保持任务性能


<details>
  <summary>Details</summary>
Motivation: 指令微调(IFT)虽能提升LLM能力，但会明显弱化模型的安全性，特别是拒绝恶意指令的能力，需要找到方法缓解这一风险

Method: 提出ProCon方法：1)引入投影约束损失项，对训练样本隐藏状态在拒绝方向上的投影进行规范化 2)采用温踢策略，在训练初期强约束后期放宽 3)扩展数据分布强化约束信号

Result: 在多种数据集、场景和LLM上的实验结果显示，ProCon能显著减少IFT带来的安全风险，同时保持任务性能提升，在整体性能上超过强基线方法

Conclusion: ProCon方法能够有效稳定训练过程中的拒绝方向，为基于可解释性的LLM内部机制探索建立了坚实基础，对未来的安全研究具有重要意义

Abstract: Instruction Fine-Tuning (IFT) has been widely adopted as an effective
post-training strategy to enhance various abilities of Large Language Models
(LLMs). However, prior studies have shown that IFT can significantly compromise
LLMs' safety, particularly their ability to refuse malicious instructions,
raising significant concerns. Recent research into the internal mechanisms of
LLMs has identified the refusal direction (r-direction) in the hidden states,
which plays a pivotal role in governing refusal behavior. Building on this
insight, our study reveals that the r-direction tends to drift during training,
which we identify as one of the causes of the associated safety risks. To
mitigate such drift, our proposed ProCon method introduces a
projection-constrained loss term that regularizes the projection magnitude of
each training sample's hidden state onto the r-direction. Our initial analysis
shows that applying an appropriate constraint can effectively mitigate the
refusal direction drift and associated safety risks, but remains limited by
overall performance barriers. To overcome this barrier, informed by our
observation of early-stage sharp drift and a data-driven perspective, we
introduce a warm-up strategy that emphasizes early-stage strong constraints and
broaden the data distribution to strengthen constraint signals, leading to an
enhanced ProCon method. Experimental results under various datasets, scenarios,
and LLMs demonstrate that our method can significantly mitigate safety risks
posed by IFT while preserving task performance gains. Even compared with strong
baselines, our method consistently delivers superior overall performance.
Crucially, our analysis indicates that ProCon can contribute to stabilizing the
r-direction during training, while such an interpretability-driven exploration
of LLMs' internal mechanisms lays a solid foundation for future safety
research.

</details>


### [56] [MachineLearningLM: Continued Pretraining Language Models on Millions of Synthetic Tabular Prediction Tasks Scales In-Context ML](https://arxiv.org/abs/2509.06806)
*Haoyu Dong,Pengkun Zhang,Mingzhe Lu,Yanzhen Shen,Guolin Ke*

Main category: cs.CL

TL;DR: MachineLearningLM是一个持续预训练框架，通过合成大量结构因果模型任务来增强LLM的上下文机器学习能力，在少样本到1024样本的范围内都表现出色，同时保持通用知识推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然具备广泛的世界知识和推理能力，但在标准机器学习任务中难以通过纯上下文学习从大量示例中有效学习，需要梯度下降之外的解决方案。

Method: 使用随机森林教师从数百万个结构因果模型中合成ML任务，通过知识蒸馏将基于树的决策策略转移到LLM中，采用token高效的提示序列化方法，支持批量推理。

Result: 在Qwen-2.5-7B-Instruct模型上，MachineLearningLM在金融、物理、生物和医疗等领域的分布外表格分类任务中平均优于强基线模型约15%，展现出明显的多样本缩放规律，准确率随样本数从8增加到1024而单调提升，在MMLU上达到75.4%的准确率。

Conclusion: MachineLearningLM成功地为通用LLM赋予了强大的上下文机器学习能力，同时保持了模型的通用知识和推理能力，实现了无需任务特定训练就能达到随机森林级别性能的目标。

Abstract: Large language models (LLMs) possess broad world knowledge and strong
general-purpose reasoning ability, yet they struggle to learn from many
in-context examples on standard machine learning (ML) tasks, that is, to
leverage many-shot demonstrations purely via in-context learning (ICL) without
gradient descent. We introduce MachineLearningLM, a portable
continued-pretraining framework that equips a general-purpose LLM with robust
in-context ML capability while preserving its general knowledge and reasoning
for broader chat workflows.
  Our pretraining procedure synthesizes ML tasks from millions of structural
causal models (SCMs), spanning shot counts up to 1,024. We begin with a
random-forest teacher, distilling tree-based decision strategies into the LLM
to strengthen robustness in numerical modeling. All tasks are serialized with a
token-efficient prompt, enabling 3x to 6x more examples per context window and
delivering up to 50x amortized throughput via batch inference.
  Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8),
MachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an
average of about 15% on out-of-distribution tabular classification across
finance, physics, biology, and healthcare domains. It exhibits a striking
many-shot scaling law: accuracy increases monotonically as in-context
demonstrations grow from 8 to 1,024. Without any task-specific training, it
attains random-forest-level accuracy across hundreds of shots. General chat
capabilities, including knowledge and reasoning, are preserved: it achieves
75.4% on MMLU.

</details>


### [57] [MoGU V2: Toward a Higher Pareto Frontier Between Model Usability and Security](https://arxiv.org/abs/2509.06807)
*Yanrui Du,Fenglei Fan,Sendong Zhao,Jiawei Cao,Ting Liu,Bing Qin*

Main category: cs.CL

TL;DR: MoGU_v2框架通过动态路由机制平衡LLM的安全性和可用性，在多种LLM类型上实现稳定改进，无需在安全性和实用性之间做权衡。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在面对恶意指令时过度保守拒绝响应的问题，提升安全性的同时保持实用可用性。

Method: MoGU_v2框架在编码安全特征的层中嵌入路由器，通过双向适配机制动态分配安全优化和可用性优化变体的权重。

Result: 在主流LLM、设备端LLM和推理LLM等多种模型上表现出强适应性和稳定改进，能轻松恢复Instruction Fine-tuning带来的安全风险。

Conclusion: MoGU_v2是一个强大且通用的解决方案，能有效缓解现实应用中的安全风险，同时保持任务性能。

Abstract: As Large Language Models (LLMs) increasingly permeate human life, their
security has emerged as a critical concern, particularly their ability to
maintain harmless responses to malicious instructions. Although extensive
methods have improved LLMs' security, they often lead to conservative,
rejection-oriented responses that compromise practical usability. This presents
a key challenge: how to advance the Pareto frontier between LLMs' usability and
security, rather than necessitate a trade-off between them. To address this, we
propose the MoGU framework, in which the intra-layer router dynamically
allocates weights by sensing hidden states, thereby balancing the contributions
of security-optimized and usability-optimized variants. Despite its initial
potential, the MoGU framework faces limitations such as parameter redundancy
and performance bottlenecks. To overcome these, we further propose an improved
MoGU_v2 framework that establishes a tighter coupling between the routers and
hidden states. In MoGU_v2, routers are embedded only in layers encoding highly
classifiable security features, and backbone modules are activated during
router optimization to enable bidirectional adaptation. MoGU_V2 exhibits strong
adaptability and stable improvements across various series of LLMs, including
mainstream LLMs serving as brains in various applications, on-device LLMs
optimized for resource-constrained scenarios, and reasoning LLMs tailored for
user interpretability. Meanwhile, even facing risks introduced by Instruction
Fine-tuning, MoGU_v2 can easily restore security without compromising the task
performance gains via a simple data-mix strategy. These comprehensive
improvements highlight MoGU_V2 as a robust and versatile solution for
mitigating security risks in real-world applications.

</details>


### [58] [Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem](https://arxiv.org/abs/2509.06809)
*Valentin Quesnel,Damien Sileo*

Main category: cs.CL

TL;DR: 利用E-prover定理证明器从TPTP公理库生成大量高质量数学推理数据，构建了三种难度控制的挑战任务，发现前沿模型在深层逻辑推理上表现弱势


<details>
  <summary>Details</summary>
Motivation: 解决高质量逻辑声数据稀缺问题，为提升大语言模型的数学推理能力提供可靠数据源

Method: 利用E-prover的饱和证明技术处理TPTP公理库，通过饱和公理、筛选有趣定理、生成任务的流水线生成保证正确的纯符号数据

Result: 构建了大规模保证有效的定理数据集，创建了含拒绝验证、前提选择和证明重构的三种挑战任务，发现前沿模型在深层结构化推理上表现弱势

Conclusion: 该框架既提供了评估模型逻辑推理空白的诊断工具，也为解决这一问题提供了可扩展的符号训练数据来源

Abstract: The scarcity of high-quality, logically sound data is a critical bottleneck
for advancing the mathematical reasoning of Large Language Models (LLMs). Our
work confronts this challenge by turning decades of automated theorem proving
research into a scalable data engine. Rather than relying on error-prone LLMs
or complex proof-assistant syntax like Lean and Isabelle, our framework
leverages E-prover's saturation capabilities on the vast TPTP axiom library to
derive a massive, guaranteed-valid corpus of theorems. Our pipeline is
principled and simple: saturate axioms, filter for "interesting" theorems, and
generate tasks. With no LLMs in the loop, we eliminate factual errors by
construction. This purely symbolic data is then transformed into three
difficulty-controlled challenges: entailment verification, premise selection,
and proof reconstruction. Our zero-shot experiments on frontier models reveal a
clear weakness: performance collapses on tasks requiring deep, structural
reasoning. Our framework provides both the diagnostic tool to measure this gap
and a scalable source of symbolic training data to address it. We make the code
and data publicly available.
  https://github.com/sileod/reasoning_core
https://hf.co/datasets/reasoning-core/rc1

</details>


### [59] [A Comparative Benchmark of Large Language Models for Labelling Wind Turbine Maintenance Logs](https://arxiv.org/abs/2509.06813)
*Max Malyi,Jonathan Shek,Alasdair McDonald,Andre Biscaya*

Main category: cs.CL

TL;DR: 这篇论文提出了一种用于基于大语言模型对风电气组维护日志进行分类的开源案准框架，并系统评估了各种LLM在可靠性、效率和模型检验方面的性能差异。


<details>
  <summary>Details</summary>
Motivation: 风电气组维护日志的非结构化文本特性纵碍了自动化分析，需要一种可重现的方法来评估LLM在这些复杂工业记录分类任务上的性能。

Method: 开发了一个公开的案准框架，系统性评估了多种专有和开源的最新大语言模型，分析它们在可靠性、运营效率和模型检验方面的权衡。

Result: 结果量化了清晰的性能层次结构，识别出了与案准标准高度一致且具有可靠、良好检验的信心分数的顶级模型。分类性能高度依赖于任务的语义模糊性。

Conclusion: 由于没有模型能够完美准确分类且检验结果差异较大，最有效和负责任的应用方式是人在循环系统，让LLM作为强大助手加速和标准化数据标注工作。

Abstract: Effective Operation and Maintenance (O&M) is critical to reducing the
Levelised Cost of Energy (LCOE) from wind power, yet the unstructured,
free-text nature of turbine maintenance logs presents a significant barrier to
automated analysis. Our paper addresses this by presenting a novel and
reproducible framework for benchmarking Large Language Models (LLMs) on the
task of classifying these complex industrial records. To promote transparency
and encourage further research, this framework has been made publicly available
as an open-source tool. We systematically evaluate a diverse suite of
state-of-the-art proprietary and open-source LLMs, providing a foundational
assessment of their trade-offs in reliability, operational efficiency, and
model calibration. Our results quantify a clear performance hierarchy,
identifying top models that exhibit high alignment with a benchmark standard
and trustworthy, well-calibrated confidence scores. We also demonstrate that
classification performance is highly dependent on the task's semantic
ambiguity, with all models showing higher consensus on objective component
identification than on interpretive maintenance actions. Given that no model
achieves perfect accuracy and that calibration varies dramatically, we conclude
that the most effective and responsible near-term application is a
Human-in-the-Loop system, where LLMs act as a powerful assistant to accelerate
and standardise data labelling for human experts, thereby enhancing O&M data
quality and downstream reliability analysis.

</details>


### [60] [COMPACT: Common-token Optimized Model Pruning Across Channels and Tokens](https://arxiv.org/abs/2509.06836)
*Eugene Kwek,Wenpeng Yin*

Main category: cs.CL

TL;DR: COMPACT是一种联合剪枝方法，通过剪枝罕见词汇和FFN中间通道来压缩LLM，保持标准transformer架构的同时实现高效部署。


<details>
  <summary>Details</summary>
Motivation: 使LLM在内存、延迟和服务成本方面更高效，适用于边缘部署、交互式应用和大规模可持续推理。现有剪枝方法存在局限性：宽度剪枝破坏标准架构或需要定制推理代码，深度剪枝移除整个层导致精度骤降。

Method: 联合剪枝：(1)剪枝罕见词汇以缩小嵌入/解嵌入层；(2)基于常见词加权激活剪枝FFN中间通道，使重要性对齐剪枝后的词分布。保持标准transformer架构，支持训练自由操作。

Result: 在Qwen、LLaMA和Gemma系列(0.5B-70B)上实验显示，在相似或更高剪枝比例下达到最先进的下游任务性能，显著减少参数、GPU内存和端到端延迟。

Conclusion: COMPACT结合了深度和宽度剪枝的优点，具有部署友好性、规模适应性、训练自由操作和竞争性剪枝时间，同时实现强大的内存节省和吞吐量提升。

Abstract: Making LLMs more efficient in memory, latency, and serving cost is crucial
for edge deployment, interactive applications, and sustainable inference at
scale. Pruning is a key technique toward this goal. However, prior pruning
methods are limited: width pruning often breaks the standard transformer layout
or requires custom inference code, while depth pruning removes entire layers
and can cause abrupt accuracy drops. In this work, we propose COMPACT, which
jointly (i) prunes rare vocabulary to shrink embedding/unembedding and (ii)
prunes FFN intermediate channels using common-token-weighted activations,
aligning importance with the post-pruning token distribution. COMPACT enjoys
merits of both depth and width pruning, such as: deployment-friendliness (keeps
a standard transformer architecture), scale-adaptivity (trade off vocab vs. FFN
pruning), training-free operation with competitive pruning time, and strong
memory savings alongside throughput gains. Experiments across Qwen, LLaMA, and
Gemma families (0.5B-70B) show state-of-the-art downstream task performance at
similar or higher pruning ratios, with substantial reductions in parameters,
GPU memory, and end-to-end latency.

</details>


### [61] [EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language Models](https://arxiv.org/abs/2509.06838)
*Mohammad Reza Mirbagheri,Mohammad Mahdi Mirkamali,Zahra Motoshaker Arani,Ali Javeri,Amir Mahdi Sadeghzadeh,Rasool Jalili*

Main category: cs.CL

TL;DR: 提出了EPT（波斯语可信度评估）指标，这是一个专门针对波斯文化设计的基准测试，用于评估大语言模型在六个关键维度的可信度：真实性、安全性、公平性、鲁棒性、隐私性和道德对齐。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在多种语言任务上表现出色，但确保其可信度仍是一个关键挑战。特别是在波斯文化背景下，需要文化敏感的评估标准来开发负责任的AI系统。

Method: 构建了带标签的数据集，使用自动化的基于LLM的评估和人工评估相结合的方法，评估了包括ChatGPT、Claude、DeepSeek、Gemini、Grok、LLaMA、Mistral和Qwen在内的多个主流模型。

Result: 研究结果显示在安全性维度存在显著缺陷，突显了需要重点关注模型行为的这一关键方面。同时揭示了这些模型与波斯伦理文化价值观的对齐情况。

Conclusion: 该研究为推进可信赖和文化负责任的AI提供了重要见解，指出了关键差距和发展机会，并公开了数据集供进一步研究使用。

Abstract: Large Language Models (LLMs), trained on extensive datasets using advanced
deep learning architectures, have demonstrated remarkable performance across a
wide range of language tasks, becoming a cornerstone of modern AI technologies.
However, ensuring their trustworthiness remains a critical challenge, as
reliability is essential not only for accurate performance but also for
upholding ethical, cultural, and social values. Careful alignment of training
data and culturally grounded evaluation criteria are vital for developing
responsible AI systems. In this study, we introduce the EPT (Evaluation of
Persian Trustworthiness) metric, a culturally informed benchmark specifically
designed to assess the trustworthiness of LLMs across six key aspects:
truthfulness, safety, fairness, robustness, privacy, and ethical alignment. We
curated a labeled dataset and evaluated the performance of several leading
models - including ChatGPT, Claude, DeepSeek, Gemini, Grok, LLaMA, Mistral, and
Qwen - using both automated LLM-based and human assessments. Our results reveal
significant deficiencies in the safety dimension, underscoring the urgent need
for focused attention on this critical aspect of model behavior. Furthermore,
our findings offer valuable insights into the alignment of these models with
Persian ethical-cultural values and highlight critical gaps and opportunities
for advancing trustworthy and culturally responsible AI. The dataset is
publicly available at: https://github.com/Rezamirbagheri110/EPT-Benchmark.

</details>


### [62] [The Majority is not always right: RL training for solution aggregation](https://arxiv.org/abs/2509.06870)
*Wenting Zhao,Pranjal Aggarwal,Swarnadeep Saha,Asli Celikyilmaz,Jason Weston,Ilia Kulikov*

Main category: cs.CL

TL;DR: 提出AggLM方法，通过强化学习训练聚合模型来整合多个候选解决方案，相比简单投票或奖励模型排名能更有效地提升LLM在推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前测试时计算扩展主要依赖简单多数投票或奖励模型排名来聚合解决方案，但这些方法收益有限，需要更智能的聚合策略来提升大语言模型的推理能力。

Method: 使用强化学习训练聚合模型，让模型学习审查、调和和综合多个候选解决方案以产生最终正确答案，并通过平衡难易训练样本来提升模型恢复少数正确答案的能力。

Result: AggLM方法在多个基准测试中优于基于规则和奖励模型的基线方法，能够有效泛化到不同模型的解决方案，包括比训练数据中更强的模型，同时比多数投票方法需要更少的token。

Conclusion: 将聚合作为显式推理技能进行学习是有效的，通过精心设计的强化学习训练可以显著提升大语言模型在复杂推理任务中的表现和效率。

Abstract: Scaling up test-time compute, by generating multiple independent solutions
and selecting or aggregating among them, has become a central paradigm for
improving large language models (LLMs) on challenging reasoning tasks. While
most prior work relies on simple majority voting or reward model ranking to
aggregate solutions, these approaches may only yield limited benefits. In this
work, we propose to learn aggregation as an explicit reasoning skill: given a
set of candidate solutions, we train an aggregator model to review, reconcile,
and synthesize a final, correct answer using reinforcement learning from
verifiable rewards. A key ingredient is careful balancing of easy and hard
training examples, allowing the model to learn both to recover
minority-but-correct answers as well as easy majority-correct answers.
Empirically, we find our method, AggLM, outperforms both strong rule-based and
reward-model baselines, across multiple benchmarks. Furthermore, it generalizes
effectively to solutions from differing models, including stronger ones than
contained in the training data, all while requiring substantially fewer tokens
than majority voting with larger numbers of solutions.

</details>


### [63] [UNH at CheckThat! 2025: Fine-tuning Vs Prompting in Claim Extraction](https://arxiv.org/abs/2509.06883)
*Joe Wilder,Nikhil Kadapala,Benji Xu,Mohammed Alsaadi,Aiden Parsons,Mitchell Rogers,Palash Agarwal,Adam Hassick,Laura Dietz*

Main category: cs.CL

TL;DR: 本文探索了多种提示学习和上下文学习方法，包括少样本提示和不同LLM家族的微调，用于从社交媒体文本中提取值得验证的主张。最佳METEOR分数通过微调FLAN-T5模型获得，但发现其他方法有时能提取更高质量的主张。


<details>
  <summary>Details</summary>
Motivation: 参与CheckThat! Task 2英文任务，研究如何从社交媒体段落中有效提取值得验证的主张，比较不同提示学习和微调方法的性能。

Method: 使用了少样本提示、上下文学习以及不同LLM家族的微调方法，包括FLAN-T5模型的微调。

Result: 微调FLAN-T5模型获得了最佳的METEOR分数，但观察到其他方法（即使METEOR分数较低）有时能提取出更高质量的主张。

Conclusion: 虽然微调FLAN-T5在自动评估指标上表现最佳，但其他方法在实际质量上可能更有优势，表明自动评估指标与人工质量评估之间可能存在差异。

Abstract: We participate in CheckThat! Task 2 English and explore various methods of
prompting and in-context learning, including few-shot prompting and fine-tuning
with different LLM families, with the goal of extracting check-worthy claims
from social media passages. Our best METEOR score is achieved by fine-tuning a
FLAN-T5 model. However, we observe that higher-quality claims can sometimes be
extracted using other methods, even when their METEOR scores are lower.

</details>


### [64] [mmBERT: A Modern Multilingual Encoder with Annealed Language Learning](https://arxiv.org/abs/2509.06888)
*Marc Marone,Orion Weller,William Fleshman,Eugene Yang,Dawn Lawrie,Benjamin Van Durme*

Main category: cs.CL

TL;DR: mmBERT是一个基于3T多语言文本训练的编码器模型，在1800多种语言上表现优异，特别是在低资源语言分类和检索任务上超越了前代模型


<details>
  <summary>Details</summary>
Motivation: 当前缺乏针对编码器模型的最新研究，特别是多语言模型领域存在研究空白，需要开发能够处理高资源和低资源语言的强大编码器模型

Method: 使用3T多语言文本训练，引入逆掩码比率调度和逆温度采样比率，在衰减阶段添加1700多种低资源语言数据

Result: 在分类和检索任务上显著超越前代模型，与OpenAI o3和Google Gemini 2.5 Pro达到相似的分类性能

Conclusion: 通过创新的训练策略和数据处理方法，mmBERT证明了编码器模型在多语言处理中的强大潜力，特别是在低资源语言上的优异表现

Abstract: Encoder-only languages models are frequently used for a variety of standard
machine learning tasks, including classification and retrieval. However, there
has been a lack of recent research for encoder models, especially with respect
to multilingual models. We introduce mmBERT, an encoder-only language model
pretrained on 3T tokens of multilingual text in over 1800 languages. To build
mmBERT we introduce several novel elements, including an inverse mask ratio
schedule and an inverse temperature sampling ratio. We add over 1700
low-resource languages to the data mix only during the decay phase, showing
that it boosts performance dramatically and maximizes the gains from the
relatively small amount of training data. Despite only including these
low-resource languages in the short decay phase we achieve similar
classification performance to models like OpenAI's o3 and Google's Gemini 2.5
Pro. Overall, we show that mmBERT significantly outperforms the previous
generation of models on classification and retrieval tasks -- on both high and
low-resource languages.

</details>


### [65] [Proof-Carrying Numbers (PCN): A Protocol for Trustworthy Numeric Answers from LLMs via Claim Verification](https://arxiv.org/abs/2509.06902)
*Aivin V. Solatorio*

Main category: cs.CL

TL;DR: Proof-Carrying Numbers (PCN) 是一种展示层协议，通过机械验证确保大语言模型生成数字的保真度，将验证放在渲染器而非模型中，实现故障关闭行为。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型可能产生数字幻觉，生成与可用数据不符的数字。现有的安全措施（检索增强生成、引用和不确定性估计）虽然提高了透明度，但无法保证保真度。

Method: PCN 将数字跨度作为与结构化声明绑定的声明绑定令牌发出，验证器根据声明的策略（如精确相等、舍入、别名或带限定符的容差）检查每个令牌。验证放在渲染器中，只有经过声明检查的数字才被标记为已验证。

Result: PCN 被形式化并证明了其健全性、诚实令牌下的完备性、故障关闭行为以及策略细化下的单调性。PCN 轻量且模型无关，可无缝集成到现有应用中，并可扩展加密承诺。

Conclusion: 通过在显示前强制验证，PCN 为数字敏感环境建立了一个简单契约：信任只能通过证明获得，而缺少标记则传达不确定性。

Abstract: Large Language Models (LLMs) as stochastic systems may generate numbers that
deviate from available data, a failure known as \emph{numeric hallucination}.
Existing safeguards -- retrieval-augmented generation, citations, and
uncertainty estimation -- improve transparency but cannot guarantee fidelity:
fabricated or misquoted values may still be displayed as if correct. We propose
\textbf{Proof-Carrying Numbers (PCN)}, a presentation-layer protocol that
enforces numeric fidelity through mechanical verification. Under PCN, numeric
spans are emitted as \emph{claim-bound tokens} tied to structured claims, and a
verifier checks each token under a declared policy (e.g., exact equality,
rounding, aliases, or tolerance with qualifiers). Crucially, PCN places
verification in the \emph{renderer}, not the model: only claim-checked numbers
are marked as verified, and all others default to unverified. This separation
prevents spoofing and guarantees fail-closed behavior. We formalize PCN and
prove soundness, completeness under honest tokens, fail-closed behavior, and
monotonicity under policy refinement. PCN is lightweight and model-agnostic,
integrates seamlessly into existing applications, and can be extended with
cryptographic commitments. By enforcing verification as a mandatory step before
display, PCN establishes a simple contract for numerically sensitive settings:
\emph{trust is earned only by proof}, while the absence of a mark communicates
uncertainty.

</details>


### [66] [Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning](https://arxiv.org/abs/2509.06948)
*Liang Chen,Xueting Han,Li Shen,Jing Bai,Kam-Fai Wong*

Main category: cs.CL

TL;DR: 提出了一种基于双层优化的新方法，通过将监督微调(SFT)目标与最优RL策略条件化，实现SFT和强化学习的协同训练，在五个推理基准测试中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统的两阶段方法（先SFT后RL）限制了两种训练范式之间的交互，制约了整体效果。强化学习虽然能激励大语言模型的推理能力，但由于试错性质导致效率低下。

Method: 采用双层优化方法：下层执行RL更新同时接收SFT监督，上层显式最大化协作收益（联合SFT-RL训练相比单独RL的性能优势）。SFT目标以最优RL策略为条件进行元学习，指导RL的优化过程。

Result: 在五个推理基准测试上的实证评估表明，该方法始终优于基线方法，并在效果和效率之间实现了更好的平衡。

Conclusion: 通过双层优化实现SFT和RL的协同训练是一种有效的方法，能够提升大语言模型推理能力的训练效率和效果。

Abstract: Reinforcement learning (RL) has proven effective in incentivizing the
reasoning abilities of large language models (LLMs), but suffers from severe
efficiency challenges due to its trial-and-error nature. While the common
practice employs supervised fine-tuning (SFT) as a warm-up stage for RL, this
decoupled two-stage approach limits interaction between SFT and RL, thereby
constraining overall effectiveness. This study introduces a novel method for
learning reasoning models that employs bilevel optimization to facilitate
better cooperation between these training paradigms. By conditioning the SFT
objective on the optimal RL policy, our approach enables SFT to meta-learn how
to guide RL's optimization process. During training, the lower level performs
RL updates while simultaneously receiving SFT supervision, and the upper level
explicitly maximizes the cooperative gain-the performance advantage of joint
SFT-RL training over RL alone. Empirical evaluations on five reasoning
benchmarks demonstrate that our method consistently outperforms baselines and
achieves a better balance between effectiveness and efficiency.

</details>


### [67] [Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models](https://arxiv.org/abs/2509.06949)
*Yinjie Wang,Ling Yang,Bowen Li,Ye Tian,Ke Shen,Mengdi Wang*

Main category: cs.CL

TL;DR: TraceRL是一个轨迹感知的强化学习框架，用于扩散语言模型的后训练，通过融入偏好推理轨迹来提升数学推理和编程任务的性能，并支持不同架构的模型适配。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散语言模型在复杂推理任务上表现不佳，需要一种能够有效利用推理轨迹信息的方法来提升模型性能，同时保持训练稳定性和架构灵活性。

Method: 提出TraceRL框架，使用基于扩散的价值模型增强训练稳定性，通过课程学习实现长链推理，并开发了加速KV缓存技术和推理引擎。

Result: TraDo-4B-Instruct在数学推理任务上持续超越7B规模的AR模型，TraDo-8B-Instruct在数学推理基准上相对Qwen2.5-7B-Instruct提升6.1%，相对Llama3.1-8B-Instruct提升51.3%。首个长链推理DLM在MATH500上相对Qwen2.5-7B-Instruct提升18.1%。

Conclusion: TraceRL框架有效提升了扩散语言模型的推理能力，实现了state-of-the-art性能，并通过开源框架促进了可复现研究和实际应用。

Abstract: We propose TraceRL, a trajectory-aware reinforcement learning framework for
diffusion language models (DLMs) that incorporates preferred inference
trajectory into post-training, and is applicable across different
architectures. Equipped with a diffusion-based value model that enhances
training stability, we demonstrate improved reasoning performance on complex
math and coding tasks. Besides, it can also be applied to adapt block-specific
models to larger blocks, which improves sampling flexibility. Employing
TraceRL, we derive a series of state-of-the-art diffusion language models,
namely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still
consistently outperforms them across complex math reasoning tasks.
TraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over
Qwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical
reasoning benchmarks. Through curriculum learning, we also derive the first
long-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1%
relative accuracy gain. To facilitate reproducible research and practical
applications, we release a comprehensive open-source framework for building,
training, and deploying diffusion LLMs across diverse architectures. The
framework integrates accelerated KV-cache techniques and inference engines for
both inference and reinforcement learning, and includes implementations of
various supervised fine-tuning and RL methods for mathematics, coding, and
general tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL

</details>


### [68] [On the Same Wavelength? Evaluating Pragmatic Reasoning in Language Models across Broad Concepts](https://arxiv.org/abs/2509.06952)
*Linlu Qiu,Cedegao E. Zhang,Joshua B. Tenenbaum,Yoon Kim,Roger P. Levy*

Main category: cs.CL

TL;DR: 这篇论文通过Wavelength游戏框架评估语言模型的语用理解能力，发现大型模型在语言理解上接近人类水平，而RSA方法能显著提升语言生成能力。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型作为会话机器人的应用增多，需要理解其语用理解能力，即如何在上下文中进行交际目标和规范的推理。

Method: 采用Wavelength通信游戏框架，研究不同规模的语言模型在语言理解和语言生成上的表现，测试了直接提示、思维链提示以及采用理性语言行为(RSA)方法进行贝叶斯语用推理的效果。

Result: 现有最先进的大型语言模型在语言理解任务上表现出接近人类的准确性，与人类判断呈现高相关性，而不需要思维链提示或RSA。在语言生成任务上，思维链提示比直接提示更好，而RSA方法能够显著提升两种提示方法的表现。

Conclusion: 这项研究帮助识别语言模型在语用理解方面的优势与限制，并证明了RSA方法在改善模型理解能力方面的潜力，为了解模型和人类在概念表征、语言理解和社会推理方面的差异开启了新的研究方向。

Abstract: Language use is shaped by pragmatics -- i.e., reasoning about communicative
goals and norms in context. As language models (LMs) are increasingly used as
conversational agents, it becomes ever more important to understand their
pragmatic reasoning abilities. We propose an evaluation framework derived from
Wavelength, a popular communication game where a speaker and a listener
communicate about a broad range of concepts in a granular manner. We study a
range of LMs on both language comprehension and language production using
direct and Chain-of-Thought (CoT) prompting, and further explore a Rational
Speech Act (RSA) approach to incorporating Bayesian pragmatic reasoning into LM
inference. We find that state-of-the-art LMs, but not smaller ones, achieve
strong performance on language comprehension, obtaining similar-to-human
accuracy and exhibiting high correlations with human judgments even without CoT
prompting or RSA. On language production, CoT can outperform direct prompting,
and using RSA provides significant improvements over both approaches. Our study
helps identify the strengths and limitations in LMs' pragmatic reasoning
abilities and demonstrates the potential for improving them with RSA, opening
up future avenues for understanding conceptual representation, language
understanding, and social reasoning in LMs and humans.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [69] [Effectively obtaining acoustic, visual and textual data from videos](https://arxiv.org/abs/2509.05786)
*Jorge E. León,Miguel Carrasco*

Main category: cs.MM

TL;DR: 提出从视频中提取音频-图像-文本多模态数据的方法，创建高质量大规模数据集以支持机器学习研究


<details>
  <summary>Details</summary>
Motivation: 机器学习模型对高质量多模态数据集需求日益增长，但结合音频、视觉和文本数据的可用数据集仍然有限

Method: 从视频中选择合适内容，提取相关数据对，使用图像到文本模型生成描述性文本，确保模态间语义连接

Result: 创建了公开可用的多模态数据集，增强了数据质量，支持多模态数据分析应用

Conclusion: 该方法有效解决了多模态数据集稀缺问题，为多模态机器学习和数据分析研究提供了重要资源支持

Abstract: The increasing use of machine learning models has amplified the demand for
high-quality, large-scale multimodal datasets. However, the availability of
such datasets, especially those combining acoustic, visual and textual data,
remains limited. This paper addresses this gap by proposing a method to extract
related audio-image-text observations from videos. We detail the process of
selecting suitable videos, extracting relevant data pairs, and generating
descriptive texts using image-to-text models. Our approach ensures a robust
semantic connection between modalities, enhancing the utility of the created
datasets for various applications. We also discuss the challenges encountered
and propose solutions to improve data quality. The resulting datasets, publicly
available, aim to support and advance research in multimodal data analysis and
machine learning.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [70] [TSPC: A Two-Stage Phoneme-Centric Architecture for code-switching Vietnamese-English Speech Recognition](https://arxiv.org/abs/2509.05983)
*Minh N. H. Nguyen,Anh Nguyen Tran,Dung Truong Dinh,Nam Van Vo*

Main category: cs.SD

TL;DR: 提出了一种针对越南语-英语代码转换语音识别的新型两阶段音素中心模型(TSPC)，通过扩展越南语音素集作为中间表示，显著降低了词错误率至20.8%。


<details>
  <summary>Details</summary>
Motivation: 现有ASR系统难以处理代码转换场景中的细微音系变化，特别是越南语-英语这种具有不同音系特征和相似发音歧义的语言对。

Method: 采用两阶段音素中心架构，基于扩展的越南语音素集作为中间表示进行混合语言建模，支持音素适应和语言转换。

Result: 在越南语-英语代码转换ASR任务中持续优于现有基线模型(包括PhoWhisper-base)，词错误率降低至20.8%，且训练资源需求更少。

Conclusion: TSPC模型通过音素中心的两阶段架构有效提升了复杂代码转换场景下的ASR性能，为混合语言语音识别提供了新的解决方案。

Abstract: Code-switching (CS) presents a significant challenge for general Auto-Speech
Recognition (ASR) systems. Existing methods often fail to capture the subtle
phonological shifts inherent in CS scenarios. The challenge is particularly
difficult for language pairs like Vietnamese and English, where both distinct
phonological features and the ambiguity arising from similar sound recognition
are present. In this paper, we propose a novel architecture for
Vietnamese-English CS ASR, a Two-Stage Phoneme-Centric model (TSPC). The TSPC
employs a phoneme-centric approach, built upon an extended Vietnamese phoneme
set as an intermediate representation to facilitate mixed-lingual modeling.
Experimental results demonstrate that TSPC consistently outperforms existing
baselines, including PhoWhisper-base, in Vietnamese-English CS ASR, achieving a
significantly lower word error rate of 20.8\% with reduced training resources.
Furthermore, the phonetic-based two-stage architecture enables phoneme
adaptation and language conversion to enhance ASR performance in complex CS
Vietnamese-English ASR scenarios.

</details>


### [71] [Xi+: Uncertainty Supervision for Robust Speaker Embedding](https://arxiv.org/abs/2509.05993)
*Junjie Li,Kong Aik Lee,Duc-Tuan Truong,Tianchi Liu,Man-Wai Mak*

Main category: cs.SD

TL;DR: 提出了改进的xi+架构，通过时间注意力模块和随机方差损失函数，在说话人识别系统中实现了约10-11%的性能提升


<details>
  <summary>Details</summary>
Motivation: 传统xi-vector模型仅通过分类损失隐式训练不确定性估计，未考虑帧间时间关系，导致监督效果不佳

Method: xi+架构包含时间注意力模块来上下文感知地捕获帧级不确定性，并引入随机方差损失函数显式监督不确定性学习

Result: 在VoxCeleb1-O集上性能提升约10%，在NIST SRE 2024评估集上提升约11%

Conclusion: xi+架构通过显式的时间注意力机制和损失函数设计，有效提升了说话人识别系统的性能

Abstract: There are various factors that can influence the performance of speaker
recognition systems, such as emotion, language and other speaker-related or
context-related variations. Since individual speech frames do not contribute
equally to the utterance-level representation, it is essential to estimate the
importance or reliability of each frame. The xi-vector model addresses this by
assigning different weights to frames based on uncertainty estimation. However,
its uncertainty estimation model is implicitly trained through classification
loss alone and does not consider the temporal relationships between frames,
which may lead to suboptimal supervision. In this paper, we propose an improved
architecture, xi+. Compared to xi-vector, xi+ incorporates a temporal attention
module to capture frame-level uncertainty in a context-aware manner. In
addition, we introduce a novel loss function, Stochastic Variance Loss, which
explicitly supervises the learning of uncertainty. Results demonstrate
consistent performance improvements of about 10\% on the VoxCeleb1-O set and
11\% on the NIST SRE 2024 evaluation set.

</details>


### [72] [DreamAudio: Customized Text-to-Audio Generation with Diffusion Models](https://arxiv.org/abs/2509.06027)
*Yi Yuan,Xubo Liu,Haohe Liu,Xiyuan Kang,Zhuo Chen,Yuxuan Wang,Mark D. Plumbley,Wenwu Wang*

Main category: cs.SD

TL;DR: DreamAudio是一个定制化文本到音频生成框架，能够从用户提供的参考音频中学习特定音频事件特征，生成包含这些个性化事件的新音频样本。


<details>
  <summary>Details</summary>
Motivation: 现有文本到音频模型主要生成语义对齐的声音，但缺乏对特定声音细粒度声学特征的精确控制，用户难以生成所需的特定音频内容。

Method: 提出新的定制化文本到音频生成框架，通过用户提供的参考音频样本来识别听觉信息，生成包含特定音频事件的新样本，并开发了两种数据集用于训练和测试。

Result: 实验表明DreamAudio生成的音频样本与定制音频特征高度一致，与输入文本提示良好对齐，同时在通用文本到音频任务中表现相当。

Conclusion: DreamAudio成功实现了定制化音频生成，提供了包含真实世界CTTA案例的基准数据集，为个性化音频生成任务提供了有效解决方案。

Abstract: With the development of large-scale diffusion-based and
language-modeling-based generative models, impressive progress has been
achieved in text-to-audio generation. Despite producing high-quality outputs,
existing text-to-audio models mainly aim to generate semantically aligned sound
and fall short on precisely controlling fine-grained acoustic characteristics
of specific sounds. As a result, users that need specific sound content may
find it challenging to generate the desired audio clips. In this paper, we
present DreamAudio for customized text-to-audio generation (CTTA).
Specifically, we introduce a new framework that is designed to enable the model
to identify auditory information from user-provided reference concepts for
audio generation. Given a few reference audio samples containing personalized
audio events, our system can generate new audio samples that include these
specific events. In addition, two types of datasets are developed for training
and testing the customized systems. The experiments show that the proposed
model, DreamAudio, generates audio samples that are highly consistent with the
customized audio features and aligned well with the input text prompts.
Furthermore, DreamAudio offers comparable performance in general text-to-audio
tasks. We also provide a human-involved dataset containing audio events from
real-world CTTA cases as the benchmark for customized generation tasks.

</details>


### [73] [MeanFlow-Accelerated Multimodal Video-to-Audio Synthesis via One-Step Generation](https://arxiv.org/abs/2509.06389)
*Xiaoran Yang,Jianxuan Yang,Xinyue Guo,Haoyu Wang,Ningning Pan,Gongping Huang*

Main category: cs.SD

TL;DR: 提出MeanFlow加速模型，通过平均速度表征流场实现一步生成，显著提升视频到音频合成的推理速度，同时保持音频质量、语义对齐和时间同步


<details>
  <summary>Details</summary>
Motivation: 解决现有音频合成方法在合成质量和推理效率之间的固有权衡问题，特别是基于流匹配的模型需要迭代采样过程导致推理速度慢

Method: 引入MeanFlow加速模型，使用平均速度表征流场实现一步生成；采用标量重缩放机制平衡条件和非条件预测以缓解CFG引起的失真；联合训练多模态条件的音频合成网络

Result: 实验结果表明，MeanFlow显著提高了推理速度，同时在视频到音频和文本到音频合成任务上都不损害感知质量

Conclusion: MeanFlow方法有效解决了音频合成中的效率瓶颈，实现了快速的一步生成，在保持合成质量的同时大幅提升推理速度

Abstract: A key challenge in synthesizing audios from silent videos is the inherent
trade-off between synthesis quality and inference efficiency in existing
methods. For instance, flow matching based models rely on modeling
instantaneous velocity, inherently require an iterative sampling process,
leading to slow inference speeds. To address this efficiency bottleneck, we
introduce a MeanFlow-accelerated model that characterizes flow fields using
average velocity, enabling one-step generation and thereby significantly
accelerating multimodal video-to-audio (VTA) synthesis while preserving audio
quality, semantic alignment, and temporal synchronization. Furthermore, a
scalar rescaling mechanism is employed to balance conditional and unconditional
predictions when classifier-free guidance (CFG) is applied, effectively
mitigating CFG-induced distortions in one step generation. Since the audio
synthesis network is jointly trained with multimodal conditions, we further
evaluate it on text-to-audio (TTA) synthesis task. Experimental results
demonstrate that incorporating MeanFlow into the network significantly improves
inference speed without compromising perceptual quality on both VTA and TTA
synthesis tasks.

</details>


### [74] [FireRedChat: A Pluggable, Full-Duplex Voice Interaction System with Cascaded and Semi-Cascaded Implementations](https://arxiv.org/abs/2509.06502)
*Junjie Chen,Yao Hu,Junjie Li,Kangyue Li,Kun Liu,Wenpeng Li,Xu Li,Ziyuan Li,Feiyu Shen,Xu Tang,Manzhen Wei,Yichen Wu,Fenglong Xie,Kaituo Xu,Kun Xie*

Main category: cs.SD

TL;DR: 这篇论文提出了一个完整的全双工语音交互系统，通过流式个性化VAD和语义转折检测器提高了拦截准确性和延迟性能，支持可控制的同时说话功能。


<details>
  <summary>Details</summary>
Motivation: 现有的全双工语音交互解决方案或是难以设计和控制的终端到终端系统，或是依赖非开源组件的模块化管线，限制了整体优化。

Method: 设计了一个包含转换控制器、交互模块和对话管理器的系统。控制器集成了流式个性化VAD来压制噪声和非主讲人的错误拦截，以及语义转折检测器来改善停止决策。

Result: 实验结果显示系统减少了错误中断，提高了语义结束检测的准确性，并降低了延迟，接近工业系统水平。

Conclusion: 该系统能够实现稳健、自然的实时全双工语音交互，为生动的助手和客服系统提供了可行的解决方案。

Abstract: Full-duplex voice interaction allows users and agents to speak simultaneously
with controllable barge-in, enabling lifelike assistants and customer service.
Existing solutions are either end-to-end, difficult to design and hard to
control, or modular pipelines governed by turn-taking controllers that ease
upgrades and per-module optimization; however, prior modular frameworks depend
on non-open components and external providers, limiting holistic optimization.
In this work, we present a complete, practical full-duplex voice interaction
system comprising a turn-taking controller, an interaction module, and a
dialogue manager. The controller integrates streaming personalized VAD (pVAD)
to suppress false barge-ins from noise and non-primary speakers, precisely
timestamp primary-speaker segments, and explicitly enable primary-speaker
barge-ins; a semantic end-of-turn detector improves stop decisions. It upgrades
heterogeneous half-duplex pipelines, cascaded, semi-cascaded, and
speech-to-speech, to full duplex. Using internal models, we implement cascaded
and semi-cascaded variants; the semi-cascaded one captures emotional and
paralinguistic cues, yields more coherent responses, lowers latency and error
propagation, and improves robustness. A dialogue manager extends capabilities
via tool invocation and context management. We also propose three system-level
metrics, barge-in, end-of-turn detection accuracy, and end-to-end latency, to
assess naturalness, control accuracy, and efficiency. Experiments show fewer
false interruptions, more accurate semantic ends, and lower latency approaching
industrial systems, enabling robust, natural, real-time full-duplex
interaction. Demos: https://fireredteam.github.io/demos/firered_chat.

</details>


### [75] [The First Voice Timbre Attribute Detection Challenge](https://arxiv.org/abs/2509.06635)
*Liping Chen,Jinghao He,Zhengyan Sheng,Kong Aik Lee,Zhen-Hua Ling*

Main category: cs.SD

TL;DR: NCMMSC 2025首届音色属性检测挑战赛，专注于音色可解释性，在VCTK-RVA数据集上比较两个语音在指定音色维度上的强度差异


<details>
  <summary>Details</summary>
Motivation: 推动语音音色的可解释性研究，建立音色属性的客观评估标准，促进音色描述技术的发展

Method: 参赛团队开发音色检测系统，在VCTK-RVA数据集上进行评估，比较两个语音在指定音色维度上的强度差异，提交结果给组织方评估

Result: 共有6支团队提交结果，其中5支团队提供了方法描述，展示了不同的音色检测技术方案

Conclusion: 该挑战赛成功推动了音色可解释性研究，为音色属性检测提供了基准测试平台，促进了相关技术的发展

Abstract: The first voice timbre attribute detection challenge is featured in a special
session at NCMMSC 2025. It focuses on the explainability of voice timbre and
compares the intensity of two speech utterances in a specified timbre
descriptor dimension. The evaluation was conducted on the VCTK-RVA dataset.
Participants developed their systems and submitted their outputs to the
organizer, who evaluated the performance and sent feedback to them. Six teams
submitted their outputs, with five providing descriptions of their
methodologies.

</details>


### [76] [AnalysisGNN: Unified Music Analysis with Graph Neural Networks](https://arxiv.org/abs/2509.06654)
*Emmanouil Karystinaios,Johannes Hentschel,Markus Neuwirth,Gerhard Widmer*

Main category: cs.SD

TL;DR: AnalysisGNN是一个基于图神经网络的音乐分析框架，通过数据混洗策略、加权多任务损失和分类器融合，整合异构标注的符号数据集进行综合乐谱分析。


<details>
  <summary>Details</summary>
Motivation: 当前计算音乐分析方法通常针对特定分析领域定制，缺乏能够整合异构标注数据集进行综合分析的统一框架。

Method: 使用图神经网络框架，采用数据混洗策略、自定义加权多任务损失函数和任务特定分类器的逻辑融合，并集成了非和弦音预测模块来识别和排除经过音和非功能音。

Result: 实验评估显示AnalysisGNN达到与传统静态数据集方法相当的性能，同时在多个异构语料库中表现出对领域转移和标注不一致性的更强韧性。

Conclusion: 该框架成功实现了对异构标注音乐数据集的整合分析，提高了分析的鲁棒性和一致性，为综合音乐分析提供了有效的解决方案。

Abstract: Recent years have seen a boom in computational approaches to music analysis,
yet each one is typically tailored to a specific analytical domain. In this
work, we introduce AnalysisGNN, a novel graph neural network framework that
leverages a data-shuffling strategy with a custom weighted multi-task loss and
logit fusion between task-specific classifiers to integrate heterogeneously
annotated symbolic datasets for comprehensive score analysis. We further
integrate a Non-Chord-Tone prediction module, which identifies and excludes
passing and non-functional notes from all tasks, thereby improving the
consistency of label signals. Experimental evaluations demonstrate that
AnalysisGNN achieves performance comparable to traditional static-dataset
approaches, while showing increased resilience to domain shifts and annotation
inconsistencies across multiple heterogeneous corpora.

</details>


### [77] [Continuous Audio Language Models](https://arxiv.org/abs/2509.06926)
*Rouard Simon,Orsini Manu,Roebel Axel,Zeghidour Neil,Défossez Alexandre*

Main category: cs.SD

TL;DR: CALM通过连续音频表示替代离散token，在更低计算成本下实现更高质量的音频生成


<details>
  <summary>Details</summary>
Motivation: 解决传统音频语言模型因使用有损压缩离散token而导致的音频质量与计算成本之间的权衡问题

Method: 使用大型Transformer主干网络生成上下文嵌入，通过MLP和一致性建模生成连续音频VAE帧

Result: 在语音和音乐生成任务上，相比最先进的离散音频语言模型，CALM实现了更高的效率和保真度

Conclusion: 连续音频语言模型通过避免有损压缩，能够以更轻量级的计算实现更高质量的音频生成

Abstract: Audio Language Models (ALM) have emerged as the dominant paradigm for speech
and music generation by representing audio as sequences of discrete tokens.
Yet, unlike text tokens, which are invertible, audio tokens are extracted from
lossy codecs with a limited bitrate. As a consequence, increasing audio quality
requires generating more tokens, which imposes a trade-off between fidelity and
computational cost. We address this issue by studying Continuous Audio Language
Models (CALM). These models instantiate a large Transformer backbone that
produces a contextual embedding at every timestep. This sequential information
then conditions an MLP that generates the next continuous frame of an audio VAE
through consistency modeling. By avoiding lossy compression, CALM achieves
higher quality at lower computational cost than their discrete counterpart.
Experiments on speech and music demonstrate improved efficiency and fidelity
over state-of-the-art discrete audio language models, facilitating lightweight,
high-quality audio generation. Samples are available at
https://continuous-audio-language-models.github.io

</details>


### [78] [Benchmarking Music Autotagging with MGPHot Expert Annotations vs. Generic Tag Datasets](https://arxiv.org/abs/2509.06936)
*Pedro Ramoneda,Pablo Alonso-Jiménez,Sergio Oramas,Xavier Serra,Dmitry Bogdanov*

Main category: cs.SD

TL;DR: 基于MGPHot数据集构建音乐自动标签新基准化评测框架，包含专业音乐学注释、标准化评估分割和预计算表征


<details>
  <summary>Details</summary>
Motivation: 解决音乐自动标签任务中缺乏包含专业音乐学注释的标准化评测数据集，以更全面评估音频表征学习模型的性能

Method: 重新构建MGPHot数据集，添加YouTube音频URL，提供标准训练/验证/测试分割，并预计算7个独立的状态前沿模型表征

Result: 在MGPHot和标准参考标签数据集上评测了多个模型，显示了专业注释与通用标签之间的关键差异

Conclusion: 提供了更先进的音乐理解研究基准化评测框架，为未来研究创造价值

Abstract: Music autotagging aims to automatically assign descriptive tags, such as
genre, mood, or instrumentation, to audio recordings. Due to its challenges,
diversity of semantic descriptions, and practical value in various
applications, it has become a common downstream task for evaluating the
performance of general-purpose music representations learned from audio data.
We introduce a new benchmarking dataset based on the recently published MGPHot
dataset, which includes expert musicological annotations, allowing for
additional insights and comparisons with results obtained on common generic tag
datasets. While MGPHot annotations have been shown to be useful for
computational musicology, the original dataset neither includes audio nor
provides evaluation setups for its use as a standardized autotagging benchmark.
To address this, we provide a curated set of YouTube URLs with retrievable
audio, and propose a train/val/test split for standardized evaluation, and
precomputed representations for seven state-of-the-art models. Using these
resources, we evaluated these models in MGPHot and standard reference tag
datasets, highlighting key differences between expert and generic tag
annotations. Altogether, our contributions provide a more advanced benchmarking
framework for future research in music understanding.

</details>
