<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 81]
- [cs.MM](#cs.MM) [Total: 3]
- [cs.SD](#cs.SD) [Total: 11]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Deep Language Geometry: Constructing a Metric Space from LLM Weights](https://arxiv.org/abs/2508.11676)
*Maksym Shamrai,Vladyslav Hamolia*

Main category: cs.CL

TL;DR: 使用LLM内部权重激活构建语言度量空间的新框架，通过剪枝算法自动生成高维语言表征，发现了与语言家族相符的关联和意外的语言连接


<details>
  <summary>Details</summary>
Motivation: 传统语言度量方法依赖于手工编码的语言特征，本文方法利用LLM内部权重激活自动提取语言表征，以反映语言现象的本质特征

Method: 通过适配的剪枝算法计算权重重要性分数，自动派生高维向量表征，构建语言度量空间，在106种语言和多语言LLM上验证

Result: 结果与已知语言家族很好对齐，同时发现了意外的语言间连接，可能表明历史接触或语言进化关系

Conclusion: 该框架能够有效提取语言的本质特征，为语言学研究提供了新的度量化方法，并发现了传统语言学方法可能没有涉及的语言关联

Abstract: We introduce a novel framework that utilizes the internal weight activations
of modern Large Language Models (LLMs) to construct a metric space of
languages. Unlike traditional approaches based on hand-crafted linguistic
features, our method automatically derives high-dimensional vector
representations by computing weight importance scores via an adapted pruning
algorithm. Our approach captures intrinsic language characteristics that
reflect linguistic phenomena. We validate our approach across diverse datasets
and multilingual LLMs, covering 106 languages. The results align well with
established linguistic families while also revealing unexpected inter-language
connections that may indicate historical contact or language evolution. The
source code, computed language latent vectors, and visualization tool are made
publicly available at https://github.com/mshamrai/deep-language-geometry.

</details>


### [2] [Can we Evaluate RAGs with Synthetic Data?](https://arxiv.org/abs/2508.11758)
*Jonas van Elburg,Peter van der Putten,Maarten Marx*

Main category: cs.CL

TL;DR: 研究发现LLM生成的合成问答数据在评估检索器配置时能可靠替代人工标注基准，但在评估生成器架构时效果不佳。


<details>
  <summary>Details</summary>
Motivation: 探索当人工标注基准不可用时，大语言模型生成的合成问答数据是否能有效替代人工标注基准来评估检索增强生成(RAG)系统。

Method: 通过两个实验进行评估：1）固定生成器，变化检索器参数；2）固定检索器参数，变化生成器架构。在四个数据集（两个开放域和两个专有数据集）上进行测试。

Result: 合成基准在评估不同检索器配置的RAG系统时表现可靠，与人工标注基准结果高度一致；但在比较不同生成器架构时无法产生一致的RAG排名。

Conclusion: 合成基准在评估检索组件时有效，但由于任务不匹配和风格偏见问题，在评估生成组件时存在局限性。

Abstract: We investigate whether synthetic question-answer (QA) data generated by large
language models (LLMs) can serve as an effective proxy for human-labeled
benchmarks when such data is unavailable. We assess the reliability of
synthetic benchmarks across two experiments: one varying retriever parameters
while keeping the generator fixed, and another varying the generator with fixed
retriever parameters. Across four datasets, of which two open-domain and two
proprietary, we find that synthetic benchmarks reliably rank the RAGs varying
in terms of retriever configuration, aligning well with human-labeled benchmark
baselines. However, they fail to produce consistent RAG rankings when comparing
generator architectures. The breakdown possibly arises from a combination of
task mismatch between the synthetic and human benchmarks, and stylistic bias
favoring certain generators.

</details>


### [3] [Limitation Learning: Catching Adverse Dialog with GAIL](https://arxiv.org/abs/2508.11767)
*Noah Kasmanoff,Rahul Zalkikar*

Main category: cs.CL

TL;DR: 使用模仿学习方法应用于对话系统，训练出能够根据提示与用户交谈的策略，同时通过辨别器发现对话模型的局限性问题。


<details>
  <summary>Details</summary>
Motivation: 在缺乏奖励函数的情况下，利用专家示范通过模仿学习构建对话策略，并通过辨别器识别模型的不良行为。

Method: 采用模仿学习方法，训练一个能够根据输入提示与用户进行对话的策略，同时训练一个能够区分专家对话和合成对话的辨别器。

Result: 策略表现有效，但辨别器结果显示了对话模型的明显局限性，包括不良行为的识别问题。

Conclusion: 这种技术可以用于识别常见于对话任务的随机数据模型的不良行为和局限性。

Abstract: Imitation learning is a proven method for creating a policy in the absence of
rewards, by leveraging expert demonstrations. In this work, we apply imitation
learning to conversation. In doing so, we recover a policy capable of talking
to a user given a prompt (input state), and a discriminator capable of
classifying between expert and synthetic conversation. While our policy is
effective, we recover results from our discriminator that indicate the
limitations of dialog models. We argue that this technique can be used to
identify adverse behavior of arbitrary data models common for dialog oriented
tasks.

</details>


### [4] [Investigating Transcription Normalization in the Faetar ASR Benchmark](https://arxiv.org/abs/2508.11771)
*Leo Peckham,Michael Ong,Naomi Nagy,Ewan Dunbar*

Main category: cs.CL

TL;DR: 研究发现Faetar ASR基准中的转录不一致性问题存在但不是主要挑战，有限词典约束解码有益，但任务仍然极其困难


<details>
  <summary>Details</summary>
Motivation: 检验Faetar自动语音识别基准中转录不一致性的作用，这是一个具有挑战性的低资源ASR基准

Method: 使用小型手工构建的词典进行分析，比较了bigram词级语言建模和有限词典约束解码的效果

Result: 转录不一致确实存在但不是主要挑战，bigram语言建模无额外益处，有限词典约束解码有益

Conclusion: Faetar ASR任务仍然极其困难，转录不一致不是主要问题，词典约束可能提供改进方向

Abstract: We examine the role of transcription inconsistencies in the Faetar Automatic
Speech Recognition benchmark, a challenging low-resource ASR benchmark. With
the help of a small, hand-constructed lexicon, we conclude that find that,
while inconsistencies do exist in the transcriptions, they are not the main
challenge in the task. We also demonstrate that bigram word-based language
modelling is of no added benefit, but that constraining decoding to a finite
lexicon can be beneficial. The task remains extremely difficult.

</details>


### [5] [A Multi-Task Evaluation of LLMs' Processing of Academic Text Input](https://arxiv.org/abs/2508.11779)
*Tianyi Li,Yu Qin,Olivia R. Liu Sheng*

Main category: cs.CL

TL;DR: 这篇论文通过系统化流程评估Gemini在学术文本处理中的能力，发现它在摘要、比较、评分和反思任务中表现局限，不建议在同行审查中无检查地使用LLM。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在学术发现和同行审查中的实际应用潜力，解决当前关于LLM能否帮助学术工作的争论。

Method: 设计包含四个任务的系统化流程：内容复现/比较/打分/反思，每个任务要求LLM扮演不同角色（神谕/判断者/知识丰富者/合作者）。使用顶级信息系统杂志的文章作为输入，采用多种文本指标进行详细的提示设计和性能评估。

Result: Gemini在学术文本处理中表现偏差：摘要和重写可靠性可接受；通过成对比较进行文本排名缺乏扩展性；学术文本打分区分度差；定性反思自相一致但缺乏深度。这些结果在语言、真实数据和人工评估中均一致，且对提示变化强劲。

Conclusion: LLM在处理学术文本时存在显著局限性，不建议在同行审查中无检查地使用。研究结果与支持LLM文本处理能力的评估相冲突，强调了在学术应用中需要更严格的验证。

Abstract: How much large language models (LLMs) can aid scientific discovery, notably
in assisting academic peer review, is in heated debate. Between a literature
digest and a human-comparable research assistant lies their practical
application potential. We organize individual tasks that computer science
studies employ in separate terms into a guided and robust workflow to evaluate
LLMs' processing of academic text input. We employ four tasks in the
assessment: content reproduction/comparison/scoring/reflection, each demanding
a specific role of the LLM (oracle/judgmental arbiter/knowledgeable
arbiter/collaborator) in assisting scholarly works, and altogether testing LLMs
with questions that increasingly require intellectual capabilities towards a
solid understanding of scientific texts to yield desirable solutions. We
exemplify a rigorous performance evaluation with detailed instructions on the
prompts. Adopting first-rate Information Systems articles at three top journals
as the input texts and an abundant set of text metrics, we record a compromised
performance of the leading LLM - Google's Gemini: its summary and paraphrase of
academic text is acceptably reliable; using it to rank texts through pairwise
text comparison is faintly scalable; asking it to grade academic texts is prone
to poor discrimination; its qualitative reflection on the text is
self-consistent yet hardly insightful to inspire meaningful research. This
evidence against an endorsement of LLMs' text-processing capabilities is
consistent across metric-based internal (linguistic assessment), external
(comparing to the ground truth), and human evaluation, and is robust to the
variations of the prompt. Overall, we do not recommend an unchecked use of LLMs
in constructing peer reviews.

</details>


### [6] [LLM-Guided Planning and Summary-Based Scientific Text Simplification: DS@GT at CLEF 2025 SimpleText](https://arxiv.org/abs/2508.11816)
*Krishna Chaitanya Marturi,Heba H. Elwazzan*

Main category: cs.CL

TL;DR: 使用大型语言模型进行科学文本简化，包括句子级和文档级两个阶段：句子级通过生成结构化计划指导简化，文档级通过摘要引导简化过程


<details>
  <summary>Details</summary>
Motivation: 解决科学文本简化任务，需要同时处理句子级和文档级的简化，确保简化后的文本既保持连贯性又忠实于原文内容

Method: 两阶段LLM框架：句子级使用LLM生成结构化计划后指导句子简化；文档级使用LLM生成摘要后引导整体简化过程

Result: 该方法能够产生更连贯且上下文忠实的科学文本简化结果

Conclusion: 基于LLM的两阶段框架在科学文本简化任务中表现出色，为CLEF 2025 SimpleText Task 1提供了有效的解决方案

Abstract: In this paper, we present our approach for the CLEF 2025 SimpleText Task 1,
which addresses both sentence-level and document-level scientific text
simplification. For sentence-level simplification, our methodology employs
large language models (LLMs) to first generate a structured plan, followed by
plan-driven simplification of individual sentences. At the document level, we
leverage LLMs to produce concise summaries and subsequently guide the
simplification process using these summaries. This two-stage, LLM-based
framework enables more coherent and contextually faithful simplifications of
scientific text.

</details>


### [7] [Hallucination Detection and Mitigation in Scientific Text Simplification using Ensemble Approaches: DS@GT at CLEF 2025 SimpleText](https://arxiv.org/abs/2508.11823)
*Krishna Chaitanya Marturi,Heba H. Elwazzan*

Main category: cs.CL

TL;DR: 本文提出了一种集成多种策略的方法来检测科学文本简化中的创造性生成和信息失真，包括BERT分类器、语义相似度、自然语言推理和LLM推理，并使用元分类器整合这些信号。


<details>
  <summary>Details</summary>
Motivation: 为了解决科学文本简化任务中可能出现的创造性生成和信息失真问题，需要开发一个能够准确检测这些问题的鲁棒系统。

Method: 构建集成框架，结合BERT分类器、语义相似度测量、自然语言推理模型和LLM推理，使用元分类器整合多种信号。对于接地生成，采用基于LLM的后编辑系统根据原始输入文本修订简化内容。

Result: 该方法在CLEF 2025 SimpleText Task 2中应用，旨在提高虚假信息和失真检测的鲁棒性。

Conclusion: 通过集成多种策略和信号，该方法能够有效检测科学文本简化中的创造性生成和信息失真问题，为文本简化质量评估提供了有效的解决方案。

Abstract: In this paper, we describe our methodology for the CLEF 2025 SimpleText Task
2, which focuses on detecting and evaluating creative generation and
information distortion in scientific text simplification. Our solution
integrates multiple strategies: we construct an ensemble framework that
leverages BERT-based classifier, semantic similarity measure, natural language
inference model, and large language model (LLM) reasoning. These diverse
signals are combined using meta-classifiers to enhance the robustness of
spurious and distortion detection. Additionally, for grounded generation, we
employ an LLM-based post-editing system that revises simplifications based on
the original input texts.

</details>


### [8] [A Survey of Idiom Datasets for Psycholinguistic and Computational Research](https://arxiv.org/abs/2508.11828)
*Michael Flor,Xinyi Liu,Anna Feldman*

Main category: cs.CL

TL;DR: 这篇调查性论文综述了语言学和计算语言学领域中用于研究习语的53个数据集，分析了它们的内容、形式和用途。


<details>
  <summary>Details</summary>
Motivation: 习语作为一种图式表达，其含义无法从单词推断，这给计算处理和人类实验研究带来了挑战。需要系统性地评估现有的习语研究数据集。

Method: 对语言学和计算语言学领域的53个习语数据集进行系统评估，分析其注释实践、覆盖范围和任务构建方式。

Result: 语言学资源包含熟悉度、透明度、组合性等规范化评分，计算数据集支持习语检测/分类、重写和跨语言建模。近期研究扩大了语言覆盖和任务多样性。

Conclusion: 虽然最近的研稖加强了语言覆盖和任务多样性，但语言学和计算语言学在习语研究方面仍然缺乏联系。

Abstract: Idioms are figurative expressions whose meanings often cannot be inferred
from their individual words, making them difficult to process computationally
and posing challenges for human experimental studies. This survey reviews
datasets developed in psycholinguistics and computational linguistics for
studying idioms, focusing on their content, form, and intended use.
Psycholinguistic resources typically contain normed ratings along dimensions
such as familiarity, transparency, and compositionality, while computational
datasets support tasks like idiomaticity detection/classification,
paraphrasing, and cross-lingual modeling. We present trends in annotation
practices, coverage, and task framing across 53 datasets. Although recent
efforts expanded language coverage and task diversity, there seems to be no
relation yet between psycholinguistic and computational research on idioms.

</details>


### [9] [Every 28 Days the AI Dreams of Soft Skin and Burning Stars: Scaffolding AI Agents with Hormones and Emotions](https://arxiv.org/abs/2508.11829)
*Leigh Levinson,Christopher J. Agostino*

Main category: cs.CL

TL;DR: 该研究提出通过模拟月经和昼夜节律等生物周期来增强AI系统的上下文相关性过滤能力，发现语言模型在不同激素阶段表现出情感和性能的规律性变化


<details>
  <summary>Details</summary>
Motivation: 解决AI系统面临的框架问题——如何从指数级大的可能性空间中确定上下文相关信息，受生物节律作为自然相关性过滤器的启发

Method: 开发了一个框架，通过周期性函数模拟关键激素（雌激素、睾酮、皮质醇）生成系统提示，将模拟的生物周期嵌入大型语言模型

Result: 语言分析显示情感和风格变化与生物阶段相关：经期悲伤情绪达到峰值，排卵期快乐情绪主导；昼夜模式显示早晨乐观转向夜间内省。在多个基准测试中观察到与生物预期一致的性能变化，最佳功能出现在中等而非极端激素范围内

Conclusion: 该方法为上下文AI提供了新途径，同时揭示了语言模型中嵌入的关于性别和生物学的社会偏见

Abstract: Despite significant advances, AI systems struggle with the frame problem:
determining what information is contextually relevant from an exponentially
large possibility space. We hypothesize that biological rhythms, particularly
hormonal cycles, serve as natural relevance filters that could address this
fundamental challenge. We develop a framework that embeds simulated menstrual
and circadian cycles into Large Language Models through system prompts
generated from periodic functions modeling key hormones including estrogen,
testosterone, and cortisol. Across multiple state-of-the-art models, linguistic
analysis reveals emotional and stylistic variations that track biological
phases; sadness peaks during menstruation while happiness dominates ovulation
and circadian patterns show morning optimism transitioning to nocturnal
introspection. Benchmarking on SQuAD, MMLU, Hellaswag, and AI2-ARC demonstrates
subtle but consistent performance variations aligning with biological
expectations, including optimal function in moderate rather than extreme
hormonal ranges. This methodology provides a novel approach to contextual AI
while revealing how societal biases regarding gender and biology are embedded
within language models.

</details>


### [10] [When Does Language Transfer Help? Sequential Fine-Tuning for Cross-Lingual Euphemism Detection](https://arxiv.org/abs/2508.11831)
*Julia Sammartino,Libby Barak,Jing Peng,Anna Feldman*

Main category: cs.CL

TL;DR: 通过跨语言转移学习提升五种语言的韦威语检测性能，对于低资源语言如约鲁巴语和土耳其语改善明显


<details>
  <summary>Details</summary>
Motivation: 韦威语具有文化变异性和模糊性，给语言模型带来挑战，特别是在低资源环境中

Method: 采用XLM-R和mBERT模型，比较了单语言细调、同时多语言细调和顺序细调策略，分析语言对组、类型学特征和预训练覆盖度的影响

Result: 顺序细调使用高资源L1语言显著提升低资源L2语言的性能；XLM-R获得更大收益但对预训练缺口和坏失学习更敏感；mBERT结果更稳定但性能较低

Conclusion: 顺序细调是一种简单但有效的策略，特别适用于改善多语言模型在低资源语言中的韦威语检测性能

Abstract: Euphemisms are culturally variable and often ambiguous, posing challenges for
language models, especially in low-resource settings. This paper investigates
how cross-lingual transfer via sequential fine-tuning affects euphemism
detection across five languages: English, Spanish, Chinese, Turkish, and
Yoruba. We compare sequential fine-tuning with monolingual and simultaneous
fine-tuning using XLM-R and mBERT, analyzing how performance is shaped by
language pairings, typological features, and pretraining coverage. Results show
that sequential fine-tuning with a high-resource L1 improves L2 performance,
especially for low-resource languages like Yoruba and Turkish. XLM-R achieves
larger gains but is more sensitive to pretraining gaps and catastrophic
forgetting, while mBERT yields more stable, though lower, results. These
findings highlight sequential fine-tuning as a simple yet effective strategy
for improving euphemism detection in multilingual models, particularly when
low-resource languages are involved.

</details>


### [11] [SupraTok: Cross-Boundary Tokenization for Enhanced Language Model Performance](https://arxiv.org/abs/2508.11857)
*Andrei-Valentin Tănase,Elena Pelican*

Main category: cs.CL

TL;DR: SupraTok是一种新颖的分词架构，通过跨边界模式学习、熵驱动数据筛选和多阶段课程学习三大创新，实现了比主流分词器更高的效率（31%提升）和竞争性多语言性能，在GPT-2规模模型上带来8.4-9.5%的基准提升。


<details>
  <summary>Details</summary>
Motivation: 当前自然语言处理中分词策略相对静态，成为模型性能的潜在瓶颈，需要重新思考子词分割方法以提升效率和语义保持能力。

Method: 基于字节对编码扩展，学习"超词"标记（连贯的多词表达式），包含跨边界模式学习、熵驱动数据筛选和多阶段课程学习三个核心创新。

Result: 英语分词效率提升31%（5.91 vs 4.51字符/标记），在38种语言保持竞争性能；集成GPT-2规模模型后在HellaSWAG和MMLU基准分别提升8.4%和9.5%。

Conclusion: 高效分词可以作为架构创新的补充路径来提升语言模型性能，但在更大规模模型上需要进一步验证。

Abstract: Tokenization remains a fundamental yet underexplored bottleneck in natural
language processing, with strategies largely static despite remarkable progress
in model architectures. We present SupraTok, a novel tokenization architecture
that reimagines subword segmentation through three innovations: cross-boundary
pattern learning that discovers multi-word semantic units, entropy-driven data
curation that optimizes training corpus quality, and multi-phase curriculum
learning for stable convergence. Our approach extends Byte-Pair Encoding by
learning "superword" tokens, coherent multi-word expressions that preserve
semantic unity while maximizing compression efficiency. SupraTok achieves 31%
improvement in English tokenization efficiency (5.91 versus 4.51 characters per
token) compared to OpenAI's o200k tokenizer and 30% improvement over Google's
Gemma 3 tokenizer (256k vocabulary), while maintaining competitive performance
across 38 languages. When integrated with a GPT-2 scale model (124M parameters)
trained on 10 billion tokens from the FineWeb-Edu dataset, SupraTok yields 8.4%
improvement on HellaSWAG and 9.5% on MMLU benchmarks without architectural
modifications. While these results are promising at this scale, further
validation at larger model scales is needed. These findings suggest that
efficient tokenization can complement architectural innovations as a path to
improved language model performance.

</details>


### [12] [In-Context Examples Matter: Improving Emotion Recognition in Conversation with Instruction Tuning](https://arxiv.org/abs/2508.11889)
*Hui Ma,Bo Zhang,Jinpeng Hu,Zenglin Shi*

Main category: cs.CL

TL;DR: 提出了InitERC，一个简单有效的一阶段上下文指令调优框架，用于对话中的情感识别，通过上下文学习实现说话人-上下文-情感的联合对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的多阶段指令调优方法无法同时捕捉说话人特征和对话上下文之间的动态交互，导致在统一框架内说话人身份、上下文线索和情感状态之间的对齐较弱。

Method: 提出InitERC框架，包含四个组件：演示池构建、上下文示例选择、提示模板设计和上下文指令调优，通过一阶段方式让大语言模型从上下文示例中学习说话人-上下文-情感对齐。

Result: 在三个广泛使用的数据集上进行大量实验，证明InitERC相比最先进的基线方法取得了显著改进。

Conclusion: InitERC是一个有效的单阶段框架，能够更好地实现说话人特征、上下文信息和情感状态之间的联合对齐，在情感识别任务上表现优异。

Abstract: Emotion recognition in conversation (ERC) aims to identify the emotion of
each utterance in a conversation, playing a vital role in empathetic artificial
intelligence. With the growing of large language models (LLMs), instruction
tuning has emerged as a critical paradigm for ERC. Existing studies mainly
focus on multi-stage instruction tuning, which first endows LLMs with speaker
characteristics, and then conducts context-aware instruction tuning to
comprehend emotional states. However, these methods inherently constrains the
capacity to jointly capture the dynamic interaction between speaker
characteristics and conversational context, resulting in weak alignment among
speaker identity, contextual cues, and emotion states within a unified
framework. In this paper, we propose InitERC, a simple yet effective one-stage
in-context instruction tuning framework for ERC. InitERC adapts LLMs to learn
speaker-context-emotion alignment from context examples via in-context
instruction tuning. Specifically, InitERC comprises four components, i.e.,
demonstration pool construction, in-context example selection, prompt template
design, and in-context instruction tuning. To explore the impact of in-context
examples, we conduct a comprehensive study on three key factors: retrieval
strategy, example ordering, and the number of examples. Extensive experiments
on three widely used datasets demonstrate that our proposed InitERC achieves
substantial improvements over the state-of-the-art baselines.

</details>


### [13] [CORE: Measuring Multi-Agent LLM Interaction Quality under Game-Theoretic Pressures](https://arxiv.org/abs/2508.11915)
*Punya Syon Pandey,Yongjin Yang,Jiarui Liu,Zhijing Jin*

Main category: cs.CL

TL;DR: 这篇论文提出了CORE指标，用于量化多满意系统中语言使用的效果，发现合作环境下语言更多重复但词汇扩展更快，而竞争环境则相反。


<details>
  <summary>Details</summary>
Motivation: 当前研究缺乏对多满意LLM系统中语言多样性的量化评估方法，需要一个统一的指标来评估不同游戏理论交互中的语言效果。

Method: 提出CORE指标，统合集群熵、词汇重复率和语义相似性等描述子，并基于Zipf定律和Heaps定律分析词频分布和词汇增长。在竞争、合作和中性环境下进行对比实验。

Result: 合作环境呈现更尖的Zipf分布和更高的Heaps指数（更多重复但词汇扩展更快），而竞争环境则相反（更少重复但词汇更受限制）。

Conclusion: 社会激励机制影响语言适应能力，CORE指标可作为多满意LLM系统语言稳健性的健壮诊断工具。

Abstract: Game-theoretic interactions between agents with Large Language Models (LLMs)
have revealed many emergent capabilities, yet the linguistic diversity of these
interactions has not been sufficiently quantified. In this paper, we present
the Conversational Robustness Evaluation Score: CORE, a metric to quantify the
effectiveness of language use within multi-agent systems across different
game-theoretic interactions. CORE integrates measures of cluster entropy,
lexical repetition, and semantic similarity, providing a direct lens of dialog
quality. We apply CORE to pairwise LLM dialogs across competitive, cooperative,
and neutral settings, further grounding our analysis in Zipf's and Heaps' Laws
to characterize word frequency distributions and vocabulary growth. Our
findings show that cooperative settings exhibit both steeper Zipf distributions
and higher Heap exponents, indicating more repetition alongside greater
vocabulary expansion. In contrast, competitive interactions display lower Zipf
and Heaps exponents, reflecting less repetition and more constrained
vocabularies. These results provide new insights into how social incentives
influence language adaptation, and highlight CORE as a robust diagnostic for
measuring linguistic robustness in multi-agent LLM systems. Our code is
available at https://github.com/psyonp/core.

</details>


### [14] [LLMs Struggle with NLI for Perfect Aspect: A Cross-Linguistic Study in Chinese and Japanese](https://arxiv.org/abs/2508.11927)
*Jie Lu,Du Jin,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 中日语言缺乏完美体的明确语法标记，导致NLI任务复杂化。研究构建了语言学驱动的模板数据集，发现高级LLM在时态推理上表现弱点。


<details>
  <summary>Details</summary>
Motivation: 中文和日语在完美体方面缺乏像英语那样的明确语法标记（如had、has、will have），这给自然语言推理（NLI）带来特别的挑战。研究者想要探索当前的大语言模型在这些语言中处理时态语义的能力。

Method: 采用语言学驱动的模板方法，为中文和日语构建了一个包含1,350对示例的NLI数据集。这个数据集重点关注完美体的时态表达。

Result: 实验结果显示，即使是先进的大语言模型也在时态推理任务上遇到困难，尤其是在检测细微的时态和参考时间移动方面。

Conclusion: 这些发现展示了模型的限制，并强调了在时态语义方面进行跨语言评估的必要性。研究人员开源了这个数据集，以便进一步研究。

Abstract: Unlike English, which uses distinct forms (e.g., had, has, will have) to mark
the perfect aspect across tenses, Chinese and Japanese lack separate
grammatical forms for tense within the perfect aspect, which complicates
Natural Language Inference (NLI). Focusing on the perfect aspect in these
languages, we construct a linguistically motivated, template-based NLI dataset
(1,350 pairs per language). Experiments reveal that even advanced LLMs struggle
with temporal inference, particularly in detecting subtle tense and
reference-time shifts. These findings highlight model limitations and
underscore the need for cross-linguistic evaluation in temporal semantics. Our
dataset is available at https://github.com/Lujie2001/CrossNLI.

</details>


### [15] [CAMF: Collaborative Adversarial Multi-agent Framework for Machine Generated Text Detection](https://arxiv.org/abs/2508.11933)
*Yue Wang,Liesheng Wei,Yuxiang Wang*

Main category: cs.CL

TL;DR: CAMF是一个多智能体协作对抗框架，通过多维度语言特征提取、对抗一致性探测和综合判断聚合来检测机器生成文本，显著优于现有零-shot检测方法


<details>
  <summary>Details</summary>
Motivation: 现有零-shot机器文本检测方法存在分析浅层、缺乏跨维度一致性研究的问题，需要更深入的多维度不一致性检测

Method: 使用多个LLM智能体进行三阶段协作对抗：多维度语言特征提取、对抗一致性探测、综合判断聚合

Result: 实验证明CAMF在机器生成文本检测方面显著优于最先进的零-shot检测技术

Conclusion: CAMF框架通过多智能体协作对抗分析跨维度文本不一致性，有效提升了机器生成文本的检测性能

Abstract: Detecting machine-generated text (MGT) from contemporary Large Language
Models (LLMs) is increasingly crucial amid risks like disinformation and
threats to academic integrity. Existing zero-shot detection paradigms, despite
their practicality, often exhibit significant deficiencies. Key challenges
include: (1) superficial analyses focused on limited textual attributes, and
(2) a lack of investigation into consistency across linguistic dimensions such
as style, semantics, and logic. To address these challenges, we introduce the
\textbf{C}ollaborative \textbf{A}dversarial \textbf{M}ulti-agent
\textbf{F}ramework (\textbf{CAMF}), a novel architecture using multiple
LLM-based agents. CAMF employs specialized agents in a synergistic three-phase
process: \emph{Multi-dimensional Linguistic Feature Extraction},
\emph{Adversarial Consistency Probing}, and \emph{Synthesized Judgment
Aggregation}. This structured collaborative-adversarial process enables a deep
analysis of subtle, cross-dimensional textual incongruities indicative of
non-human origin. Empirical evaluations demonstrate CAMF's significant
superiority over state-of-the-art zero-shot MGT detection techniques.

</details>


### [16] [CarelessWhisper: Turning Whisper into a Causal Streaming Model](https://arxiv.org/abs/2508.12301)
*Tomer Krichli,Bhiksha Raj,Joseph Keshet*

Main category: cs.CL

TL;DR: 将Transformer编码器-解码器模型通过LoRA精调转换为低延迟流式ASR模型，在小分块尺庨下性能超过现有方法


<details>
  <summary>Details</summary>
Motivation: 当前SOTA ASR模型如Whisper和Canary主要用于离线识别，无法直接用于流式实时识别，需要解决架构和训练方法的限制

Method: 通过LoRA精调将非因果性编码器改造为因果性编码器，使用弱对齐数据集同时精调编码器和解码器，并提出更新的推理机制

Result: 在小于300ms的低延迟分块尺庨下，精调后模型在大多数情况下超过现有非精调流式方法，且复杂度更低，还能提供更好的单词级时间戳

Conclusion: 通过LoRA精调可以高效将现有离线ASR模型转换为低延迟流式模型，为实时语音识别提供了有效解决方案

Abstract: Automatic Speech Recognition (ASR) has seen remarkable progress, with models
like OpenAI Whisper and NVIDIA Canary achieving state-of-the-art (SOTA)
performance in offline transcription. However, these models are not designed
for streaming (online or real-time) transcription, due to limitations in their
architecture and training methodology. We propose a method to turn the
transformer encoder-decoder model into a low-latency streaming model that is
careless about future context. We present an analysis explaining why it is not
straightforward to convert an encoder-decoder transformer to a low-latency
streaming model. Our proposed method modifies the existing (non-causal) encoder
to a causal encoder by fine-tuning both the encoder and decoder using Low-Rank
Adaptation (LoRA) and a weakly aligned dataset. We then propose an updated
inference mechanism that utilizes the fine-tune causal encoder and decoder to
yield greedy and beam-search decoding, and is shown to be locally optimal.
Experiments on low-latency chunk sizes (less than 300 msec) show that our
fine-tuned model outperforms existing non-fine-tuned streaming approaches in
most cases, while using a lower complexity. Additionally, we observe that our
training process yields better alignment, enabling a simple method for
extracting word-level timestamps. We release our training and inference code,
along with the fine-tuned models, to support further research and development
in streaming ASR.

</details>


### [17] [Learning Wisdom from Errors: Promoting LLM's Continual Relation Learning through Exploiting Error Cases](https://arxiv.org/abs/2508.12031)
*Shaozhe Yin,Jinyu Guo,Kai Shuang,Xia Liu,Ruize Ou*

Main category: cs.CL

TL;DR: 基于指令的指导对比学习方法，通过分析错误案例来减轻大语言模型在持续关系提取中的忘危问题


<details>
  <summary>Details</summary>
Motivation: 现有的持续关系提取方法主要使用内存回放和对比学习，但忽视了错误案例所反映的模型认知偏差，这些偏差能更有效地揭示模型的学习问题

Method: 提出指令基础的持续对比微调方法：1) 将每个任务的训练和内存数据按初始响应正确性分为两部分；2) 通过双任务微调区别处理；3) 利用LLM的指令跟随能力进行指令微调方式的对比调整

Result: 在TACRED和FewRel数据集上进行实验评估，结果显示该模型实现了新的state-of-the-art持续关系提取性能，并取得了显著改进

Conclusion: 专门利用错误案例来调整模型认知偏差的方法在持续关系提取任务中具有重要价值，能够有效减轻大语言模型的忘危问题

Abstract: Continual Relation Extraction (CRE) aims to continually learn new emerging
relations while avoiding catastrophic forgetting. Existing CRE methods mainly
use memory replay and contrastive learning to mitigate catastrophic forgetting.
However, these methods do not attach importance to the error cases that can
reveal the model's cognitive biases more effectively. To address this issue, we
propose an instruction-based continual contrastive tuning approach for Large
Language Models (LLMs) in CRE. Different from existing CRE methods that
typically handle the training and memory data in a unified manner, this
approach splits the training and memory data of each task into two parts
respectively based on the correctness of the initial responses and treats them
differently through dual-task fine-tuning. In addition, leveraging the
advantages of LLM's instruction-following ability, we propose a novel
instruction-based contrastive tuning strategy for LLM to continuously correct
current cognitive biases with the guidance of previous data in an
instruction-tuning manner, which mitigates the gap between old and new
relations in a more suitable way for LLMs. We experimentally evaluate our model
on TACRED and FewRel, and the results show that our model achieves new
state-of-the-art CRE performance with significant improvements, demonstrating
the importance of specializing in exploiting error cases.

</details>


### [18] [Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation](https://arxiv.org/abs/2508.12040)
*Jinyi Han,Tingyun Li,Shisong Chen,Jie Shi,Xinyi Wang,Guanglei Yue,Jiaqing Liang,Xin Lin,Liqian Wen,Zulong Chen,Yanghua Xiao*

Main category: cs.CL

TL;DR: FineCE是一种新颖的细粒度置信度估计方法，通过监督学习训练模型来预测文本生成过程中的连续置信度分数，解决了LLM过度自信的问题


<details>
  <summary>Details</summary>
Motivation: 大型语言模型缺乏自我意识，经常对错误预测给出高置信度分数，现有方法无法提供生成过程中的细粒度连续置信度估计

Method: 开发了构建训练数据的完整流程，捕捉LLM响应的概率分布，然后以监督方式训练置信度预测模型；提出后向置信度集成策略和三种最优置信度估计位置识别策略

Result: 在多个基准数据集上的广泛实验表明，FineCE始终优于现有的经典置信度估计方法

Conclusion: FineCE通过细粒度置信度估计显著提升了LLM生成输出的可信度和可靠性

Abstract: While large language models (LLMs) have demonstrated remarkable performance
across diverse tasks, they fundamentally lack self-awareness and frequently
exhibit overconfidence, assigning high confidence scores to incorrect
predictions. Accurate confidence estimation is therefore critical for enhancing
the trustworthiness and reliability of LLM-generated outputs. However, existing
approaches suffer from coarse-grained scoring mechanisms that fail to provide
fine-grained, continuous confidence estimates throughout the generation
process. To address these limitations, we introduce FineCE, a novel confidence
estimation method that delivers accurate, fine-grained confidence scores during
text generation. Specifically, we first develop a comprehensive pipeline for
constructing training data that effectively captures the underlying
probabilistic distribution of LLM responses, and then train a model to predict
confidence scores for arbitrary text sequences in a supervised manner.
Furthermore, we propose a Backward Confidence Integration (BCI) strategy that
leverages information from the subsequent text to enhance confidence estimation
for the current sequence during inference. We also introduce three strategies
for identifying optimal positions to perform confidence estimation within the
generation process. Extensive experiments on multiple benchmark datasets
demonstrate that FineCE consistently outperforms existing classical confidence
estimation methods. Our code and all baselines used in the paper are available
on GitHub.

</details>


### [19] [Beyond Modality Limitations: A Unified MLLM Approach to Automated Speaking Assessment with Effective Curriculum Learning](https://arxiv.org/abs/2508.12591)
*Yu-Hsuan Fang,Tien-Hong Lo,Yao-Ting Sung,Berlin Chen*

Main category: cs.CL

TL;DR: 本文首次系统性研究多模态大语言模型在自动说话评测中的应用，提出了专门的语音优先多模态训练方法，显著提升了评测性能。


<details>
  <summary>Details</summary>
Motivation: 传统自动说话评测系统存在单一模态限制：文本方法缺乏音响信息，音频方法缺乏语义上下文。多模态大语言模型为全面评测提供了新机遇。

Method: 提出语音优先多模态训练（SFMT）方法，利用课程学习原理，先建立健壮的语音模型基础，再进行跨模态协同融合。

Result: 在标准数据集上将全面评测性能从PCC 0.783提升到0.846。在表达方面的评估中，SFMT比传统训练方法绝对准确率提高4%。

Conclusion: 多模态大语言模型在自动说话评测中显示出优异性能，特别是通过专门的训练策略可以有效解决表达方面的挑战，为该领域开启了新途径。

Abstract: Traditional Automated Speaking Assessment (ASA) systems exhibit inherent
modality limitations: text-based approaches lack acoustic information while
audio-based methods miss semantic context. Multimodal Large Language Models
(MLLM) offer unprecedented opportunities for comprehensive ASA by
simultaneously processing audio and text within unified frameworks. This paper
presents a very first systematic study of MLLM for comprehensive ASA,
demonstrating the superior performance of MLLM across the aspects of content
and language use . However, assessment on the delivery aspect reveals unique
challenges, which is deemed to require specialized training strategies. We thus
propose Speech-First Multimodal Training (SFMT), leveraging a curriculum
learning principle to establish more robust modeling foundations of speech
before cross-modal synergetic fusion. A series of experiments on a benchmark
dataset show MLLM-based systems can elevate the holistic assessment performance
from a PCC value of 0.783 to 0.846. In particular, SFMT excels in the
evaluation of the delivery aspect, achieving an absolute accuracy improvement
of 4% over conventional training approaches, which also paves a new avenue for
ASA.

</details>


### [20] [J6: Jacobian-Driven Role Attribution for Multi-Objective Prompt Optimization in LLMs](https://arxiv.org/abs/2508.12086)
*Yao Wu*

Main category: cs.CL

TL;DR: J6方法通过雅可比矩阵分解为六个可解释组件，解决LLM多目标优化中的冲突问题，提供硬决策和软策略的动态更新框架


<details>
  <summary>Details</summary>
Motivation: 现有LLM多目标优化方法依赖标量梯度聚合，忽略了目标与参数间的几何结构，难以平衡事实性提升和置信度增加等冲突目标

Method: 提出结构化雅可比方法J6，将梯度交互矩阵分解为六个可解释组件，支持argmax硬决策和softmax软策略的动态更新框架

Result: J6提供了参数归因、任务干扰和几何对齐适应的深入洞察，形成了冲突感知的提示优化机制

Conclusion: J6为多目标神经调优引入了结构化雅可比推理的新途径，提供了原则性和可扩展的优化机制

Abstract: In large language model (LLM) adaptation, balancing multiple optimization
objectives such as improving factuality (heat) and increasing confidence (via
low entropy) poses a fundamental challenge, especially when prompt parameters
(e.g., hidden-layer insertions h and embedding modifications w) interact in
non-trivial ways. Existing multi-objective optimization strategies often rely
on scalar gradient aggregation, ignoring the deeper geometric structure between
objectives and parameters. We propose J6, a structured Jacobian-based method
that decomposes the gradient interaction matrix into six interpretable
components. This decomposition enables both hard decision-making (e.g.,
choosing the dominant update direction via argmax) and soft strategies (e.g.,
attention-style weighting via softmax over J6), forming a dynamic update
framework that adapts to local conflict and synergy. Moreover, the
interpretable structure of J6 provides insight into parameter attribution, task
interference, and geometry-aligned adaptation. Our work introduces a principled
and extensible mechanism for conflict-aware prompt optimization, and opens a
new avenue for incorporating structured Jacobian reasoning into multi-objective
neural tuning.

</details>


### [21] [STEM: Efficient Relative Capability Evaluation of LLMs through Structured Transition Samples](https://arxiv.org/abs/2508.12096)
*Haiquan Hu,Jiazhi Jiang,Shiyou Xu,Ruhan Zeng,Tian Wang*

Main category: cs.CL

TL;DR: STEM是一个轻量级可解释的评估框架，通过分析同架构不同参数规模LLMs的性能转变来识别关键样本，从而高效估计未知模型的能力位置。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能力快速提升，传统基准测试面临过拟合、计算成本高、难以区分模型真实能力差异等问题，需要更有效的评估方法。

Method: 提出STEM框架，通过分析同架构不同规模模型的性能转变识别关键过渡样本(STS)，用这些样本来估计未知模型的能力排名。

Result: 在六个多样化基准测试上验证，STEM能可靠捕捉性能趋势，与真实模型能力排名一致，展现了良好的泛化能力。

Conclusion: STEM是一种实用且可扩展的细粒度评估方法，适用于不同架构的LLMs评估，解决了传统评估方法的局限性。

Abstract: Evaluating large language models (LLMs) has become increasingly challenging
as model capabilities advance rapidly. While recent models often achieve higher
scores on standard benchmarks, these improvements do not consistently reflect
enhanced real-world reasoning capabilities. Moreover, widespread overfitting to
public benchmarks and the high computational cost of full evaluations have made
it both expensive and less effective to distinguish meaningful differences
between models. To address these challenges, we propose the \textbf{S}tructured
\textbf{T}ransition \textbf{E}valuation \textbf{M}ethod (STEM), a lightweight
and interpretable evaluation framework for efficiently estimating the relative
capabilities of LLMs. STEM identifies \textit{significant transition samples}
(STS) by analyzing consistent performance transitions among LLMs of the same
architecture but varying parameter scales. These samples enable STEM to
effectively estimate the capability position of an unknown model. Qwen3 model
family is applied to construct the STS pool on six diverse and representative
benchmarks. To assess generalizability. Experimental results indicate that STEM
reliably captures performance trends, aligns with ground-truth rankings of
model capability. These findings highlight STEM as a practical and scalable
method for fine-grained, architecture-agnostic evaluation of LLMs.

</details>


### [22] [Exploring Efficiency Frontiers of Thinking Budget in Medical Reasoning: Scaling Laws between Computational Resources and Reasoning Quality](https://arxiv.org/abs/2508.12140)
*Ziqian Bi,Lu Chen,Junhao Song,Hongying Luo,Enze Ge,Junmin Huang,Tianyang Wang,Keyu Chen,Chia Xin Liang,Zihan Wei,Huafeng Liu,Chunjie Tian,Jibin Guan,Joe Yeong,Yongzhi Xu,Peng Wang,Junfeng Hao*

Main category: cs.CL

TL;DR: 这研究首次系统评估了医学推理任务中的思考预算机制，揭示了计算资源与推理质量之间的基本缩放规律，为医疗AI系统的动态资源分配提供了关键机制。


<details>
  <summary>Details</summary>
Motivation: 为了理解计算资源与医学推理质量之间的关系，以及如何通过思考预算控制来优化医疗AI系统的性能和成本效益。

Method: 系统性评估Qwen3和DeepSeek-R1两大模型家族，涉及1.5B到235B参数范围，在15个医学数据集上进行测试。通过控制思考预算从零到无限令牌的实验，分析缩放关系和效率治理。

Result: 发现了对数缩放关系：高效率治理（0-256令牌）适用于实时应用，平衡治理（256-512令牌）提供最佳成本效益，高准确治理（>512令牌）仅适用于关键诊断任务。较小模型从扩展思考中获得更大收益（15-20%收益，大模型仅5-10%）。不同医学专业需要不同深度的推理过程。

Conclusion: 思考预算控制是优化医疗AI系统的关键机制，能够根据临床需求动态分配资源，同时保持透明性，为医疗部署提供重要支撑。

Abstract: This study presents the first comprehensive evaluation of thinking budget
mechanisms in medical reasoning tasks, revealing fundamental scaling laws
between computational resources and reasoning quality. We systematically
evaluated two major model families, Qwen3 (1.7B to 235B parameters) and
DeepSeek-R1 (1.5B to 70B parameters), across 15 medical datasets spanning
diverse specialties and difficulty levels. Through controlled experiments with
thinking budgets ranging from zero to unlimited tokens, we establish
logarithmic scaling relationships where accuracy improvements follow a
predictable pattern with both thinking budget and model size. Our findings
identify three distinct efficiency regimes: high-efficiency (0 to 256 tokens)
suitable for real-time applications, balanced (256 to 512 tokens) offering
optimal cost-performance tradeoffs for routine clinical support, and
high-accuracy (above 512 tokens) justified only for critical diagnostic tasks.
Notably, smaller models demonstrate disproportionately larger benefits from
extended thinking, with 15 to 20% improvements compared to 5 to 10% for larger
models, suggesting a complementary relationship where thinking budget provides
greater relative benefits for capacity-constrained models. Domain-specific
patterns emerge clearly, with neurology and gastroenterology requiring
significantly deeper reasoning processes than cardiovascular or respiratory
medicine. The consistency between Qwen3 native thinking budget API and our
proposed truncation method for DeepSeek-R1 validates the generalizability of
thinking budget concepts across architectures. These results establish thinking
budget control as a critical mechanism for optimizing medical AI systems,
enabling dynamic resource allocation aligned with clinical needs while
maintaining the transparency essential for healthcare deployment.

</details>


### [23] [LLM-as-a-Judge for Privacy Evaluation? Exploring the Alignment of Human and LLM Perceptions of Privacy in Textual Data](https://arxiv.org/abs/2508.12158)
*Stephen Meisenbacher,Alexandra Klymenko,Florian Matthes*

Main category: cs.CL

TL;DR: 本文探讨使用LLM作为隐私评估器的可行性，通过比较LLM与人类对文本隐私敏感度的评估，发现LLM能够准确模拟人类隐私视角，为解决隐私评估难题提供新思路。


<details>
  <summary>Details</summary>
Motivation: 隐私保护NLP领域面临隐私评估准确性的挑战，而LLM在其他NLP子领域作为评估器已取得显著成功，因此研究是否可以利用LLM-as-a-Judge范式来评估文本数据的隐私敏感性。

Method: 研究涉及10个数据集、13个LLM模型和677名人类调查参与者，通过比较LLM评估与人类隐私感知的一致性，分析人类和LLM的推理模式来评估LLM作为隐私评估器的效果。

Result: 研究发现隐私确实难以量化测量（人类间一致性较低），但LLM能够准确建模全局人类隐私视角，在隐私评估方面展现出潜力。

Conclusion: LLM作为隐私评估器具有可行性，为通过创新技术解决方案解决紧迫隐私问题提供了新的探索方向，但需要进一步讨论其优缺点和局限性。

Abstract: Despite advances in the field of privacy-preserving Natural Language
Processing (NLP), a significant challenge remains the accurate evaluation of
privacy. As a potential solution, using LLMs as a privacy evaluator presents a
promising approach $\unicode{x2013}$ a strategy inspired by its success in
other subfields of NLP. In particular, the so-called $\textit{LLM-as-a-Judge}$
paradigm has achieved impressive results on a variety of natural language
evaluation tasks, demonstrating high agreement rates with human annotators.
Recognizing that privacy is both subjective and difficult to define, we
investigate whether LLM-as-a-Judge can also be leveraged to evaluate the
privacy sensitivity of textual data. Furthermore, we measure how closely LLM
evaluations align with human perceptions of privacy in text. Resulting from a
study involving 10 datasets, 13 LLMs, and 677 human survey participants, we
confirm that privacy is indeed a difficult concept to measure empirically,
exhibited by generally low inter-human agreement rates. Nevertheless, we find
that LLMs can accurately model a global human privacy perspective, and through
an analysis of human and LLM reasoning patterns, we discuss the merits and
limitations of LLM-as-a-Judge for privacy evaluation in textual data. Our
findings pave the way for exploring the feasibility of LLMs as privacy
evaluators, addressing a core challenge in solving pressing privacy issues with
innovative technical solutions.

</details>


### [24] [Arabic Multimodal Machine Learning: Datasets, Applications, Approaches, and Challenges](https://arxiv.org/abs/2508.12227)
*Abdelhamid Haouhat,Slimane Bellaouar,Attia Nehar,Hadda Cherroun,Ahmed Abdelali*

Main category: cs.CL

TL;DR: 阿拉伯多模态机器学习综述研究，通过新的分类法对数据集、应用、方法和挑战进行系统分析，持点提出研究空白和发展机遇。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯多模态机器学习已经发展到一定成熟阶段，需要进行全面的综述性研究来整理目前的研究状况和持点指明未来方向。

Method: 采用新的分类法对现有研究进行系统分类，主要包括四个核心领域：数据集、应用场景、技术方法和面临的挑战。

Result: 提供了阿拉伯多模态机器学习领域的结构化概览，识别出了当前的研究状态、存在的研究空白和关键的研究问题。

Conclusion: 本综述为研究人员提供了建议性的研究框架，帮助他们抓住领域发展机遇并解决相关挑战，以推动阿拉伯多模态机器学习领域的进一步发展。

Abstract: Multimodal Machine Learning (MML) aims to integrate and analyze information
from diverse modalities, such as text, audio, and visuals, enabling machines to
address complex tasks like sentiment analysis, emotion recognition, and
multimedia retrieval. Recently, Arabic MML has reached a certain level of
maturity in its foundational development, making it time to conduct a
comprehensive survey. This paper explores Arabic MML by categorizing efforts
through a novel taxonomy and analyzing existing research. Our taxonomy
organizes these efforts into four key topics: datasets, applications,
approaches, and challenges. By providing a structured overview, this survey
offers insights into the current state of Arabic MML, highlighting areas that
have not been investigated and critical research gaps. Researchers will be
empowered to build upon the identified opportunities and address challenges to
advance the field.

</details>


### [25] [SEA-BED: Southeast Asia Embedding Benchmark](https://arxiv.org/abs/2508.12243)
*Wuttikorn Ponwitayarat,Raymond Ng,Jann Railey Montalan,Thura Aung,Jian Gang Ngui,Yosephine Susanto,William Tjhi,Panuthep Tasawong,Erik Cambria,Ekapol Chuangsuwanich,Sarana Nutanong,Peerat Limkonchotiwat*

Main category: cs.CL

TL;DR: 首个专门针对东南亚语言的大规模嵌入模型评测标准SEA-BED，包含169个数据集、9项任务和10种语言，71%人工构建，发现东南亚语言在嵌入模型上表现差异显著且需要人工精细数据集支持


<details>
  <summary>Details</summary>
Motivation: 东南亚地区近七亿人口但缺乏专门的嵌入模型评测标准，现有多语言标准中SEA数据集稀缺且多为机器翻译，没有反映原生语言特性

Method: 构建SEA-BED标准，包含169个数据集、9个任务类型和10种语言，其71%人工构建；评测17个嵌入模型，分析任务难度、语言差异、跨标准对比和翻译质量影响

Result: 发现模型排名显著变化，东南亚语言间表现不一致，人工精细数据集对低资源语言如缅甸语至关重要，机器翻译与人工翻译存在明显差异

Conclusion: SEA-BED填补了东南亚语言嵌入模型评估的空白，证明了语言特定标准的必要性，并强调人工构建高质量原生数据集对低资源语言NLP研究的关键作用

Abstract: Sentence embeddings are essential for NLP tasks such as semantic search,
re-ranking, and textual similarity. Although multilingual benchmarks like MMTEB
broaden coverage, Southeast Asia (SEA) datasets are scarce and often
machine-translated, missing native linguistic properties. With nearly 700
million speakers, the SEA region lacks a region-specific embedding benchmark.
We introduce SEA-BED, the first large-scale SEA embedding benchmark with 169
datasets across 9 tasks and 10 languages, where 71% are formulated by humans,
not machine generation or translation. We address three research questions: (1)
which SEA languages and tasks are challenging, (2) whether SEA languages show
unique performance gaps globally, and (3) how human vs. machine translations
affect evaluation. We evaluate 17 embedding models across six studies,
analyzing task and language challenges, cross-benchmark comparisons, and
translation trade-offs. Results show sharp ranking shifts, inconsistent model
performance among SEA languages, and the importance of human-curated datasets
for low-resource languages like Burmese.

</details>


### [26] [What do Speech Foundation Models Learn? Analysis and Applications](https://arxiv.org/abs/2508.12255)
*Ankita Pasad*

Main category: cs.CL

TL;DR: 这篇论文提出了一种轻量级分析框架，用于研究语音基础模型（SFMs）编码的音响和语言知识，并为口语语言理解任务提供了新的数据集和评估方法。


<details>
  <summary>Details</summary>
Motivation: 虽然语音基础模型发展快速，但我们对其所获得知识的理解迟迟迟后。同时，对需要深层理解的口语语言理解任务的研究仍然有限，主要因为缺乏相关数据集。

Method: 使用统计工具和无需训练的任务构建轻量级分析框架，对多个SFM模型进行比较研究。同时为口语语言理解评测提供了命名实体识别和命名实体定位任务，并开发了基于SFM的端到端模型。

Result: 分析结果显示了对下游任务性能的具体含义。端到端模型在命名实体识别和定位任务上超越了传统的流水线方法（语音识别+文本模型）。

Conclusion: 本论文解决了关于SFM的之前未解决问题，为社区提供了分析工具和数据集，以便在未来模型开发和采用中做出明智的设计选择。

Abstract: Speech foundation models (SFMs) are designed to serve as general-purpose
representations for a wide range of speech-processing tasks. The last five
years have seen an influx of increasingly successful self-supervised and
supervised pre-trained models with impressive performance on various downstream
tasks.
  Although the zoo of SFMs continues to grow, our understanding of the
knowledge they acquire lags behind. This thesis presents a lightweight analysis
framework using statistical tools and training-free tasks to investigate the
acoustic and linguistic knowledge encoded in SFM layers. We conduct a
comparative study across multiple SFMs and statistical tools. Our study also
shows that the analytical insights have concrete implications for downstream
task performance.
  The effectiveness of an SFM is ultimately determined by its performance on
speech applications. Yet it remains unclear whether the benefits extend to
spoken language understanding (SLU) tasks that require a deeper understanding
than widely studied ones, such as speech recognition. The limited exploration
of SLU is primarily due to a lack of relevant datasets. To alleviate that, this
thesis contributes tasks, specifically spoken named entity recognition (NER)
and named entity localization (NEL), to the Spoken Language Understanding
Evaluation benchmark. We develop SFM-based approaches for NER and NEL, and find
that end-to-end (E2E) models leveraging SFMs can surpass traditional cascaded
(speech recognition followed by a text model) approaches. Further, we evaluate
E2E SLU models across SFMs and adaptation strategies to assess the impact on
task performance.
  Collectively, this thesis tackles previously unanswered questions about SFMs,
providing tools and datasets to further our understanding and to enable the
community to make informed design choices for future model development and
adoption.

</details>


### [27] [Structuring the Unstructured: A Systematic Review of Text-to-Structure Generation for Agentic AI with a Universal Evaluation Framework](https://arxiv.org/abs/2508.12257)
*Zheye Deng,Chunkit Chan,Tianshi Zheng,Wei Fan,Weiqi Wang,Yangqiu Song*

Main category: cs.CL

TL;DR: 本文对文本到结构化转换技术进行了系统性综述，分析了方法、数据集和评估指标，并提出了通用评估框架。


<details>
  <summary>Details</summary>
Motivation: AI系统向代理操作和上下文感知检索发展需要将非结构化文本转换为表格、知识图谱和图表等结构化格式，但当前研究缺乏对方法、数据集和指标的综合分析。

Method: 采用系统性文献综述方法，分析文本到结构转换技术，评估现有数据集和评估标准。

Result: 建立了文本到结构化输出的通用评估框架，确认文本到结构转换作为下一代AI系统的基础设施地位。

Conclusion: 文本到结构转换是AI系统发展的关键技术，需要进一步研究方法来应对现有挑战并推动该领域发展。

Abstract: The evolution of AI systems toward agentic operation and context-aware
retrieval necessitates transforming unstructured text into structured formats
like tables, knowledge graphs, and charts. While such conversions enable
critical applications from summarization to data mining, current research lacks
a comprehensive synthesis of methodologies, datasets, and metrics. This
systematic review examines text-to-structure techniques and the encountered
challenges, evaluates current datasets and assessment criteria, and outlines
potential directions for future research. We also introduce a universal
evaluation framework for structured outputs, establishing text-to-structure as
foundational infrastructure for next-generation AI systems.

</details>


### [28] [Fast, Slow, and Tool-augmented Thinking for LLMs: A Review](https://arxiv.org/abs/2508.12265)
*Xinda Jia,Jinpeng Li,Zezhong Wang,Jingjing Li,Xingshan Zeng,Yasheng Wang,Weinan Zhang,Yong Yu,Weiwen Liu*

Main category: cs.CL

TL;DR: 这篇论文提出了一种基于认知心理学的LLM推理策略分类法，通过快慢边界和内外边界来系统分析大语言模型的适应性推理方法。


<details>
  <summary>Details</summary>
Motivation: 实际任务中需要根据问题需求适应地选择推理策略，从快速直觉到步骤式推理和工具增强思维，但缺乏系统的分类框架。

Method: 提出了一种新的分类法：通过快慢边界（直觉与沉思过程）和内外边界（模型参数内部推理与外部工具增强）来系统分析LLM推理策略。对最新的适应性推理研究进行了系统性调查和分类。

Result: 建立了一个系统的LLM推理策略分类框架，并基于关键决策因素对方法进行了分类。详细的调查结果需要查看论文完整内容。

Conclusion: 提出了开放性挑战和未来研究方向，以促进更适应、高效和可靠的大语言模型发展。

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in
reasoning across diverse domains. However, effective reasoning in real-world
tasks requires adapting the reasoning strategy to the demands of the problem,
ranging from fast, intuitive responses to deliberate, step-by-step reasoning
and tool-augmented thinking. Drawing inspiration from cognitive psychology, we
propose a novel taxonomy of LLM reasoning strategies along two knowledge
boundaries: a fast/slow boundary separating intuitive from deliberative
processes, and an internal/external boundary distinguishing reasoning grounded
in the model's parameters from reasoning augmented by external tools. We
systematically survey recent work on adaptive reasoning in LLMs and categorize
methods based on key decision factors. We conclude by highlighting open
challenges and future directions toward more adaptive, efficient, and reliable
LLMs.

</details>


### [29] [The Self-Execution Benchmark: Measuring LLMs' Attempts to Overcome Their Lack of Self-Execution](https://arxiv.org/abs/2508.12277)
*Elon Ezra,Ariel Weizman,Amos Azaria*

Main category: cs.CL

TL;DR: 这篇论文探索了大语言模型预测自身响应的能力，通过自我执行测试发现模型表现差强且模型规模增加不能提升性能


<details>
  <summary>Details</summary>
Motivation: 当前对LLM的评估主要集中在知识和推理能力上，本文想要探索一种不同的评估方式：模型是否能预测自身的响应特性

Method: 引入了自我执行测试(SEB)，测量模型预测其输出特性的能力，包括问题难度预测、拒绝回答预测、联想倾向预测等

Result: 模型在该测试上表现普遍较差，模型规模或能力的提升并不能持续改善性能

Conclusion: 这些结果表明LLM在表征和推理自身行为方面存在根本性的限制

Abstract: Large language models (LLMs) are commonly evaluated on tasks that test their
knowledge or reasoning abilities. In this paper, we explore a different type of
evaluation: whether an LLM can predict aspects of its own responses. Since LLMs
lack the ability to execute themselves, we introduce the Self-Execution
Benchmark, which measures a model's ability to anticipate properties of its
output, such as whether a question will be difficult for it, whether it will
refuse to answer, or what kinds of associations it is likely to produce. Our
experiments show that models generally perform poorly on this benchmark, and
that increased model size or capability does not consistently lead to better
performance. These results suggest a fundamental limitation in how LLMs
represent and reason about their own behavior.

</details>


### [30] [Legal$Δ$: Enhancing Legal Reasoning in LLMs via Reinforcement Learning with Chain-of-Thought Guided Information Gain](https://arxiv.org/abs/2508.12281)
*Xin Dai,Buqiang Xu,Zhenghao Liu,Yukun Yan,Huiyuan Xie,Xiaoyuan Yi,Shuo Wang,Ge Yu*

Main category: cs.CL

TL;DR: LegalΔ是一个强化学习框架，通过思维链引导的信息增益来增强法律推理能力，在准确性和可解释性方面优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有法律大语言模型在生成可靠和可解释的推理过程方面存在困难，往往产生直接答案而缺乏多步推理，限制了在复杂法律场景中的有效性。

Method: 采用双模式输入设置（直接答案模式和推理增强模式），最大化两者间的信息增益；两阶段方法：1)从DeepSeek-R1提取潜在推理能力，2)通过差异比较和多维奖励机制（评估结构连贯性和法律领域特异性）精炼推理质量。

Result: 在多个法律推理任务上的实验结果表明，LegalΔ在准确性和可解释性方面均优于强基线模型，能够产生更稳健和可信的法律判断，且不依赖标注的偏好数据。

Conclusion: LegalΔ框架通过强化学习和信息增益机制有效提升了法律AI的推理能力和可解释性，为复杂法律场景提供了更可靠的自动化决策支持。

Abstract: Legal Artificial Intelligence (LegalAI) has achieved notable advances in
automating judicial decision-making with the support of Large Language Models
(LLMs). However, existing legal LLMs still struggle to generate reliable and
interpretable reasoning processes. They often default to fast-thinking behavior
by producing direct answers without explicit multi-step reasoning, limiting
their effectiveness in complex legal scenarios that demand rigorous
justification. To address this challenge, we propose Legal$\Delta$, a
reinforcement learning framework designed to enhance legal reasoning through
chain-of-thought guided information gain. During training, Legal$\Delta$
employs a dual-mode input setup-comprising direct answer and
reasoning-augmented modes-and maximizes the information gain between them. This
encourages the model to acquire meaningful reasoning patterns rather than
generating superficial or redundant explanations. Legal$\Delta$ follows a
two-stage approach: (1) distilling latent reasoning capabilities from a
powerful Large Reasoning Model (LRM), DeepSeek-R1, and (2) refining reasoning
quality via differential comparisons, combined with a multidimensional reward
mechanism that assesses both structural coherence and legal-domain specificity.
Experimental results on multiple legal reasoning tasks demonstrate that
Legal$\Delta$ outperforms strong baselines in both accuracy and
interpretability. It consistently produces more robust and trustworthy legal
judgments without relying on labeled preference data. All code and data will be
released at https://github.com/NEUIR/LegalDelta.

</details>


### [31] [A Question Answering Dataset for Temporal-Sensitive Retrieval-Augmented Generation](https://arxiv.org/abs/2508.12282)
*Ziyang Chen,Erxue Min,Xiang Zhao,Yunxin Li,Xin Jia,Jinzhi Liao,Jichao Li,Shuaiqiang Wang,Baotian Hu,Dawei Yin*

Main category: cs.CL

TL;DR: ChronoQA是一个大规模中文问答基准数据集，专门用于评估检索增强生成(RAG)系统中的时间推理能力，包含5,176个高质量问题，覆盖多种时间类型和表达方式。


<details>
  <summary>Details</summary>
Motivation: 现有的问答数据集在时间推理方面存在不足，需要专门针对中文RAG系统的时间敏感性评估基准，以反映现实世界中对时间对齐和逻辑一致性的需求。

Method: 从2019-2024年的30多万篇新闻文章中构建数据集，包含绝对、聚合和相对时间类型的问题，支持单文档和多文档场景，采用规则、LLM和人工多阶段验证确保数据质量。

Result: 创建了一个动态、可靠且可扩展的ChronoQA数据集，具有全面的结构标注，能够支持广泛时间任务的结构化评估。

Conclusion: ChronoQA为推进时间敏感的检索增强问答系统提供了强大的基准资源，能够有效评估RAG系统的时间推理能力。

Abstract: We introduce ChronoQA, a large-scale benchmark dataset for Chinese question
answering, specifically designed to evaluate temporal reasoning in
Retrieval-Augmented Generation (RAG) systems. ChronoQA is constructed from over
300,000 news articles published between 2019 and 2024, and contains 5,176
high-quality questions covering absolute, aggregate, and relative temporal
types with both explicit and implicit time expressions. The dataset supports
both single- and multi-document scenarios, reflecting the real-world
requirements for temporal alignment and logical consistency. ChronoQA features
comprehensive structural annotations and has undergone multi-stage validation,
including rule-based, LLM-based, and human evaluation, to ensure data quality.
By providing a dynamic, reliable, and scalable resource, ChronoQA enables
structured evaluation across a wide range of temporal tasks, and serves as a
robust benchmark for advancing time-sensitive retrieval-augmented question
answering systems.

</details>


### [32] [Incorporating Legal Logic into Deep Learning: An Intelligent Approach to Probation Prediction](https://arxiv.org/abs/2508.12286)
*Qinghua Wang,Xu Zhang,Lingyan Yang,Rui Shao,Bonan Wang,Fang Wang,Cunquan Qu*

Main category: cs.CL

TL;DR: 提出了一种将法律逻辑融入深度学习模型的新方法，用于缓刑预测，通过构建专业数据集和基于双轨惩罚理论的多任务模型，在性能和可解释性方面都优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前智能司法辅助系统缺乏专门的缓刑预测方法，现有研究主要依赖数据驱动方法而忽视了司法决策的法律逻辑基础，需要同时考虑犯罪情节和悔罪表现的综合分析。

Method: 三阶段方法：1)构建包含事实描述和缓刑法律要素的专业数据集；2)基于缓刑法律逻辑和双轨惩罚理论设计多任务双理论缓刑预测模型(MT-DT)；3)在数据集上进行实验验证。

Result: MT-DT模型在缓刑数据集上表现优于基线模型，对底层法律逻辑的分析进一步验证了所提方法的有效性。

Conclusion: 将法律逻辑融入深度学习模型的方法能够有效提升缓刑预测的准确性和可解释性，为智能司法辅助系统提供了更符合司法实践的技术方案。

Abstract: Probation is a crucial institution in modern criminal law, embodying the
principles of fairness and justice while contributing to the harmonious
development of society. Despite its importance, the current Intelligent
Judicial Assistant System (IJAS) lacks dedicated methods for probation
prediction, and research on the underlying factors influencing probation
eligibility remains limited. In addition, probation eligibility requires a
comprehensive analysis of both criminal circumstances and remorse. Much of the
existing research in IJAS relies primarily on data-driven methodologies, which
often overlooks the legal logic underpinning judicial decision-making. To
address this gap, we propose a novel approach that integrates legal logic into
deep learning models for probation prediction, implemented in three distinct
stages. First, we construct a specialized probation dataset that includes fact
descriptions and probation legal elements (PLEs). Second, we design a distinct
probation prediction model named the Multi-Task Dual-Theory Probation
Prediction Model (MT-DT), which is grounded in the legal logic of probation and
the \textit{Dual-Track Theory of Punishment}. Finally, our experiments on the
probation dataset demonstrate that the MT-DT model outperforms baseline models,
and an analysis of the underlying legal logic further validates the
effectiveness of the proposed approach.

</details>


### [33] [Consensus or Conflict? Fine-Grained Evaluation of Conflicting Answers in Question-Answering](https://arxiv.org/abs/2508.12355)
*Eviatar Nachshoni,Arie Cattan,Shmuel Amar,Ori Shapira,Ido Dagan*

Main category: cs.CL

TL;DR: 提出了NATCONFQA基准测试，用于评估LLM在多答案问答任务中处理冲突答案的能力，发现现有模型在冲突处理方面存在脆弱性。


<details>
  <summary>Details</summary>
Motivation: 多答案问答任务中可能存在冲突答案，传统QA假设证据一致性，但构建包含真实冲突的数据集成本高且劳动密集，现有基准多依赖合成数据或自动标注，不够可靠。

Method: 扩展冲突感知的MAQA设置，要求模型不仅识别所有有效答案，还要检测特定冲突答案对；利用事实核查数据集构建NATCONFQA基准，包含详细冲突标签。

Result: 评估了8个高端LLM，发现它们在处理各类冲突时表现脆弱，并采用了有缺陷的解决策略。

Conclusion: LLM在多答案冲突处理方面存在明显不足，需要开发更有效的冲突检测和解决机制，NATCONFQA为相关研究提供了可靠的基准测试。

Abstract: Large Language Models (LLMs) have demonstrated strong performance in question
answering (QA) tasks. However, Multi-Answer Question Answering (MAQA), where a
question may have several valid answers, remains challenging. Traditional QA
settings often assume consistency across evidences, but MAQA can involve
conflicting answers. Constructing datasets that reflect such conflicts is
costly and labor-intensive, while existing benchmarks often rely on synthetic
data, restrict the task to yes/no questions, or apply unverified automated
annotation. To advance research in this area, we extend the conflict-aware MAQA
setting to require models not only to identify all valid answers, but also to
detect specific conflicting answer pairs, if any. To support this task, we
introduce a novel cost-effective methodology for leveraging fact-checking
datasets to construct NATCONFQA, a new benchmark for realistic, conflict-aware
MAQA, enriched with detailed conflict labels, for all answer pairs. We evaluate
eight high-end LLMs on NATCONFQA, revealing their fragility in handling various
types of conflicts and the flawed strategies they employ to resolve them.

</details>


### [34] [ReaLM: Reflection-Enhanced Autonomous Reasoning with Small Language Models](https://arxiv.org/abs/2508.12387)
*Yuanfeng Xu,Zehui Dai,Jian Liang,Jiapeng Guan,Guangrun Wang,Liang Lin,Xiaohui Lv*

Main category: cs.CL

TL;DR: ReaLM是一个强化学习框架，通过多路径验证、渐进自主学习和知识蒸馏，提升小语言模型在垂直领域的推理能力、自主性和泛化性


<details>
  <summary>Details</summary>
Motivation: 现有小语言模型在复杂推理中存在能力不足、依赖外部指导、泛化性差的问题，需要一种能够同时提升推理能力、自主性和泛化性的方法

Method: 提出ReaLM框架：1）MRPV多路径过程验证对比正负推理路径；2）EAAI渐进自主学习逐步减少外部信号依赖；3）引导式思维链蒸馏编码领域知识

Result: 在垂直领域和通用推理任务上的大量实验表明，ReaLM显著提升了小语言模型在推理能力、自主性和泛化性三个方面的性能

Conclusion: ReaLM框架有效解决了小语言模型在复杂推理中的核心挑战，为垂直领域应用提供了强大而经济的解决方案

Abstract: Small Language Models (SLMs) are a cost-effective alternative to Large
Language Models (LLMs), but often struggle with complex reasoning due to their
limited capacity and a tendency to produce mistakes or inconsistent answers
during multi-step reasoning. Existing efforts have improved SLM performance,
but typically at the cost of one or more of three key aspects: (1) reasoning
capability, due to biased supervision that filters out negative reasoning paths
and limits learning from errors; (2) autonomy, due to over-reliance on
externally generated reasoning signals; and (3) generalization, which suffers
when models overfit to teacher-specific patterns. In this paper, we introduce
ReaLM, a reinforcement learning framework for robust and self-sufficient
reasoning in vertical domains. To enhance reasoning capability, we propose
Multi-Route Process Verification (MRPV), which contrasts both positive and
negative reasoning paths to extract decisive patterns. To reduce reliance on
external guidance and improve autonomy, we introduce Enabling Autonomy via
Asymptotic Induction (EAAI), a training strategy that gradually fades external
signals. To improve generalization, we apply guided chain-of-thought
distillation to encode domain-specific rules and expert knowledge into SLM
parameters, making them part of what the model has learned. Extensive
experiments on both vertical and general reasoning tasks demonstrate that ReaLM
significantly improves SLM performance across aspects (1)-(3) above.

</details>


### [35] [MedKGent: A Large Language Model Agent Framework for Constructing Temporally Evolving Medical Knowledge Graph](https://arxiv.org/abs/2508.12393)
*Duzhen Zhang,Zixiao Wang,Zhong-Zhi Li,Yahan Yu,Shuncheng Jia,Jiahua Dong,Haotian Xu,Xing Wu,Yingying Zhang,Tielin Zhang,Jie Yang,Xiuying Chen,Le Song*

Main category: cs.CL

TL;DR: MedKGent是一个基于LLM代理的框架，用于构建时间演化的医学知识图谱，通过提取和构建代理处理PubMed摘要，生成高质量、时间感知的医学KG，在多个下游任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前知识图谱构建方法存在泛化性有限、忽视时间动态性和上下文不确定性的问题，需要一种能够处理医学知识演化的自动化构建框架。

Method: 使用Qwen2.5-32B-Instruct模型驱动的两个专门代理：提取代理通过采样估计置信度识别知识三元组，构建代理基于置信度和时间戳增量整合三元组到时间演化图谱中。

Result: 构建了包含156,275个实体和2,971,384个关系三元组的KG，准确率接近90%，在7个医学问答基准测试中显著优于非增强基线。

Conclusion: MedKGent成功构建了高质量的时间演化医学知识图谱，展示了在药物重定位等下游应用中的实用价值，为大规模医学知识管理提供了有效解决方案。

Abstract: The rapid expansion of medical literature presents growing challenges for
structuring and integrating domain knowledge at scale. Knowledge Graphs (KGs)
offer a promising solution by enabling efficient retrieval, automated
reasoning, and knowledge discovery. However, current KG construction methods
often rely on supervised pipelines with limited generalizability or naively
aggregate outputs from Large Language Models (LLMs), treating biomedical
corpora as static and ignoring the temporal dynamics and contextual uncertainty
of evolving knowledge. To address these limitations, we introduce MedKGent, a
LLM agent framework for constructing temporally evolving medical KGs.
Leveraging over 10 million PubMed abstracts published between 1975 and 2023, we
simulate the emergence of biomedical knowledge via a fine-grained daily time
series. MedKGent incrementally builds the KG in a day-by-day manner using two
specialized agents powered by the Qwen2.5-32B-Instruct model. The Extractor
Agent identifies knowledge triples and assigns confidence scores via
sampling-based estimation, which are used to filter low-confidence extractions
and inform downstream processing. The Constructor Agent incrementally
integrates the retained triples into a temporally evolving graph, guided by
confidence scores and timestamps to reinforce recurring knowledge and resolve
conflicts. The resulting KG contains 156,275 entities and 2,971,384 relational
triples. Quality assessments by two SOTA LLMs and three domain experts
demonstrate an accuracy approaching 90\%, with strong inter-rater agreement. To
evaluate downstream utility, we conduct RAG across seven medical question
answering benchmarks using five leading LLMs, consistently observing
significant improvements over non-augmented baselines. Case studies further
demonstrate the KG's value in literature-based drug repurposing via
confidence-aware causal inference.

</details>


### [36] [Extracting Post-Acute Sequelae of SARS-CoV-2 Infection Symptoms from Clinical Notes via Hybrid Natural Language Processing](https://arxiv.org/abs/2508.12405)
*Zilong Bai,Zihan Xu,Cong Sun,Chengxi Zang,H. Timothy Bunnell,Catherine Sinfield,Jacqueline Rutter,Aaron Thomas Martinez,L. Charles Bailey,Mark Weiner,Thomas R. Campion,Thomas Carton,Christopher B. Forrest,Rainu Kaushal,Fei Wang,Yifan Peng*

Main category: cs.CL

TL;DR: 一种混合自然语言处理流水线，结合规则基于命名实体识别和BERT基于断言检测，用于从临床笔记中提取COVID-19后遗症状的有效识别和断言检测。


<details>
  <summary>Details</summary>
Motivation: 准确有效诊断COVID-19后遗症(PASC)面临挑战，因为其症状多样且随时间变化，需要一种能够处理大量临床笔记的自动化方法。

Method: 开发了混合NLP流水线，集成规则基于命名实体识别和BERT基于断言检测模块，使用专业医生开发的全面PASC词典，基于美国11个健康系统的160份进展笔记进行模型开发和评估。

Result: 在断言检测中获得内部验证平均F1分0.82，外部验证平均F1分0.76，每份笔记处理时间仅需2.448秒，相关性测试显示高度显著相关(ρ>0.83正面提及，ρ>0.72负面提及，P<0.0001)。

Conclusion: 该模型显示了在PASC诊断中的有效性和效率，为改善PASC诊断提供了潜力。

Abstract: Accurately and efficiently diagnosing Post-Acute Sequelae of COVID-19 (PASC)
remains challenging due to its myriad symptoms that evolve over long- and
variable-time intervals. To address this issue, we developed a hybrid natural
language processing pipeline that integrates rule-based named entity
recognition with BERT-based assertion detection modules for PASC-symptom
extraction and assertion detection from clinical notes. We developed a
comprehensive PASC lexicon with clinical specialists. From 11 health systems of
the RECOVER initiative network across the U.S., we curated 160 intake progress
notes for model development and evaluation, and collected 47,654 progress notes
for a population-level prevalence study. We achieved an average F1 score of
0.82 in one-site internal validation and 0.76 in 10-site external validation
for assertion detection. Our pipeline processed each note at $2.448\pm 0.812$
seconds on average. Spearman correlation tests showed $\rho >0.83$ for positive
mentions and $\rho >0.72$ for negative ones, both with $P <0.0001$. These
demonstrate the effectiveness and efficiency of our models and their potential
for improving PASC diagnosis.

</details>


### [37] [ZigzagAttention: Efficient Long-Context Inference with Exclusive Retrieval and Streaming Heads](https://arxiv.org/abs/2508.12407)
*Zhuorui Liu,Chen Zhang,Dawei Song*

Main category: cs.CL

TL;DR: ZigzagAttention通过将注意力头按层分类为检索头或流式头，优化KV缓存内存占用，减少延迟同时保持性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型处理长上下文时KV缓存消耗巨大，现有方法通过区分重要检索头和不重要流式头来优化内存，但混合头类型会导致额外的张量访问延迟

Method: 设计新标准强制每层只包含检索头或流式头，避免混合头带来的额外延迟，实现KV缓存优化

Result: 显著减少延迟，性能损失可忽略，在基准测试中表现竞争力

Conclusion: 按层分类注意力头的方法能有效优化KV缓存，在减少延迟的同时保持模型性能

Abstract: With the rapid development of large language models (LLMs), handling long
context has become one of the vital abilities in LLMs. Such long-context
ability is accompanied by difficulties in deployment, especially due to the
increased consumption of KV cache. There is certain work aiming to optimize the
memory footprint of KV cache, inspired by the observation that attention heads
can be categorized into retrieval heads that are of great significance and
streaming heads that are of less significance. Typically, identifying the
streaming heads and and waiving the KV cache in the streaming heads would
largely reduce the overhead without hurting the performance that much. However,
since employing both retrieval and streaming heads in one layer decomposes one
large round of attention computation into two small ones, it may unexpectedly
bring extra latency on accessing and indexing tensors. Based on this intuition,
we impose an important improvement to the identification process of retrieval
and streaming heads, in which we design a criterion that enforces exclusively
retrieval or streaming heads gathered in one unique layer. In this way, we
further eliminate the extra latency and only incur negligible performance
degradation. Our method named \textsc{ZigzagAttention} is competitive among
considered baselines owing to reduced latency and comparable performance.

</details>


### [38] [The Cultural Gene of Large Language Models: A Study on the Impact of Cross-Corpus Training on Model Values and Biases](https://arxiv.org/abs/2508.12411)
*Emanuel Z. Fenech-Borg,Tilen P. Meznaric-Kos,Milica D. Lekovic-Bojovic,Arni J. Hentze-Djurhuus*

Main category: cs.CL

TL;DR: 这篇论文探索了大语言模型的文化偏向，通过文化挖掘数据集对比GPT-4和ERNIE Bot，发现西方模型呈现个人主义和低权力距离特征，而东方模型呈现集体主义和高权力距离特征


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型全球部署，但其基础文化和伦理偏向很少被探索，需要研究LLMs如何继承训练语料库的系统性价值观式

Method: 提出"文化基因"概念，构建包含200个提示的文化挖掘数据集(CPD)，重点考察个人主义-集体主义(IDV)和权力距离(PDI)两个文化维度，使用标准化零样本提示比较GPT-4和ERNIE Bot

Result: 人工标注显示两个模型在两个维度上都存在显著和一致的分异：GPT-4呈现个人主义(IDV约1.21)和低权力距离(PDI约-1.05)倾向，ERNIE Bot呈现集体主义(IDV约-0.89)和高权力距离(PDI约0.76)倾向，差异统计显著(p<0.001)，文化对齐指数显示GPT-4更接近美国，ERNIE Bot更接近中国

Conclusion: 大语言模型作为其文化语料库的统计镜像，具有明显的文化偏向，需要文化意识的评估和部署以避免算法文化霸权

Abstract: Large language models (LLMs) are deployed globally, yet their underlying
cultural and ethical assumptions remain underexplored. We propose the notion of
a "cultural gene" -- a systematic value orientation that LLMs inherit from
their training corpora -- and introduce a Cultural Probe Dataset (CPD) of 200
prompts targeting two classic cross-cultural dimensions:
Individualism-Collectivism (IDV) and Power Distance (PDI). Using standardized
zero-shot prompts, we compare a Western-centric model (GPT-4) and an
Eastern-centric model (ERNIE Bot). Human annotation shows significant and
consistent divergence across both dimensions. GPT-4 exhibits individualistic
and low-power-distance tendencies (IDV score approx 1.21; PDI score approx
-1.05), while ERNIE Bot shows collectivistic and higher-power-distance
tendencies (IDV approx -0.89; PDI approx 0.76); differences are statistically
significant (p < 0.001). We further compute a Cultural Alignment Index (CAI)
against Hofstede's national scores and find GPT-4 aligns more closely with the
USA (e.g., IDV CAI approx 0.91; PDI CAI approx 0.88) whereas ERNIE Bot aligns
more closely with China (IDV CAI approx 0.85; PDI CAI approx 0.81). Qualitative
analyses of dilemma resolution and authority-related judgments illustrate how
these orientations surface in reasoning. Our results support the view that LLMs
function as statistical mirrors of their cultural corpora and motivate
culturally aware evaluation and deployment to avoid algorithmic cultural
hegemony.

</details>


### [39] [Uncovering Emergent Physics Representations Learned In-Context by Large Language Models](https://arxiv.org/abs/2508.12448)
*Yeongwoo Song,Jaeyong Bae,Dong-Kyum Kim,Hawoong Jeong*

Main category: cs.CL

TL;DR: 这篇论文通过物理任务探索大语言模型的上下文学习能力，发现模型在长上下文中能够学习物理概念并编码关键物理变量。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在上下文学习方面表现突出，但其内部机制仍不明确。物理任务提供了基于基础原理的结构化动态数据，适合探索LLM的出现性推理行为。

Method: 使用物理系统动态预测任务作为代理，逐步增加输入上下文长度来评估模型性能。通过稀疏自编码器(SAEs)分析模型激活状态，识别与物理变量相关的特征。

Result: 动态预测性能随着上下文长度增加而提升。SAEs捕获的特征与能量等关键物理变量呈现显著相关性，证明LLM在上下文学习过程中编码了有意义的物理概念。

Conclusion: 该研究为理解LLM如何进行上下文学习提供了新的案例研究，扩展了我们对大语言模型在现实任务中学习概念机制的认知。

Abstract: Large language models (LLMs) exhibit impressive in-context learning (ICL)
abilities, enabling them to solve wide range of tasks via textual prompts
alone. As these capabilities advance, the range of applicable domains continues
to expand significantly. However, identifying the precise mechanisms or
internal structures within LLMs that allow successful ICL across diverse,
distinct classes of tasks remains elusive. Physics-based tasks offer a
promising testbed for probing this challenge. Unlike synthetic sequences such
as basic arithmetic or symbolic equations, physical systems provide
experimentally controllable, real-world data based on structured dynamics
grounded in fundamental principles. This makes them particularly suitable for
studying the emergent reasoning behaviors of LLMs in a realistic yet tractable
setting. Here, we mechanistically investigate the ICL ability of LLMs,
especially focusing on their ability to reason about physics. Using a dynamics
forecasting task in physical systems as a proxy, we evaluate whether LLMs can
learn physics in context. We first show that the performance of dynamics
forecasting in context improves with longer input contexts. To uncover how such
capability emerges in LLMs, we analyze the model's residual stream activations
using sparse autoencoders (SAEs). Our experiments reveal that the features
captured by SAEs correlate with key physical variables, such as energy. These
findings demonstrate that meaningful physical concepts are encoded within LLMs
during in-context learning. In sum, our work provides a novel case study that
broadens our understanding of how LLMs learn in context.

</details>


### [40] [M3PO: Multimodal-Model-Guided Preference Optimization for Visual Instruction Following](https://arxiv.org/abs/2508.12458)
*Ruirui Gao,Emily Johnson,Bowen Tan,Yanfei Qian*

Main category: cs.CL

TL;DR: 通过智能选择多模态生成的高质量偏好对进行敏感学习，M3PO方法在低成本下显著提升大视觉-语言模型的指令追随能力


<details>
  <summary>Details</summary>
Motivation: 解决大视觉-语言模型开发中人工注释成本高、一致性差的问题，以及传统SFT和偏好优化方法无法高效利用模型自身生成空间识别难样本的挑战

Method: 提出M3PO方法，通过多模态对齐分数(MAS)和模型自身一致性/信心度维度，组合成M3P-Score，智能选择最有学习价值的偏好对进行DPO精细调整

Result: 在多模态指令追随测试集(MME-Bench, POPE, IFT, 人类偏好分数)上持续超越SFT、模拟RLHF、普通DPO和RM-DPO等基线方法

Conclusion: M3PO为LVLMs提供了一种数据高效、成本低廉的偏好优化方案，通过智能样本选择机制显著提升了模型的多模态指令追随能力

Abstract: Large Vision-Language Models (LVLMs) hold immense potential for complex
multimodal instruction following, yet their development is often hindered by
the high cost and inconsistency of human annotation required for effective
fine-tuning and preference alignment. Traditional supervised fine-tuning (SFT)
and existing preference optimization methods like RLHF and DPO frequently
struggle to efficiently leverage the model's own generation space to identify
highly informative "hard negative" samples. To address these challenges, we
propose Multimodal-Model-Guided Preference Optimization (M3PO), a novel and
data-efficient method designed to enhance LVLMs' capabilities in visual
instruction following. M3PO intelligently selects the most "learning-valuable"
preference sample pairs from a diverse pool of LVLM-generated candidates. This
selection is driven by a sophisticated mechanism that integrates two crucial
signals: a Multimodal Alignment Score (MAS) to assess external quality and the
model's Self-Consistency / Confidence (log-probability) to gauge internal
belief. These are combined into a novel M3P-Score, which specifically
identifies preferred responses and challenging dispreferred responses that the
model might confidently generate despite being incorrect. These high-quality
preference pairs are then used for efficient Direct Preference Optimization
(DPO) fine-tuning on base LVLMs like LLaVA-1.5 (7B/13B) using LoRA. Our
extensive experiments demonstrate that M3PO consistently outperforms strong
baselines, including SFT, simulated RLHF, vanilla DPO, and RM-DPO, across a
comprehensive suite of multimodal instruction following benchmarks (MME-Bench,
POPE, IFT, Human Pref. Score).

</details>


### [41] [LoraxBench: A Multitask, Multilingual Benchmark Suite for 20 Indonesian Languages](https://arxiv.org/abs/2508.12459)
*Alham Fikri Aji,Trevor Cohn*

Main category: cs.CL

TL;DR: LoraxBench是一个针对印尼低资源语言的基准测试，涵盖6个任务和20种语言，发现多语言模型在印尼低资源语言上表现存在明显差距，且语域变化显著影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 印尼作为世界人口大国，拥有700种语言，但在NLP领域进展相对落后，需要专门的基准测试来评估低资源语言处理能力。

Method: 构建LoraxBench基准测试，包含阅读理解、开放域问答、语言推理、因果推理、翻译和文化问答6个任务，覆盖20种印尼语言，并为3种语言添加两种正式度语域。

Result: 基准测试具有挑战性，印尼语与其他低资源语言性能存在明显差距，区域特定模型与通用多语言模型相比没有明显优势，语域变化（特别是社交媒体中不常见的高级礼貌语域）显著影响模型表现。

Conclusion: 印尼低资源语言NLP仍面临重大挑战，需要更多针对性的研究和模型优化，特别是在处理不同语域和低资源语言方面。

Abstract: As one of the world's most populous countries, with 700 languages spoken,
Indonesia is behind in terms of NLP progress. We introduce LoraxBench, a
benchmark that focuses on low-resource languages of Indonesia and covers 6
diverse tasks: reading comprehension, open-domain QA, language inference,
causal reasoning, translation, and cultural QA. Our dataset covers 20
languages, with the addition of two formality registers for three languages. We
evaluate a diverse set of multilingual and region-focused LLMs and found that
this benchmark is challenging. We note a visible discrepancy between
performance in Indonesian and other languages, especially the low-resource
ones. There is no clear lead when using a region-specific model as opposed to
the general multilingual model. Lastly, we show that a change in register
affects model performance, especially with registers not commonly found in
social media, such as high-level politeness `Krama' Javanese.

</details>


### [42] [Is GPT-OSS Good? A Comprehensive Evaluation of OpenAI's Latest Open Source Models](https://arxiv.org/abs/2508.12461)
*Ziqian Bi,Keyu Chen,Chiung-Yi Tseng,Danyang Zhang,Tianyang Wang,Hongying Luo,Lu Chen,Junming Huang,Jibin Guan,Junfeng Hao,Junhao Song*

Main category: cs.CL

TL;DR: OpenAI发布GPT-OSS开源大模型（20B和120B参数），评估显示较小模型在多个基准测试中表现更好，稀疏架构扩展不一定带来性能提升


<details>
  <summary>Details</summary>
Motivation: 评估OpenAI首个开源大语言模型GPT-OSS的性能表现，比较不同规模稀疏架构模型的效率，为开源模型选择提供实证依据

Method: 使用10个基准测试评估6个开源大模型（14.7B-235B参数），包括密集和稀疏架构，采用标准化推理设置和统计验证方法

Result: GPT-OSS-20B在多个测试中优于GPT-OSS-120B，内存和能耗更低；两模型在开源模型中处于中游水平，代码生成强但多语言能力弱

Conclusion: 稀疏架构的扩展不一定带来性能的成比例提升，需要优化策略研究，为未来开源部署提供更高效的模型选择指导

Abstract: In August 2025, OpenAI released GPT-OSS models, its first open weight large
language models since GPT-2 in 2019, comprising two mixture of experts
architectures with 120B and 20B parameters. We evaluated both variants against
six contemporary open source large language models ranging from 14.7B to 235B
parameters, representing both dense and sparse designs, across ten benchmarks
covering general knowledge, mathematical reasoning, code generation,
multilingual understanding, and conversational ability. All models were tested
in unquantised form under standardised inference settings, with statistical
validation using McNemars test and effect size analysis. Results show that
gpt-oss-20B consistently outperforms gpt-oss-120B on several benchmarks, such
as HumanEval and MMLU, despite requiring substantially less memory and energy
per response. Both models demonstrate mid-tier overall performance within the
current open source landscape, with relative strength in code generation and
notable weaknesses in multilingual tasks. These findings provide empirical
evidence that scaling in sparse architectures may not yield proportional
performance gains, underscoring the need for further investigation into
optimisation strategies and informing more efficient model selection for future
open source deployments.

</details>


### [43] [The Structural Sources of Verb Meaning Revisited: Large Language Models Display Syntactic Bootstrapping](https://arxiv.org/abs/2508.12482)
*Xiaomeng Zhu,R. Thomas McCoy,Robert Frank*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Syntactic bootstrapping (Gleitman, 1990) is the hypothesis that children use
the syntactic environments in which a verb occurs to learn its meaning. In this
paper, we examine whether large language models exhibit a similar behavior. We
do this by training RoBERTa and GPT-2 on perturbed datasets where syntactic
information is ablated. Our results show that models' verb representation
degrades more when syntactic cues are removed than when co-occurrence
information is removed. Furthermore, the representation of mental verbs, for
which syntactic bootstrapping has been shown to be particularly crucial in
human verb learning, is more negatively impacted in such training regimes than
physical verbs. In contrast, models' representation of nouns is affected more
when co-occurrences are distorted than when syntax is distorted. In addition to
reinforcing the important role of syntactic bootstrapping in verb learning, our
results demonstrated the viability of testing developmental hypotheses on a
larger scale through manipulating the learning environments of large language
models.

</details>


### [44] [Mitigating Hallucinations in Large Language Models via Causal Reasoning](https://arxiv.org/abs/2508.12495)
*Yuangang Li,Yiqing Shen,Yi Nian,Jiechao Gao,Ziyi Wang,Chenxiao Yu,Shawn Li,Jie Wang,Xiyang Hu,Yue Zhao*

Main category: cs.CL

TL;DR: 提出CDCR-SFT框架，通过显式构建因果DAG并进行推理，有效提升LLMs的因果推理能力并减少幻觉


<details>
  <summary>Details</summary>
Motivation: 现有LLMs推理方法（如CoT）在语言token层面操作，无法建模变量间的因果关系和条件独立性，导致逻辑不一致的幻觉

Method: 监督微调框架CDCR-SFT，训练LLMs显式构建变量级有向无环图（DAG）并在其上进行推理，同时构建包含25,368样本的CausalDR数据集

Result: 在8个任务上测试4个LLM，CDCR-SFT在CLADDER上达到95.33%准确率（首次超越人类94.8%），在HaluEval上幻觉减少10%

Conclusion: LLMs中显式因果结构建模能有效减轻输出中的逻辑不一致性，证明了因果推理能力与幻觉之间的负相关关系

Abstract: Large language models (LLMs) exhibit logically inconsistent hallucinations
that appear coherent yet violate reasoning principles, with recent research
suggesting an inverse relationship between causal reasoning capabilities and
such hallucinations. However, existing reasoning approaches in LLMs, such as
Chain-of-Thought (CoT) and its graph-based variants, operate at the linguistic
token level rather than modeling the underlying causal relationships between
variables, lacking the ability to represent conditional independencies or
satisfy causal identification assumptions. To bridge this gap, we introduce
causal-DAG construction and reasoning (CDCR-SFT), a supervised fine-tuning
framework that trains LLMs to explicitly construct variable-level directed
acyclic graph (DAG) and then perform reasoning over it. Moreover, we present a
dataset comprising 25,368 samples (CausalDR), where each sample includes an
input question, explicit causal DAG, graph-based reasoning trace, and validated
answer. Experiments on four LLMs across eight tasks show that CDCR-SFT improves
the causal reasoning capability with the state-of-the-art 95.33% accuracy on
CLADDER (surpassing human performance of 94.8% for the first time) and reduces
the hallucination on HaluEval with 10% improvements. It demonstrates that
explicit causal structure modeling in LLMs can effectively mitigate logical
inconsistencies in LLM outputs. Code is available at
https://github.com/MrLYG/CDCR-SFT.

</details>


### [45] [CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection](https://arxiv.org/abs/2508.12535)
*Seonglae Cho,Zekun Wu,Adriano Koshiyama*

Main category: cs.CL

TL;DR: CorrSteer是一种基于相关性选择稀疏自编码器特征的方法，仅使用推理时激活来自动化特征选择和转向系数计算，在多个任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统稀疏自编码器在下游转向任务中需要对比数据集或大量激活存储的限制，避免伪相关性。

Method: 通过将样本正确性与推理时生成的token的SAE激活进行相关性分析来选择特征，使用平均激活获得转向系数，实现全自动化流程。

Result: 在Gemma 2 2B和LLaMA 3.1 8B上，QA、偏见缓解、越狱预防和推理基准任务表现显著提升，MMLU性能提高4.1%，HarmBench提高22.9%（仅用4000样本）。

Conclusion: 基于相关性选择的方法是一种有效且可扩展的自动化SAE转向方法，所选特征展现出与任务需求一致的语义模式，揭示了驱动性能的底层能力。

Abstract: Sparse Autoencoders (SAEs) can extract interpretable features from large
language models (LLMs) without supervision. However, their effectiveness in
downstream steering tasks is limited by the requirement for contrastive
datasets or large activation storage. To address these limitations, we propose
CorrSteer, which selects features by correlating sample correctness with SAE
activations from generated tokens at inference time. This approach uses only
inference-time activations to extract more relevant features, thereby avoiding
spurious correlations. It also obtains steering coefficients from average
activations, automating the entire pipeline. Our method shows improved task
performance on QA, bias mitigation, jailbreaking prevention, and reasoning
benchmarks on Gemma 2 2B and LLaMA 3.1 8B, notably achieving a +4.1%
improvement in MMLU performance and a +22.9% improvement in HarmBench with only
4000 samples. Selected features demonstrate semantically meaningful patterns
aligned with each task's requirements, revealing the underlying capabilities
that drive performance. Our work establishes correlationbased selection as an
effective and scalable approach for automated SAE steering across language
model applications.

</details>


### [46] [Semantic Anchoring in Agentic Memory: Leveraging Linguistic Structures for Persistent Conversational Context](https://arxiv.org/abs/2508.12630)
*Maitreyi Chatterjee,Devansh Agarwal*

Main category: cs.CL

TL;DR: 提出Semantic Anchoring混合记忆架构，通过结合依赖解析、篇章关系标注和共指消解来增强向量检索，在长期对话中比传统RAG方法提升18%的事实回忆和篇章连贯性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多会话和长期交互中受限于记忆持久性问题，传统RAG系统使用密集向量存储对话历史，虽然能捕捉语义相似性但忽略了更精细的语言结构。

Method: 提出混合代理记忆架构Semantic Anchoring，在向量存储基础上增加显式语言线索，结合依赖解析、篇章关系标注和共指消解来创建结构化记忆条目。

Result: 在适配的长期对话数据集上实验显示，语义锚定相比强大的RAG基线在事实回忆和篇章连贯性方面提升高达18%。

Conclusion: 通过融合显式语言结构和向量表示，语义锚定方法显著提高了长期对话中的记忆性能和上下文理解能力。

Abstract: Large Language Models (LLMs) have demonstrated impressive fluency and task
competence in conversational settings. However, their effectiveness in
multi-session and long-term interactions is hindered by limited memory
persistence. Typical retrieval-augmented generation (RAG) systems store
dialogue history as dense vectors, which capture semantic similarity but
neglect finer linguistic structures such as syntactic dependencies, discourse
relations, and coreference links. We propose Semantic Anchoring, a hybrid
agentic memory architecture that enriches vector-based storage with explicit
linguistic cues to improve recall of nuanced, context-rich exchanges. Our
approach combines dependency parsing, discourse relation tagging, and
coreference resolution to create structured memory entries. Experiments on
adapted long-term dialogue datasets show that semantic anchoring improves
factual recall and discourse coherence by up to 18% over strong RAG baselines.
We further conduct ablation studies, human evaluations, and error analysis to
assess robustness and interpretability.

</details>


### [47] [Beyond GPT-5: Making LLMs Cheaper and Better via Performance-Efficiency Optimized Routing](https://arxiv.org/abs/2508.12631)
*Yiqun Zhang,Hao Li,Jianhao Chen,Hangfan Zhang,Peng Ye,Lei Bai,Shuyue Hu*

Main category: cs.CL

TL;DR: Avengers-Pro是一个测试时路由框架，通过动态分配查询给不同容量和效率的LLM，在性能和效率之间实现最优平衡，在6个基准测试中超越最强单模型7%准确率，同时显著降低成本。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在性能和效率之间的平衡挑战，GPT-5虽然引入了测试时路由，但需要更统一的解决方案来处理所有性能-效率权衡问题。

Method: 提出Avengers-Pro测试时路由框架，通过嵌入和聚类输入查询，然后基于性能-效率分数将每个查询路由到最合适的模型。集成了不同容量和效率的LLM。

Result: 在6个挑战性基准和8个领先模型上实现SOTA结果：超越最强单模型(GPT-5-medium)7%平均准确率；以27%更低成本匹配最强模型性能；以63%更低成本达到90%性能；实现帕累托前沿。

Conclusion: Avengers-Pro提供了一个统一的解决方案，能够在任何给定成本下获得最高准确率，或在任何给定准确率下实现最低成本，为LLM的性能-效率权衡问题提供了有效方法。

Abstract: Balancing performance and efficiency is a central challenge in large language
model (LLM) advancement. GPT-5 addresses this with test-time routing,
dynamically assigning queries to either an efficient or a high-capacity model
during inference. In this work, we present Avengers-Pro, a test-time routing
framework that ensembles LLMs of varying capacities and efficiencies, providing
a unified solution for all performance-efficiency tradeoffs. The Avengers-Pro
embeds and clusters incoming queries, then routes each to the most suitable
model based on a performance-efficiency score. Across 6 challenging benchmarks
and 8 leading models -- including GPT-5-medium, Gemini-2.5-pro, and
Claude-opus-4.1 -- Avengers-Pro achieves state-of-the-art results: by varying a
performance-efficiency trade-off parameter, it can surpass the strongest single
model (GPT-5-medium) by +7% in average accuracy. Moreover, it can match the
average accuracy of the strongest single model at 27% lower cost, and reach
~90% of that performance at 63% lower cost. Last but not least, it achieves a
Pareto frontier, consistently yielding the highest accuracy for any given cost,
and the lowest cost for any given accuracy, among all single models. Code is
available at https://github.com/ZhangYiqun018/AvengersPro.

</details>


### [48] [Prompt-Induced Linguistic Fingerprints for LLM-Generated Fake News Detection](https://arxiv.org/abs/2508.12632)
*Chi Wang,Min Gao,Zongwei Wang,Junwei Yin,Kai Shu,Chenghua Lin*

Main category: cs.CL

TL;DR: 提出LIFE方法，通过分析LLM生成真假新闻的概率分布差异来检测AI生成的假新闻，在多个数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型快速发展，假新闻生成变得容易且难以检测，现有方法主要关注文本内容但效果有限，需要更可靠的检测手段

Method: LIFE方法通过分布差异分析发现提示诱导的语言指纹，重构词级概率分布来寻找判别模式，并利用关键片段技术放大语言差异

Result: 实验显示LIFE在LLM生成假新闻检测上达到最先进性能，同时在人类撰写假新闻上也保持高检测性能

Conclusion: 通过概率分布分析揭示的语言指纹为假新闻检测提供了有效的新途径，LIFE方法在多种场景下都表现出色

Abstract: With the rapid development of large language models, the generation of fake
news has become increasingly effortless, posing a growing societal threat and
underscoring the urgent need for reliable detection methods. Early efforts to
identify LLM-generated fake news have predominantly focused on the textual
content itself; however, because much of that content may appear coherent and
factually consistent, the subtle traces of falsification are often difficult to
uncover. Through distributional divergence analysis, we uncover prompt-induced
linguistic fingerprints: statistically distinct probability shifts between
LLM-generated real and fake news when maliciously prompted. Based on this
insight, we propose a novel method named Linguistic Fingerprints Extraction
(LIFE). By reconstructing word-level probability distributions, LIFE can find
discriminative patterns that facilitate the detection of LLM-generated fake
news. To further amplify these fingerprint patterns, we also leverage
key-fragment techniques that accentuate subtle linguistic differences, thereby
improving detection reliability. Our experiments show that LIFE achieves
state-of-the-art performance in LLM-generated fake news and maintains high
performance in human-written fake news. The code and data are available at
https://anonymous.4open.science/r/LIFE-E86A.

</details>


### [49] [Breaking Language Barriers: Equitable Performance in Multilingual Language Models](https://arxiv.org/abs/2508.12662)
*Tanay Nagar,Grigorii Khvatskii,Anna Sokol,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: 通过代码转换技术生成合成语料库，细调LLM以提升低资源语言的常识推理性能，同时保持高资源语言的表现


<details>
  <summary>Details</summary>
Motivation: 解决LLM在低资源语言(LRLs)与高资源语言(HRLs)之间常识推理性能差异的问题，确保不同语言社区的公平访问

Method: 使用受控语言混合方法生成合成代码转换文本，并在这些数据集上细调LLM

Result: 细调后的LLM在LRLs上表现显著提升，同时保持或增强了HRLs的性能

Conclusion: 代码转换细调方法能够有效缩小语言间的性能差距，提供了一种提升多语言公平性的有效途径

Abstract: Cutting-edge LLMs have emerged as powerful tools for multilingual
communication and understanding. However, LLMs perform worse in Common Sense
Reasoning (CSR) tasks when prompted in low-resource languages (LRLs) like Hindi
or Swahili compared to high-resource languages (HRLs) like English. Equalizing
this inconsistent access to quality LLM outputs is crucial to ensure fairness
for speakers of LRLs and across diverse linguistic communities. In this paper,
we propose an approach to bridge this gap in LLM performance. Our approach
involves fine-tuning an LLM on synthetic code-switched text generated using
controlled language-mixing methods. We empirically demonstrate that fine-tuning
LLMs on synthetic code-switched datasets leads to substantial improvements in
LRL model performance while preserving or enhancing performance in HRLs.
Additionally, we present a new dataset of synthetic code-switched text derived
from the CommonSenseQA dataset, featuring three distinct language ratio
configurations.

</details>


### [50] [Leveraging Large Language Models for Predictive Analysis of Human Misery](https://arxiv.org/abs/2508.12669)
*Bishanka Seal,Rahul Seetharaman,Aman Bansal,Abhilash Nandy*

Main category: cs.CL

TL;DR: 这研究探索了大语言模型在预测人类悲伤感情方面的能力，通过多种提示策略和游戏化评估框架进行综合分析。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLM在情感预测任务中的表现，尤其是在动态环境中的适应能力，以评估其在实际应用中的潜力。

Method: 采用多种提示策略（零样本、少样本、检索基于BERT的提示）进行回归分析，并创建了"悲伤游戏表演"游戏化框架，包含顺序比较、二元分类、数值估计和反馈驱动的合理性分析。

Result: 少样本方法在情感预测任务中表现明显优于零样本基线，游戏化评估显示了LLM在动态情感推理中的广泛潜力。

Conclusion: 研究证明了上下文示例在情感预测中的重要性，并通过创新的游戏化评估框架为LLM在动态情感理解任务中的应用开启了新方向。

Abstract: This study investigates the use of Large Language Models (LLMs) for
predicting human-perceived misery scores from natural language descriptions of
real-world scenarios. The task is framed as a regression problem, where the
model assigns a scalar value from 0 to 100 to each input statement. We evaluate
multiple prompting strategies, including zero-shot, fixed-context few-shot, and
retrieval-based prompting using BERT sentence embeddings. Few-shot approaches
consistently outperform zero-shot baselines, underscoring the value of
contextual examples in affective prediction. To move beyond static evaluation,
we introduce the "Misery Game Show", a novel gamified framework inspired by a
television format. It tests LLMs through structured rounds involving ordinal
comparison, binary classification, scalar estimation, and feedback-driven
reasoning. This setup enables us to assess not only predictive accuracy but
also the model's ability to adapt based on corrective feedback. The gamified
evaluation highlights the broader potential of LLMs in dynamic emotional
reasoning tasks beyond standard regression. Code and data link:
https://github.com/abhi1nandy2/Misery_Data_Exps_GitHub

</details>


### [51] [ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction](https://arxiv.org/abs/2508.12685)
*Xingshan Zeng,Weiwen Liu,Lingzhi Wang,Liangyou Li,Fei Mi,Yasheng Wang,Lifeng Shang,Xin Jiang,Qun Liu*

Main category: cs.CL

TL;DR: ToolACE-MT是一个非自回归迭代生成框架，用于构建高质量的多轮代理对话数据，通过三阶段流程（粗粒度初始化、迭代精炼、离线验证）替代昂贵的自回归交互方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于模拟的代理任务数据生成方法严重依赖多个LLM代理之间昂贵的自回归交互，限制了代理任务在现实世界中的性能表现。

Method: 三阶段框架：1）粗粒度初始化构建结构完整但语义粗糙的对话骨架；2）迭代精炼通过掩码填充操作引入现实复杂性并持续优化；3）离线验证通过规则和模型检查确保正确性和连贯性。

Result: 实验证明ToolACE-MT能够实现高效、有效且可泛化的代理数据生成，为工具增强LLM场景中的高质量数据构建提供了新范式。

Conclusion: ToolACE-MT为非自回归迭代生成框架提供了可行的解决方案，显著降低了代理对话数据生成的成本，同时保持了高质量标准。

Abstract: Agentic task-solving with Large Language Models (LLMs) requires multi-turn,
multi-step interactions, often involving complex function calls and dynamic
user-agent exchanges. Existing simulation-based data generation methods for
such scenarios rely heavily on costly autoregressive interactions between
multiple LLM agents, thereby limiting real-world performance of agentic tasks.
In this paper, we propose a novel Non-Autoregressive Iterative Generation
framework, called ToolACE-MT, for constructing high-quality multi-turn agentic
dialogues. ToolACE-MT generates full conversational trajectories through three
stages: coarse-grained initialization, iterative refinement, and offline
verification. The initialization phase builds a structurally complete yet
semantically coarse dialogue skeleton; the iterative refinement phase
introduces realistic complexities and continued refinement via mask-and-fill
operations; and the offline verification phase ensures correctness and
coherence via rule- and model-based checks. Experiments demonstrate that
ToolACE-MT enables efficient, effective and generalizable agentic data
generation, offering a new paradigm for high-quality data construction in
tool-augmented LLM scenarios.

</details>


### [52] [DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning](https://arxiv.org/abs/2508.12726)
*Weize Liu,Yongchi Zhao,Yijia Luo,Mingyu Xu,Jiaheng Liu,Yanan Li,Xiguo Hu,Yuchi Xu,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: 提出了DESIGNER数据合成管道，通过设计逻辑概念从原始文档生成多学科复杂推理问题，创建了两个大规模数据集DLR-Book和DLR-Web，显著提升了模型的多学科推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有推理数据集缺乏学科广度和结构深度，无法有效激发强大的推理行为，需要创建更具挑战性和多样性的多学科推理数据集。

Method: 引入设计逻辑概念，模仿人类教育者的问题创建过程，使用LLMs从12万多个现有问题中逆向工程抽象出设计逻辑，并将其与学科源材料匹配生成推理问题。

Result: 创建了包含304万本书籍问题和166万网页问题的大规模数据集，实验显示合成问题难度和多样性远超基线数据集，SFT实验证明数据集显著优于同等规模的多学科数据集。

Conclusion: DESIGNER方法能有效生成高质量多学科推理问题，训练后的模型在多学科推理性能上超越了官方Qwen3模型，为解决LLMs复杂推理问题提供了有效方案。

Abstract: Large language models (LLMs) have achieved remarkable success in many natural
language tasks but still struggle with complex, multi-step reasoning,
particularly across diverse disciplines. Existing reasoning datasets often
either lack disciplinary breadth or the structural depth necessary to elicit
robust reasoning behaviors. We propose DESIGNER: a DESIGN-logic-guidEd
Reasoning data synthesis pipeline that leverages naturally available, extensive
raw documents (book corpus and web corpus) to generate multidisciplinary
challenging questions. A core innovation of our approach is the introduction of
a Design Logic concept, which mimics the question-creation process of human
educators. We use LLMs to reverse-engineer and abstract over 120,000 design
logics from existing questions across various disciplines. By matching these
design logics with disciplinary source materials, we are able to create
reasoning questions that far surpass the difficulty and diversity of existing
datasets. Based on this pipeline, we synthesized two large-scale reasoning
datasets that span 75 disciplines: Design-Logic-Reasoning-Book (DLR-Book),
containing 3.04 million challenging questions synthesized from the book corpus,
and Design-Logic-Reasoning-Web (DLR-Web), with 1.66 million challenging
questions from the web corpus. Our data analysis demonstrates that the
questions synthesized by our method exhibit substantially greater difficulty
and diversity than those in the baseline datasets. We validate the
effectiveness of these datasets by conducting SFT experiments on the
Qwen3-8B-Base and Qwen3-4B-Base models. The results show that our dataset
significantly outperforms existing multidisciplinary datasets of the same
volume. Training with the full datasets further enables the models to surpass
the multidisciplinary reasoning performance of the official Qwen3-8B and
Qwen3-4B models.

</details>


### [53] [LinguaSafe: A Comprehensive Multilingual Safety Benchmark for Large Language Models](https://arxiv.org/abs/2508.12733)
*Zhiyuan Ning,Tianle Gu,Jiaxin Song,Shixin Hong,Lingyu Li,Huacan Liu,Jie Li,Yixu Wang,Meng Lingyu,Yan Teng,Yingchun Wang*

Main category: cs.CL

TL;DR: LinguaSafe是一个包含12种语言、45k条目的多语言安全基准测试，通过翻译、转创和本地化数据构建，提供多维度的安全评估框架，填补了LLM在多语言安全评估方面的空白。


<details>
  <summary>Details</summary>
Motivation: 现有LLM多语言安全评估缺乏全面性和多样性数据，限制了多语言安全对齐的发展，需要解决这一关键差距。

Method: 结合翻译、转创和本地化数据构建包含12种语言45k条目的数据集，建立多维度的细粒度评估框架，包括直接/间接安全评估和过度敏感性评估。

Result: 不同领域和语言的安全性和有用性评估结果差异显著，即使是资源水平相似的语言也存在明显差异。

Conclusion: LinguaSafe基准测试强调了全面评估LLM多语言安全性的重要性，为实现更平衡的安全对齐提供了重要工具，数据集和代码已公开以促进进一步研究。

Abstract: The widespread adoption and increasing prominence of large language models
(LLMs) in global technologies necessitate a rigorous focus on ensuring their
safety across a diverse range of linguistic and cultural contexts. The lack of
a comprehensive evaluation and diverse data in existing multilingual safety
evaluations for LLMs limits their effectiveness, hindering the development of
robust multilingual safety alignment. To address this critical gap, we
introduce LinguaSafe, a comprehensive multilingual safety benchmark crafted
with meticulous attention to linguistic authenticity. The LinguaSafe dataset
comprises 45k entries in 12 languages, ranging from Hungarian to Malay. Curated
using a combination of translated, transcreated, and natively-sourced data, our
dataset addresses the critical need for multilingual safety evaluations of
LLMs, filling the void in the safety evaluation of LLMs across diverse
under-represented languages from Hungarian to Malay. LinguaSafe presents a
multidimensional and fine-grained evaluation framework, with direct and
indirect safety assessments, including further evaluations for oversensitivity.
The results of safety and helpfulness evaluations vary significantly across
different domains and different languages, even in languages with similar
resource levels. Our benchmark provides a comprehensive suite of metrics for
in-depth safety evaluation, underscoring the critical importance of thoroughly
assessing multilingual safety in LLMs to achieve more balanced safety
alignment. Our dataset and code are released to the public to facilitate
further research in the field of multilingual LLM safety.

</details>


### [54] [CRED-SQL: Enhancing Real-world Large Scale Database Text-to-SQL Parsing through Cluster Retrieval and Execution Description](https://arxiv.org/abs/2508.12769)
*Shaoming Duan,Zirui Wang,Chuanyi Liu,Zhibin Zhu,Yuhao Zhang,Peiyi Han,Liang Yan,Zewu Penge*

Main category: cs.CL

TL;DR: CRED-SQL是一个针对大规模数据库的Text-to-SQL框架，通过聚类检索和执行描述语言来解决语义不匹配问题，在两个大型跨域基准测试中达到了新的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然提升了Text-to-SQL系统的准确性，但在大规模数据库中，自然语言问题与SQL查询之间的语义不匹配问题仍然严重，特别是在语义相似属性导致的模式链接困难和语义漂移方面。

Method: CRED-SQL框架包含两个核心组件：1）基于聚类的模式检索来识别与自然语言问题最相关的表和列；2）引入执行描述语言（EDL）作为中间自然语言表示，将任务分解为Text-to-EDL和EDL-to-SQL两个阶段。

Result: 在两个大规模跨域基准测试SpiderUnion和BirdUnion上的广泛实验表明，CRED-SQL实现了新的最先进性能，验证了其有效性和可扩展性。

Conclusion: CRED-SQL通过创新的聚类检索和中间语言表示方法，有效解决了大规模数据库中Text-to-SQL的语义不匹配问题，为相关领域提供了有效的解决方案。

Abstract: Recent advances in large language models (LLMs) have significantly improved
the accuracy of Text-to-SQL systems. However, a critical challenge remains: the
semantic mismatch between natural language questions (NLQs) and their
corresponding SQL queries. This issue is exacerbated in large-scale databases,
where semantically similar attributes hinder schema linking and semantic drift
during SQL generation, ultimately reducing model accuracy. To address these
challenges, we introduce CRED-SQL, a framework designed for large-scale
databases that integrates Cluster Retrieval and Execution Description. CRED-SQL
first performs cluster-based large-scale schema retrieval to pinpoint the
tables and columns most relevant to a given NLQ, alleviating schema mismatch.
It then introduces an intermediate natural language representation-Execution
Description Language (EDL)-to bridge the gap between NLQs and SQL. This
reformulation decomposes the task into two stages: Text-to-EDL and EDL-to-SQL,
leveraging LLMs' strong general reasoning capabilities while reducing semantic
deviation. Extensive experiments on two large-scale, cross-domain
benchmarks-SpiderUnion and BirdUnion-demonstrate that CRED-SQL achieves new
state-of-the-art (SOTA) performance, validating its effectiveness and
scalability. Our code is available at https://github.com/smduan/CRED-SQL.git

</details>


### [55] [From SALAMANDRA to SALAMANDRATA: BSC Submission for WMT25 General Machine Translation Shared Task](https://arxiv.org/abs/2508.12774)
*Javier Garcia Gilabert,Xixian Liao,Severino Da Dalt,Ella Bohman,Audrey Mash,Francesca De Luca Fornaciari,Irene Baucells,Joan Llop,Miguel Claramunt Argote,Carlos Escolano,Maite Melero*

Main category: cs.CL

TL;DR: SALAMANDRATA模型家族是SALAMANDRA LLMs的改进版本，专门针对38种欧洲语言的翻译任务进行训练，提供2B和7B两个规模版本，采用持续预训练和监督微调的两阶段训练方法，并在WMT25机器翻译任务中应用了质量感知的解码策略。


<details>
  <summary>Details</summary>
Motivation: 开发专门针对多语言翻译任务的高性能模型，特别是针对38种欧洲语言的翻译需求，提升机器翻译的质量和效率。

Method: 采用两阶段训练方法：首先在平行数据上进行持续预训练，然后在高质量指令上进行监督微调。在WMT25任务中还使用了词汇表适配、二次持续预训练和微调，以及Minimum Bayes Risk Decoding和COMET/COMET-KIWI重排序等质量感知解码策略。

Result: 开发出了SALAMANDRATA模型家族（2B和7B版本）以及更新的SALAMANDRATA-V2模型，这些模型专门针对多语言翻译任务进行了优化，并在Hugging Face平台上公开发布。

Conclusion: SALAMANDRATA系列模型通过专门的多语言翻译训练方法和先进的质量控制策略，为欧洲语言翻译任务提供了有效的解决方案，并在WMT25共享任务中得到了应用和验证。

Abstract: In this paper, we present the SALAMANDRATA family of models, an improved
iteration of SALAMANDRA LLMs (Gonzalez-Agirre et al., 2025) specifically
trained to achieve strong performance in translation-related tasks for 38
European languages. SALAMANDRATA comes in two scales: 2B and 7B parameters. For
both versions, we applied the same training recipe with a first step of
continual pre-training on parallel data, and a second step of supervised
fine-tuning on high-quality instructions. The BSC submission to the WMT25
General Machine Translation shared task is based on the 7B variant of
SALAMANDRATA. We first adapted the model vocabulary to support the additional
non-European languages included in the task. This was followed by a second
phase of continual pre-training and supervised fine-tuning, carefully designed
to optimize performance across all translation directions for this year's
shared task. For decoding, we employed two quality-aware strategies: Minimum
Bayes Risk Decoding and Tuned Re-ranking using COMET and COMET-KIWI
respectively. We publicly release both the 2B and 7B versions of SALAMANDRATA,
along with the newer SALAMANDRATA-V2 model, on Hugging Face1

</details>


### [56] [HeteroRAG: A Heterogeneous Retrieval-Augmented Generation Framework for Medical Vision Language Tasks](https://arxiv.org/abs/2508.12778)
*Zhe Chen,Yusheng Liao,Shuyang Jiang,Zhiyuan Zhu,Haolin Li,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 提出了HeteroRAG框架，通过多模态检索增强生成技术解决医疗大视觉语言模型的事实不准确问题，在12个数据集上实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 医疗大视觉语言模型存在事实不准确和输出不可靠的问题，当前的多模态RAG系统无法在异构数据源上进行有效检索，影响临床决策的可信度

Method: 构建MedAtlas多模态报告库，开发HeteroRAG框架：使用模态特定CLIP进行报告检索，多语料查询生成器动态构建查询，通过异构知识偏好调优实现跨模态多源知识对齐

Result: 在12个数据集和3种模态上的广泛实验表明，HeteroRAG在大多数医疗视觉语言基准测试中达到最先进性能，显著提高了Med-LVLMs的事实准确性和可靠性

Conclusion: HeteroRAG框架通过有效整合异构知识源，成功解决了医疗大视觉语言模型的事实准确性问题，为临床诊断提供了更可靠的AI辅助工具

Abstract: Medical large vision-language Models (Med-LVLMs) have shown promise in
clinical applications but suffer from factual inaccuracies and unreliable
outputs, posing risks in real-world diagnostics. While retrieval-augmented
generation has emerged as a potential solution, current medical multimodal RAG
systems are unable to perform effective retrieval across heterogeneous sources.
The irrelevance of retrieved reports affects the factuality of analysis, while
insufficient knowledge affects the credibility of clinical decision-making. To
bridge the gap, we construct MedAtlas, which includes extensive multimodal
report repositories and diverse text corpora. Based on it, we present
HeteroRAG, a novel framework that enhances Med-LVLMs through heterogeneous
knowledge sources. The framework introduces Modality-specific CLIPs for
effective report retrieval and a Multi-corpora Query Generator for dynamically
constructing queries for diverse corpora. Incorporating knowledge from such
multifaceted sources, Med-LVLM is then trained with Heterogeneous Knowledge
Preference Tuning to achieve cross-modality and multi-source knowledge
alignment. Extensive experiments across 12 datasets and 3 modalities
demonstrate that the proposed HeteroRAG achieves state-of-the-art performance
in most medical vision language benchmarks, significantly improving factual
accuracy and reliability of Med-LVLMs.

</details>


### [57] [Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward](https://arxiv.org/abs/2508.12800)
*Yong Deng,Guoqing Wang,Zhenzhe Ying,Xiaofeng Wu,Jinzhen Lin,Wenwen Xiong,Yuqin Dai,Shuo Yang,Zhanwei Zhang,Qiwen Wang,Yang Qin,Changhua Meng*

Main category: cs.CL

TL;DR: 这篇论文提出了Atom-Searcher框架，通过原子思维分解和过程奖励解决了现有深度研究中的奖励稀疏和梯度冲突问题，在多个标准测试集上实现了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度研究系统依赖于结果基于强化学习，存在奖励稀疏和梯度冲突等问题，限制了性能提升和训练效率。

Method: 提出原子思维范式，将推理分解为细粒度功能单元，通过推理奖励模型(RRM)提供细粒度指导；构建Atom-Searcher RL框架，采用课程受体奖励调度，先优先过程奖励再转到结果奖励。

Result: 在7个标准测试集上都实现了持续的性能提升，具有可扩展计算、更可解释的人类化推理模式等优势。

Conclusion: 原子思维和Atom-Searcher框架有效解决了深度研究中的奖励问题，提供了更高效和可解释的自主推理能力。

Abstract: Large language models (LLMs) exhibit remarkable problem-solving abilities,
but struggle with complex tasks due to static internal knowledge.
Retrieval-Augmented Generation (RAG) enhances access to external information,
yet remains limited in multi-hop reasoning and strategic search due to rigid
workflows. Recent advancements in agentic deep research empower LLMs to
autonomously reason, search, and synthesize information. However, current
approaches relying on outcome-based reinforcement learning (RL) face critical
issues such as conflicting gradients and reward sparsity, limiting performance
gains and training efficiency. To address these, we first propose Atomic
Thought, a novel LLM thinking paradigm that decomposes reasoning into
fine-grained functional units. These units are supervised by Reasoning Reward
Models (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained
guidance. Building on this, we propose Atom-Searcher, a novel RL framework for
agentic deep research that integrates Atomic Thought and ATR. Atom-Searcher
uses a curriculum-inspired reward schedule, prioritizing process-level ATR
early and transitioning to outcome rewards, accelerating convergence on
effective reasoning paths. Experiments on seven benchmarks show consistent
improvements over the state-of-the-art. Key advantages include: (1)
Atom-Searcher scales computation at test-time. (2) Atomic Thought provides
supervision anchors for RRMs, bridging deep research tasks and RRMs. (3)
Atom-Searcher exhibits more interpretable, human-like reasoning patterns.

</details>


### [58] [When Alignment Hurts: Decoupling Representational Spaces in Multilingual Models](https://arxiv.org/abs/2508.12803)
*Ahmed Elshabrawy,Hour Kaing,Haiyue Song,Alham Fikri Aji,Hideki Tanaka,Masao Utiyama,Raj Dabre*

Main category: cs.CL

TL;DR: 研究表明，高资源标准语言（如现代标准阿拉伯语MSA）的过度表征纠缠会阻碍相关低资源方言的生成建模。通过在线变分探测框架实现子空间解耦，在25种阿拉伯方言上平均提升生成质量+2.0 chrF++。


<details>
  <summary>Details</summary>
Motivation: 挑战高资源标准语言必然有助于相关低资源变体建模的假设，探索表征纠缠对生成建模的负面影响，并为多语言多领域LLMs提供表征分配控制方法。

Method: 提出在线变分探测框架，在微调过程中持续估计标准变体的子空间，实现基于投影的解耦。使用阿拉伯语作为案例研究，分析并直接干预LLMs的内部表征几何结构。

Result: 在25种方言上，干预使生成质量平均提升+2.0 chrF++（最高+4.9），尽管标准语言性能有所下降。提供了高资源变体子空间主导限制相关变体生成能力的因果证据。

Conclusion: 统一几何和信息论探测与子空间级因果干预，为密切相关的语言家族提供改进生成建模的实用工具，并为多语言多领域LLMs的表征分配控制提供新方法。

Abstract: Alignment with high-resource standard languages is often assumed to aid the
modeling of related low-resource varieties. We challenge this assumption by
demonstrating that excessive representational entanglement with a dominant
variety, such as Modern Standard Arabic (MSA) in relation to Arabic dialects,
can actively hinder generative modeling. We present the first comprehensive
causal study of this phenomenon by analyzing and directly intervening in the
internal representation geometry of large language models (LLMs). Our key
contribution is an online variational probing framework that continuously
estimates the subspace of the standard variety during fine-tuning, enabling
projection-based decoupling from this space. While our study uses Arabic as a
case due to its unusually rich parallel resources across 25 dialects, the
broader motivation is methodological: dialectal MT serves as a controlled proxy
for generative tasks where comparable multi-variety corpora are unavailable.
Across 25 dialects, our intervention improves generation quality by up to +4.9
chrF++ and +2.0 on average compared to standard fine-tuning, despite a measured
tradeoff in standard-language performance. These results provide causal
evidence that subspace dominance by high-resource varieties can restrict
generative capacity for related varieties. More generally, we unify geometric
and information-theoretic probing with subspace-level causal interventions,
offering practical tools for improving generative modeling in closely related
language families and, more broadly, for controlling representational
allocation in multilingual and multi-domain LLMs. Code will be released.

</details>


### [59] [ding-01 :ARG0: An AMR Corpus for Spontaneous French Dialogue](https://arxiv.org/abs/2508.12819)
*Jeongwoo Kang,Maria Boritchev,Maximin Coavoux*

Main category: cs.CL

TL;DR: 构建法语语义语料库，通过AMR标注法语对话，扩展框架以处理自发语音特征，并训练AMR解析器作为辅助标注工具。


<details>
  <summary>Details</summary>
Motivation: 为法语对话开发语义资源，解决AMR框架对自发语音覆盖不足的问题，支持法语特有的句子结构标注。

Method: 标注DinG语料库中的法语对话，扩展AMR框架以适应自发语音特征，制定详细标注指南，训练和评估AMR解析器。

Result: 发布了免费许可的法语语义语料库，开发了能够辅助人工标注的AMR解析模型。

Conclusion: 该工作推进了法语对话语义资源的发展，为后续研究提供了标注工具和语料基础。

Abstract: We present our work to build a French semantic corpus by annotating French
dialogue in Abstract Meaning Representation (AMR). Specifically, we annotate
the DinG corpus, consisting of transcripts of spontaneous French dialogues
recorded during the board game Catan. As AMR has insufficient coverage of the
dynamics of spontaneous speech, we extend the framework to better represent
spontaneous speech and sentence structures specific to French. Additionally, to
support consistent annotation, we provide an annotation guideline detailing
these extensions. We publish our corpus under a free license (CC-SA-BY). We
also train and evaluate an AMR parser on our data. This model can be used as an
assistance annotation tool to provide initial annotations that can be refined
by human annotators. Our work contributes to the development of semantic
resources for French dialogue.

</details>


### [60] [Context Matters: Incorporating Target Awareness in Conversational Abusive Language Detection](https://arxiv.org/abs/2508.12828)
*Raneem Alharthi,Rajwa Alharthi,Aiqi Jiang,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: 本研究探讨了利用父推文上下文特征来检测回复推文中的辱骂性语言，发现结合上下文内容特征能显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的辱骂性语言检测研究主要关注单个社交媒体帖子，忽略了从周围帖子中获得的额外上下文信息，特别是在对话交流场景中。

Method: 研究对话交流（父推文-回复推文对），测试了基于内容和账户的上下文特征，使用四种分类模型在标注数据集上进行实验比较。

Result: 实验表明，结合上下文特征相比仅使用回复推文特征有显著改进，其中内容特征比账户特征贡献更大，且组合多种特征效果最佳。

Conclusion: 上下文信息对辱骂性语言检测至关重要，特别是在对话场景中，内容特征比用户身份特征更有价值，应开发更多上下文感知的检测模型。

Abstract: Abusive language detection has become an increasingly important task as a
means to tackle this type of harmful content in social media. There has been a
substantial body of research developing models for determining if a social
media post is abusive or not; however, this research has primarily focused on
exploiting social media posts individually, overlooking additional context that
can be derived from surrounding posts. In this study, we look at conversational
exchanges, where a user replies to an earlier post by another user (the parent
tweet). We ask: does leveraging context from the parent tweet help determine if
a reply post is abusive or not, and what are the features that contribute the
most? We study a range of content-based and account-based features derived from
the context, and compare this to the more widely studied approach of only
looking at the features from the reply tweet. For a more generalizable study,
we test four different classification models on a dataset made of
conversational exchanges (parent-reply tweet pairs) with replies labeled as
abusive or not. Our experiments show that incorporating contextual features
leads to substantial improvements compared to the use of features derived from
the reply tweet only, confirming the importance of leveraging context. We
observe that, among the features under study, it is especially the
content-based features (what is being posted) that contribute to the
classification performance rather than account-based features (who is posting
it). While using content-based features, it is best to combine a range of
different features to ensure improved performance over being more selective and
using fewer features. Our study provides insights into the development of
contextualized abusive language detection models in realistic settings
involving conversations.

</details>


### [61] [It takes a village to write a book: Mapping anonymous contributions in Stephen Langton's Quaestiones Theologiae](https://arxiv.org/abs/2508.12830)
*Jan Maliszewski*

Main category: cs.CL

TL;DR: 这篇论文提出了一种利用风格测度技术分析中世纪教育文献产生过程的方法，通过对Stephen Langton神学问题集的研究来验证其编辑工作层次的假设。


<details>
  <summary>Details</summary>
Motivation: 虽然间接证据显示早期经院时代就存在基于口讲教学记录的文学产出，但很少有源泄这种实践。需要开发计算方法来研究中世纪大学的合作文学产出过程。

Method: 采用风格测度作者归属技术，基于最常见单词、词性标注和伪后缀进行分析。实施HTR流水线（手写文本识别）和自动化转写对齐技术。

Result: 这项研究将提供两个方法论政益：直接比较手工编写和自动提取数据的性能，验证基于transformer的OCR和自动对齐技术在经院拉丁语语料库中的有效性。

Conclusion: 如果成功，这项研究将为中世纪大学合作文学产出的探索性分析提供一个可重用的模板，促进对经院传统的计算研究。

Abstract: While the indirect evidence suggests that already in the early scholastic
period the literary production based on records of oral teaching (so-called
reportationes) was not uncommon, there are very few sources commenting on the
practice. This paper details the design of a study applying stylometric
techniques of authorship attribution to a collection developed from
reportationes -- Stephen Langton's Quaestiones Theologiae -- aiming to uncover
layers of editorial work and thus validate some hypotheses regarding the
collection's formation. Following Camps, Cl\'erice, and Pinche (2021), I
discuss the implementation of an HTR pipeline and stylometric analysis based on
the most frequent words, POS tags, and pseudo-affixes. The proposed study will
offer two methodological gains relevant to computational research on the
scholastic tradition: it will directly compare performance on manually composed
and automatically extracted data, and it will test the validity of
transformer-based OCR and automated transcription alignment for workflows
applied to scholastic Latin corpora. If successful, this study will provide an
easily reusable template for the exploratory analysis of collaborative literary
production stemming from medieval universities.

</details>


### [62] [Word Meanings in Transformer Language Models](https://arxiv.org/abs/2508.12863)
*Jumbly Grindrod,Peter Grindrod*

Main category: cs.CL

TL;DR: 这篇论文通过对RoBERTa-base模型的分析发现，转换器语言模型在词汇嵌入空间中编码了丰富的语义信息，推翻了某些语义消过主义假设。


<details>
  <summary>Details</summary>
Motivation: 探索转换器语言模型如何表征词汇意义，特别是是否存在类似于词典存储的机制，其中每个词都有包含语义信息的入口。

Method: 提取RoBERTa-base模型的标记嵌入空间，使用k-means聚类算法将其分为200个聚类。第一个研究手动检查这些聚类是否对语义信息敏感；第二个研究测试聚类是否对五种心理语言度量敏感：价值观、具体性、象征性、禁忌词和获得年龄。

Result: 发现显示词汇嵌入空间中编码了广泛的语义信息，聚类结果显示出对语义信息的敏感性。

Conclusion: 这些发现规则了某些"语义消过主义"的假设，证明转换器语言模型通过词汇嵌入空间有效地处理和表征语义信息。

Abstract: We investigate how word meanings are represented in the transformer language
models. Specifically, we focus on whether transformer models employ something
analogous to a lexical store - where each word has an entry that contains
semantic information. To do this, we extracted the token embedding space of
RoBERTa-base and k-means clustered it into 200 clusters. In our first study, we
then manually inspected the resultant clusters to consider whether they are
sensitive to semantic information. In our second study, we tested whether the
clusters are sensitive to five psycholinguistic measures: valence,
concreteness, iconicity, taboo, and age of acquisition. Overall, our findings
were very positive - there is a wide variety of semantic information encoded
within the token embedding space. This serves to rule out certain "meaning
eliminativist" hypotheses about how transformer LLMs process semantic
information.

</details>


### [63] [An LLM Agent-Based Complex Semantic Table Annotation Approach](https://arxiv.org/abs/2508.12868)
*Yilin Geng,Shujing Wang,Chuan Wang,Keqing He,Yanfei Lv,Ying Wang,Zaiwen Feng,Xiaoying Bai*

Main category: cs.CL

TL;DR: 这篇论文提出了一种基于LLM的民工智能代理方法，通过设计五个外部工具和ReAct框架来解决语义表注解任务中的复杂挑战，在保持高准确度的同时大幅降低时间成本和计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 复杂表格在语义表注解任务中遇到多种挑战，包括列名/单元格值的语义丢失、严格的本体论层次要求、同词异义、拼写错误和缩写等问题，影响了注解的准确性。

Method: 基于ReAct框架设计实现五个外部工具，让STA代理能够根据表格特征动态选择适合的注解策略，并利用Levenshtein距离减少冗余注解。

Result: 在SemTab挑战的Tough Tables和BiodivTab数据集上进行实验，方法在各种指标上都超过了现有方法，并实现了时间成本降低70%和LLM令牌使用量减少60%。

Conclusion: 该方法为语义表注解任务提供了一种高效且成本效益高的解决方案，能够有效处理复杂表格的各种挑战问题。

Abstract: The Semantic Table Annotation (STA) task, which includes Column Type
Annotation (CTA) and Cell Entity Annotation (CEA), maps table contents to
ontology entities and plays important roles in various semantic applications.
However, complex tables often pose challenges such as semantic loss of column
names or cell values, strict ontological hierarchy requirements, homonyms,
spelling errors, and abbreviations, which hinder annotation accuracy. To
address these issues, this paper proposes an LLM-based agent approach for CTA
and CEA. We design and implement five external tools with tailored prompts
based on the ReAct framework, enabling the STA agent to dynamically select
suitable annotation strategies depending on table characteristics. Experiments
are conducted on the Tough Tables and BiodivTab datasets from the SemTab
challenge, which contain the aforementioned challenges. Our method outperforms
existing approaches across various metrics. Furthermore, by leveraging
Levenshtein distance to reduce redundant annotations, we achieve a 70%
reduction in time costs and a 60% reduction in LLM token usage, providing an
efficient and cost-effective solution for STA.

</details>


### [64] [A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models](https://arxiv.org/abs/2508.12903)
*Jinyi Han,Xinyi Wang,Haiquan Zhao,Tingyun li,Zishang Jiang,Sihang Jiang,Jiaqing Liang,Xin Lin,Weikang Zhou,Zeye Sun,Fei Yu,Yanghua Xiao*

Main category: cs.CL

TL;DR: PASR是一种主动式自优化方法，让LLM在生成过程中动态决定是否、何时以及如何优化输出，相比固定迭代次数的传统方法，在减少41.6%token消耗的同时提升8.2%准确率


<details>
  <summary>Details</summary>
Motivation: 现有自优化方法依赖固定迭代次数的被动过程，难以根据生成上下文动态确定最佳优化时机和内容，而人类在执行过程中会动态优化思路

Method: 提出PASR方法，基于模型内部状态和演化上下文主动决定是否、何时以及如何优化，而不是重新生成整个响应

Result: 在10个多样化任务上的实验显示，PASR显著提升问题解决性能，Qwen3-8B模型上相比标准生成减少41.6%token消耗，同时准确率提升8.2%

Conclusion: PASR通过主动式自优化在生成过程中动态优化输出，实现了效率和质量的双重提升，为LLM自优化提供了新思路

Abstract: Recent advances in self-refinement have demonstrated significant potential
for improving the outputs of large language models (LLMs) through iterative
refinement. However, most existing self-refinement methods rely on a reactive
process with a fixed number of iterations, making it difficult to determine the
optimal timing and content of refinement based on the evolving generation
context. Inspired by the way humans dynamically refine their thoughts during
execution, we propose ProActive Self-Refinement (PASR), a novel method that
enables LLMs to refine their outputs during the generation process. Unlike
methods that regenerate entire responses, PASR proactively decides whether,
when, and how to refine based on the model's internal state and evolving
context. We conduct extensive experiments on a diverse set of 10 tasks to
evaluate the effectiveness of PASR. Experimental results show that PASR
significantly enhances problem-solving performance. In particular, on Qwen3-8B,
PASR reduces average token consumption by 41.6 percent compared to standard
generation, while also achieving an 8.2 percent improvement in accuracy. Our
code and all baselines used in the paper are available in the GitHub.

</details>


### [65] [Analyzing Information Sharing and Coordination in Multi-Agent Planning](https://arxiv.org/abs/2508.12981)
*Tianyue Ou,Saujas Vaduguru,Daniel Fried*

Main category: cs.CL

TL;DR: 本研究构建了一个基于LLM的多智能体系统用于旅行规划任务，通过引入笔记本机制和协调器智能体，显著提升了复杂约束规划任务的性能。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在复杂的长时域、多约束规划任务中面临信息共享和协调的挑战，特别是在需要处理详细信息和满足复杂相互依赖约束的场景下。

Method: 构建基于LLM的多智能体系统进行旅行规划，评估笔记本机制促进信息共享的效果，并测试协调器智能体在自由对话中的协调能力。

Result: 笔记本机制将幻觉细节导致的错误减少18%，协调器在重点子区域进一步减少错误13.5%。组合使用两种机制在TravelPlanner基准测试中达到25%的通过率，相比单智能体基线的7.5%有17.5%的绝对提升。

Conclusion: 结构化信息共享和反射式协调是多智能体系统中应对长时域规划任务的关键组件，具有重要的应用潜力。

Abstract: Multi-agent systems (MASs) have pushed the boundaries of large language model
(LLM) agents in domains such as web research and software engineering. However,
long-horizon, multi-constraint planning tasks involve conditioning on detailed
information and satisfying complex interdependent constraints, which can pose a
challenge for these systems. In this study, we construct an LLM-based MAS for a
travel planning task which is representative of these challenges. We evaluate
the impact of a notebook to facilitate information sharing, and evaluate an
orchestrator agent to improve coordination in free form conversation between
agents. We find that the notebook reduces errors due to hallucinated details by
18%, while an orchestrator directs the MAS to focus on and further reduce
errors by up to 13.5% within focused sub-areas. Combining both mechanisms
achieves a 25% final pass rate on the TravelPlanner benchmark, a 17.5% absolute
improvement over the single-agent baseline's 7.5% pass rate. These results
highlight the potential of structured information sharing and reflective
orchestration as key components in MASs for long horizon planning with LLMs.

</details>


### [66] [WebMall -- A Multi-Shop Benchmark for Evaluating Web Agents](https://arxiv.org/abs/2508.13024)
*Ralph Peeters,Aaron Steiner,Luca Schwarz,Julian Yuya Caspary,Christian Bizer*

Main category: cs.CL

TL;DR: WebMall是一个多商店在线购物基准测试，用于评估网络代理在比价购物中的效果和效率，包含91个跨商店任务和来自真实电商的异构产品数据。


<details>
  <summary>Details</summary>
Motivation: 现有的电商基准测试如WebShop或ShoppingBench缺乏跨商店比价购物任务，产品数据同质性较高，无法充分评估网络代理在真实多商店环境中的性能。

Method: 构建四个模拟在线商店，使用Common Crawl爬取的真实产品数据填充，设计91个跨商店任务（包括基础任务和高级任务），评估8个不同配置的基线代理。

Result: 最佳配置在基础任务集上达到75%完成率和87% F1分数，在高级任务集上达到53%完成率和63% F1分数。

Conclusion: WebMall为网络代理研究提供了更真实、更具挑战性的评估基准，促进了电商场景中导航、推理和效率方面的技术进步。

Abstract: LLM-based web agents have the potential to automate long-running web tasks,
such as finding offers for specific products in multiple online shops and
subsequently ordering the cheapest products that meet the users needs. This
paper introduces WebMall, a multi-shop online shopping benchmark for evaluating
the effectiveness and efficiency of web agents for comparison-shopping. WebMall
consists of four simulated online shops populated with authentic product offers
sourced from the Common Crawl, alongside a suite of 91 cross-shop tasks. These
tasks include basic tasks such as finding specific products in multiple shops,
performing price comparisons, adding items to the shopping cart, and completing
checkout. Advanced tasks involve searching for products based on vague
requirements, identifying suitable substitutes, and finding compatible
products. Compared to existing e-commerce benchmarks, such as WebShop or
ShoppingBench, WebMall introduces comparison-shopping tasks across multiple
shops. Furthermore, the product offers are more heterogeneous, as they
originate from hundreds of distinct real-world shops. The tasks in WebMall
require longer interaction trajectories than those in WebShop, while remaining
representative of real-world shopping behaviors. We evaluate eight baseline
agents on WebMall, varying in observation modality, memory utilization, and
underlying large language model (GPT 4.1 and Claude Sonnet 4). The
best-performing configurations achieve completion rates of 75% and 53%, and F1
scores of 87% and 63%, on the basic and advanced task sets, respectively.
WebMall is publicly released to facilitate research on web agents and to
promote advancements in navigation, reasoning, and efficiency within e-commerce
scenarios.

</details>


### [67] [Integrating Feedback Loss from Bi-modal Sarcasm Detector for Sarcastic Speech Synthesis](https://arxiv.org/abs/2508.13028)
*Zhu Li,Yuqing Zhang,Xiyuan Gao,Devraj Raghuvanshi,Nagendra Kumar,Shekhar Nayak,Matt Coler*

Main category: cs.CL

TL;DR: 通过二阶段微调和双模态证据损失机制，提出了一种能够生成具有颠刺敏感性语音的新方法，显著提升了合成语音的风趣感知能力。


<details>
  <summary>Details</summary>
Motivation: 颠刺语音合成对于娱乐和人机交互应用至关重要，但由于颠刺语调的细微差异性和标注数据的稀缺，该任务仍面临挑战。

Method: 采用二阶段迁移学习策略：先在多样化语音样式数据集上微调，然后在颠刺语音数据集上精细调整。同时在TTS训练中集成双模态颠刺检测模型的反馈损失，以提升颠刺感知能力。

Result: 客观和主观评估都表明，所提方法能够显著提高合成语音的质量、自然度和颠刺感知能力。

Conclusion: 该研究提出的方法有效解决了颠刺语音合成的挑战，为生成更自然、更具颠刺敏感性的语音提供了有效的技术路径。

Abstract: Sarcastic speech synthesis, which involves generating speech that effectively
conveys sarcasm, is essential for enhancing natural interactions in
applications such as entertainment and human-computer interaction. However,
synthesizing sarcastic speech remains a challenge due to the nuanced prosody
that characterizes sarcasm, as well as the limited availability of annotated
sarcastic speech data. To address these challenges, this study introduces a
novel approach that integrates feedback loss from a bi-modal sarcasm detection
model into the TTS training process, enhancing the model's ability to capture
and convey sarcasm. In addition, by leveraging transfer learning, a speech
synthesis model pre-trained on read speech undergoes a two-stage fine-tuning
process. First, it is fine-tuned on a diverse dataset encompassing various
speech styles, including sarcastic speech. In the second stage, the model is
further refined using a dataset focused specifically on sarcastic speech,
enhancing its ability to generate sarcasm-aware speech. Objective and
subjective evaluations demonstrate that our proposed methods improve the
quality, naturalness, and sarcasm-awareness of synthesized speech.

</details>


### [68] [Can Large Models Teach Student Models to Solve Mathematical Problems Like Human Beings? A Reasoning Distillation Method via Multi-LoRA Interaction](https://arxiv.org/abs/2508.13037)
*Xinhe Li,Jiajun Liu,Peng Wang*

Main category: cs.CL

TL;DR: LoRID是一种基于多LoRA交互的数学推理蒸馏方法，通过模拟人类System 1和System 2两种思维模式，提升小语言模型的数学推理能力，在GSM8K数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决小语言模型(SLMs)数学推理能力弱的问题，现有方法主要依赖大语言模型生成大量数据进行填鸭式训练，这类似于心理学中的System 1思维。但人类学习还需要System 2思维，即先获取知识再通过实践强化。

Method: 提出基于多LoRA交互的数学推理蒸馏方法(LoRID)：1)用LLM创建知识增强数据集；2)训练直觉推理器(IR)直接生成思维链；3)训练知识生成器(KG)和深度推理器(DR)模拟System 2思维；4)通过IR和DR输出一致性评估进行迭代推理。

Result: LoRID在GSM8K数据集上表现优异，在五个基础模型上分别比第二名方法高出2.3%、16.1%、2.4%、12.3%和1.8%的准确率，达到最先进性能。

Conclusion: 该方法通过模拟人类两种思维模式，有效提升了小语言模型的数学推理能力，多LoRA交互和迭代推理机制显著改善了推理性能。

Abstract: Recent studies have demonstrated that Large Language Models (LLMs) have
strong mathematical reasoning abilities but rely on hundreds of billions of
parameters. To tackle the challenge of poor reasoning in Small Language Models
(SLMs), existing methods typically leverage LLMs to generate massive amounts of
data for cramming training. In psychology, they are akin to System 1 thinking,
which resolves reasoning problems rapidly based on experience and intuition.
However, human learning also requires System 2 thinking, where knowledge is
first acquired and then reinforced through practice. Inspired by such two
distinct modes of thinking, we propose a novel method based on the multi-LoRA
Interaction for mathematical reasoning Distillation (LoRID). First, we input
the question and reasoning of each sample into an LLM to create
knowledge-enhanced datasets. Subsequently, we train a LoRA block on the student
model as an Intuitive Reasoner (IR), which directly generates Chain-of-Thoughts
for problem-solving. Then, to imitate System 2 thinking, we train the Knowledge
Generator (KG) and Deep Reasoner (DR), respectively. The former outputs only
knowledge after receiving problems, while the latter uses that knowledge to
perform reasoning. Finally, to address the randomness in the generation of IR
and DR, we evaluate whether their outputs are consistent, and the inference
process needs to be iterated if not. This step can enhance the mathematical
reasoning ability of SLMs through mutual feedback. Experimental results show
that LoRID achieves state-of-the-art performance, especially on the GSM8K
dataset, where it outperforms the second-best method by 2.3%, 16.1%, 2.4%,
12.3%, and 1.8% accuracy across the five base models, respectively.

</details>


### [69] [Büyük Dil Modelleri için TR-MMLU Benchmarkı: Performans Değerlendirmesi, Zorluklar ve İyileştirme Fırsatları](https://arxiv.org/abs/2508.13044)
*M. Ali Bayram,Ali Arda Fincan,Ahmet Semih Gümüş,Banu Diri,Savaş Yıldırım,Öner Aytaş*

Main category: cs.CL

TL;DR: 提出了土耳其语MMLU基准(TR-MMLU)，包含6200道选择题，用于评估大语言模型在土耳其语上的语言和概念能力


<details>
  <summary>Details</summary>
Motivation: 当前语言模型评估主要针对资源丰富的语言，土耳其语等资源有限语言缺乏全面的评估基准，需要专门的评测框架

Method: 基于土耳其教育体系构建包含62个领域的6200道选择题数据集，建立标准化评估框架，并对先进LLM进行评测

Result: 创建了TR-MMLU基准，为土耳其NLP研究提供了标准评估工具，揭示了现有模型在土耳其语处理方面的改进空间

Conclusion: TR-MMLU为土耳其NLP研究设立了新标准，将推动该领域的发展并激发未来创新

Abstract: Language models have made significant advancements in understanding and
generating human language, achieving remarkable success in various
applications. However, evaluating these models remains a challenge,
particularly for resource-limited languages like Turkish. To address this
issue, we introduce the Turkish MMLU (TR-MMLU) benchmark, a comprehensive
evaluation framework designed to assess the linguistic and conceptual
capabilities of large language models (LLMs) in Turkish. TR-MMLU is based on a
meticulously curated dataset comprising 6,200 multiple-choice questions across
62 sections within the Turkish education system. This benchmark provides a
standard framework for Turkish NLP research, enabling detailed analyses of
LLMs' capabilities in processing Turkish text. In this study, we evaluated
state-of-the-art LLMs on TR-MMLU, highlighting areas for improvement in model
design. TR-MMLU sets a new standard for advancing Turkish NLP research and
inspiring future innovations.

</details>


### [70] [Doğal Dil İşlemede Tokenizasyon Standartları ve Ölçümü: Türkçe Üzerinden Büyük Dil Modellerinin Karşılaştırmalı Analizi](https://arxiv.org/abs/2508.13058)
*M. Ali Bayram,Ali Arda Fincan,Ahmet Semih Gümüş,Sercan Karakaş,Banu Diri,Savaş Yıldırım*

Main category: cs.CL

TL;DR: 这篇论文提出了一种新的评估框架，用于分析对于形态丰富和低资源语言（如土耳其语）的标记化方案。研究发现语言特定标记百分比与下游性能更相关，而且单纯增加模型参数并不能提升语言性能。


<details>
  <summary>Details</summary>
Motivation: 标记化是NLP中的基础预处理步骤，对大语言模型的语言学和语义理解能力有重要影响。尤其是对于形态丰富和低资源语言，需要专门的评估方法来解决标记化挑战。

Method: 使用土耳其MMLU（TR-MMLU）数据集（包含6,200道多选题），通过评估词汇规模、标记数量、处理时间、语言特定标记百分比（%TR）和标记纯度（%Pure）等指标来分析标记化器的性能。

Result: 分析显示语言特定标记百分比与下游性能（如MMLU分数）的相关性更强，而标记纯度的相关性较弱。同时，单纯增加模型参数并不能有效提升语言性能。

Conclusion: 该研究为形态复杂语言建立了健壮而实用的标记化标准，强调了采用适配的语言特定标记化方法的重要性。

Abstract: Tokenization is a fundamental preprocessing step in Natural Language
Processing (NLP), significantly impacting the capability of large language
models (LLMs) to capture linguistic and semantic nuances. This study introduces
a novel evaluation framework addressing tokenization challenges specific to
morphologically-rich and low-resource languages such as Turkish. Utilizing the
Turkish MMLU (TR-MMLU) dataset, comprising 6,200 multiple-choice questions from
the Turkish education system, we assessed tokenizers based on vocabulary size,
token count, processing time, language-specific token percentages (\%TR), and
token purity (\%Pure). These newly proposed metrics measure how effectively
tokenizers preserve linguistic structures. Our analysis reveals that
language-specific token percentages exhibit a stronger correlation with
downstream performance (e.g., MMLU scores) than token purity. Furthermore,
increasing model parameters alone does not necessarily enhance linguistic
performance, underscoring the importance of tailored, language-specific
tokenization methods. The proposed framework establishes robust and practical
tokenization standards for morphologically complex languages.

</details>


### [71] [Evaluating ASR robustness to spontaneous speech errors: A study of WhisperX using a Speech Error Database](https://arxiv.org/abs/2508.13060)
*John Alderete,Macarious Kin Fung Hui,Aanchan Mohan*

Main category: cs.CL

TL;DR: SFUSED是一个用于测试和评估语音识别模型的公开语音错误数据库，包含5300个标注的英语语音错误，通过WhisperX评估证明了其作为ASR系统诊断工具的有效性。


<details>
  <summary>Details</summary>
Motivation: 开发一个系统标注的自发英语语音错误数据库，用于测试和评估语音识别模型的性能，提供多维度分类标注来支持模型评估。

Method: 收集和系统标注自发英语语音错误，包含意图和实际错误产生的标注，采用多维度分类体系（语言层级、上下文敏感性、退化词、词修正、词级和音节级错误定位），使用WhisperX对5300个词和音系错误进行转录准确性评估。

Result: SFUSED数据库被证明是评估ASR系统性能的有效诊断工具，能够通过多维度分类变量来测试语音识别模型的准确性。

Conclusion: SFUSED数据库的设计和标注方法为语音识别模型的测试和评估提供了有价值的工具，特别是在分析不同类型语音错误对ASR系统性能的影响方面。

Abstract: The Simon Fraser University Speech Error Database (SFUSED) is a public data
collection developed for linguistic and psycholinguistic research. Here we
demonstrate how its design and annotations can be used to test and evaluate
speech recognition models. The database comprises systematically annotated
speech errors from spontaneous English speech, with each error tagged for
intended and actual error productions. The annotation schema incorporates
multiple classificatory dimensions that are of some value to model assessment,
including linguistic hierarchical level, contextual sensitivity, degraded
words, word corrections, and both word-level and syllable-level error
positioning. To assess the value of these classificatory variables, we
evaluated the transcription accuracy of WhisperX across 5,300 documented word
and phonological errors. This analysis demonstrates the atabase's effectiveness
as a diagnostic tool for ASR system performance.

</details>


### [72] [Reinforced Context Order Recovery for Adaptive Reasoning and Planning](https://arxiv.org/abs/2508.13070)
*Long Ma,Fangwei Zhong,Yizhou Wang*

Main category: cs.CL

TL;DR: ReCOR是一个基于强化学习的框架，通过自适应选择token生成顺序来提升语言模型在推理和规划任务上的性能，无需标注数据即可从文本中学习最优生成顺序。


<details>
  <summary>Details</summary>
Motivation: 当前因果语言模型和扩散模型使用固定或随机的token生成顺序，这可能偏离原始的逻辑顺序，导致在处理需要自适应token生成顺序的推理和规划问题时遇到困难。

Method: 提出ReCOR框架，通过强化学习自监督地估计每个未填充token的预测难度，在训练和推理过程中自适应选择下一个要生成的token，无需人工标注即可从数据中提取最优生成顺序。

Result: 在具有挑战性的推理和规划数据集上的实验表明，ReCOR相比基线方法表现出优越性能，有时甚至优于使用真实顺序监督的oracle模型。

Conclusion: ReCOR框架通过自适应token生成顺序显著提升了语言模型在复杂推理任务上的能力，证明了学习数据依赖的生成顺序对于解决需要灵活推理模式的问题至关重要。

Abstract: Modern causal language models, followed by rapid developments in discrete
diffusion models, can now produce a wide variety of interesting and useful
content. However, these families of models are predominantly trained to output
tokens with a fixed (left-to-right) or random order, which may deviate from the
logical order in which tokens are generated originally. In this paper, we
observe that current causal and diffusion models encounter difficulties in
problems that require adaptive token generation orders to solve tractably,
which we characterize with the $\mathcal{V}$-information framework. Motivated
by this, we propose Reinforced Context Order Recovery (ReCOR), a
reinforcement-learning-based framework to extract adaptive, data-dependent
token generation orders from text data without annotations. Self-supervised by
token prediction statistics, ReCOR estimates the hardness of predicting every
unfilled token and adaptively selects the next token during both training and
inference. Experiments on challenging reasoning and planning datasets
demonstrate the superior performance of ReCOR compared with baselines,
sometimes outperforming oracle models supervised with the ground-truth order.

</details>


### [73] [DocHPLT: A Massively Multilingual Document-Level Translation Dataset](https://arxiv.org/abs/2508.13079)
*Dayyán O'Brien,Bhavitvya Malik,Ona de Gibert,Pinzhen Chen,Barry Haddow,Jörg Tiedemann*

Main category: cs.CL

TL;DR: DocHPLT是迄今为止最大的公开文档级翻译数据集，包含1.24亿个文档对，涵盖50种语言与英语配对，包含42.6亿个句子，为长上下文建模和文档级翻译提供重要基础设施。


<details>
  <summary>Details</summary>
Motivation: 现有文档级机器翻译资源仅适用于少数高资源语言，为促进全球社区的文档级翻译和长上下文建模训练与评估，需要创建大规模多语言文档级翻译数据集。

Method: 修改现有的网页提取流程以保持源文档的完整性，保留所有内容包括未对齐部分，而不是基于句子级数据拼接文档的重建方法。通过初步实验确定最佳训练上下文策略。

Result: 在DocHPLT上微调的大型语言模型显著优于现成的指令调优基线，特别是对低资源语言的改进尤为显著。

Conclusion: DocHPLT数据集在宽松许可下开源，为推进多语言文档级翻译提供了必要的基础设施，特别有助于低资源语言的发展。

Abstract: Existing document-level machine translation resources are only available for
a handful of languages, mostly high-resourced ones. To facilitate the training
and evaluation of document-level translation and, more broadly, long-context
modeling for global communities, we create DocHPLT, the largest publicly
available document-level translation dataset to date. It contains 124 million
aligned document pairs across 50 languages paired with English, comprising 4.26
billion sentences, with further possibility to provide 2500 bonus pairs not
involving English. Unlike previous reconstruction-based approaches that piece
together documents from sentence-level data, we modify an existing web
extraction pipeline to preserve complete document integrity from the source,
retaining all content including unaligned portions. After our preliminary
experiments identify the optimal training context strategy for document-level
translation, we demonstrate that LLMs fine-tuned on DocHPLT substantially
outperform off-the-shelf instruction-tuned baselines, with particularly
dramatic improvements for under-resourced languages. We open-source the dataset
under a permissive license, providing essential infrastructure for advancing
multilingual document-level translation.

</details>


### [74] [All for law and law for all: Adaptive RAG Pipeline for Legal Research](https://arxiv.org/abs/2508.13107)
*Figarri Keisha,Prince Singh,Pallavi,Dion Fernandes,Aravindh Manivannan,Ilham Wicaksono,Faisal Ahmad*

Main category: cs.CL

TL;DR: 通过三项具体改进（上下文感知查询翻译、开源检索策略、综合评估框架）构建了一个高效且成本效益的法律领域RAG系统，在检索质量和回答准确性方面可与专有方案相比或更优。


<details>
  <summary>Details</summary>
Motivation: 法律领域对于准确性和可考性要求极高，RAG技术能够通过引用来源减少大语言模型的幻觉现象，因此需要专门为法律领域设计高效的RAG系统。

Method: 1）上下文感知查询翻译器，分离文档引用和自然语言问题
2）使用SBERT和GTE嵌入的开源检索策略
3）结合RAGAS、BERTScore-F1和ROUGE-Recall的综合评估框架

Result: 检索性能显著提升：Recall@K提高30-95%，Precision@K提高约2.5倍（K>4时）；定制法律提示词产生更准确和上下文相关的答案；开源管线在检索质量方面可与专有方案相比或更优。

Conclusion: 通过任务感知的组件级调优，可以建立高效、可复现且成本效益的法律RAG系统，为法律研究提供可靠的辅助。

Abstract: Retrieval-Augmented Generation (RAG) mitigates hallucinations by grounding
large language model outputs in cited sources, a capability that is especially
critical in the legal domain. We present an end-to-end RAG pipeline that
revisits and extends the LegalBenchRAG baseline with three targeted
enhancements: (i) a context-aware query translator that disentangles document
references from natural-language questions and adapts retrieval depth and
response style based on expertise and specificity, (ii) open-source retrieval
strategies using SBERT and GTE embeddings that achieve substantial performance
gains (improving Recall@K by 30-95\% and Precision@K by $\sim$2.5$\times$ for
$K>4$) while remaining cost-efficient, and (iii) a comprehensive evaluation and
generation framework that combines RAGAS, BERTScore-F1, and ROUGE-Recall to
assess semantic alignment and faithfulness across models and prompt designs.
Our results show that carefully designed open-source pipelines can rival or
outperform proprietary approaches in retrieval quality, while a custom
legal-grounded prompt consistently produces more faithful and contextually
relevant answers than baseline prompting. Taken together, these contributions
demonstrate the potential of task-aware, component-level tuning to deliver
legally grounded, reproducible, and cost-effective RAG systems for legal
research assistance.

</details>


### [75] [AutoBnB-RAG: Enhancing Multi-Agent Incident Response with Retrieval-Augmented Generation](https://arxiv.org/abs/2508.13118)
*Zefang Liu,Arman Anwar*

Main category: cs.CL

TL;DR: 这篇论文提出了AutoBnB-RAG框架，通过结合检索增强生成技术来改善大语言模型在事件响应中的决策能力，在多种团队结构下都显著提高了成功率和决策质量。


<details>
  <summary>Details</summary>
Motivation: 事件响应需要快速、协同的决策，而大语言模型在模拟环境中往往因缺乏外部知识而限制了思维能力。

Method: 基于AutoBnB框架构建AutoBnB-RAG，结合检索增强生成技术，包括两种检索设置：基于精选技术文档的RAG-Wiki和使用叙事风格事件报告的RAG-News，并在8种团队结构下进行评估。

Result: 检索增强提高了决策质量和成功率，能够重建复杂的多阶段攻击，在多种组织模型中都取得了显著改善。

Conclusion: 这项工作证明了将检索机制集成到基于LLM的多代理系统中对网络安全决策的价值。

Abstract: Incident response (IR) requires fast, coordinated, and well-informed
decision-making to contain and mitigate cyber threats. While large language
models (LLMs) have shown promise as autonomous agents in simulated IR settings,
their reasoning is often limited by a lack of access to external knowledge. In
this work, we present AutoBnB-RAG, an extension of the AutoBnB framework that
incorporates retrieval-augmented generation (RAG) into multi-agent incident
response simulations. Built on the Backdoors & Breaches (B&B) tabletop game
environment, AutoBnB-RAG enables agents to issue retrieval queries and
incorporate external evidence during collaborative investigations. We introduce
two retrieval settings: one grounded in curated technical documentation
(RAG-Wiki), and another using narrative-style incident reports (RAG-News). We
evaluate performance across eight team structures, including newly introduced
argumentative configurations designed to promote critical reasoning. To
validate practical utility, we also simulate real-world cyber incidents based
on public breach reports, demonstrating AutoBnB-RAG's ability to reconstruct
complex multi-stage attacks. Our results show that retrieval augmentation
improves decision quality and success rates across diverse organizational
models. This work demonstrates the value of integrating retrieval mechanisms
into LLM-based multi-agent systems for cybersecurity decision-making.

</details>


### [76] [Spot the BlindSpots: Systematic Identification and Quantification of Fine-Grained LLM Biases in Contact Center Summaries](https://arxiv.org/abs/2508.13124)
*Kawin Mayilvaghanan,Siddhant Gupta,Ayush Kumar*

Main category: cs.CL

TL;DR: 提出了BlindSpot框架来检测和量化LLM在客服通话摘要中的操作偏见，发现了所有测试模型都存在系统性偏见


<details>
  <summary>Details</summary>
Motivation: LLM在客服中心每天生成数百万通话摘要，但其是否对特定方面存在系统性偏见尚未研究，特别是操作偏见维度

Method: 构建包含15个操作偏见维度的分类法，使用LLM作为零样本分类器计算转录和摘要的分布差异，通过保真度差距和覆盖率两个指标量化偏见

Result: 对2500个真实通话和20个不同规模家族的LLM摘要分析显示，偏见是系统性的，存在于所有评估模型中

Conclusion: 操作偏见是LLM摘要中普遍存在的系统性问题，需要专门框架来检测和缓解

Abstract: Abstractive summarization is a core application in contact centers, where
Large Language Models (LLMs) generate millions of summaries of call transcripts
daily. Despite their apparent quality, it remains unclear whether LLMs
systematically under- or over-attend to specific aspects of the transcript,
potentially introducing biases in the generated summary. While prior work has
examined social and positional biases, the specific forms of bias pertinent to
contact center operations - which we term Operational Bias - have remained
unexplored. To address this gap, we introduce BlindSpot, a framework built upon
a taxonomy of 15 operational bias dimensions (e.g., disfluency, speaker, topic)
for the identification and quantification of these biases. BlindSpot leverages
an LLM as a zero-shot classifier to derive categorical distributions for each
bias dimension in a pair of transcript and its summary. The bias is then
quantified using two metrics: Fidelity Gap (the JS Divergence between
distributions) and Coverage (the percentage of source labels omitted). Using
BlindSpot, we conducted an empirical study with 2500 real call transcripts and
their summaries generated by 20 LLMs of varying scales and families (e.g., GPT,
Llama, Claude). Our analysis reveals that biases are systemic and present
across all evaluated models, regardless of size or family.

</details>


### [77] [MuDRiC: Multi-Dialect Reasoning for Arabic Commonsense Validation](https://arxiv.org/abs/2508.13130)
*Kareem Elozeiri,Mervat Abassy,Preslav Nakov,Yuxia Wang*

Main category: cs.CL

TL;DR: 这篇论文提出了MuDRiC数据集和基于GCN的新方法，用于阿拉伯语多方言常识验证，补充了现有资源仅聚焦现代标准阿拉伯语的空白。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语常识验证任务在多方言环境下研究不足，现有资源主要聚焦现代标准阿拉伯语(MSA)，而广泛使用的地区方言却缺乏补充。

Method: 提出了两项核心贡献：1) MuDRiC数据集，包含多种阿拉伯语方言的常识数据；2) 基于图卷积神经网络(GCN)的新方法，优化语义关系建模。

Result: 实验结果显示该方法在阿拉伯语常识验证任务上实现了更优异的性能。

Conclusion: 该研究通过提供基础数据集和新题方法，为处理阿拉伯语复杂语言变体的自然语言理解做出了贡献，是首个阿拉伯语多方言常识推理数据集。

Abstract: Commonsense validation evaluates whether a sentence aligns with everyday
human understanding, a critical capability for developing robust natural
language understanding systems. While substantial progress has been made in
English, the task remains underexplored in Arabic, particularly given its rich
linguistic diversity. Existing Arabic resources have primarily focused on
Modern Standard Arabic (MSA), leaving regional dialects underrepresented
despite their prevalence in spoken contexts. To bridge this gap, we present two
key contributions: (i) we introduce MuDRiC, an extended Arabic commonsense
dataset incorporating multiple dialects, and (ii) a novel method adapting Graph
Convolutional Networks (GCNs) to Arabic commonsense reasoning, which enhances
semantic relationship modeling for improved commonsense validation. Our
experimental results demonstrate that this approach achieves superior
performance in Arabic commonsense validation. Our work enhances Arabic natural
language understanding by providing both a foundational dataset and a novel
method for handling its complex variations. To the best of our knowledge, we
release the first Arabic multi-dialect commonsense reasoning dataset.

</details>


### [78] [Improving Detection of Watermarked Language Models](https://arxiv.org/abs/2508.13131)
*Dara Bahri,John Wieting*

Main category: cs.CL

TL;DR: 本文研究如何通过结合水印检测器和非水印检测器来提高大语言模型生成文本的检测效果


<details>
  <summary>Details</summary>
Motivation: 水印技术的检测效果强度依赖于语言模型的熵作用，而经过指令循环调整或RLHF后的模型熵作用有限，使得单纯依靠水印的检测革具挑战性

Method: 探索多种混合方案，将水印检测器与非水印检测器结合使用

Result: 在广泛的实验条件下，混合方案的性能超过了任何单一类型检测器

Conclusion: 通过结合水印和非水印检测技术，可以有效提高LLM生成文本的检测能力

Abstract: Watermarking has recently emerged as an effective strategy for detecting the
generations of large language models (LLMs). The strength of a watermark
typically depends strongly on the entropy afforded by the language model and
the set of input prompts. However, entropy can be quite limited in practice,
especially for models that are post-trained, for example via instruction tuning
or reinforcement learning from human feedback (RLHF), which makes detection
based on watermarking alone challenging. In this work, we investigate whether
detection can be improved by combining watermark detectors with non-watermark
ones. We explore a number of hybrid schemes that combine the two, observing
performance gains over either class of detector under a wide range of
experimental conditions.

</details>


### [79] [OptimalThinkingBench: Evaluating Over and Underthinking in LLMs](https://arxiv.org/abs/2508.13141)
*Pranjal Aggarwal,Seungone Kim,Jack Lanchantin,Sean Welleck,Jason Weston,Ilia Kulikov,Swarnadeep Saha*

Main category: cs.CL

TL;DR: 这是一个统一的性能测试平台OptimalThinkingBench，用于评估LLM在简单和复杂任务上的思考效率，发现既有模型都无法在性能和效率之间找到最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在简单任务上过度思考浪费计算资源，而在复杂任务上又思考不足的问题，需要一个统一的评测标准来鼓励发展最佳思考模型。

Method: 构建包含OverthinkingBench（简单查询）和UnderthinkingBench（复杂推理任务）的统一测试平台，使用思考调整准确率指标，对33个不同模型进行全面评估。

Result: 没有任何模型能够在该测试上实现最佳思考。思考模型在简单查询上浪费数百个token但性能没有提升，而非思考模型在复杂任务上表现不如更小的思考模型。

Conclusion: 当前的优化方法都是在两个子测试之间做折衷，强调需要发展更好的统一最佳思考模型来平衡性能和效率。

Abstract: Thinking LLMs solve complex tasks at the expense of increased compute and
overthinking on simpler problems, while non-thinking LLMs are faster and
cheaper but underthink on harder reasoning problems. This has led to the
development of separate thinking and non-thinking LLM variants, leaving the
onus of selecting the optimal model for each query on the end user. In this
work, we introduce OptimalThinkingBench, a unified benchmark that jointly
evaluates overthinking and underthinking in LLMs and also encourages the
development of optimally-thinking models that balance performance and
efficiency. Our benchmark comprises two sub-benchmarks: OverthinkingBench,
featuring simple queries in 72 domains, and UnderthinkingBench, containing 11
challenging reasoning tasks. Using novel thinking-adjusted accuracy metrics, we
perform extensive evaluation of 33 different thinking and non-thinking models
and show that no model is able to optimally think on our benchmark. Thinking
models often overthink for hundreds of tokens on the simplest user queries
without improving performance. In contrast, large non-thinking models
underthink, often falling short of much smaller thinking models. We further
explore several methods to encourage optimal thinking, but find that these
approaches often improve on one sub-benchmark at the expense of the other,
highlighting the need for better unified and optimal models in the future.

</details>


### [80] [Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation](https://arxiv.org/abs/2508.13144)
*David Heineman,Valentin Hofmann,Ian Magnusson,Yuling Gu,Noah A. Smith,Hannaneh Hajishirzi,Kyle Lo,Jesse Dodge*

Main category: cs.CL

TL;DR: 这篇论文分析了语言模型评测基准的质量标准，提出了信器和噪声两个关键指标，并提出了三种提高评测可靠性的干预方法


<details>
  <summary>Details</summary>
Motivation: 大型语言模型开发成本高昂，需要依靠小规模实验做决策，而现有评测基准的质量影响了这些决策的可靠性

Method: 引入信器（评测区分模型能力的能力）和噪声（评测对随机变化的敏感度）两个指标，进行了大规模实验，包括30个基准和375个模型，评估了三种干预方法：改用更好的指标（如困惑度代替准确率）、筛选噪声子任务、平均中间检查点输出

Result: 信器噪声比更高的基准在小规模实验中更可靠，噪声更小的基准有更低的缩放律预测错误，提出的三种干预方法都能提高评测的可靠性

Conclusion: 建议在创建新基准或选择现有基准时，应该追求高信器和低噪声的评测方案，以提高评测结果的可靠性和决策质量

Abstract: Developing large language models is expensive and involves making decisions
with small experiments, typically by evaluating on large, multi-task evaluation
suites. In this work, we analyze specific properties which make a benchmark
more reliable for such decisions, and interventions to design higher-quality
evaluation benchmarks. We introduce two key metrics that show differences in
current benchmarks: signal, a benchmark's ability to separate better models
from worse models, and noise, a benchmark's sensitivity to random variability
between training steps. We demonstrate that benchmarks with a better
signal-to-noise ratio are more reliable when making decisions at small scale,
and those with less noise have lower scaling law prediction error. These
results suggest that improving signal or noise will lead to more useful
benchmarks, so we introduce three interventions designed to directly affect
signal or noise. For example, we propose that switching to a metric that has
better signal and noise (e.g., perplexity rather than accuracy) leads to better
reliability and improved scaling law error. We also find that filtering noisy
subtasks, to improve an aggregate signal-to-noise ratio, leads to more reliable
multi-task evaluations. We also find that averaging the output of a model's
intermediate checkpoints to reduce noise leads to consistent improvements. We
conclude by recommending that those creating new benchmarks, or selecting which
existing benchmarks to use, aim for high signal and low noise. We use 30
benchmarks for these experiments, and 375 open-weight language models from 60M
to 32B parameters, resulting in a new, publicly available dataset of 900K
evaluation benchmark results, totaling 200M instances.

</details>


### [81] [RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns](https://arxiv.org/abs/2508.13152)
*Xin Chen,Junchao Wu,Shu Yang,Runzhe Zhan,Zeyu Wu,Ziyang Luo,Di Wang,Min Yang,Lidia S. Chao,Derek F. Wong*

Main category: cs.CL

TL;DR: RepreGuard是一种基于LLM内部表示统计特征的高效检测方法，在分布内外场景下都能有效区分AI生成文本和人类撰写文本，平均AUROC达到94.92%


<details>
  <summary>Details</summary>
Motivation: 现有检测方法在分布外场景下的鲁棒性不足，作者假设LLM内部表示包含更全面和原始的特征，能更有效捕捉AI生成文本和人类文本的统计模式差异

Method: 使用代理模型收集两种文本的表示，提取能更好识别AI生成文本的激活特征，通过计算文本表示在该特征方向上的投影分数并与预设阈值比较进行分类

Result: 在分布内外场景下平均AUROC达到94.92%，优于所有基线方法，对不同文本长度和主流攻击具有强鲁棒性

Conclusion: LLM内部表示确实包含区分AI生成文本和人类文本的有效特征，RepreGuard方法在检测性能和鲁棒性方面都表现出色

Abstract: Detecting content generated by large language models (LLMs) is crucial for
preventing misuse and building trustworthy AI systems. Although existing
detection methods perform well, their robustness in out-of-distribution (OOD)
scenarios is still lacking. In this paper, we hypothesize that, compared to
features used by existing detection methods, the internal representations of
LLMs contain more comprehensive and raw features that can more effectively
capture and distinguish the statistical pattern differences between
LLM-generated texts (LGT) and human-written texts (HWT). We validated this
hypothesis across different LLMs and observed significant differences in neural
activation patterns when processing these two types of texts. Based on this, we
propose RepreGuard, an efficient statistics-based detection method.
Specifically, we first employ a surrogate model to collect representation of
LGT and HWT, and extract the distinct activation feature that can better
identify LGT. We can classify the text by calculating the projection score of
the text representations along this feature direction and comparing with a
precomputed threshold. Experimental results show that RepreGuard outperforms
all baselines with average 94.92% AUROC on both in-distribution (ID) and OOD
scenarios, while also demonstrating robust resilience to various text sizes and
mainstream attacks. Data and code are publicly available at:
https://github.com/NLP2CT/RepreGuard

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [82] [Ges-QA: A Multidimensional Quality Assessment Dataset for Audio-to-3D Gesture Generation](https://arxiv.org/abs/2508.12020)
*Zhilin Gao,Yunhao Li,Sijing Wu,Yuqin Cao,Huiyu Duan,Guangtao Zhai*

Main category: cs.MM

TL;DR: 提出Ges-QA数据集和多模态转换器网络Ges-QAer，用于评估音频到3D手势生成质量和音手一致性，解决现有指标与人类偏好不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 现有音频到3D手势生成评估指标（如FGD、Beat Constancy）无法反映人类偏好，需要建立更符合人类观感的客观质量评估标准。

Method: 构建Ges-QA数据集（1,400个样本），包含多维度质量分数和音手一致性标签；设计多模态转换器网络Ges-QAer，通过视频、音频和3D骨架三个分支进行多维度评分。

Result: Ges-QAer在Ges-QA数据集上达到最先进性能，实验结果和消融研究验证了方法的有效性。

Conclusion: 该研究为A2G任务提供了更符合人类偏好的客观质量评估方法，Ges-QA数据集和Ges-QAer模型对虚拟现实和计算机图形学应用具有重要意义。

Abstract: The Audio-to-3D-Gesture (A2G) task has enormous potential for various
applications in virtual reality and computer graphics, etc. However, current
evaluation metrics, such as Fr\'echet Gesture Distance or Beat Constancy, fail
at reflecting the human preference of the generated 3D gestures. To cope with
this problem, exploring human preference and an objective quality assessment
metric for AI-generated 3D human gestures is becoming increasingly significant.
In this paper, we introduce the Ges-QA dataset, which includes 1,400 samples
with multidimensional scores for gesture quality and audio-gesture consistency.
Moreover, we collect binary classification labels to determine whether the
generated gestures match the emotions of the audio. Equipped with our Ges-QA
dataset, we propose a multi-modal transformer-based neural network with 3
branches for video, audio and 3D skeleton modalities, which can score A2G
contents in multiple dimensions. Comparative experimental results and ablation
studies demonstrate that Ges-QAer yields state-of-the-art performance on our
dataset.

</details>


### [83] [CEM-Net: Cross-Emotion Memory Network for Emotional Talking Face Generation](https://arxiv.org/abs/2508.12368)
*Kangyi Wu,Pengna Li,Jingwen Fu,Yang Wu,Yuhan Liu,Sanping Zhou,Jinjun Wang*

Main category: cs.MM

TL;DR: 跨情感内存网络(CEM-Net)解决参考图片情感与音频情感冲突问题，通过音频情感增强和情感桥接内存模块，生成更准确、自然的情感说话人脸视频


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了参考图片可能包含与音频情感冲突的强情感，导致生成结果情感不准确和变形

Method: 提出CEM-Net，包含音频情感增强模块(AEE)和情感桥接内存模块(EBM)，通过跨重构训练策略增强音频情感，并使用内存网络补偿缺乏的面部运动信息

Result: 实验表明CEM-Net能够合成表情丰富、自然、唇垂同步的说话人脸视频，具有更好的情感准确性

Conclusion: CEM-Net通过处理参考图片与音频情感冲突的问题，有效提升了情感说话人脸生成的质量和准确性

Abstract: Emotional talking face generation aims to animate a human face in given
reference images and generate a talking video that matches the content and
emotion of driving audio. However, existing methods neglect that reference
images may have a strong emotion that conflicts with the audio emotion, leading
to severe emotion inaccuracy and distorted generated results. To tackle the
issue, we introduce a cross-emotion memory network(CEM-Net), designed to
generate emotional talking faces aligned with the driving audio when reference
images exhibit strong emotion. Specifically, an Audio Emotion Enhancement
module(AEE) is first devised with the cross-reconstruction training strategy to
enhance audio emotion, overcoming the disruption from reference image emotion.
Secondly, since reference images cannot provide sufficient facial motion
information of the speaker under audio emotion, an Emotion Bridging Memory
module(EBM) is utilized to compensate for the lacked information. It brings in
expression displacement from the reference image emotion to the audio emotion
and stores it in the memory.Given a cross-emotion feature as a query, the
matching displacement can be retrieved at inference time. Extensive experiments
have demonstrated that our CEM-Net can synthesize expressive, natural and
lip-synced talking face videos with better emotion accuracy.

</details>


### [84] [MAGNeT: Multimodal Adaptive Gaussian Networks for Intent Inference in Moving Target Selection across Complex Scenarios](https://arxiv.org/abs/2508.12992)
*Xiangxian Li,Yawen Zheng,Baiqiao Zhang,Yijia Ma,XianhuiCao XianhuiCao,Juan Liu,Yulong Bian,Jin Huang,Chenglei Yang*

Main category: cs.MM

TL;DR: MAGNeT是一种多模态自适应高斯网络，通过结合经典统计建模和上下文感知方法，实现了在少样本条件下对移动目标选择的低错误率。


<details>
  <summary>Details</summary>
Motivation: 多媒体交互系统中移动目标选择面临新挑战，现有概率模型需要大量训练数据且缺乏跨场景迁移能力，无法适应多样化多媒体环境。

Method: MAGNeT动态融合来自不同场景的预拟合三元高斯模型，基于实时上下文线索进行多模态自适应，在保持模型可解释性的同时实现少样本有效适应。

Result: 在车载振动条件下的2D和3D移动目标选择数据集实验中，MAGNeT通过多因素条件的高斯专家上下文感知融合，实现了较低的少样本错误率。

Conclusion: MAGNeT成功解决了跨场景迁移问题，在少样本条件下显著提升了移动目标选择的性能，为多样化多媒体环境中的交互提供了有效解决方案。

Abstract: Moving target selection in multimedia interactive systems faces unprecedented
challenges as users increasingly interact across diverse and dynamic
contexts-from live streaming in moving vehicles to VR gaming in varying
environments. Existing approaches rely on probabilistic models that relate
endpoint distribution to target properties such as size and speed. However,
these methods require substantial training data for each new context and lack
transferability across scenarios, limiting their practical deployment in
diverse multimedia environments where rich multimodal contextual information is
readily available. This paper introduces MAGNeT (Multimodal Adaptive Gaussian
Networks), which addresses these problems by combining classical statistical
modeling with a context-aware multimodal method. MAGNeT dynamically fuses
pre-fitted Ternary-Gaussian models from various scenarios based on real-time
contextual cues, enabling effective adaptation with minimal training data while
preserving model interpretability. We conduct experiments on self-constructed
2D and 3D moving target selection datasets under in-vehicle vibration
conditions. Extensive experiments demonstrate that MAGNeT achieves lower error
rates with few-shot samples by applying context-aware fusion of Gaussian
experts from multi-factor conditions.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [85] [Prediction of Spotify Chart Success Using Audio and Streaming Features](https://arxiv.org/abs/2508.11632)
*Ian Jacob Cabansag,Paul Ntegeka*

Main category: cs.SD

TL;DR: 开发了一个分类管道，基于音乐特征和早期参与数据预测歌曲在Spotify排行榜上的成功，树模型表现最佳，准确率约97%


<details>
  <summary>Details</summary>
Motivation: 理解影响歌曲在Spotify排行榜上排名上升的因素，特别是早期阶段，可以指导营销、投资决策和艺术方向

Method: 使用2024年美国Top 200 Spotify每日排行榜数据和Spotify Web API构建数据集，包含14,639首独特歌曲的元数据和音频特征。分两阶段：基准测试四种模型（逻辑回归、K近邻、随机森林、XGBoost），然后进行交叉验证、超参数调优和详细类别评估

Result: 树模型表现最佳，随机森林和XGBoost的宏观F1分数接近0.95，准确率约97%。即使排除流媒体计数和排名历史，仅基于音频属性的模型仍保持预测能力

Conclusion: 这些发现验证了基于音频的建模在A&R发掘、播放列表优化和热门预测方面的潜力，远在歌曲达到临界质量之前

Abstract: Spotify's streaming charts offer a real-time lens into music popularity,
driving discovery, playlists, and even revenue potential. Understanding what
influences a song's rise in ranks on these charts-especially early on-can guide
marketing efforts, investment decisions, and even artistic direction. In this
project, we developed a classification pipeline to predict a song's chart
success based on its musical characteristics and early engagement data. Using
all 2024 U.S. Top 200 Spotify Daily Charts and the Spotify Web API, we built a
dataset containing both metadata and audio features for 14,639 unique songs.
  The project was structured in two phases. First, we benchmarked four models:
Logistic Regression, K Nearest Neighbors, Random Forest, and XGBoost-using a
standard train-test split. In the second phase, we incorporated
cross-validation, hyperparameter tuning, and detailed class-level evaluation to
ensure robustness. Tree-based models consistently outperformed the rest, with
Random Forest and XGBoost achieving macro F1-scores near 0.95 and accuracy
around 97%.
  Even when stream count and rank history were excluded, models trained solely
on audio attributes retained predictive power. These findings validate the
potential of audio-based modeling in A&R scouting, playlist optimization, and
hit forecasting-long before a track reaches critical mass.

</details>


### [86] [Audio Flamingo Sound-CoT Technical Report: Improving Chain-of-Thought Reasoning in Sound Understanding](https://arxiv.org/abs/2508.11818)
*Zhifeng Kong,Arushi Goel,Joao Felipe Santos,Sreyan Ghosh,Rafael Valle,Wei Ping,Bryan Catanzaro*

Main category: cs.SD

TL;DR: 通过构建AF-CoT-Train训练数据集和AF-Reasoning-Eval评测标准，证明了链式思维微调在音频语言模型中的效果


<details>
  <summary>Details</summary>
Motivation: 链式思维推理在文本和图像模型中已显示显著改善，但在音频语言模型中的潜力尚未得到充分探索

Method: 构建AF-Reasoning-Eval评测标准，开发自动化流水线将现有音频数据转换为明确的推理链，生成包含124万样本的AF-CoT-Train数据集，对Audio Flamingo系列模型进行微调

Result: 在多个推理评测标准上观察到显著改进，验证了链式思维微调对高级音响理解能力的有效性

Conclusion: 链式思维学习在音频语言模型中同样具有重要价值，为音响理解的推理能力提供了新的发展方向

Abstract: Chain-of-thought reasoning has demonstrated significant improvements in large
language models and vision language models, yet its potential for audio
language models remains largely unexplored. In this technical report, we take a
preliminary step towards closing this gap. For better assessment of sound
reasoning, we propose AF-Reasoning-Eval, a benchmark targeting common-sense
reasoning and the ability to discriminate among closely related choices. To
prepare training corpus for sound reasoning abilities, we propose automatic
pipelines that transform existing audio question answering and classification
data into explicit reasoning chains, yielding AF-CoT-Train with 1.24M samples.
We study the effect of finetuning Audio Flamingo series on AF-CoT-Train and
observe considerable improvements on several reasoning benchmarks, validating
the effectiveness of chain-of-thought finetuning on advanced sound
understanding.

</details>


### [87] [Cross-Modal Knowledge Distillation with Multi-Level Data Augmentation for Low-Resource Audio-Visual Sound Event Localization and Detection](https://arxiv.org/abs/2508.12334)
*Qing Wang,Ya Jiang,Hang Chen,Sabato Marco Siniscalchi,Jun Du,Jianqing Gao*

Main category: cs.SD

TL;DR: 通过跨模态知识萌蓈和多层次数据增强技术，提出了一种在低资源情况下提升音视频声音事件定位检测性能的方法，在DCASE比赛中取得了显著成效


<details>
  <summary>Details</summary>
Motivation: 解决低资源情况下音视频声音事件定位检测(SELD)性能不佳的问题，通过知识萌蓈技术利用音频单模态模型的知识来提升音视频模型的表现

Method: 使用音频单模态SELD模型作为教师模型，通过输出响应和中间特征表示向音视频学生模型进行知识萌蓈，结合多层次网络特征的随机混合数据增强技术，以及专门为SELD任务设计的损失函数

Result: 在DCASE 2023和2024 SELD数据集上进行了大量实验，方法在整体指标上相比基线提升22%~36%，达到了与在更大数据集上训练的教师模型相当或更好的结果，在两个DCASE任务上都超越了最先进方法

Conclusion: 该研究提出的跨模态知识萌蓈框架结合多层次数据增强技术，能够有效提升低资源情况下音视频SELD的性能，为跨模态学习领域提供了有效的解决方案

Abstract: This work presents a cross-modal knowledge distillation (CMKD) framework
combined with multi-level data augmentation for low-resource audio-visual (AV)
sound event localization and detection (SELD). An audio-only SELD model acts as
the teacher, transferring knowledge to an AV student model through both output
responses and intermediate feature representations. To enhance learning, data
augmentation is applied by mixing features randomly selected from multiple
network layers and associated loss functions tailored to the SELD task.
Extensive experiments on the DCASE 2023 and 2024 SELD datasets show that the
proposed method significantly improves AV SELD performance, yielding relative
gains of 22%~36% in the overall metric over the baseline. Notably, our approach
achieves results comparable to or better than teacher models trained on much
larger datasets, surpassing state-of-the-art methods on both DCASE 2023 and
2024 SELD tasks.

</details>


### [88] [What Matters for Bioacoustic Encoding](https://arxiv.org/abs/2508.11845)
*Marius Miron,David Robinson,Milad Alizadeh,Ellen Gilsenan-McMahon,Gagan Narula,Olivier Pietquin,Matthieu Geist,Emmanuel Chemla,Maddie Cusimano,Felix Effenberger,Masato Hagiwara,Benjamin Hoffman,Sara Keen,Diane Kim,Jane Lawton,Jen-Yu Liu,Aza Raskin*

Main category: cs.SD

TL;DR: 这篇论文进行了大规模生物声学编码器研究，通过自监督预训练和监督后训练组合，在26个数据集上实现了独树一庄的性能，并确认了数据多样性的重要性。


<details>
  <summary>Details</summary>
Motivation: 生物声学领域缺乏注解数据，需要通用的编码器来提取有用表征。以往研究存在范围窄局限性（主要聚焦鸟类）、模型架构和评估任务的缺乏等问题。

Method: 进行大规模实验研究，包括训练数据的多样性和规模、模型架构和训练方案、评估任务和数据集的广度。采用自监督预训练经验后监督后训练的组合方式，使用混合生物声学+通用音频语料库。

Result: 在26个数据集上（包括物种分类、检测、个体识别、发声库发现等任务）获得了独树一庄的性能，显示了在分布内和分布外都有优异表现。证明了两个训练阶段中数据多样性的关键作用。

Conclusion: 通过系统性的实验设计和评估，提出了最优的生物声学编码器训练方案，为未来研究提供了重要指导。将释放模型检查点以支持进一步研究和应用。

Abstract: Bioacoustics, the study of sounds produced by living organisms, plays a vital
role in conservation, biodiversity monitoring, and behavioral studies. Many
tasks in this field, such as species, individual, and behavior classification
and detection, are well-suited to machine learning. However, they often suffer
from limited annotated data, highlighting the need for a general-purpose
bioacoustic encoder capable of extracting useful representations for diverse
downstream tasks. Such encoders have been proposed before, but are often
limited in scope due to a focus on a narrow range of species (typically birds),
and a reliance on a single model architecture or training paradigm. Moreover,
they are usually evaluated on a small set of tasks and datasets. In this work,
we present a large-scale empirical study that covers aspects of bioacoustics
that are relevant to research but have previously been scarcely considered:
training data diversity and scale, model architectures and training recipes,
and the breadth of evaluation tasks and datasets. We obtain encoders that are
state-of-the-art on the existing and proposed benchmarks. We also identify what
matters for training these encoders, such that this work can be extended when
more data are available or better architectures are proposed. Specifically,
across 26 datasets with tasks including species classification, detection,
individual ID, and vocal repertoire discovery, we find self-supervised
pre-training followed by supervised post-training on a mixed bioacoustics +
general-audio corpus yields the strongest in- and out-of-distribution
performance. We show the importance of data diversity in both stages. To
support ongoing research and application, we will release the model
checkpoints.

</details>


### [89] [Towards Automatic Evaluation and High-Quality Pseudo-Parallel Dataset Construction for Audio Editing: A Human-in-the-Loop Method](https://arxiv.org/abs/2508.11966)
*Yuhang Jia,Hui Wang,Xin Nie,Yujie Guo,Lianru Gao,Yong Qin*

Main category: cs.SD

TL;DR: 这篇论文提出了一个新的音频编辑评估框架AuditEval，包括首个主观评估数据集AuditScore和自动MOS评分模型，以解决音频编辑领域缺乏高质量数据集和评估指标的挑战。


<details>
  <summary>Details</summary>
Motivation: 音频编辑领域缺乏高质量的标准数据集和全面的评估指标，这不仅影响了对音频编辑质量的评估，也限制了任务本身的发展。

Method: 1）构建AuditScore数据集：包含6,300个编辑样本，由专业评分员在质量、相关性和真实性三个维度进行主观评注 2）训练AuditEval模型：基于AuditScore数据训练自动MOS评分模型 3）构建伪并行数据集：利用AuditEval评估和筛选合成混合的编辑对，选择最可能的样本

Result: 实验结果验证了专家知识引入筛选策略在生成高质量数据方面的有效性，同时也曝露了仅依赖客观指标的局限性。

Conclusion: 该研究为音频编辑领域提供了一个全面的评估框架，包括主观评注数据集、自动评分模型和高质量数据集构建方法，有助于推动音频编辑技术的发展。

Abstract: Audio editing aims to manipulate audio content based on textual descriptions,
supporting tasks such as adding, removing, or replacing audio events. Despite
recent progress, the lack of high-quality benchmark datasets and comprehensive
evaluation metrics remains a major challenge for both assessing audio editing
quality and improving the task itself. In this work, we propose a novel
approach for audio editing task by incorporating expert knowledge into both the
evaluation and dataset construction processes: 1) First, we establish
AuditScore, the first comprehensive dataset for subjective evaluation of audio
editing, consisting of over 6,300 edited samples generated from 7
representative audio editing frameworks and 23 system configurations. Each
sample is annotated by professional raters on three key aspects of audio
editing quality: overall Quality, Relevance to editing intent, and Faithfulness
to original features. 2) Based on this dataset, we train AuditEval, the first
model designed for automatic MOS-style scoring tailored to audio editing tasks.
AuditEval addresses the critical lack of objective evaluation metrics and the
prohibitive cost of subjective assessment in this field. 3) We further leverage
AuditEval to evaluate and filter a large amount of synthetically mixed editing
pairs, constructing a high-quality pseudo-parallel dataset by selecting the
most plausible samples. Objective experiments validate the effectiveness of our
expert-informed filtering strategy in yielding higher-quality data, while also
revealing the limitations of relying solely on objective metrics. The dataset,
codes and tools can be found at: https://github.com/NKU-HLT/AuditEval.

</details>


### [90] [Optimizing Neural Architectures for Hindi Speech Separation and Enhancement in Noisy Environments](https://arxiv.org/abs/2508.12009)
*Arnav Ramamoorthy*

Main category: cs.SD

TL;DR: 该论文提出了一种基于DEMUCS模型的印地语语音分离和增强方法，通过U-Net和LSTM层进行微调，在边缘设备上实现了显著的语音清晰度和可懂度提升。


<details>
  <summary>Details</summary>
Motivation: 解决印地语语音处理在边缘设备上的挑战，克服传统方法的局限性，为印度语境下的语音处理提供定制化AI解决方案。

Method: 使用DEMUCS模型架构，结合U-Net和LSTM层进行微调，在包含40万个印地语语音片段的数据集上训练，并使用ESC-50和MS-SNSD进行数据增强以模拟多样化声学环境。

Result: 使用PESQ和STOI指标评估显示，在极端噪声条件下表现出优越性能，语音清晰度和可懂度得到显著改善。同时探索量化技术以降低计算需求，适用于TWS耳机等资源受限设备。

Conclusion: 研究表明定制化AI算法在印度语境语音处理中的有效性，为优化边缘设备架构的未来发展提供了方向。

Abstract: This paper addresses the challenges of Hindi speech separation and
enhancement using advanced neural network architectures, with a focus on edge
devices. We propose a refined approach leveraging the DEMUCS model to overcome
limitations of traditional methods, achieving substantial improvements in
speech clarity and intelligibility. The model is fine-tuned with U-Net and LSTM
layers, trained on a dataset of 400,000 Hindi speech clips augmented with
ESC-50 and MS-SNSD for diverse acoustic environments. Evaluation using PESQ and
STOI metrics shows superior performance, particularly under extreme noise
conditions. To ensure deployment on resource-constrained devices like TWS
earbuds, we explore quantization techniques to reduce computational
requirements. This research highlights the effectiveness of customized AI
algorithms for speech processing in Indian contexts and suggests future
directions for optimizing edge-based architectures.

</details>


### [91] [Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection](https://arxiv.org/abs/2508.12230)
*Bing Han,Anbai Jiang,Xinhu Zheng,Wei-Qiang Zhang,Jia Liu,Pingyi Fan,Yanmin Qian*

Main category: cs.SD

TL;DR: 本文提出了一种基于自监督预训练模型的机器异常声音检测方法，通过LoRA简化微调、机器感知组适配器和双层对比学习捐失函数，在各大测试集上都取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 机器异常声音检测的通用性能受限于数据收集困难和声学环境的复杂性，需要提升模型的演化性能。

Method: 利用大规模语音和音频数据集预训练的自监督模型，采用Fully-Connected LoRA简化微调防止过拟合，设计机器感知组适配器提升模型对不同机器的区分能力，以及使用向量量化和双层对比学习捐失处理缺少属性标签的数据。

Result: 在DCASE 2020-2024五年的ASD挑战赛数据集上进行测试，实验结果显示新方法对比基线方法有显著提升，证明了提出策略的有效性。

Conclusion: 预训练模型虽然预训练数据集与ASD任务存在不一致性，但仍能为ASD带来显著改善，通过优化微调策略和特殊的模块设计可以有效提升机器异常声音检测的通用性能。

Abstract: Machine anomalous sound detection (ASD) is a valuable technique across
various applications. However, its generalization performance is often limited
due to challenges in data collection and the complexity of acoustic
environments. Inspired by the success of large pre-trained models in numerous
fields, this paper introduces a robust ASD model that leverages self-supervised
pre-trained models trained on large-scale speech and audio datasets. Although
there are inconsistencies between the pre-training datasets and the ASD task,
our findings indicate that pre-training still provides substantial benefits for
ASD. To mitigate overfitting and retain learned knowledge when fine-tuning with
limited data, we explore Fully-Connected Low-Rank Adaptation (LoRA) as an
alternative to full fine-tuning. Additionally, we propose a Machine-aware Group
Adapter module, which enables the model to capture differences between various
machines within a unified framework, thereby enhancing the generalization
performance of ASD systems. To address the challenge of missing attribute
labels, we design a novel objective function that dynamically clusters
unattributed data using vector quantization and optimizes through a dual-level
contrastive learning loss. The proposed methods are evaluated on all benchmark
datasets, including the DCASE 2020-2024 five ASD challenges, and the
experimental results show significant improvements of our new approach and
demonstrate the effectiveness of our proposed strategies.

</details>


### [92] [HuBERT-VIC: Improving Noise-Robust Automatic Speech Recognition of Speech Foundation Model via Variance-Invariance-Covariance Regularization](https://arxiv.org/abs/2508.12292)
*Hyebin Ahn,Kangwook Jang,Hoirin Kim*

Main category: cs.SD

TL;DR: HuBERT-VIC是一个噪声鲁棒的语音基础模型，通过VICReg目标函数调整噪声语音表示的统计特性，相比在噪声语音上预训练的基线模型，在LibriSpeech测试集上性能提升23.3%（clean）和13.2%（other）。


<details>
  <summary>Details</summary>
Motivation: 语音基础模型主要在干净数据上训练，在噪声环境下性能会显著下降，需要提高模型对噪声的鲁棒性。

Method: 提出HuBERT-VIC模型，采用方差、不变性和协方差正则化（VICReg）目标函数来调整噪声语音表示的统计特性，使模型能够捕捉多样化的声学特征。

Result: 在LibriSpeech测试集上，相比在噪声语音上预训练的基线模型，相对性能提升23.3%（test-clean）和13.2%（test-other）。

Conclusion: VICReg目标函数能有效提高语音基础模型在噪声环境下的鲁棒性和泛化能力。

Abstract: Noise robustness in speech foundation models (SFMs) has been a critical
challenge, as most models are primarily trained on clean data and experience
performance degradation when the models are exposed to noisy speech. To address
this issue, we propose HuBERT-VIC, a noise-robust SFM with variance,
in-variance, and covariance regularization (VICReg) objectives. These
objectives adjust the statistics of noisy speech representations, enabling the
model to capture diverse acoustic characteristics and improving the
generalization ability across different types of noise. When applied to HuBERT,
our model shows relative performance improvements of 23.3% on LibriSpeech
test-clean and 13.2% on test-other, compared to the baseline model pre-trained
on noisy speech.

</details>


### [93] [Exploring the Feasibility of LLMs for Automated Music Emotion Annotation](https://arxiv.org/abs/2508.12626)
*Meng Yang,Jon McCormack,Maria Teresa Llano,Wanchao Su*

Main category: cs.SD

TL;DR: 本研究评估了使用GPT-4o进行音乐情感标注的可行性，发现虽然准确性略低于人类专家，但其成本效益和效率使其成为大规模音乐情感标注的有前景的替代方案。


<details>
  <summary>Details</summary>
Motivation: 当前音乐情感标注主要依赖人工标注，资源消耗大且限制了标注数据的规模，需要探索自动化解决方案。

Method: 使用GPT-4o在四象限效价-唤醒框架下对GiantMIDI-Piano古典钢琴音乐数据集进行情感标注，并与三位人类专家的标注进行比较评估。

Result: GPT的标注准确性低于人类专家，在特定情感状态分类上缺乏细微差别，但其变异性仍在专家自然分歧范围内。

Conclusion: GPT标注虽然目前不如人类专家，但其成本效益和效率优势使其成为音乐情感标注的可扩展替代方案。

Abstract: Current approaches to music emotion annotation remain heavily reliant on
manual labelling, a process that imposes significant resource and labour
burdens, severely limiting the scale of available annotated data. This study
examines the feasibility and reliability of employing a large language model
(GPT-4o) for music emotion annotation. In this study, we annotated
GiantMIDI-Piano, a classical MIDI piano music dataset, in a four-quadrant
valence-arousal framework using GPT-4o, and compared against annotations
provided by three human experts. We conducted extensive evaluations to assess
the performance and reliability of GPT-generated music emotion annotations,
including standard accuracy, weighted accuracy that accounts for inter-expert
agreement, inter-annotator agreement metrics, and distributional similarity of
the generated labels.
  While GPT's annotation performance fell short of human experts in overall
accuracy and exhibited less nuance in categorizing specific emotional states,
inter-rater reliability metrics indicate that GPT's variability remains within
the range of natural disagreement among experts. These findings underscore both
the limitations and potential of GPT-based annotation: despite its current
shortcomings relative to human performance, its cost-effectiveness and
efficiency render it a promising scalable alternative for music emotion
annotation.

</details>


### [94] [MATPAC++: Enhanced Masked Latent Prediction for Self-Supervised Audio Representation Learning](https://arxiv.org/abs/2508.12709)
*Aurian Quelennec,Pierre Chouteau,Geoffroy Peeters,Slim Essid*

Main category: cs.SD

TL;DR: 本文提出MATPAC++，通过在自监督学习框架中集成多选择学习(MCL)来显式建模音频预测的模糊性，显著提升了音频表示学习性能，在多个下游任务上达到state-of-the-art水平。


<details>
  <summary>Details</summary>
Motivation: 现有的掩码潜在预测方法在音频自监督学习中表现优异，但预测器模块的作用被忽视。音频内容固有的模糊性（特别是多声源情况）需要更好的建模方式。

Method: 在MATPAC系统基础上集成多选择学习(MCL)，改进预测和无监督分类任务，显式处理预测模糊性问题。

Result: 在AudioSet微调任务上达到state-of-the-art，下游任务整体性能最优。在纯音乐数据训练时，以显著提升的效率获得最佳性能。

Conclusion: MCL能有效建模音频预测的模糊性，提升表示质量，MATPAC++在多个基准测试中展现卓越性能，特别在音乐领域具有高效优势。

Abstract: Masked latent prediction has emerged as a leading paradigm in self-supervised
learning (SSL), especially for general audio and music representation learning.
While recent methods have demonstrated strong performance, the role of the
predictor module used at the output of such SSL systems remains mainly
overlooked, despite being crucial for solving the pretext task at hand. In
particular, this module should be able to deal with the ambiguity inherent in
audio content, especially when it is composed of multiple sound sources. This
work proposes a novel enhancement: integrating Multiple Choice Learning (MCL)
to explicitly model prediction ambiguity and improve representation quality. We
build on top of the recently proposed MATPAC system, improving its prediction
and unsupervised classification pretext tasks with MCL. We extensively evaluate
our method, MATPAC++, through both linear probing across multiple downstream
tasks and fine-tuning on AudioSet, employing a unified protocol that enables
rigorous and fair comparisons with state-of-the-art SSL approaches. Results
show that our proposal achieves state-of-the-art when fine-tuned on AudioSet
and overall state-of-the-art scores on downstream tasks. Additionally, we
examine domain specialisation by training exclusively on music data, where our
model achieves state-of-the-art performance with significantly improved
efficiency.

</details>


### [95] [FoleySpace: Vision-Aligned Binaural Spatial Audio Generation](https://arxiv.org/abs/2508.12918)
*Lei Zhao,Rujin Chen,Chi Zhang,Xiao-Lei Zhang,Xuelong Li*

Main category: cs.SD

TL;DR: FoleySpace是一个视频到双耳音频生成框架，通过视觉信息引导生成沉浸式空间一致的立体声，解决了现有单声道音频缺乏空间感知的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频到音频技术主要关注单声道音频生成，缺乏空间感知能力，而能够提供更强沉浸感的双耳空间音频生成技术研究不足。

Method: 开发声音源估计方法确定视频帧中声源的2D坐标和深度，通过坐标映射机制转换为3D轨迹，结合预训练V2A模型生成的单声道音频，作为扩散模型的输入条件生成空间一致的双耳音频。

Result: 实验结果表明，该方法在空间感知一致性方面优于现有方法，有效提升了音视频体验的沉浸质量。

Conclusion: FoleySpace框架成功实现了视频到双耳音频的生成，通过视觉引导的空间音频合成技术显著增强了音频的空间一致性和沉浸感。

Abstract: Recently, with the advancement of AIGC, deep learning-based video-to-audio
(V2A) technology has garnered significant attention. However, existing research
mostly focuses on mono audio generation that lacks spatial perception, while
the exploration of binaural spatial audio generation technologies, which can
provide a stronger sense of immersion, remains insufficient. To solve this
problem, we propose FoleySpace, a framework for video-to-binaural audio
generation that produces immersive and spatially consistent stereo sound guided
by visual information. Specifically, we develop a sound source estimation
method to determine the sound source 2D coordinates and depth in each video
frame, and then employ a coordinate mapping mechanism to convert the 2D source
positions into a 3D trajectory. This 3D trajectory, together with the monaural
audio generated by a pre-trained V2A model, serves as a conditioning input for
a diffusion model to generate spatially consistent binaural audio. To support
the generation of dynamic sound fields, we constructed a training dataset based
on recorded Head-Related Impulse Responses that includes various sound source
movement scenarios. Experimental results demonstrate that the proposed method
outperforms existing approaches in spatial perception consistency, effectively
enhancing the immersive quality of the audio-visual experience.

</details>
