<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 39]
- [cs.SD](#cs.SD) [Total: 7]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs](https://arxiv.org/abs/2509.13480)
*Andrea Piergentili,Beatrice Savoldi,Matteo Negri,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 本文首次系统评估了大型语言模型在意大利语性别中性改写任务中的表现，提出了衡量中立性和语义保真度的二维框架，发现开源模型优于现有专用模型，微调后的小模型性能可媲美大型模型。


<details>
  <summary>Details</summary>
Motivation: 意大利语等语法性别语言中的性别中性改写具有挑战性，需要消除不必要的性别指代同时保持语义完整性，目前缺乏对此任务的系统性评估。

Method: 采用少样本提示比较多个LLM，对选定模型进行微调，并应用针对性清洗提升任务相关性，建立中立性和语义保真度的二维评估框架。

Result: 开源权重LLM优于现有的意大利语GNR专用模型，微调后的小型模型以更小规模达到或超过最佳开源LLM的性能。

Conclusion: 研究揭示了在优化训练数据时保持中立性和意义保存之间的权衡关系，为语法性别语言的性别中性改写提供了有效的评估方法和模型优化策略。

Abstract: Gender-neutral rewriting (GNR) aims to reformulate text to eliminate
unnecessary gender specifications while preserving meaning, a particularly
challenging task in grammatical-gender languages like Italian. In this work, we
conduct the first systematic evaluation of state-of-the-art large language
models (LLMs) for Italian GNR, introducing a two-dimensional framework that
measures both neutrality and semantic fidelity to the input. We compare
few-shot prompting across multiple LLMs, fine-tune selected models, and apply
targeted cleaning to boost task relevance. Our findings show that open-weight
LLMs outperform the only existing model dedicated to GNR in Italian, whereas
our fine-tuned models match or exceed the best open-weight LLM's performance at
a fraction of its size. Finally, we discuss the trade-off between optimizing
the training data for neutrality and meaning preservation.

</details>


### [2] [Op-Fed: Opinion, Stance, and Monetary Policy Annotations on FOMC Transcripts Using Active Learning](https://arxiv.org/abs/2509.13539)
*Alisa Kanganis,Katherine A. Keith*

Main category: cs.CL

TL;DR: Op-Fed是一个包含1044条人工标注句子的数据集，来自FOMC会议记录，用于分析货币政策立场分类。通过五阶段分层标注方案和主动学习解决数据不平衡和上下文依赖问题。


<details>
  <summary>Details</summary>
Motivation: FOMC的货币政策决策影响数百万人，但现有数据集中表达非中性货币政策立场的句子不足8%，且65%的实例需要句子级以上的上下文，需要专门的数据集来支持相关研究。

Method: 开发了五阶段分层标注方案来分离意见、货币政策和货币政策立场等维度，并使用主动学习选择标注实例，使所有模式方面的正例数量翻倍。

Result: 性能最佳的闭源LLM在意见分类上达到0.80的零样本准确率，但在货币政策立场分类上只有0.61，低于人类基准的0.89。

Conclusion: Op-Fed数据集可用于未来模型训练、置信度校准，并作为未来标注工作的种子数据集。

Abstract: The U.S. Federal Open Market Committee (FOMC) regularly discusses and sets
monetary policy, affecting the borrowing and spending decisions of millions of
people. In this work, we release Op-Fed, a dataset of 1044 human-annotated
sentences and their contexts from FOMC transcripts. We faced two major
technical challenges in dataset creation: imbalanced classes -- we estimate
fewer than 8% of sentences express a non-neutral stance towards monetary policy
-- and inter-sentence dependence -- 65% of instances require context beyond the
sentence-level. To address these challenges, we developed a five-stage
hierarchical schema to isolate aspects of opinion, monetary policy, and stance
towards monetary policy as well as the level of context needed. Second, we
selected instances to annotate using active learning, roughly doubling the
number of positive instances across all schema aspects. Using Op-Fed, we found
a top-performing, closed-weight LLM achieves 0.80 zero-shot accuracy in opinion
classification but only 0.61 zero-shot accuracy classifying stance towards
monetary policy -- below our human baseline of 0.89. We expect Op-Fed to be
useful for future model training, confidence calibration, and as a seed dataset
for future annotation efforts.

</details>


### [3] [Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at DSTC 12](https://arxiv.org/abs/2509.13569)
*John Mendonça,Lining Zhang,Rahul Mallidi,Alon Lavie,Isabel Trancoso,Luis Fernando D'Haro,João Sedoc*

Main category: cs.CL

TL;DR: DSTC12 Track 1 针对对话系统评估的挑战，提出了两个子任务：多维度自动评估和多语言/文化安全检测，结果显示现有方法在文化安全方面仍有显著改进空间


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速发展凸显了对话系统评估的需求，传统指标不足且安全考虑往往定义狭窄或存在文化偏见，需要更全面的评估框架

Method: 设立两个子任务：(1) 对话级多维度自动评估指标（10个维度），(2) 多语言和多文化安全检测。使用Llama-3-8B和Llama-Guard-3-1B作为基线模型

Result: 任务1中Llama-3-8B基线获得最高平均Spearman相关系数0.1681，表明仍有很大改进空间；任务2中参赛团队在多语言安全子集上显著优于基线（最佳ROC-AUC 0.9648），但基线在文化子集上表现更好（0.5126 ROC-AUC）

Conclusion: 对话系统评估在多维度自动评估和文化感知安全检测方面仍面临重大挑战，特别是在文化敏感的安全检测领域需要进一步研究和发展

Abstract: The rapid advancement of Large Language Models (LLMs) has intensified the
need for robust dialogue system evaluation, yet comprehensive assessment
remains challenging. Traditional metrics often prove insufficient, and safety
considerations are frequently narrowly defined or culturally biased. The DSTC12
Track 1, "Dialog System Evaluation: Dimensionality, Language, Culture and
Safety," is part of the ongoing effort to address these critical gaps. The
track comprised two subtasks: (1) Dialogue-level, Multi-dimensional Automatic
Evaluation Metrics, and (2) Multilingual and Multicultural Safety Detection.
For Task 1, focused on 10 dialogue dimensions, a Llama-3-8B baseline achieved
the highest average Spearman's correlation (0.1681), indicating substantial
room for improvement. In Task 2, while participating teams significantly
outperformed a Llama-Guard-3-1B baseline on the multilingual safety subset (top
ROC-AUC 0.9648), the baseline proved superior on the cultural subset (0.5126
ROC-AUC), highlighting critical needs in culturally-aware safety. This paper
describes the datasets and baselines provided to participants, as well as
submission evaluation results for each of the two proposed subtasks.

</details>


### [4] [Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning](https://arxiv.org/abs/2509.13624)
*Shambhavi Krishna,Atharva Naik,Chaitali Agarwal,Sudharshan Govindan,Taesung Lee,Haw-Shiuan Chang*

Main category: cs.CL

TL;DR: 提出了一个分析框架来研究LLM跨任务迁移学习中的潜在能力和副作用，发现性能提升主要受隐藏统计因素和语言特征影响，而非表面数据集相似性


<details>
  <summary>Details</summary>
Motivation: 由于LLM部署到多样化应用中，无法为所有任务获取高质量训练数据，需要依赖不同特征的迁移学习数据集并应对分布外请求

Method: 构建迁移学习矩阵和降维分析框架，训练10个模型识别潜在能力（推理、情感分类、自然语言理解、算术等）并分析迁移学习的副作用

Result: 性能改进往往无法用表面数据集相似性或源数据质量解释，隐藏统计因素（类别分布、生成长度倾向）和特定语言特征更具影响力

Conclusion: 这项工作揭示了迁移学习的复杂动态，为更可预测和有效的LLM适应铺平了道路

Abstract: Large language models are increasingly deployed across diverse applications.
This often includes tasks LLMs have not encountered during training. This
implies that enumerating and obtaining the high-quality training data for all
tasks is infeasible. Thus, we often need to rely on transfer learning using
datasets with different characteristics, and anticipate out-of-distribution
requests. Motivated by this practical need, we propose an analysis framework,
building a transfer learning matrix and dimensionality reduction, to dissect
these cross-task interactions. We train and analyze 10 models to identify
latent abilities (e.g., Reasoning, Sentiment Classification, NLU, Arithmetic)
and discover the side effects of the transfer learning. Our findings reveal
that performance improvements often defy explanations based on surface-level
dataset similarity or source data quality. Instead, hidden statistical factors
of the source dataset, such as class distribution and generation length
proclivities, alongside specific linguistic features, are actually more
influential. This work offers insights into the complex dynamics of transfer
learning, paving the way for more predictable and effective LLM adaptation.

</details>


### [5] [CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset](https://arxiv.org/abs/2509.14161)
*Brian Yan,Injy Hamed,Shuichiro Shimizu,Vasista Lodagala,William Chen,Olga Iakovenko,Bashar Talafha,Amir Hussein,Alexander Polok,Kalvin Chang,Dominik Klement,Sara Althubaiti,Puyuan Peng,Matthew Wiesner,Thamar Solorio,Ahmed Ali,Sanjeev Khudanpur,Shinji Watanabe,Chih-Chen Chen,Zhen Wu,Karim Benharrak,Anuj Diwan,Samuele Cornell,Eunjung Yeo,Kwanghee Choi,Carlos Carvalho,Karen Rosero*

Main category: cs.CL

TL;DR: CS-FLEURS是一个新的代码切换语音识别和翻译数据集，包含4个测试集覆盖113种语言对，以及128小时的训练数据，旨在推动低资源语言的代码切换研究。


<details>
  <summary>Details</summary>
Motivation: 当前代码切换语音研究主要局限于高资源语言，缺乏对低资源语言的支持。CS-FLEURS旨在填补这一空白，为开发跨多种语言的代码切换语音系统提供标准化评估基准。

Method: 构建包含4个测试集的数据集：1）14个X-英语语言对，真实语音朗读合成代码切换句子；2）16个X-英语语言对，使用生成式文本转语音；3）60个{阿拉伯语、普通话、印地语、西班牙语}-X语言对；4）45个X-英语低资源语言对，使用拼接式文本转语音。同时提供128小时生成式文本转语音训练数据。

Result: 成功创建了覆盖52种语言、113个独特代码切换语言对的大规模数据集，包括真实语音和合成语音数据，为代码切换语音研究提供了全面的资源。

Conclusion: CS-FLEURS数据集将显著扩展代码切换语音研究的范围，特别是在低资源语言方面，为未来研究提供了标准化的评估基准和训练资源。

Abstract: We present CS-FLEURS, a new dataset for developing and evaluating
code-switched speech recognition and translation systems beyond high-resourced
languages. CS-FLEURS consists of 4 test sets which cover in total 113 unique
code-switched language pairs across 52 languages: 1) a 14 X-English language
pair set with real voices reading synthetically generated code-switched
sentences, 2) a 16 X-English language pair set with generative text-to-speech
3) a 60 {Arabic, Mandarin, Hindi, Spanish}-X language pair set with the
generative text-to-speech, and 4) a 45 X-English lower-resourced language pair
test set with concatenative text-to-speech. Besides the four test sets,
CS-FLEURS also provides a training set with 128 hours of generative
text-to-speech data across 16 X-English language pairs. Our hope is that
CS-FLEURS helps to broaden the scope of future code-switched speech research.
Dataset link: https://huggingface.co/datasets/byan/cs-fleurs.

</details>


### [6] [Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs](https://arxiv.org/abs/2509.13664)
*Zhuoxuan Zhang,Jinhao Duan,Edward Kim,Kaidi Xu*

Main category: cs.CL

TL;DR: 研究发现大语言模型在浅层神经元中线性编码问题歧义信息，通过操纵这些神经元可以控制模型从直接回答转为弃答


<details>
  <summary>Details</summary>
Motivation: 现实问题普遍存在歧义性，但大语言模型往往给出自信回答而非寻求澄清，需要理解模型内部如何表示和处理歧义

Method: 在模型预填充阶段识别歧义编码神经元(AENs)，训练探测器进行歧义检测，并通过神经元操纵控制模型行为

Result: 发现少量神经元(最少1个)编码歧义信息，基于AENs的探测器在歧义检测上表现优异且具有跨数据集泛化能力，通过操纵AENs可控制模型行为

Conclusion: 大语言模型形成了紧凑的内部歧义表示，这为实现可解释和可控的行为提供了可能

Abstract: Ambiguity is pervasive in real-world questions, yet large language models
(LLMs) often respond with confident answers rather than seeking clarification.
In this work, we show that question ambiguity is linearly encoded in the
internal representations of LLMs and can be both detected and controlled at the
neuron level. During the model's pre-filling stage, we identify that a small
number of neurons, as few as one, encode question ambiguity information. Probes
trained on these Ambiguity-Encoding Neurons (AENs) achieve strong performance
on ambiguity detection and generalize across datasets, outperforming
prompting-based and representation-based baselines. Layerwise analysis reveals
that AENs emerge from shallow layers, suggesting early encoding of ambiguity
signals in the model's processing pipeline. Finally, we show that through
manipulating AENs, we can control LLM's behavior from direct answering to
abstention. Our findings reveal that LLMs form compact internal representations
of question ambiguity, enabling interpretable and controllable behavior.

</details>


### [7] [CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction](https://arxiv.org/abs/2509.13672)
*Shang Qin,Jingheng Ye,Yinghui Li,Hai-Tao Zheng,Qi Li,Jinxiao Shan,Zhixing Li,Hong-Gee Kim*

Main category: cs.CL

TL;DR: 提出了首个中文文献语法错误纠正的持续学习基准CL²GEC，包含10个学科的10,000条人工标注句子，评估LLM在持续学习场景下的跨学科适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有中文语法纠错研究缺乏多学科学术写作的专用基准，忽视了持续学习作为处理领域特定语言变异和防止灾难性遗忘的有效解决方案。

Method: 构建包含10个学科10,000句的标注数据集，在持续学习设置下评估大语言模型，包括顺序调优、参数高效适应和四种代表性CL算法，使用标准GEC指标和适应任务变异的持续学习指标。

Result: 实验结果表明，基于正则化的方法比基于重放或简单顺序方法更能有效缓解遗忘问题。

Conclusion: 该基准为跨学科学术领域的自适应语法错误纠正研究提供了严谨的基础，展示了持续学习在CGEC中的重要性。

Abstract: The growing demand for automated writing assistance in diverse academic
domains highlights the need for robust Chinese Grammatical Error Correction
(CGEC) systems that can adapt across disciplines. However, existing CGEC
research largely lacks dedicated benchmarks for multi-disciplinary academic
writing, overlooking continual learning (CL) as a promising solution to handle
domain-specific linguistic variation and prevent catastrophic forgetting. To
fill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning
benchmark for Chinese Literature Grammatical Error Correction, designed to
evaluate adaptive CGEC across multiple academic fields. Our benchmark includes
10,000 human-annotated sentences spanning 10 disciplines, each exhibiting
distinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating
grammatical error correction in a continual learning setting, simulating
sequential exposure to diverse academic disciplines to reflect real-world
editorial dynamics. We evaluate large language models under sequential tuning,
parameter-efficient adaptation, and four representative CL algorithms, using
both standard GEC metrics and continual learning metrics adapted to task-level
variation. Experimental results reveal that regularization-based methods
mitigate forgetting more effectively than replay-based or naive sequential
approaches. Our benchmark provides a rigorous foundation for future research in
adaptive grammatical error correction across diverse academic domains.

</details>


### [8] [AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation](https://arxiv.org/abs/2509.13677)
*Xinxu Zhou,Jiaqi Bai,Zhenqi Sun,Fanxiang Zeng,Yue Liu*

Main category: cs.CL

TL;DR: AgentCTG是一个新颖的可扩展框架，通过模拟多智能体工作流中的控制和调节机制，实现对文本生成的精确复杂控制。该方法在多个公开数据集上达到最先进水平，并在角色驱动重写任务中验证了实际应用效果。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理中的受控文本生成面临细粒度条件控制的挑战，特别是在实际在线应用中需要考虑成本、可扩展性、领域知识学习和更精确控制等多重需求。

Method: 提出AgentCTG框架，模拟多智能体工作流中的控制和调节机制，探索不同智能体间的协作方法，并引入自动提示模块来增强生成效果。

Result: 在多个公开数据集上取得最先进结果，在角色驱动重写任务中成功将原始文本转换为符合特定角色配置文件的新文本，同时保留领域知识。在线导航角色扮演应用中显著提升了驾驶体验。

Conclusion: AgentCTG通过多智能体协作机制有效解决了受控文本生成的精确控制问题，为在线社区提供了更沉浸式的交互体验，促进了个性化和用户参与度。

Abstract: Although significant progress has been made in many tasks within the field of
Natural Language Processing (NLP), Controlled Text Generation (CTG) continues
to face numerous challenges, particularly in achieving fine-grained conditional
control over generation. Additionally, in real scenario and online
applications, cost considerations, scalability, domain knowledge learning and
more precise control are required, presenting more challenge for CTG. This
paper introduces a novel and scalable framework, AgentCTG, which aims to
enhance precise and complex control over the text generation by simulating the
control and regulation mechanisms in multi-agent workflows. We explore various
collaboration methods among different agents and introduce an auto-prompt
module to further enhance the generation effectiveness. AgentCTG achieves
state-of-the-art results on multiple public datasets. To validate its
effectiveness in practical applications, we propose a new challenging
Character-Driven Rewriting task, which aims to convert the original text into
new text that conform to specific character profiles and simultaneously
preserve the domain knowledge. When applied to online navigation with
role-playing, our approach significantly enhances the driving experience
through improved content delivery. By optimizing the generation of contextually
relevant text, we enable a more immersive interaction within online
communities, fostering greater personalization and user engagement.

</details>


### [9] [Improving Context Fidelity via Native Retrieval-Augmented Reasoning](https://arxiv.org/abs/2509.13683)
*Suyuchen Wang,Jinlin Wang,Xinyu Wang,Shiqi Li,Xiangru Tang,Sirui Hong,Xiao-Wen Chang,Chenglin Wu,Bang Liu*

Main category: cs.CL

TL;DR: CARE框架通过让LLMs在推理过程中显式整合上下文证据，显著提升了检索准确性和答案生成性能，无需昂贵监督微调


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在上下文保真度方面存在困难，现有方法要么依赖昂贵的监督微调，要么训练模型进行网络搜索但未能充分利用给定上下文

Method: 提出CARE框架，教导LLMs在推理过程中显式整合上下文证据，利用模型自身的检索能力，仅需有限标记证据数据

Result: 在多个真实世界和反事实QA基准测试中，该方法显著优于监督微调、传统检索增强生成方法和外部检索解决方案

Conclusion: 这项工作代表了在使LLMs更准确、可靠和高效处理知识密集型任务方面的根本性进步

Abstract: Large language models (LLMs) often struggle with context fidelity, producing
inconsistent answers when responding to questions based on provided
information. Existing approaches either rely on expensive supervised
fine-tuning to generate evidence post-answer or train models to perform web
searches without necessarily improving utilization of the given context. We
propose CARE, a novel native retrieval-augmented reasoning framework that
teaches LLMs to explicitly integrate in-context evidence within their reasoning
process with the model's own retrieval capabilities. Our method requires
limited labeled evidence data while significantly enhancing both retrieval
accuracy and answer generation performance through strategically retrieved
in-context tokens in the reasoning chain. Extensive experiments on multiple
real-world and counterfactual QA benchmarks demonstrate that our approach
substantially outperforms supervised fine-tuning, traditional
retrieval-augmented generation methods, and external retrieval solutions. This
work represents a fundamental advancement in making LLMs more accurate,
reliable, and efficient for knowledge-intensive tasks.

</details>


### [10] [Can Large Language Models Robustly Perform Natural Language Inference for Japanese Comparatives?](https://arxiv.org/abs/2509.13695)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 本文构建了一个专注于日语比较句的自然语言推理数据集，评估了各种大语言模型在零样本和少样本设置下的表现，发现模型对提示格式敏感且难以处理日语特有的语言现象，但包含逻辑语义表示的提示能帮助模型解决困难推理问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言推理方面表现优异，但涉及数值和逻辑表达式的推理仍然具有挑战性。比较句是与此类推理相关的关键语言现象，但模型在处理这些现象方面的鲁棒性，特别是在训练数据中非主导语言（如日语）中的表现，尚未得到充分探索。

Method: 构建了一个专注于比较句的日语自然语言推理数据集，并在零样本和少样本设置下评估了各种大语言模型。分析了不同提示格式和少样本示例对模型性能的影响，并测试了包含逻辑语义表示的提示效果。

Result: 模型在零样本设置下对提示格式敏感，在少样本设置下受黄金标签影响。模型难以处理日语特有的语言现象。包含逻辑语义表示的提示能帮助模型预测那些即使在少样本示例下也难以解决的推理问题的正确标签。

Conclusion: 研究表明大语言模型在处理日语比较句推理时存在局限性，特别是在处理语言特有现象方面。逻辑语义表示可以作为有效的提示策略来提升模型在困难推理任务上的表现，这为改进多语言NLI系统提供了重要见解。

Abstract: Large Language Models (LLMs) perform remarkably well in Natural Language
Inference (NLI). However, NLI involving numerical and logical expressions
remains challenging. Comparatives are a key linguistic phenomenon related to
such inference, but the robustness of LLMs in handling them, especially in
languages that are not dominant in the models' training data, such as Japanese,
has not been sufficiently explored. To address this gap, we construct a
Japanese NLI dataset that focuses on comparatives and evaluate various LLMs in
zero-shot and few-shot settings. Our results show that the performance of the
models is sensitive to the prompt formats in the zero-shot setting and
influenced by the gold labels in the few-shot examples. The LLMs also struggle
to handle linguistic phenomena unique to Japanese. Furthermore, we observe that
prompts containing logical semantic representations help the models predict the
correct labels for inference problems that they struggle to solve even with
few-shot examples.

</details>


### [11] [Integrating Text and Time-Series into (Large) Language Models to Predict Medical Outcomes](https://arxiv.org/abs/2509.13696)
*Iyadh Ben Cheikh Larbi,Ajay Madhavan Ravichandran,Aljoscha Burchardt,Roland Roller*

Main category: cs.CL

TL;DR: 使用DSPy提示优化技术将指令调优的大语言模型应用于临床分类任务，联合处理临床文本和结构化EHR数据，性能媲美专用多模态系统但更简单灵活


<details>
  <summary>Details</summary>
Motivation: 大语言模型在文本生成方面表现出色，但在处理包含时间序列等结构化数据的临床分类任务方面仍有待探索

Method: 采用基于DSPy的提示优化技术，使指令调优的LLMs能够联合处理临床笔记和结构化电子健康记录(EHR)输入

Result: 该方法在性能上达到与专用多模态系统相当的水平，同时需要更少的复杂性，并在不同任务间具有更好的适应性

Conclusion: 通过提示优化技术，大语言模型可以有效处理临床分类任务，为医疗AI应用提供了更简单灵活的解决方案

Abstract: Large language models (LLMs) excel at text generation, but their ability to
handle clinical classification tasks involving structured data, such as time
series, remains underexplored. In this work, we adapt instruction-tuned LLMs
using DSPy-based prompt optimization to process clinical notes and structured
EHR inputs jointly. Our results show that this approach achieves performance on
par with specialized multimodal systems while requiring less complexity and
offering greater adaptability across tasks.

</details>


### [12] [DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models](https://arxiv.org/abs/2509.13702)
*Xiao Zheng*

Main category: cs.CL

TL;DR: DSCC-HS是一个主动式框架，通过在自回归解码过程中动态注入校准向量来抑制LLM幻觉，无需修改目标模型，在TruthfulQA和BioGEN基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前RAG等方法对LLM幻觉的处理是被动的，需要一种主动干预的框架来在解码过程中实时抑制幻觉生成。

Method: 基于双过程认知理论，使用紧凑代理模型分别作为事实对齐代理(FAP)和幻觉检测代理(HDP)，在推理时通过计算两者logits差异生成实时转向向量，动态引导大模型解码。

Result: 在TruthfulQA上达到99.2%的事实一致性率，在BioGEN长文本基准上获得最高FActScore 46.50，均达到最先进水平。

Conclusion: DSCC-HS为增强LLM事实性提供了一个原理清晰且高效的即插即用解决方案，验证了其在抑制幻觉方面的有效性。

Abstract: Large Language Model (LLM) hallucination is a significant barrier to their
reliable deployment. Current methods like Retrieval-Augmented Generation (RAG)
are often reactive. We introduce **Dynamic Self-reinforcing Calibration for
Hallucination Suppression (DSCC-HS)**, a novel, proactive framework that
intervenes during autoregressive decoding. Inspired by dual-process cognitive
theory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a
Factual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During
inference, these proxies dynamically steer a large target model by injecting a
real-time steering vector, which is the difference between FAP and HDP logits,
at each decoding step. This plug-and-play approach requires no modification to
the target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS
achieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%
Factual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained
the highest FActScore of 46.50. These results validate DSCC-HS as a principled
and efficient solution for enhancing LLM factuality.

</details>


### [13] [Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models](https://arxiv.org/abs/2509.13706)
*Peter Beidler,Mark Nguyen,Kevin Lybarger,Ola Holmberg,Eric Ford,John Kang*

Main category: cs.CL

TL;DR: 开发了基于NLP的放射肿瘤学事件报告严重性筛查工具，使用SVM和BlueBERT模型，通过跨机构迁移学习显著提升性能，达到与人类专家相近的检测水平


<details>
  <summary>Details</summary>
Motivation: 医疗事件报告的手动审查耗时且需要专业知识，需要自动化工具来高效识别高严重性事件报告

Method: 使用7,094份机构报告和571份IAEA SAFRON报告，训练SVM和BlueBERT模型，采用跨机构迁移学习策略（BlueBERT_TRANSFER）

Result: 机构内测试AUROC达0.82(SVM)/0.81(BlueBERT)；跨机构测试通过迁移学习从0.56提升至0.78；在人工编辑数据集上达到与人类性能相近的水平(AUROC 0.74-0.85 vs 0.81)

Conclusion: 成功开发了跨机构的NLP模型，能够有效检测高严重性放射肿瘤学事件报告，性能接近人类专家水平

Abstract: PURPOSE: Incident reports are an important tool for safety and quality
improvement in healthcare, but manual review is time-consuming and requires
subject matter expertise. Here we present a natural language processing (NLP)
screening tool to detect high-severity incident reports in radiation oncology
across two institutions.
  METHODS AND MATERIALS: We used two text datasets to train and evaluate our
NLP models: 7,094 reports from our institution (Inst.), and 571 from IAEA
SAFRON (SF), all of which had severity scores labeled by clinical content
experts. We trained and evaluated two types of models: baseline support vector
machines (SVM) and BlueBERT which is a large language model pretrained on
PubMed abstracts and hospitalized patient data. We assessed for
generalizability of our model in two ways. First, we evaluated models trained
using Inst.-train on SF-test. Second, we trained a BlueBERT_TRANSFER model that
was first fine-tuned on Inst.-train then on SF-train before testing on SF-test
set. To further analyze model performance, we also examined a subset of 59
reports from our Inst. dataset, which were manually edited for clarity.
  RESULTS Classification performance on the Inst. test achieved AUROC 0.82
using SVM and 0.81 using BlueBERT. Without cross-institution transfer learning,
performance on the SF test was limited to an AUROC of 0.42 using SVM and 0.56
using BlueBERT. BlueBERT_TRANSFER, which was fine-tuned on both datasets,
improved the performance on SF test to AUROC 0.78. Performance of SVM, and
BlueBERT_TRANSFER models on the manually curated Inst. reports (AUROC 0.85 and
0.74) was similar to human performance (AUROC 0.81).
  CONCLUSION: In summary, we successfully developed cross-institution NLP
models on incident report text from radiation oncology centers. These models
were able to detect high-severity reports similarly to humans on a curated
dataset.

</details>


### [14] [DSPC: Dual-Stage Progressive Compression Framework for Efficient Long-Context Reasoning](https://arxiv.org/abs/2509.13723)
*Yaxin Gao,Yao Lu,Zongfei Zhang,Jiaqi Nie,Shanqing Yu,Qi Xuan*

Main category: cs.CL

TL;DR: 提出DSPC双阶段渐进压缩方法，无需训练即可压缩LLM提示词，在保持语义的同时显著减少计算成本


<details>
  <summary>Details</summary>
Motivation: 解决LLM提示词越来越长导致计算成本增加的问题，现有方法需要训练辅助模型，计算开销大

Method: 两阶段无训练方法：粗粒度阶段基于TF-IDF过滤低语义价值句子；细粒度阶段通过注意力贡献、跨模型损失差异和位置重要性评估token重要性，修剪低效用token

Result: 在LLaMA-3.1-8B-Instruct和GPT-3.5-Turbo上验证，FewShot任务仅用1/3token达到49.17性能，比最佳基线LongLLMLingua提升7.76

Conclusion: DSPC是一种有效的无训练提示词压缩方法，能在有限token预算下显著提升性能，解决提示词膨胀问题

Abstract: Large language models (LLMs) have achieved remarkable success in many natural
language processing (NLP) tasks. To achieve more accurate output, the prompts
used to drive LLMs have become increasingly longer, which incurs higher
computational costs. To address this prompt inflation problem, prompt
compression has been proposed. However, most existing methods require training
a small auxiliary model for compression, incurring a significant amount of
additional computation. To avoid this, we propose a two-stage, training-free
approach, called Dual-Stage Progressive Compression (DSPC). In the
coarse-grained stage, semantic-related sentence filtering removes sentences
with low semantic value based on TF-IDF. In the fine-grained stage, token
importance is assessed using attention contribution, cross-model loss
difference, and positional importance, enabling the pruning of low-utility
tokens while preserving semantics. We validate DSPC on LLaMA-3.1-8B-Instruct
and GPT-3.5-Turbo under a constrained token budget and observe consistent
improvements. For instance, in the FewShot task of the Longbench dataset, DSPC
achieves a performance of 49.17 by using only 3x fewer tokens, outperforming
the best state-of-the-art baseline LongLLMLingua by 7.76.

</details>


### [15] [Implementing a Logical Inference System for Japanese Comparatives](https://arxiv.org/abs/2509.13734)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 提出基于组合语义的日语比较句逻辑推理系统ccg-jcomp，解决日语比较句在自然语言推理中的挑战，并在日语NLI数据集上验证其有效性


<details>
  <summary>Details</summary>
Motivation: 日语和英语比较句在形态和语义上存在差异，现有基于英语比较句的逻辑推理系统难以直接应用于日语，需要专门针对日语比较句设计逻辑推理系统

Method: 基于组合语义构建日语比较句的逻辑推理系统ccg-jcomp，采用逻辑基础方法处理数值和逻辑表达式

Result: 在包含比较表达的日语NLI数据集上评估系统性能，并与现有大语言模型进行准确率对比

Conclusion: 提出的ccg-jcomp系统在日语比较句推理任务中表现出有效性，为日语比较句的逻辑推理提供了专门解决方案

Abstract: Natural Language Inference (NLI) involving comparatives is challenging
because it requires understanding quantities and comparative relations
expressed by sentences. While some approaches leverage Large Language Models
(LLMs), we focus on logic-based approaches grounded in compositional semantics,
which are promising for robust handling of numerical and logical expressions.
Previous studies along these lines have proposed logical inference systems for
English comparatives. However, it has been pointed out that there are several
morphological and semantic differences between Japanese and English
comparatives. These differences make it difficult to apply such systems
directly to Japanese comparatives. To address this gap, this study proposes
ccg-jcomp, a logical inference system for Japanese comparatives based on
compositional semantics. We evaluate the proposed system on a Japanese NLI
dataset containing comparative expressions. We demonstrate the effectiveness of
our system by comparing its accuracy with that of existing LLMs.

</details>


### [16] [Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications](https://arxiv.org/abs/2509.13775)
*Vani Kanjirangat,Ljiljana Dolamic,Fabio Rinaldi*

Main category: cs.CL

TL;DR: 本文探讨了阿拉伯语方言识别(ADI)的数据高效和参数高效方法，包括软提示策略、LoRA重参数化以及零样本/少样本推理，发现LoRA微调模型表现最佳


<details>
  <summary>Details</summary>
Motivation: 研究如何通过数据高效和参数高效的方法来解决阿拉伯语方言识别问题，探索大型语言模型在方言识别中的能力

Method: 使用软提示策略(prefix-tuning、prompt-tuning、P-tuning、P-tuning V2)和LoRA重参数化，在阿拉伯语特定编码器模型上进行实验，并分析零样本和少样本推理

Result: LLM在少样本或零样本设置下难以区分方言细微差别，软提示编码器变体表现更好，而基于LoRA的微调模型表现最佳，甚至超过完全微调

Conclusion: LoRA微调是阿拉伯语方言识别的最有效方法，软提示策略也表现良好，而LLM在少样本设置下对方言细微差别的识别能力有限

Abstract: This paper discusses our exploration of different data-efficient and
parameter-efficient approaches to Arabic Dialect Identification (ADI). In
particular, we investigate various soft-prompting strategies, including
prefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA
reparameterizations. For the data-efficient strategy, we analyze hard prompting
with zero-shot and few-shot inferences to analyze the dialect identification
capabilities of Large Language Models (LLMs). For the parameter-efficient PEFT
approaches, we conducted our experiments using Arabic-specific encoder models
on several major datasets. We also analyzed the n-shot inferences on
open-source decoder-only models, a general multilingual model (Phi-3.5), and an
Arabic-specific one(SILMA). We observed that the LLMs generally struggle to
differentiate the dialectal nuances in the few-shot or zero-shot setups. The
soft-prompted encoder variants perform better, while the LoRA-based fine-tuned
models perform best, even surpassing full fine-tuning.

</details>


### [17] [Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning](https://arxiv.org/abs/2509.13790)
*Yangning Li,Tingwei Lu,Yinghui Li,Yankai Chen,Wei-Chieh Huang,Wenhao Jiang,Hui Wang,Hai-Tao Zheng,Philip S. Yu*

Main category: cs.CL

TL;DR: CAMPUS是一个动态多视角课程学习框架，通过能力感知的课程调度和动态子课程选择，解决了传统课程学习中静态难度度量导致的课程僵化问题，显著提升了指令调优效果。


<details>
  <summary>Details</summary>
Motivation: 传统课程学习方法依赖静态启发式难度度量，无法适应模型在训练过程中不断演进的能力，导致固定的、可能次优的学习轨迹，限制了指令调优的最终性能。

Method: 提出CAMPUS框架，包含三个核心优势：1）动态子课程选择；2）能力感知的课程调度调整；3）基于多难度的调度策略，实现自适应课程学习。

Result: 大量实验证明，CAMPUS在高效指令调优方面优于其他最先进的基线方法，表现出卓越的性能。

Conclusion: CAMPUS通过动态适应模型能力演进的多视角课程学习，有效解决了课程僵化问题，为指令调优提供了更优的学习轨迹和最终性能。

Abstract: Efficient instruction tuning aims to enhance the ultimate performance of
large language models (LLMs) trained on a given instruction dataset. Curriculum
learning as a typical data organization strategy has shown preliminary
effectiveness in instruction tuning. However, current curriculum tuning methods
suffer from the curriculum rigidity, since they rely solely on static heuristic
difficulty metrics. These methods fail to adapt to the evolving capabilities of
models during training, resulting in a fixed and potentially sub-optimal
learning trajectory. To address the issue, Competence-Aware Multi-Perspective
cUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS
offers several advantages: (1) Dynamic selection for sub-curriculum. (2)
Competency-aware adjustment to the curriculum schedule. (3) Multiple
difficulty-based scheduling. Extensive experiments prove the superior
performance of CAMPUS, compared to other state-of-the-art baselines for
efficient instruction tuning.

</details>


### [18] [Measuring Gender Bias in Job Title Matching for Grammatical Gender Languages](https://arxiv.org/abs/2509.13803)
*Laura García-Sardiña,Hermenegildo Fabregat,Daniel Deniz,Rabih Zbib*

Main category: cs.CL

TL;DR: 本文研究了语法性别对自动职位排名系统的影响，提出了基于RBO指标的性别偏见评估方法，并在四种语法性别语言中创建了测试集来评估多语言模型的性别偏见。


<details>
  <summary>Details</summary>
Motivation: 研究显式语法性别在职位名称中的分配如何影响自动职位排名系统的结果，旨在评估和量化多语言模型中的性别偏见问题。

Method: 提出使用RBO（Rank-Biased Overlap）指标来比较控制性别因素的排名结果，在四种语法性别语言中生成包含阳性和阴性形式的职位名称测试集，并评估多个现成的多语言模型。

Result: 所有测试的多语言模型都表现出不同程度的性别偏见，证明了现有系统在性别公平性方面存在的问题。

Conclusion: 该研究为评估职位排名系统中的性别偏见提供了方法论基础和测试数据集，揭示了当前多语言模型普遍存在的性别偏见问题，为未来开发更公平的AI系统奠定了基础。

Abstract: This work sets the ground for studying how explicit grammatical gender
assignment in job titles can affect the results of automatic job ranking
systems. We propose the usage of metrics for ranking comparison controlling for
gender to evaluate gender bias in job title ranking systems, in particular RBO
(Rank-Biased Overlap). We generate and share test sets for a job title matching
task in four grammatical gender languages, including occupations in masculine
and feminine form and annotated by gender and matching relevance. We use the
new test sets and the proposed methodology to evaluate the gender bias of
several out-of-the-box multilingual models to set as baselines, showing that
all of them exhibit varying degrees of gender bias.

</details>


### [19] [Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs](https://arxiv.org/abs/2509.13813)
*Edward Phillips,Sean Wu,Soheila Molaei,Danielle Belgrave,Anshul Thakur,David Clifton*

Main category: cs.CL

TL;DR: 提出了一种基于几何框架的黑盒不确定性量化方法，通过原型分析同时提供全局和局部不确定性估计，用于检测大语言模型的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有黑盒方法只能提供全局不确定性估计，而局部方法需要白盒访问模型内部状态，需要一种仅通过黑盒访问就能同时提供全局和局部不确定性估计的方法。

Method: 基于响应嵌入的原型分析几何框架：全局层面使用几何体积（凸包体积）衡量不确定性，局部层面使用几何怀疑度对响应可靠性进行排序和选择。

Result: 在短问答数据集上表现优于或相当于现有方法，在医疗数据集上取得显著更好的结果，特别是在幻觉风险较高的场景中。

Conclusion: 该几何框架为黑盒模型提供了有效的全局和局部不确定性量化方法，理论上证明了凸包体积与熵的联系，在关键风险领域具有重要应用价值。

Abstract: Large language models demonstrate impressive results across diverse tasks but
are still known to hallucinate, generating linguistically plausible but
incorrect answers to questions. Uncertainty quantification has been proposed as
a strategy for hallucination detection, but no existing black-box approach
provides estimates for both global and local uncertainty. The former attributes
uncertainty to a batch of responses, while the latter attributes uncertainty to
individual responses. Current local methods typically rely on white-box access
to internal model states, whilst black-box methods only provide global
uncertainty estimates. We introduce a geometric framework to address this,
based on archetypal analysis of batches of responses sampled with only
black-box model access. At the global level, we propose Geometric Volume, which
measures the convex hull volume of archetypes derived from response embeddings.
At the local level, we propose Geometric Suspicion, which ranks responses by
reliability and enables hallucination reduction through preferential response
selection. Unlike prior dispersion methods which yield only a single global
score, our approach provides semantic boundary points which have utility for
attributing reliability to individual responses. Experiments show that our
framework performs comparably to or better than prior methods on short form
question-answering datasets, and achieves superior results on medical datasets
where hallucinations carry particularly critical risks. We also provide
theoretical justification by proving a link between convex hull volume and
entropy.

</details>


### [20] [Findings of the Third Automatic Minuting (AutoMin) Challenge](https://arxiv.org/abs/2509.13814)
*Kartik Shinde,Laurent Besacier,Ondrej Bojar,Thibaut Thonet,Tirthankar Ghosal*

Main category: cs.CL

TL;DR: AutoMin 2025共享任务聚焦于会议自动纪要生成和问答任务，参与团队较少但包含多个基线系统评估


<details>
  <summary>Details</summary>
Motivation: 推动自动会议纪要技术发展，评估当前大语言模型在结构化会议纪要生成和跨语言问答任务上的表现

Method: 设置两个主要任务：1）结构化会议纪要生成（支持英语和捷克语，涵盖项目会议和欧洲议会会议）；2）问答任务（单语言英语问答和跨语言捷克语问答）

Result: 2025年参与度较低：纪要生成任务只有1个团队参加，问答任务有2个团队参加。组织者提供了多个基线系统进行综合评估

Conclusion: 尽管参与团队较少，但通过基线系统的全面评估，为当前大语言模型在自动会议纪要领域的性能提供了有价值的基准数据

Abstract: This paper presents the third edition of AutoMin, a shared task on automatic
meeting summarization into minutes. In 2025, AutoMin featured the main task of
minuting, the creation of structured meeting minutes, as well as a new task:
question answering (QA) based on meeting transcripts.
  The minuting task covered two languages, English and Czech, and two domains:
project meetings and European Parliament sessions. The QA task focused solely
on project meetings and was available in two settings: monolingual QA in
English, and cross-lingual QA, where questions were asked and answered in Czech
based on English meetings.
  Participation in 2025 was more limited compared to previous years, with only
one team joining the minuting task and two teams participating in QA. However,
as organizers, we included multiple baseline systems to enable a comprehensive
evaluation of current (2025) large language models (LLMs) on both tasks.

</details>


### [21] [Large Language Models Discriminate Against Speakers of German Dialects](https://arxiv.org/abs/2509.13835)
*Minh Duc Bui,Carolin Holtermann,Valentin Hofmann,Anne Lauscher,Katharina von der Wense*

Main category: cs.CL

TL;DR: 研究发现大型语言模型对德国方言使用者存在显著的命名偏见和使用偏见，所有测试模型都表现出负面形容词关联，并且在决策中重现这些偏见。与之前研究相反，明确标注方言使用者身份反而会放大偏见。


<details>
  <summary>Details</summary>
Motivation: 尽管方言具有重要文化价值，但方言使用者常面临负面社会刻板印象。本研究旨在探究这些刻板印象是否在大型语言模型中得以体现，分析模型是否对德国方言使用者存在偏见。

Method: 基于社会语言学文献构建评估框架，通过关联任务和决策任务评估方言命名偏见和使用偏见。创建包含7种德国地区方言及其标准德语对照句子的新颖评估语料库。

Result: 所有评估的LLM都表现出显著的方言命名和使用偏见，反映在负面形容词关联上；所有模型在决策中都重现这些偏见；明确标注语言人口统计信息（德国方言使用者）比隐晦提示更能放大偏见。

Conclusion: 大型语言模型确实反映了社会中对方言使用者的负面刻板印象，存在系统性偏见，且明确的人口统计标注会加剧这种偏见，这对LLM的公平性评估和 mitigation 策略提出了重要启示。

Abstract: Dialects represent a significant component of human culture and are found
across all regions of the world. In Germany, more than 40% of the population
speaks a regional dialect (Adler and Hansen, 2022). However, despite cultural
importance, individuals speaking dialects often face negative societal
stereotypes. We examine whether such stereotypes are mirrored by large language
models (LLMs). We draw on the sociolinguistic literature on dialect perception
to analyze traits commonly associated with dialect speakers. Based on these
traits, we assess the dialect naming bias and dialect usage bias expressed by
LLMs in two tasks: an association task and a decision task. To assess a model's
dialect usage bias, we construct a novel evaluation corpus that pairs sentences
from seven regional German dialects (e.g., Alemannic and Bavarian) with their
standard German counterparts. We find that: (1) in the association task, all
evaluated LLMs exhibit significant dialect naming and dialect usage bias
against German dialect speakers, reflected in negative adjective associations;
(2) all models reproduce these dialect naming and dialect usage biases in their
decision making; and (3) contrary to prior work showing minimal bias with
explicit demographic mentions, we find that explicitly labeling linguistic
demographics--German dialect speakers--amplifies bias more than implicit cues
like dialect usage.

</details>


### [22] [Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs](https://arxiv.org/abs/2509.13869)
*Yang Liu,Chenhui Chu*

Main category: cs.CL

TL;DR: 该研究分析了12个大型语言模型在四种不同类型偏见场景中与人类价值观的对齐情况，发现模型参数规模不必然降低偏见误对齐率和攻击成功率，模型对特定场景类型有对齐偏好，同家族模型判断一致性更高，且小模型经过微调后能生成更易读但模型认同度较低的偏见解释。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在与人类价值观（特别是涉及复杂敏感社会偏见的场景）未对齐时可能产生不良后果。先前研究使用专家设计或基于代理的模拟偏见场景揭示了这种未对齐现象，但尚不清楚不同类型场景（如包含负面与非负面问题的场景）中模型与人类价值观的对齐是否存在差异。

Method: 研究分析了来自四个模型家族的12个大型语言模型在四个数据集上的表现，考察了模型在不同类型偏见场景中的对齐情况、判断一致性、对偏见理解能力的解释偏好，并通过微调赋予小模型解释社会偏见价值观的能力。

Result: 研究发现：1）大参数规模的LLM不一定具有更低的误对齐率和攻击成功率；2）LLM对特定类型的场景表现出一定程度的对齐偏好；3）同一模型家族的LLM倾向于具有更高的判断一致性；4）不同LLM在对社会偏见价值观的理解能力上没有显著差异；5）LLM偏好自己生成的解释；6）微调后的小模型能生成更易读但模型认同度相对较低的解释。

Conclusion: 该研究揭示了LLM在社会偏见价值观对齐方面的复杂特性，表明单纯增大模型规模不能解决偏见对齐问题，需要针对不同类型场景和模型特性开发更精细的对齐方法，同时小模型通过适当训练也能获得解释偏见的能力，但在模型认同度方面仍需改进。

Abstract: Large language models (LLMs) can lead to undesired consequences when
misaligned with human values, especially in scenarios involving complex and
sensitive social biases. Previous studies have revealed the misalignment of
LLMs with human values using expert-designed or agent-based emulated bias
scenarios. However, it remains unclear whether the alignment of LLMs with human
values differs across different types of scenarios (e.g., scenarios containing
negative vs. non-negative questions). In this study, we investigate the
alignment of LLMs with human values regarding social biases (HVSB) in different
types of bias scenarios. Through extensive analysis of 12 LLMs from four model
families and four datasets, we demonstrate that LLMs with large model parameter
scales do not necessarily have lower misalignment rate and attack success rate.
Moreover, LLMs show a certain degree of alignment preference for specific types
of scenarios and the LLMs from the same model family tend to have higher
judgment consistency. In addition, we study the understanding capacity of LLMs
with their explanations of HVSB. We find no significant differences in the
understanding of HVSB across LLMs. We also find LLMs prefer their own generated
explanations. Additionally, we endow smaller language models (LMs) with the
ability to explain HVSB. The generation results show that the explanations
generated by the fine-tuned smaller LMs are more readable, but have a
relatively lower model agreeability.

</details>


### [23] [Combining Evidence and Reasoning for Biomedical Fact-Checking](https://arxiv.org/abs/2509.13879)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: CER框架结合科学证据检索、大语言模型推理和监督真实性预测，用于生物医学事实核查，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 医疗领域中的错误信息（如疫苗犹豫和未经证实的治疗方法）对公共卫生和医疗系统信任构成风险，生物医学声明验证因复杂术语、领域专业知识和科学证据基础需求而具有独特挑战。

Method: 提出CER框架，整合科学证据检索、大语言模型推理和监督真实性预测，通过结合大语言模型的文本生成能力和高质量生物医学科学证据的检索技术，有效减少幻觉风险。

Result: 在专家标注的数据集（HealthFC、BioASQ-7b、SciFact）上评估显示达到最先进性能，并展现出良好的跨数据集泛化能力。

Conclusion: CER框架通过整合证据检索和语言模型推理，为生物医学事实核查提供了有效解决方案，代码和数据已开源以确保透明性和可重复性。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https: //github.com/PRAISELab-PicusLab/CER.

</details>


### [24] [Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification](https://arxiv.org/abs/2509.13888)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: CER是一个用于生物医学事实核查的新框架，结合科学证据检索、大语言模型推理和监督真实性预测，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的错误信息（如疫苗犹豫和未经证实的治疗方法）对公共卫生和医疗系统信任构成风险。生物医学声明验证具有独特挑战性，包括复杂术语、需要领域专业知识以及必须基于科学证据。

Method: CER框架整合科学证据检索、大语言模型推理和监督真实性预测。通过将大语言模型的文本生成能力与高质量生物医学科学证据的先进检索技术相结合，有效减轻幻觉风险。

Result: 在专家标注的数据集（HealthFC、BioASQ-7b、SciFact）上评估显示达到最先进性能，并展现出有前景的跨数据集泛化能力。

Conclusion: CER框架通过结合证据检索和推理，为生物医学事实核查提供了有效的解决方案，代码和数据已开源以确保透明度和可重现性。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https://github.com/PRAISELab-PicusLab/CER

</details>


### [25] [Do Large Language Models Understand Word Senses?](https://arxiv.org/abs/2509.13905)
*Domenico Meconi,Simone Stirpe,Federico Martelli,Leonardo Lavalle,Roberto Navigli*

Main category: cs.CL

TL;DR: 本文评估了指令调优大语言模型在词义消歧任务上的能力，发现GPT-4o和DeepSeek-V3等领先模型与专门WSD系统性能相当，且在生成任务中能以高达98%的准确率解释上下文中的词义。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在词义理解方面进行了广泛评估，但其是否真正掌握词义感知的能力仍未被充分探索，本文旨在填补这一研究空白。

Method: 通过评估指令调优LLMs的词义消歧能力，并与专门WSD系统比较；同时评估两种顶级开源和闭源LLMs在三种生成设置下的词义理解能力：定义生成、自由形式解释和示例生成。

Result: 在WSD任务中，GPT-4o和DeepSeek-V3等领先模型与专门WSD系统性能相当，且在不同领域和难度级别上表现出更强的鲁棒性；在生成任务中，LLMs能以高达98%的准确率解释词义，其中自由形式解释任务表现最佳。

Conclusion: 大语言模型在词义消歧方面已达到专门系统的水平，并在生成性词义解释任务中表现出色，特别是在自由形式解释方面，这最符合其生成能力的特点。

Abstract: Understanding the meaning of words in context is a fundamental capability for
Large Language Models (LLMs). Despite extensive evaluation efforts, the extent
to which LLMs show evidence that they truly grasp word senses remains
underexplored. In this paper, we address this gap by evaluating both i) the
Word Sense Disambiguation (WSD) capabilities of instruction-tuned LLMs,
comparing their performance to state-of-the-art systems specifically designed
for the task, and ii) the ability of two top-performing open- and closed-source
LLMs to understand word senses in three generative settings: definition
generation, free-form explanation, and example generation. Notably, we find
that, in the WSD task, leading models such as GPT-4o and DeepSeek-V3 achieve
performance on par with specialized WSD systems, while also demonstrating
greater robustness across domains and levels of difficulty. In the generation
tasks, results reveal that LLMs can explain the meaning of words in context up
to 98\% accuracy, with the highest performance observed in the free-form
explanation task, which best aligns with their generative capabilities.

</details>


### [26] [Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG](https://arxiv.org/abs/2509.13930)
*Dayeon Ki,Marine Carpuat,Paul McNamee,Daniel Khashabi,Eugene Yang,Dawn Lawrie,Kevin Duh*

Main category: cs.CL

TL;DR: 研究发现多语言检索增强生成系统存在英语偏好偏见，模型会优先引用英语文档而非最相关的文档，这种偏见在低资源语言和中间位置文档中更加明显


<details>
  <summary>Details</summary>
Motivation: 研究多语言检索增强生成系统中不同文档语言的混合是否会对生成和引用产生意外影响，特别是模型是否会在不同语言间表现出偏好偏见

Method: 采用受控方法，利用模型内部机制测量语言偏好，同时保持文档相关性等其他因素不变，在8种语言和6个开源模型上进行实验

Result: 模型在英语查询时优先引用英语来源，这种偏见在低资源语言和中间位置文档中被放大，模型有时会牺牲文档相关性来满足语言偏好

Conclusion: 引用选择并非总是由信息量驱动，研究揭示了语言模型如何利用多语言上下文并影响引用行为，对多语言RAG系统的公平性和效果有重要启示

Abstract: Multilingual Retrieval-Augmented Generation (mRAG) systems enable language
models to answer knowledge-intensive queries with citation-supported responses
across languages. While such systems have been proposed, an open questions is
whether the mixture of different document languages impacts generation and
citation in unintended ways. To investigate, we introduce a controlled
methodology using model internals to measure language preference while holding
other factors such as document relevance constant. Across eight languages and
six open-weight models, we find that models preferentially cite English sources
when queries are in English, with this bias amplified for lower-resource
languages and for documents positioned mid-context. Crucially, we find that
models sometimes trade-off document relevance for language preference,
indicating that citation choices are not always driven by informativeness
alone. Our findings shed light on how language models leverage multilingual
context and influence citation behavior.

</details>


### [27] [Long-context Reference-based MT Quality Estimation](https://arxiv.org/abs/2509.13980)
*Sami Ul Haq,Chinonso Cynthia Osuji,Sheila Castilho,Brian Davis*

Main category: cs.CL

TL;DR: 基于COMET框架构建的翻译质量评估系统，通过长上下文数据增强训练，预测错误跨度标注分数，在WMT25共享任务中表现优于短片段模型


<details>
  <summary>Details</summary>
Motivation: 解决传统翻译质量评估模型仅基于短片段训练的限制，通过利用长上下文信息来提升与人工评估的相关性

Method: 使用COMET框架，通过拼接领域内人工标注句子构建长上下文训练数据，计算加权平均分数，整合多种人工评估数据集（MQM、SQM、DA）并进行尺度归一化，训练多语言回归模型

Result: 实验结果显示，相比仅使用短片段训练的模型，融入长上下文信息的方法显著提高了与人工评估的相关性

Conclusion: 长上下文信息对于翻译质量评估具有重要价值，该方法在WMT25共享任务中展示了改进的评估性能

Abstract: In this paper, we present our submission to the Tenth Conference on Machine
Translation (WMT25) Shared Task on Automated Translation Quality Evaluation.
  Our systems are built upon the COMET framework and trained to predict
segment-level Error Span Annotation (ESA) scores using augmented long-context
data.
  To construct long-context training data, we concatenate in-domain,
human-annotated sentences and compute a weighted average of their scores.
  We integrate multiple human judgment datasets (MQM, SQM, and DA) by
normalising their scales and train multilingual regression models to predict
quality scores from the source, hypothesis, and reference translations.
  Experimental results show that incorporating long-context information
improves correlations with human judgments compared to models trained only on
short segments.

</details>


### [28] [Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency](https://arxiv.org/abs/2509.13990)
*Colin Hong,Xu Guo,Anand Chaanan Singh,Esha Choukse,Dmitrii Ustiugov*

Main category: cs.CL

TL;DR: Slim-SC是一种通过逐步剪枝冗余推理链来加速Self-Consistency测试时缩放技术的方法，在保持或提高准确性的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: Self-Consistency(SC)虽然能提升LLM推理性能，但其数量级计算开销限制了广泛应用。现有加速方法主要依赖模型置信度或缺乏实证支持的经验法则。

Method: 提出Slim-SC，基于思维层面的链间相似性分析，采用逐步剪枝策略识别和移除冗余推理链，减少计算负担。

Result: 在三个STEM推理数据集和两种LLM架构上，Slim-SC将推理延迟降低45%，KVC使用减少26%，同时保持或提高准确性。

Conclusion: Slim-SC为SC提供了一种简单高效的替代方案，通过理论分析和实证验证揭示了可操作的优化机会，实现了计算效率与性能的平衡。

Abstract: Recently, Test-Time Scaling (TTS) has gained increasing attention for
improving LLM reasoning performance at test time without retraining the model.
A notable TTS technique is Self-Consistency (SC), which generates multiple
reasoning chains in parallel and selects the final answer via majority voting.
While effective, the order-of-magnitude computational overhead limits its broad
deployment. Prior attempts to accelerate SC mainly rely on model-based
confidence scores or heuristics with limited empirical support. For the first
time, we theoretically and empirically analyze the inefficiencies of SC and
reveal actionable opportunities for improvement. Building on these insights, we
propose Slim-SC, a step-wise pruning strategy that identifies and removes
redundant chains using inter-chain similarity at the thought level. Experiments
on three STEM reasoning datasets and two recent LLM architectures show that
Slim-SC reduces inference latency and KVC usage by up to 45% and 26%,
respectively, with R1-Distill, while maintaining or improving accuracy, thus
offering a simple yet efficient TTS alternative for SC.

</details>


### [29] [Early Stopping Chain-of-thoughts in Large Language Models](https://arxiv.org/abs/2509.14004)
*Minjia Mao,Bowen Yin,Yu Zhu,Xiao Fang*

Main category: cs.CL

TL;DR: ES-CoT是一种推理时方法，通过检测答案收敛性来提前停止思维链生成，在保持准确性的同时平均减少41%的推理token使用量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在解决复杂问题时需要生成长思维链，但这会导致高昂的推理成本。研究旨在减少推理成本同时最小化性能损失。

Method: 在每个推理步骤结束时让LLM输出当前最终答案（步骤答案），跟踪连续相同步骤答案的运行长度作为收敛度量，当运行长度出现急剧增加并超过最小阈值时终止生成。

Result: 在5个推理数据集和3个LLM上的实验显示，ES-CoT平均减少约41%的推理token，同时保持与标准CoT相当的准确性。该方法还能与自一致性提示无缝集成，并在超参数选择上保持鲁棒性。

Conclusion: ES-CoT是一种实用有效的推理效率提升方法，通过检测答案收敛性实现早期停止，在保持性能的同时显著降低推理成本。

Abstract: Reasoning large language models (LLMs) have demonstrated superior capacities
in solving complicated problems by generating long chain-of-thoughts (CoT), but
such a lengthy CoT incurs high inference costs. In this study, we introduce
ES-CoT, an inference-time method that shortens CoT generation by detecting
answer convergence and stopping early with minimal performance loss. At the end
of each reasoning step, we prompt the LLM to output its current final answer,
denoted as a step answer. We then track the run length of consecutive identical
step answers as a measure of answer convergence. Once the run length exhibits a
sharp increase and exceeds a minimum threshold, the generation is terminated.
We provide both empirical and theoretical support for this heuristic: step
answers steadily converge to the final answer, and large run-length jumps
reliably mark this convergence. Experiments on five reasoning datasets across
three LLMs show that ES-CoT reduces the number of inference tokens by about
41\% on average while maintaining accuracy comparable to standard CoT. Further,
ES-CoT integrates seamlessly with self-consistency prompting and remains robust
across hyperparameter choices, highlighting it as a practical and effective
approach for efficient reasoning.

</details>


### [30] [Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale](https://arxiv.org/abs/2509.14008)
*Hasan Abed Al Kader Hammoud,Mohammad Zbeeb,Bernard Ghanem*

Main category: cs.CL

TL;DR: Hala是一个阿拉伯语为中心的指令和翻译模型家族，通过翻译调优流程构建，在阿拉伯语基准测试中实现了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语NLP中高质量指令数据和专门化模型的缺乏问题，通过构建阿拉伯语为中心的指令跟随模型来推动阿拉伯语NLP研究。

Method: 采用翻译调优流程：先压缩AR↔EN教师模型到FP8精度，生成高质量双语监督数据，然后在轻量级语言模型上微调，翻译英文指令集为阿拉伯语，最后通过slerp合并平衡阿拉伯语专业化和基础模型优势。

Result: Hala模型在350M到9B参数规模上训练，在阿拉伯语基准测试中在"nano"(≤2B)和"small"(7-9B)类别中都达到了最先进水平，超越了其基础模型。

Conclusion: Hala系列模型为阿拉伯语NLP提供了有效的解决方案，通过创新的翻译调优流程和模型合并技术，显著提升了阿拉伯语指令跟随能力，并开源了模型、数据和配方以加速研究。

Abstract: We present Hala, a family of Arabic-centric instruction and translation
models built with our translate-and-tune pipeline. We first compress a strong
AR$\leftrightarrow$EN teacher to FP8 (yielding $\sim$2$\times$ higher
throughput with no quality loss) and use it to create high-fidelity bilingual
supervision. A lightweight language model LFM2-1.2B is then fine-tuned on this
data and used to translate high-quality English instruction sets into Arabic,
producing a million-scale corpus tailored to instruction following. We train
Hala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to
balance Arabic specialization with base-model strengths. On Arabic-centric
benchmarks, Hala achieves state-of-the-art results within both the "nano"
($\leq$2B) and "small" (7-9B) categories, outperforming their bases. We release
models, data, evaluation, and recipes to accelerate research in Arabic NLP.

</details>


### [31] [Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality](https://arxiv.org/abs/2509.14023)
*Sami Ul Haq,Sheila Castilho,Yvette Graham*

Main category: cs.CL

TL;DR: 本研究比较了文本和音频两种方式对机器翻译系统的评估效果，发现音频评估能提供更自然的质量判断，建议将语音评估纳入未来MT评估框架


<details>
  <summary>Details</summary>
Motivation: 当前机器翻译质量评估主要依赖文本方式，但许多实际应用涉及语音翻译，需要更自然的音频评估方法

Method: 使用Amazon Mechanical Turk收集众包评估，比较10个WMT机器翻译系统的文本和音频评估结果，并进行统计显著性测试和自复制实验

Result: 音频评估得出的排名与文本评估基本一致，但在某些情况下能识别出翻译系统间的显著差异

Conclusion: 语音作为更丰富自然的模态，应该被纳入未来机器翻译评估框架中

Abstract: Machine Translation (MT) has achieved remarkable performance, with growing
interest in speech translation and multimodal approaches. However, despite
these advancements, MT quality assessment remains largely text centric,
typically relying on human experts who read and compare texts. Since many
real-world MT applications (e.g Google Translate Voice Mode, iFLYTEK
Translator) involve translation being spoken rather printed or read, a more
natural way to assess translation quality would be through speech as opposed
text-only evaluations. This study compares text-only and audio-based
evaluations of 10 MT systems from the WMT General MT Shared Task, using
crowd-sourced judgments collected via Amazon Mechanical Turk. We additionally,
performed statistical significance testing and self-replication experiments to
test reliability and consistency of audio-based approach. Crowd-sourced
assessments based on audio yield rankings largely consistent with text only
evaluations but, in some cases, identify significant differences between
translation systems. We attribute this to speech richer, more natural modality
and propose incorporating speech-based assessments into future MT evaluation
frameworks.

</details>


### [32] [You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models](https://arxiv.org/abs/2509.14031)
*Paweł Mąka,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 论文验证了训练数据中上下文丰富样本的稀疏性是上下文利用困难的关键瓶颈，提出了两种训练策略，在单语和多语设置中分别实现了最高6%和8%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 实现人类水平翻译需要利用上下文确保连贯性和处理复杂现象（如代词消歧），但标准训练数据中上下文丰富样本的稀疏性被认为是上下文利用困难的原因。

Method: 通过构建具有受控比例上下文相关示例的训练数据集，系统验证数据稀疏性与模型性能的关系，并提出和评估两种训练策略来充分利用可用数据。

Result: 研究发现训练数据稀疏性与模型性能存在强关联，不同上下文现象的改进不能相互泛化，跨语言迁移有限。提出的训练策略在ctxPro评估中分别带来6%和8%的准确率提升。

Conclusion: 数据稀疏性是上下文利用的关键瓶颈，需要针对性的训练策略来改善上下文利用能力，不同上下文现象需要分别处理，跨语言迁移效果有限。

Abstract: Achieving human-level translations requires leveraging context to ensure
coherence and handle complex phenomena like pronoun disambiguation. Sparsity of
contextually rich examples in the standard training data has been hypothesized
as the reason for the difficulty of context utilization. In this work, we
systematically validate this claim in both single- and multilingual settings by
constructing training datasets with a controlled proportions of contextually
relevant examples. We demonstrate a strong association between training data
sparsity and model performance confirming sparsity as a key bottleneck.
Importantly, we reveal that improvements in one contextual phenomenon do no
generalize to others. While we observe some cross-lingual transfer, it is not
significantly higher between languages within the same sub-family. Finally, we
propose and empirically evaluate two training strategies designed to leverage
the available data. These strategies improve context utilization, resulting in
accuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in
single- and multilingual settings respectively.

</details>


### [33] [Enhancing Multi-Agent Debate System Performance via Confidence Expression](https://arxiv.org/abs/2509.14034)
*Zijie Lin,Bryan Hooi*

Main category: cs.CL

TL;DR: 本文提出ConfMAD框架，在多智能体辩论系统中引入置信度表达机制，解决LLM在辩论中难以有效沟通知识优势的问题，提升辩论效果和系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有MAD系统中，虽然某些LLM在特定任务上具有更优的知识或推理能力，但由于缺乏置信度表达，难以在辩论中清晰传达这种优势。不恰当的置信度表达会导致智能体固执坚持错误信念或过早收敛于次优答案，降低辩论有效性。

Method: 提出ConfMAD框架，在多智能体辩论过程中集成置信度表达机制，让LLM能够明确传达其置信度水平。

Result: 实验结果表明该方法有效，并进一步分析了置信度如何影响辩论动态，为设计置信度感知的MAD系统提供了见解。

Conclusion: 在MAD系统中引入置信度表达能够显著提升辩论效果和整体系统性能，ConfMAD框架为解决LLM在协作辩论中的置信度表达问题提供了有效解决方案。

Abstract: Generative Large Language Models (LLMs) have demonstrated remarkable
performance across a wide range of tasks. Recent research has introduced
Multi-Agent Debate (MAD) systems, which leverage multiple LLMs to simulate
human debate and thereby improve task performance. However, while some LLMs may
possess superior knowledge or reasoning capabilities for specific tasks, they
often struggle to clearly communicate this advantage during debates, in part
due to a lack of confidence expression. Moreover, inappropriate confidence
expression can cause agents in MAD systems to either stubbornly maintain
incorrect beliefs or converge prematurely on suboptimal answers, ultimately
reducing debate effectiveness and overall system performance. To address these
challenges, we propose incorporating confidence expression into MAD systems to
allow LLMs to explicitly communicate their confidence levels. To validate this
approach, we develop ConfMAD, a MAD framework that integrates confidence
expression throughout the debate process. Experimental results demonstrate the
effectiveness of our method, and we further analyze how confidence influences
debate dynamics, offering insights into the design of confidence-aware MAD
systems.

</details>


### [34] [SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation](https://arxiv.org/abs/2509.14036)
*Zekang Liu,Wei Feng,Fanhua Shang,Lianyu Hu,Jichao Feng,Liqing Gao*

Main category: cs.CL

TL;DR: 提出基于问题的手语翻译任务(QB-SLT)，通过对话上下文提升翻译质量，开发了SSL-SSAW跨模态自监督学习方法，在新建数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 对话在手语翻译中提供重要上下文线索，相比传统gloss标注，对话更自然且易于标注，需要探索如何有效整合对话信息来改进翻译

Method: 提出跨模态自监督学习结合Sigmoid自注意力加权(SSL-SSAW)的融合方法：使用对比学习对齐多模态特征，SSAW模块自适应提取问题和手语序列特征，利用自监督学习增强表示能力

Result: 在新建的CSL-Daily-QA和PHOENIX-2014T-QA数据集上达到最先进性能，问题辅助可以达到甚至超越gloss辅助的效果，可视化结果验证了对话整合的有效性

Conclusion: QB-SLT任务和SSL-SSAW方法有效利用了对话上下文，证明了问题辅助在手语翻译中的潜力，为手语翻译提供了新的研究方向和实用解决方案

Abstract: Sign Language Translation (SLT) bridges the communication gap between deaf
people and hearing people, where dialogue provides crucial contextual cues to
aid in translation. Building on this foundational concept, this paper proposes
Question-based Sign Language Translation (QB-SLT), a novel task that explores
the efficient integration of dialogue. Unlike gloss (sign language
transcription) annotations, dialogue naturally occurs in communication and is
easier to annotate. The key challenge lies in aligning multimodality features
while leveraging the context of the question to improve translation. To address
this issue, we propose a cross-modality Self-supervised Learning with Sigmoid
Self-attention Weighting (SSL-SSAW) fusion method for sign language
translation. Specifically, we employ contrastive learning to align
multimodality features in QB-SLT, then introduce a Sigmoid Self-attention
Weighting (SSAW) module for adaptive feature extraction from question and sign
language sequences. Additionally, we leverage available question text through
self-supervised learning to enhance representation and translation
capabilities. We evaluated our approach on newly constructed CSL-Daily-QA and
PHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably,
easily accessible question assistance can achieve or even surpass the
performance of gloss assistance. Furthermore, visualization results demonstrate
the effectiveness of incorporating dialogue in improving translation quality.

</details>


### [35] [Canary-1B-v2 & Parakeet-TDT-0.6B-v3: Efficient and High-Performance Models for Multilingual ASR and AST](https://arxiv.org/abs/2509.14128)
*Monica Sekoyan,Nithin Rao Koluguri,Nune Tadevosyan,Piotr Zelasko,Travis Bartley,Nick Karpov,Jagadeesh Balam,Boris Ginsburg*

Main category: cs.CL

TL;DR: Canary-1B-v2是一个快速、鲁棒的多语言语音识别和语音翻译模型，支持25种欧洲语言，比Whisper-large-v3在英语ASR上表现更好且快10倍


<details>
  <summary>Details</summary>
Motivation: 开发一个高效的多语言语音处理模型，在保持高性能的同时显著提升处理速度，并减少ASR和AST任务中的幻觉问题

Method: 采用FastConformer编码器和Transformer解码器架构，进行两阶段预训练和微调，使用动态数据平衡，并添加非语音音频数据减少幻觉，使用NeMo强制对齐器进行时间戳标注

Result: 在英语ASR上超越Whisper-large-v3且速度快10倍，在多语言ASR和AST任务上与Seamless-M4T-v2-large等大型模型竞争，同时发布了更轻量的Parakeet-TDT-0.6B-v3模型

Conclusion: Canary-1B-v2证明了在语音处理任务中，精心设计的架构和训练策略可以在保持高性能的同时实现显著的速度提升，为实际应用提供了高效的解决方案

Abstract: This report introduces Canary-1B-v2, a fast, robust multilingual model for
Automatic Speech Recognition (ASR) and Speech-to-Text Translation (AST). Built
with a FastConformer encoder and Transformer decoder, it supports 25 languages
primarily European. The model was trained on 1.7M hours of total data samples,
including Granary and NeMo ASR Set 3.0, with non-speech audio added to reduce
hallucinations for ASR and AST. We describe its two-stage pre-training and
fine-tuning process with dynamic data balancing, as well as experiments with an
nGPT encoder. Results show nGPT scales well with massive data, while
FastConformer excels after fine-tuning. For timestamps, Canary-1B-v2 uses the
NeMo Forced Aligner (NFA) with an auxiliary CTC model, providing reliable
segment-level timestamps for ASR and AST. Evaluations show Canary-1B-v2
outperforms Whisper-large-v3 on English ASR while being 10x faster, and
delivers competitive multilingual ASR and AST performance against larger models
like Seamless-M4T-v2-large and LLM-based systems. We also release
Parakeet-TDT-0.6B-v3, a successor to v2, offering multilingual ASR across the
same 25 languages with just 600M parameters.

</details>


### [36] [AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity](https://arxiv.org/abs/2509.14171)
*Yifan Liu,Wenkuan Zhao,Shanshan Zhong,Jinghui Qin,Mingfu Liang,Zhongzhan Huang,Wushao Wen*

Main category: cs.CL

TL;DR: 提出了AssoCiAm基准，通过混合计算方法解决关联任务中的模糊性问题，评估MLLMs的联想能力，发现认知与联想之间存在强正相关关系。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型评估框架往往忽视了关联任务中固有的模糊性，这种模糊性源于联想的发散性，会降低评估的可靠性。

Method: 将模糊性分解为内部模糊性和外部模糊性，引入AssoCiAm基准，采用混合计算方法来规避模糊性，对MLLMs进行广泛实验。

Result: 实验揭示了认知与联想之间存在强正相关关系，评估过程中的模糊性会导致MLLMs行为更加随机化，验证了所提方法能确保更准确可靠的评估。

Conclusion: AssoCiAm基准有效解决了关联评估中的模糊性问题，为MLLMs的联想能力提供了更可靠的评估框架，证实了认知与联想的重要关联。

Abstract: Recent advancements in multimodal large language models (MLLMs) have garnered
significant attention, offering a promising pathway toward artificial general
intelligence (AGI). Among the essential capabilities required for AGI,
creativity has emerged as a critical trait for MLLMs, with association serving
as its foundation. Association reflects a model' s ability to think creatively,
making it vital to evaluate and understand. While several frameworks have been
proposed to assess associative ability, they often overlook the inherent
ambiguity in association tasks, which arises from the divergent nature of
associations and undermines the reliability of evaluations. To address this
issue, we decompose ambiguity into two types-internal ambiguity and external
ambiguity-and introduce AssoCiAm, a benchmark designed to evaluate associative
ability while circumventing the ambiguity through a hybrid computational
method. We then conduct extensive experiments on MLLMs, revealing a strong
positive correlation between cognition and association. Additionally, we
observe that the presence of ambiguity in the evaluation process causes MLLMs'
behavior to become more random-like. Finally, we validate the effectiveness of
our method in ensuring more accurate and reliable evaluations. See Project Page
for the data and codes.

</details>


### [37] [Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs](https://arxiv.org/abs/2509.14180)
*Akhil Theerthala*

Main category: cs.CL

TL;DR: 本研究提出了一个整合金融背景和行为金融学的可重复框架，用于构建端到端财务顾问的监督数据，并通过微调8B参数模型实现了与更大模型相当的性能，同时成本降低80%。


<details>
  <summary>Details</summary>
Motivation: 个性化财务建议需要考虑用户目标、约束、风险承受能力和司法管辖区。现有的LLM工作主要集中在投资者和财务规划师的支持系统，而其他研究通过代理管道处理更广泛的个人理财任务，但维护成本高且财务回报低于预期。

Method: 引入了一个新颖的可重复框架，整合相关金融背景和行为金融学研究来构建监督数据，创建了19k样本的推理数据集，并对Qwen-3-8B模型进行了全面微调。

Result: 通过保留测试集和盲法LLM评审研究显示，经过精心数据策划和行为整合的8B模型在事实准确性、流畅性和个性化指标上与更大的基线模型（14-32B参数）表现相当，同时成本比大型对应模型低80%。

Conclusion: 通过仔细的数据策划和行为整合，较小的8B参数模型可以实现与显著更大的模型相当的性能，同时大幅降低成本，为个性化财务顾问系统提供了高效可行的解决方案。

Abstract: Personalized financial advice requires consideration of user goals,
constraints, risk tolerance, and jurisdiction. Prior LLM work has focused on
support systems for investors and financial planners. Simultaneously, numerous
recent studies examine broader personal finance tasks, including budgeting,
debt management, retirement, and estate planning, through agentic pipelines
that incur high maintenance costs, yielding less than 25% of their expected
financial returns. In this study, we introduce a novel and reproducible
framework that integrates relevant financial context with behavioral finance
studies to construct supervision data for end-to-end advisors. Using this
framework, we create a 19k sample reasoning dataset and conduct a comprehensive
fine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test
split and a blind LLM-jury study, we demonstrate that through careful data
curation and behavioral integration, our 8B model achieves performance
comparable to significantly larger baselines (14-32B parameters) across factual
accuracy, fluency, and personalization metrics while incurring 80% lower costs
than the larger counterparts.

</details>


### [38] [Framing Migration: A Computational Analysis of UK Parliamentary Discourse](https://arxiv.org/abs/2509.14197)
*Vahid Ghafouri,Robert McNeil,Teodor Yankov,Madeleine Sumption,Luc Rocher,Scott A. Hale,Adam Mahdi*

Main category: cs.CL

TL;DR: 使用大语言模型分析英美议会75年移民话语，发现美国日益极化而英国党派态度相对一致，但保守党与工党意识形态差距在2025年达到最负面水平，英国话语呈现安全化和去一体化趋势。


<details>
  <summary>Details</summary>
Motivation: 通过大规模计算分析来理解英美两国议会移民话语的长期演变趋势和差异，探索大语言模型在政治历史话语分析中的 scalability 和精细分析能力。

Method: 使用开源大语言模型对英国议会75年辩论和美国国会辩论进行自动标注，识别对移民的高层立场态度；针对英国开发半自动化框架提取细粒度叙事框架，追踪话语随时间推移和政党变化的趋势。

Result: 美国移民话语日益极化，英国各党派态度相对一致但保守党与工党存在持久意识形态差距（2025年最负面）；英国话语向边境管控、非法移民等安全化叙事转变，社会融合等长期一体化框架减少；移民讨论从国内法转向国际法和人权法。

Conclusion: 大语言模型能够支持政治历史语境中可扩展的细粒度话语分析，揭示了移民话语的复杂演变模式和跨国差异，为理解政治话语动态提供了新的分析工具。

Abstract: We present a large-scale computational analysis of migration-related
discourse in UK parliamentary debates spanning over 75 years and compare it
with US congressional discourse. Using open-weight LLMs, we annotate each
statement with high-level stances toward migrants and track the net tone toward
migrants across time and political parties. For the UK, we extend this with a
semi-automated framework for extracting fine-grained narrative frames to
capture nuances of migration discourse. Our findings show that, while US
discourse has grown increasingly polarised, UK parliamentary attitudes remain
relatively aligned across parties, with a persistent ideological gap between
Labour and the Conservatives, reaching its most negative level in 2025. The
analysis of narrative frames in the UK parliamentary statements reveals a shift
toward securitised narratives such as border control and illegal immigration,
while longer-term integration-oriented frames such as social integration have
declined. Moreover, discussions of national law about immigration have been
replaced over time by international law and human rights, revealing nuances in
discourse trends. Taken together broadly, our findings demonstrate how LLMs can
support scalable, fine-grained discourse analysis in political and historical
contexts.

</details>


### [39] [Apertus: Democratizing Open and Compliant LLMs for Global Language Environments](https://arxiv.org/abs/2509.14233)
*Alejandro Hernández-Cano,Alexander Hägele,Allen Hao Huang,Angelika Romanou,Antoni-Joan Solergibert,Barna Pasztor,Bettina Messmer,Dhia Garbaya,Eduard Frank Ďurech,Ido Hakimi,Juan García Giraldo,Mete Ismayilzada,Negar Foroutan,Skander Moalla,Tiancheng Chen,Vinko Sabolčec,Yixuan Xu,Michael Aerni,Badr AlKhamissi,Ines Altemir Marinas,Mohammad Hossein Amani,Matin Ansaripour,Ilia Badanin,Harold Benoit,Emanuela Boros,Nicholas Browning,Fabian Bösch,Maximilian Böther,Niklas Canova,Camille Challier,Clement Charmillot,Jonathan Coles,Jan Deriu,Arnout Devos,Lukas Drescher,Daniil Dzenhaliou,Maud Ehrmann,Dongyang Fan,Simin Fan,Silin Gao,Miguel Gila,María Grandury,Diba Hashemi,Alexander Hoyle,Jiaming Jiang,Mark Klein,Andrei Kucharavy,Anastasiia Kucherenko,Frederike Lübeck,Roman Machacek,Theofilos Manitaras,Andreas Marfurt,Kyle Matoba,Simon Matrenok,Henrique Mendoncça,Fawzi Roberto Mohamed,Syrielle Montariol,Luca Mouchel,Sven Najem-Meyer,Jingwei Ni,Gennaro Oliva,Matteo Pagliardini,Elia Palme,Andrei Panferov,Léo Paoletti,Marco Passerini,Ivan Pavlov,Auguste Poiroux,Kaustubh Ponkshe,Nathan Ranchin,Javi Rando,Mathieu Sauser,Jakhongir Saydaliev,Muhammad Ali Sayfiddinov,Marian Schneider,Stefano Schuppli,Marco Scialanga,Andrei Semenov,Kumar Shridhar,Raghav Singhal,Anna Sotnikova,Alexander Sternfeld,Ayush Kumar Tarun,Paul Teiletche,Jannis Vamvas,Xiaozhe Yao,Hao Zhao Alexander Ilic,Ana Klimovic,Andreas Krause,Caglar Gulcehre,David Rosenthal,Elliott Ash,Florian Tramèr,Joost VandeVondele,Livio Veraldi,Martin Rajman,Thomas Schulthess,Torsten Hoefler,Antoine Bosselut,Martin Jaggi,Imanol Schlag*

Main category: cs.CL

TL;DR: Apertus是一个完全开源的大型语言模型套件，专注于数据合规性和多语言表示，使用开放可用数据训练，尊重robots.txt排除规则，采用Goldfish目标减少记忆风险，支持1800多种语言，在8B和70B规模上达到先进的多语言基准性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前开源模型生态系统中数据合规性和多语言代表性不足的问题，许多现有模型发布权重时缺乏可复现的数据管道且不尊重内容所有者权利。

Method: 使用完全开放可用数据进行预训练，遵循robots.txt排除规则，过滤非许可、有毒和个人身份信息内容；采用Goldfish目标抑制数据逐字记忆；在多语言数据上训练（15T tokens，1800+语言，40%非英语内容）。

Result: Apertus模型在8B和70B规模上接近完全开源模型的最先进多语言基准结果，与开源权重对应模型相当或超越。

Conclusion: Apertus提供了一个完全透明、合规的开源LLM解决方案，不仅发布模型权重，还提供完整科学成果（数据准备脚本、检查点、评估套件和训练代码），支持透明审计和扩展。

Abstract: We present Apertus, a fully open suite of large language models (LLMs)
designed to address two systemic shortcomings in today's open model ecosystem:
data compliance and multilingual representation. Unlike many prior models that
release weights without reproducible data pipelines or regard for content-owner
rights, Apertus models are pretrained exclusively on openly available data,
retroactively respecting robots.txt exclusions and filtering for
non-permissive, toxic, and personally identifiable content. To mitigate risks
of memorization, we adopt the Goldfish objective during pretraining, strongly
suppressing verbatim recall of data while retaining downstream task
performance. The Apertus models also expand multilingual coverage, training on
15T tokens from over 1800 languages, with ~40% of pretraining data allocated to
non-English content. Released at 8B and 70B scales, Apertus approaches
state-of-the-art results among fully open models on multilingual benchmarks,
rivalling or surpassing open-weight counterparts. Beyond model weights, we
release all scientific artifacts from our development cycle with a permissive
license, including data preparation scripts, checkpoints, evaluation suites,
and training code, enabling transparent audit and extension.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [40] [A Domain Knowledge Informed Approach for Anomaly Detection of Electric Vehicle Interior Sounds](https://arxiv.org/abs/2509.13390)
*Deepti Kunte,Bram Cornelis,Claudio Colangeli,Karl Janssens,Brecht Van Baelen,Konstantinos Gryllias*

Main category: cs.SD

TL;DR: 提出了一种基于领域知识的模型选择方法，使用健康样本的扰动生成代理异常来支持无监督异常检测的模型选择，在汽车舱室声音异常检测中显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 汽车舱室声音异常检测通常是无监督学习问题，但由于缺乏标记的故障数据和验证指标的局限性，模型选择面临重大挑战。

Method: 通过结构化扰动健康频谱图生成代理异常，在验证集中使用这些代理异常来支持模型选择，基于领域知识指导的方法。

Result: 在包含五种典型故障类型的高保真电动汽车数据集上实验表明，使用代理异常选择的模型显著优于传统模型选择策略。

Conclusion: 提出的领域知识驱动的代理异常方法为无监督异常检测中的模型选择提供了有效解决方案，公开数据集有助于进一步研究。

Abstract: The detection of anomalies in automotive cabin sounds is critical for
ensuring vehicle quality and maintaining passenger comfort. In many real-world
settings, this task is more appropriately framed as an unsupervised learning
problem rather than the supervised case due to the scarcity or complete absence
of labeled faulty data. In such an unsupervised setting, the model is trained
exclusively on healthy samples and detects anomalies as deviations from normal
behavior. However, in the absence of labeled faulty samples for validation and
the limited reliability of commonly used metrics, such as validation
reconstruction error, effective model selection remains a significant
challenge. To overcome these limitations, a domain-knowledge-informed approach
for model selection is proposed, in which proxy-anomalies engineered through
structured perturbations of healthy spectrograms are used in the validation set
to support model selection. The proposed methodology is evaluated on a
high-fidelity electric vehicle dataset comprising healthy and faulty cabin
sounds across five representative fault types viz., Imbalance, Modulation,
Whine, Wind, and Pulse Width Modulation. This dataset, generated using advanced
sound synthesis techniques, and validated via expert jury assessments, has been
made publicly available to facilitate further research. Experimental
evaluations on the five fault cases demonstrate the selection of optimal models
using proxy-anomalies, significantly outperform conventional model selection
strategies.

</details>


### [41] [Field of View Enhanced Signal Dependent Binauralization with Mixture of Experts Framework for Continuous Source Motion](https://arxiv.org/abs/2509.13548)
*Manan Mittal,Thomas Deppisch,Joseph Forrer,Chris Le Sueur,Zamir Ben-Hur,David Lou Along,Daniel D. E. Wong*

Main category: cs.SD

TL;DR: 提出了一种用于双耳信号匹配中视场增强的混合专家框架，支持动态空间音频渲染和实时移动声源跟踪


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖于显式到达方向估计或在Ambisonics域操作，无法有效处理连续说话者运动和动态空间音频需求

Method: 基于信号依赖的框架，通过隐式定位在线组合多个双耳滤波器，无需显式方向估计，对阵列几何形状不敏感

Result: 能够实现实时移动声源跟踪和增强，支持语音聚焦、降噪以及AR/VR中的世界锁定音频应用

Conclusion: 为下一代消费音频设备提供了灵活的空间音频捕获和个性化播放解决方案，适应动态声源运动需求

Abstract: We propose a novel mixture of experts framework for field-of-view enhancement
in binaural signal matching. Our approach enables dynamic spatial audio
rendering that adapts to continuous talker motion, allowing users to emphasize
or suppress sounds from selected directions while preserving natural binaural
cues. Unlike traditional methods that rely on explicit direction-of-arrival
estimation or operate in the Ambisonics domain, our signal-dependent framework
combines multiple binaural filters in an online manner using implicit
localization. This allows for real-time tracking and enhancement of moving
sound sources, supporting applications such as speech focus, noise reduction,
and world-locked audio in augmented and virtual reality. The method is agnostic
to array geometry offering a flexible solution for spatial audio capture and
personalized playback in next-generation consumer audio devices.

</details>


### [42] [Neural Speech Separation with Parallel Amplitude and Phase Spectrum Estimation](https://arxiv.org/abs/2509.13825)
*Fei Liu,Yang Ai,Zhen-Hua Ling*

Main category: cs.SD

TL;DR: APSS是一种新颖的神经语音分离模型，通过并行估计振幅和相位频谱来实现更完整准确的语音分离，在多个数据集上表现出优越性能和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数语音分离方法主要关注振幅频谱估计，而忽略了相位频谱的重要性。APSS旨在通过显式并行估计振幅和相位频谱，实现更完整和准确的语音分离。

Method: APSS首先从混合语音信号中提取振幅和相位频谱，通过特征组合器融合成联合表示，使用时频Transformer的深度处理器捕获时频依赖关系，最后通过并行振幅和相位分离器估计各说话人的频谱，通过逆短时傅里叶变换重建分离的语音信号。

Result: 实验结果表明APSS超越了时域分离方法和基于隐式相位估计的时频方法，在多个数据集上取得了稳定且具有竞争力的结果。

Conclusion: APSS通过并行振幅和相位频谱估计的创新方法，展现了强大的泛化能力和实际应用价值，为语音分离领域提供了新的有效解决方案。

Abstract: This paper proposes APSS, a novel neural speech separation model with
parallel amplitude and phase spectrum estimation. Unlike most existing speech
separation methods, the APSS distinguishes itself by explicitly estimating the
phase spectrum for more complete and accurate separation. Specifically, APSS
first extracts the amplitude and phase spectra from the mixed speech signal.
Subsequently, the extracted amplitude and phase spectra are fused by a feature
combiner into joint representations, which are then further processed by a deep
processor with time-frequency Transformers to capture temporal and spectral
dependencies. Finally, leveraging parallel amplitude and phase separators, the
APSS estimates the respective spectra for each speaker from the resulting
features, which are then combined via inverse short-time Fourier transform
(iSTFT) to reconstruct the separated speech signals. Experimental results
indicate that APSS surpasses both time-domain separation methods and
implicit-phase-estimation-based time-frequency approaches. Also, APSS achieves
stable and competitive results on multiple datasets, highlighting its strong
generalization capability and practical applicability.

</details>


### [43] [Noise Supervised Contrastive Learning and Feature-Perturbed for Anomalous Sound Detection](https://arxiv.org/abs/2509.13853)
*Shun Huang,Zhihua Fang,Liang He*

Main category: cs.SD

TL;DR: 本文提出了一种单阶段监督对比学习(OS-SCL)方法，通过特征扰动和一阶段噪声监督对比学习，有效解决了无监督异常声音检测中不同机器同类型样本误报率高的问题，并在DCASE 2020挑战赛上取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 无监督异常声音检测在处理来自不同机器的同类型样本时经常出现误报，现有自监督方法未能有效解决这一问题。

Method: 提出OS-SCL训练技术，在嵌入空间进行特征扰动，采用一阶段噪声监督对比学习方法；同时提出从原始音频提取的时频特征TFgram。

Result: 仅使用Log-Mel特征时达到94.64% AUC、88.42% pAUC和89.24% mAUC；使用TFgram特征时性能进一步提升至95.71% AUC、90.23% pAUC和91.23% mAUC。

Conclusion: OS-SCL方法有效解决了异常声音检测中的误报问题，TFgram特征能够更好地捕捉关键信息，方法在标准数据集上表现出色。

Abstract: Unsupervised anomalous sound detection aims to detect unknown anomalous
sounds by training a model using only normal audio data. Despite advancements
in self-supervised methods, the issue of frequent false alarms when handling
samples of the same type from different machines remains unresolved. This paper
introduces a novel training technique called one-stage supervised contrastive
learning (OS-SCL), which significantly addresses this problem by perturbing
features in the embedding space and employing a one-stage noisy supervised
contrastive learning approach. On the DCASE 2020 Challenge Task 2, it achieved
94.64\% AUC, 88.42\% pAUC, and 89.24\% mAUC using only Log-Mel features.
Additionally, a time-frequency feature named TFgram is proposed, which is
extracted from raw audio. This feature effectively captures critical
information for anomalous sound detection, ultimately achieving 95.71\% AUC,
90.23\% pAUC, and 91.23\% mAUC. The source code is available at:
\underline{www.github.com/huangswt/OS-SCL}.

</details>


### [44] [RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing](https://arxiv.org/abs/2509.14003)
*Liting Gao,Yi Yuan,Yaru Chen,Yuelan Cheng,Zhenbo Li,Juan Wen,Shubin Zhang,Wenwu Wang*

Main category: cs.SD

TL;DR: 提出了一种基于校正流匹配的端到端扩散框架，用于文本引导的音频编辑，无需辅助标注或掩码即可实现语义对齐。


<details>
  <summary>Details</summary>
Motivation: 文本引导的音频编辑仍处于早期阶段，现有方法在处理复杂编辑时存在困难或缺乏实用性，需要精确的定位和忠实的文本提示编辑。

Method: 基于校正流匹配的端到端扩散框架，构建了包含重叠多事件音频的数据集来支持复杂场景的训练和基准测试。

Result: 实验表明该模型无需辅助标注或掩码即可实现忠实的语义对齐，同时在各项指标上保持有竞争力的编辑质量。

Conclusion: 提出的方法为文本引导的音频编辑提供了一种高效实用的解决方案，在复杂场景下表现出色。

Abstract: Diffusion models have shown remarkable progress in text-to-audio generation.
However, text-guided audio editing remains in its early stages. This task
focuses on modifying the target content within an audio signal while preserving
the rest, thus demanding precise localization and faithful editing according to
the text prompt. Existing training-based and zero-shot methods that rely on
full-caption or costly optimization often struggle with complex editing or lack
practicality. In this work, we propose a novel end-to-end efficient rectified
flow matching-based diffusion framework for audio editing, and construct a
dataset featuring overlapping multi-event audio to support training and
benchmarking in complex scenarios. Experiments show that our model achieves
faithful semantic alignment without requiring auxiliary captions or masks,
while maintaining competitive editing quality across metrics.

</details>


### [45] [Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices](https://arxiv.org/abs/2509.14049)
*Jordi Grau-Haro,Ruben Ribes-Serrano,Javier Naranjo-Alcazar,Marta Garcia-Ballesteros,Pedro Zuccarello*

Main category: cs.SD

TL;DR: 对多种CNN架构在树莓派上进行音频标签任务的综合评估，包括1D/2D PANNs模型、ConvNeXt变体、MobileNetV3等，通过ONNX格式转换和24小时持续推理测试性能稳定性


<details>
  <summary>Details</summary>
Motivation: 解决CNN模型在资源受限设备（如树莓派）上部署时面临的计算效率和热管理挑战，为边缘计算场景中的音频标签应用提供实用解决方案

Method: 评估多种CNN架构（PANNs框架的1D/2D模型、ConvNeXt音频分类适配版、MobileNetV3、CNN9/CNN13），转换为ONNX格式，进行24小时持续推理测试以评估延迟和热行为稳定性

Result: 通过合适的模型选择和优化，可以在长时间运行中保持一致的推理延迟并有效管理热行为

Conclusion: 研究为在实际边缘计算场景中部署音频标签模型提供了有价值的见解，证明了在资源受限设备上实现稳定性能的可行性

Abstract: Convolutional Neural Networks (CNNs) have demonstrated exceptional
performance in audio tagging tasks. However, deploying these models on
resource-constrained devices like the Raspberry Pi poses challenges related to
computational efficiency and thermal management. In this paper, a comprehensive
evaluation of multiple convolutional neural network (CNN) architectures for
audio tagging on the Raspberry Pi is conducted, encompassing all 1D and 2D
models from the Pretrained Audio Neural Networks (PANNs) framework, a
ConvNeXt-based model adapted for audio classification, as well as MobileNetV3
architectures. In addition, two PANNs-derived networks, CNN9 and CNN13,
recently proposed, are also evaluated. To enhance deployment efficiency and
portability across diverse hardware platforms, all models are converted to the
Open Neural Network Exchange (ONNX) format. Unlike previous works that focus on
a single model, our analysis encompasses a broader range of architectures and
involves continuous 24-hour inference sessions to assess performance stability.
Our experiments reveal that, with appropriate model selection and optimization,
it is possible to maintain consistent inference latency and manage thermal
behavior effectively over extended periods. These findings provide valuable
insights for deploying audio tagging models in real-world edge computing
scenarios.

</details>


### [46] [AnyAccomp: Generalizable Accompaniment Generation via Quantized Melodic Bottleneck](https://arxiv.org/abs/2509.14052)
*Junan Zhang,Yunjia Zhang,Xueyao Zhang,Zhizheng Wu*

Main category: cs.SD

TL;DR: AnyAccomp是一个歌唱伴奏生成框架，通过解耦伴奏生成与源依赖伪影，解决了现有方法对分离人声的过拟合问题，在干净人声和乐器独奏上表现出优异的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的歌唱伴奏生成技术使用源分离的人声作为输入，但会过度拟合分离伪影，导致在真实世界的干净人声输入上失败，存在严重的训练-测试不匹配问题。

Method: AnyAccomp采用量化旋律瓶颈，使用色度图和VQ-VAE提取离散且音色不变的旋律核心表示，然后通过流匹配模型基于这些鲁棒编码生成伴奏。

Result: 实验表明AnyAccomp在分离人声基准上具有竞争力，同时在干净录音室人声和乐器独奏的泛化测试集上显著优于基线方法，实现了伴奏生成能力的质的飞跃。

Conclusion: 该框架实现了对乐器的鲁棒伴奏生成（现有模型完全失败的任务），为更通用的音乐共创工具铺平了道路。

Abstract: Singing Accompaniment Generation (SAG) is the process of generating
instrumental music for a given clean vocal input. However, existing SAG
techniques use source-separated vocals as input and overfit to separation
artifacts. This creates a critical train-test mismatch, leading to failure on
clean, real-world vocal inputs. We introduce AnyAccomp, a framework that
resolves this by decoupling accompaniment generation from source-dependent
artifacts. AnyAccomp first employs a quantized melodic bottleneck, using a
chromagram and a VQ-VAE to extract a discrete and timbre-invariant
representation of the core melody. A subsequent flow-matching model then
generates the accompaniment conditioned on these robust codes. Experiments show
AnyAccomp achieves competitive performance on separated-vocal benchmarks while
significantly outperforming baselines on generalization test sets of clean
studio vocals and, notably, solo instrumental tracks. This demonstrates a
qualitative leap in generalization, enabling robust accompaniment for
instruments - a task where existing models completely fail - and paving the way
for more versatile music co-creation tools. Demo audio and code:
https://anyaccomp.github.io

</details>
