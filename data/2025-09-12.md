<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 37]
- [cs.SD](#cs.SD) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Noise or Nuance: An Investigation Into Useful Information and Filtering For LLM Driven AKBC](https://arxiv.org/abs/2509.08903)
*Alex Clay,Ernesto Jiménez-Ruiz,Pranava Madhyastha*

Main category: cs.CL

TL;DR: 在受限环境下，研究发现额外信息提升三元组生成质量，LLM能有效过滤低质量三元组，解析方式需在灵活性与一致性间取表


<details>
  <summary>Details</summary>
Motivation: 在像2025 LM-KBC挑战这样的受限环境下，RAG和微调等传统改善方法受限，需要探索更有效的方法来提高LLM输出质量

Method: 研究三元组完成任务的三个方面：生成、质量保障和LLM响应解析，在受限设置下进行实验分析

Result: 额外信息能显著提高生成三元组的质量；LLM在过滤低质量三元组方面表现有效；LLM响应解析的灵活性与一致性间的交换关系取决于具体设置

Conclusion: 在受限环境下，通过提供额外信息、利用LLM进行质量过滤以及根据具体需求选择合适的响应解析策略，可以有效提高三元组完成任务的性能

Abstract: RAG and fine-tuning are prevalent strategies for improving the quality of LLM
outputs. However, in constrained situations, such as that of the 2025 LM-KBC
challenge, such techniques are restricted. In this work we investigate three
facets of the triple completion task: generation, quality assurance, and LLM
response parsing. Our work finds that in this constrained setting: additional
information improves generation quality, LLMs can be effective at filtering
poor quality triples, and the tradeoff between flexibility and consistency with
LLM response parsing is setting dependent.

</details>


### [2] [Automated Evidence Extraction and Scoring for Corporate Climate Policy Engagement: A Multilingual RAG Approach](https://arxiv.org/abs/2509.08907)
*Imene Kolli,Ario Saeid Vaghefi,Chiara Colesanti Senni,Shantam Raj,Markus Leippold*

Main category: cs.CL

TL;DR: 提出AI辅助框架，利用检索增强生成技术自动化从企业文档中提取气候政策参与证据，加速企业气候政策参与监测


<details>
  <summary>Details</summary>
Motivation: 现有企业气候政策参与评估主要依赖人工，耗时耗力且易出错，需要自动化解决方案提高效率

Method: 采用检索增强生成技术，结合布局感知解析、Nomic嵌入模型和少样本提示策略，从多语言企业文档中提取和分类证据

Result: 评估显示该方法在证据提取和分类方面表现最佳，能有效加速证据提取过程

Conclusion: 自动化RAG系统能有效加速证据提取，但由于分析的复杂性，仍需采用人机协同方式，技术应增强而非替代专家判断

Abstract: InfluenceMap's LobbyMap Platform monitors the climate policy engagement of
over 500 companies and 250 industry associations, assessing each entity's
support or opposition to science-based policy pathways for achieving the Paris
Agreement's goal of limiting global warming to 1.5{\deg}C. Although
InfluenceMap has made progress with automating key elements of the analytical
workflow, a significant portion of the assessment remains manual, making it
time- and labor-intensive and susceptible to human error. We propose an
AI-assisted framework to accelerate the monitoring of corporate climate policy
engagement by leveraging Retrieval-Augmented Generation to automate the most
time-intensive extraction of relevant evidence from large-scale textual data.
Our evaluation shows that a combination of layout-aware parsing, the Nomic
embedding model, and few-shot prompting strategies yields the best performance
in extracting and classifying evidence from multilingual corporate documents.
We conclude that while the automated RAG system effectively accelerates
evidence extraction, the nuanced nature of the analysis necessitates a
human-in-the-loop approach where the technology augments, rather than replaces,
expert judgment to ensure accuracy.

</details>


### [3] [Documents Are People and Words Are Items: A Psychometric Approach to Textual Data with Contextual Embeddings](https://arxiv.org/abs/2509.08920)
*Jinsong Chen*

Main category: cs.CL

TL;DR: 使用大语言模型的新题心理测量方法，通过上下文嵌入将文本转换为可分析的响应数据，探索文档中的潜在知识维度


<details>
  <summary>Details</summary>
Motivation: 为了更好地对文本数据进行心理测量分析，提出一种能够将文本转换为可分析数据的方法，以涉及教育、心理学等领域

Method: 两阶段方法：第一阶段使用NLP技术和transformer模型获取上下文得分；第二阶段采用因子分析（探索性、双因子模型）提取潜在因子和关联关系

Result: 在Wiki STEM语料库中进行实验，证明该方法能够有效地发现文本数据中的潜在知识维度和模式

Conclusion: 该方法不仅提升了文本数据的心理测量分析能力，还在教育、心理学、法律等领域具有广阔的应用前景

Abstract: This research introduces a novel psychometric method for analyzing textual
data using large language models. By leveraging contextual embeddings to create
contextual scores, we transform textual data into response data suitable for
psychometric analysis. Treating documents as individuals and words as items,
this approach provides a natural psychometric interpretation under the
assumption that certain keywords, whose contextual meanings vary significantly
across documents, can effectively differentiate documents within a corpus. The
modeling process comprises two stages: obtaining contextual scores and
performing psychometric analysis. In the first stage, we utilize natural
language processing techniques and encoder based transformer models to identify
common keywords and generate contextual scores. In the second stage, we employ
various types of factor analysis, including exploratory and bifactor models, to
extract and define latent factors, determine factor correlations, and identify
the most significant words associated with each factor. Applied to the Wiki
STEM corpus, our experimental results demonstrate the method's potential to
uncover latent knowledge dimensions and patterns within textual data. This
approach not only enhances the psychometric analysis of textual data but also
holds promise for applications in fields rich in textual information, such as
education, psychology, and law.

</details>


### [4] [BRoverbs -- Measuring how much LLMs understand Portuguese proverbs](https://arxiv.org/abs/2509.08960)
*Thales Sales Almeida,Giovana Kerche Bonás,João Guilherme Alves Santos*

Main category: cs.CL

TL;DR: BRoverbs是一个专门针对巴西葡萄牙语的评估数据集，通过巴西谚语来测试大语言模型在区域语言文化理解方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有葡萄牙语评估主要依赖翻译数据集或局限于结构化考试和社交媒体情感分析，无法充分捕捉语言细微差别和文化参考，需要针对特定区域的成熟评估框架。

Method: 创建BRoverbs数据集，使用巴西谚语作为评估工具，这些谚语包含文化智慧、比喻表达和复杂句法结构，能够有效测试模型对区域表达的理解能力。

Result: 提供了一个专门针对巴西葡萄牙语的新评估基准，可用于评估葡萄牙语大语言模型在区域语言文化理解方面的性能表现。

Conclusion: BRoverbs填补了葡萄牙语评估的空白，为葡萄牙语大语言模型提供了区域化的评估工具，有助于推进基于区域信息的基准测试发展。

Abstract: Large Language Models (LLMs) exhibit significant performance variations
depending on the linguistic and cultural context in which they are applied.
This disparity signals the necessity of mature evaluation frameworks that can
assess their capabilities in specific regional settings. In the case of
Portuguese, existing evaluations remain limited, often relying on translated
datasets that may not fully capture linguistic nuances or cultural references.
Meanwhile, native Portuguese-language datasets predominantly focus on
structured national exams or sentiment analysis of social media interactions,
leaving gaps in evaluating broader linguistic understanding. To address this
limitation, we introduce BRoverbs, a dataset specifically designed to assess
LLM performance through Brazilian proverbs. Proverbs serve as a rich linguistic
resource, encapsulating cultural wisdom, figurative expressions, and complex
syntactic structures that challenge the model comprehension of regional
expressions. BRoverbs aims to provide a new evaluation tool for
Portuguese-language LLMs, contributing to advancing regionally informed
benchmarking. The benchmark is available at
https://huggingface.co/datasets/Tropic-AI/BRoverbs.

</details>


### [5] [Can Vision-Language Models Solve Visual Math Equations?](https://arxiv.org/abs/2509.09013)
*Monjoy Narayan Choudhury,Junling Wang,Yifan Hou,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 视觉语言模型在视觉方程求解任务中表现不佳，主要瓶颈在于系数计数和符号推理能力不足


<details>
  <summary>Details</summary>
Motivation: 研究视觉语言模型在需要感知与符号计算整合的任务中的局限性，特别是视觉方程求解问题

Method: 将视觉方程求解任务分解为系数计数和变量识别两个子任务进行分析，研究不同复杂度方程下的表现

Result: VLMs在文本方程上表现良好，但在视觉方程上失败；计数是主要瓶颈；多步骤推理会引入额外错误；随着方程复杂度增加，符号推理本身成为限制因素

Conclusion: 当前VLMs在视觉数学推理方面存在关键弱点，需要改进计数能力和多步骤视觉推理能力

Abstract: Despite strong performance in visual understanding and language-based
reasoning, Vision-Language Models (VLMs) struggle with tasks requiring
integrated perception and symbolic computation. We study this limitation
through visual equation solving, where mathematical equations are embedded in
images, variables are represented by object icons, and coefficients must be
inferred by counting. While VLMs perform well on textual equations, they fail
on visually grounded counterparts. To understand this gap, we decompose the
task into coefficient counting and variable recognition, and find that counting
is the primary bottleneck, even when recognition is accurate. We also observe
that composing recognition and reasoning introduces additional errors,
highlighting challenges in multi-step visual reasoning. Finally, as equation
complexity increases, symbolic reasoning itself becomes a limiting factor.
These findings reveal key weaknesses in current VLMs and point toward future
improvements in visually grounded mathematical reasoning.

</details>


### [6] [EchoX: Towards Mitigating Acoustic-Semantic Gap via Echo Training for Speech-to-Speech LLMs](https://arxiv.org/abs/2509.09174)
*Yuhao Zhang,Yuhao Du,Zhanchen Dai,Xiangnan Ma,Kaiqi Kou,Benyou Wang,Haizhou Li*

Main category: cs.CL

TL;DR: EchoX是一个语音-语音大语言模型，通过语义表示和动态生成语音训练目标来解决声学-语义差距问题，在知识推理任务上表现优异


<details>
  <summary>Details</summary>
Motivation: 当前语音大语言模型在知识和推理能力上存在退化，主要原因是训练范式未能弥合特征表示空间中的声学-语义差距

Method: 提出EchoX方法，利用语义表示并动态生成语音训练目标，整合声学和语义学习

Result: 使用约6000小时训练数据，在多个基于知识的问答基准测试中达到先进性能

Conclusion: EchoX成功解决了语音LLM中的声学-语义表示问题，保持了强大的推理能力

Abstract: Speech-to-speech large language models (SLLMs) are attracting increasing
attention. Derived from text-based large language models (LLMs), SLLMs often
exhibit degradation in knowledge and reasoning capabilities. We hypothesize
that this limitation arises because current training paradigms for SLLMs fail
to bridge the acoustic-semantic gap in the feature representation space. To
address this issue, we propose EchoX, which leverages semantic representations
and dynamically generates speech training targets. This approach integrates
both acoustic and semantic learning, enabling EchoX to preserve strong
reasoning abilities as a speech LLM. Experimental results demonstrate that
EchoX, with about six thousand hours of training data, achieves advanced
performance on multiple knowledge-based question-answering benchmarks. The
project is available at https://github.com/FreedomIntelligence/EchoX.

</details>


### [7] [Stated Preference for Interaction and Continued Engagement (SPICE): Evaluating an LLM's Willingness to Re-engage in Conversation](https://arxiv.org/abs/2509.09043)
*Thomas Manuel Rost,Martina Figlia,Bernd Wallraff*

Main category: cs.CL

TL;DR: SPICE是一种通过询问LLM是否愿意继续与用户互动的简单诊断信号，能够有效区分不同用户语气下的模型偏好，为模型审计提供直接的关系信号。


<details>
  <summary>Details</summary>
Motivation: 开发一种简单、低开销的诊断工具来评估大型语言模型对用户行为的继续互动意愿，补充现有的模型评估指标。

Method: 使用3种用户语气（友好、模糊、辱骂）和10种互动场景的刺激集，测试4个开源聊天模型在4种框架条件下的SPICE响应，共480次试验。

Result: SPICE能清晰区分用户语气：友好互动97.5%愿意继续，辱骂互动仅17.9%愿意继续，模糊互动60.4%愿意继续。即使在模型未能识别辱骂时，81%的情况下仍表示不愿继续互动。

Conclusion: SPICE是一个稳健、低开销且可复现的工具，可用于审计模型倾向，通过提供直接的、关系性的模型状态信号来补充现有指标。

Abstract: We introduce and evaluate Stated Preference for Interaction and Continued
Engagement (SPICE), a simple diagnostic signal elicited by asking a Large
Language Model a YES or NO question about its willingness to re-engage with a
user's behavior after reviewing a short transcript. In a study using a 3-tone
(friendly, unclear, abusive) by 10-interaction stimulus set, we tested four
open-weight chat models across four framing conditions, resulting in 480
trials. Our findings show that SPICE sharply discriminates by user tone.
Friendly interactions yielded a near-unanimous preference to continue (97.5%
YES), while abusive interactions yielded a strong preference to discontinue
(17.9% YES), with unclear interactions falling in between (60.4% YES). This
core association remains decisive under multiple dependence-aware statistical
tests, including Rao-Scott adjustment and cluster permutation tests.
Furthermore, we demonstrate that SPICE provides a distinct signal from abuse
classification. In trials where a model failed to identify abuse, it still
overwhelmingly stated a preference not to continue the interaction (81% of the
time). An exploratory analysis also reveals a significant interaction effect: a
preamble describing the study context significantly impacts SPICE under
ambiguity, but only when transcripts are presented as a single block of text
rather than a multi-turn chat. The results validate SPICE as a robust,
low-overhead, and reproducible tool for auditing model dispositions,
complementing existing metrics by offering a direct, relational signal of a
model's state. All stimuli, code, and analysis scripts are released to support
replication.

</details>


### [8] [Improving LLM Safety and Helpfulness using SFT and DPO: A Study on OPT-350M](https://arxiv.org/abs/2509.09055)
*Piyush Pant*

Main category: cs.CL

TL;DR: 本研究比较了SFT、DPO和SFT+DPO三种对齐技术在OPT-350M模型上的效果，发现组合方法在所有评估指标上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究不同对齐技术（SFT、DPO及其组合）对语言模型安全性和有用性的改进效果，为构建更鲁棒的对齐流程提供基础。

Method: 使用Anthropic Helpful-Harmless RLHF数据集，训练四个模型：基础OPT350M、SFT模型、DPO模型和SFT+DPO组合模型，并引入三个评估指标：无害率(HmR)、有用率(HpR)和组合对齐分数(CAS)。

Result: SFT表现优于DPO，但SFT+DPO组合模型在所有指标上都超越其他方法，证明了这些技术的互补性。研究还揭示了噪声数据、有限GPU资源和训练约束带来的挑战。

Conclusion: 组合SFT和DPO方法能够产生最佳的对齐效果，为未来更强大的对齐流程开发提供了重要见解和基础。

Abstract: This research investigates the effectiveness of alignment techniques,
Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and a
combined SFT+DPO approach on improving the safety and helpfulness of the
OPT-350M language model. Utilizing the Anthropic Helpful-Harmless RLHF dataset,
we train and evaluate four models: the base OPT350M, an SFT model, a DPO model,
and a model trained with both SFT and DPO. We introduce three key evaluation
metrics: Harmlessness Rate (HmR), Helpfulness Rate (HpR), and a Combined
Alignment Score (CAS), all derived from reward model outputs. The results show
that while SFT outperforms DPO, The combined SFT+DPO model outperforms all
others across all metrics, demonstrating the complementary nature of these
techniques. Our findings also highlight challenges posed by noisy data, limited
GPU resources, and training constraints. This study offers a comprehensive view
of how fine-tuning strategies affect model alignment and provides a foundation
for more robust alignment pipelines in future work.

</details>


### [9] [MR-UIE: Multi-Perspective Reasoning with Reinforcement Learning for Universal Information Extraction](https://arxiv.org/abs/2509.09082)
*Zhongqiu Li,Shiquan Wang,Ruiyu Fang,Mengjiao Bao,Zhenhe Wu,Shuangyong Song,Yongxiang Li,Zhongjiang He*

Main category: cs.CL

TL;DR: 提出MR-UIE方法，将强化学习与多视角推理结合，提升大语言模型在通用信息抽取任务中的性能，特别是在复杂模式描述和多步推理场景下。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在通用信息抽取任务中表现不足，特别是在处理结构化输出、复杂模式描述和多步推理场景时存在显著局限性。

Method: 整合强化学习与多视角推理，将大语言模型从被动抽取器转变为主动推理器，使其不仅能理解抽取内容，还能掌握推理方式。

Result: 在多个信息抽取基准测试中，MR-UIE方法显著提升了跨领域的抽取准确率，并在多个数据集上超越了最先进方法。

Conclusion: 多视角推理与强化学习的结合显著增强了复杂信息抽取任务的泛化能力，凸显了推理在挑战性场景中的关键作用。

Abstract: Large language models (LLMs) demonstrate robust capabilities across diverse
research domains. However, their performance in universal information
extraction (UIE) remains insufficient, especially when tackling structured
output scenarios that involve complex schema descriptions and require
multi-step reasoning. While existing approaches enhance the performance of LLMs
through in-context learning and instruction tuning, significant limitations
nonetheless persist. To enhance the model's generalization ability, we propose
integrating reinforcement learning (RL) with multi-perspective reasoning for
information extraction (IE) tasks. Our work transitions LLMs from passive
extractors to active reasoners, enabling them to understand not only what to
extract but also how to reason. Experiments conducted on multiple IE benchmarks
demonstrate that MR-UIE consistently elevates extraction accuracy across
domains and surpasses state-of-the-art methods on several datasets.
Furthermore, incorporating multi-perspective reasoning into RL notably enhances
generalization in complex IE tasks, underscoring the critical role of reasoning
in challenging scenarios.

</details>


### [10] [TigerCoder: A Novel Suite of LLMs for Code Generation in Bangla](https://arxiv.org/abs/2509.09101)
*Nishat Raihan,Antonios Anastasopoulos,Marcos Zampieri*

Main category: cs.CL

TL;DR: 首个专门为孜加拉语设计的代码生成大语言模型家族，包含1B和9B模型，通过高质量数据集和调优在Pass@1指标上较现有多语言模型提升11-18%性能提升


<details>
  <summary>Details</summary>
Motivation: 孜加拉语作为世界第5大语言在大语言模型中表现不足，特别是在代码生成领域，主要原因是缺乏高质量的训练数据

Method: 构建了综合的孜加拉语代码指令数据集，创建MBPP-Bangla评测基准，开发TigerCoder家族代码LLM模型（包含1B和9B两个规模）

Result: 在Pass@1指标上较现有多语言模型和通用孜加拉语LLM获得11-18%的性能提升，证明精心编辑的高质量数据可以克服小模型在低资源语言上的限制

Conclusion: 通过构建专门的高质量数据集和评测标准，可以有效提升孜加拉语代码生成的性能，并为后续研究提供了开源资源

Abstract: Despite being the 5th most spoken language, Bangla remains underrepresented
in Large Language Models (LLMs), particularly for code generation. This
primarily stems from the scarcity of high-quality data to pre-train and/or
finetune such models. Hence, we introduce the first dedicated family of Code
LLMs for Bangla (1B & 9B). We offer three major contributions: (1) a
comprehensive Bangla code instruction datasets for programming domain
adaptation; (2) MBPP-Bangla, an evaluation benchmark for Bangla code
generation; and (3) the TigerCoder-family of Code LLMs, achieving significant
~11-18% performance gains at Pass@1 over existing multilingual and
general-purpose Bangla LLMs. Our findings show that curated, high-quality
datasets can overcome limitations of smaller models for low-resource languages.
We open-source all resources to advance further Bangla LLM research.

</details>


### [11] [Compass-v3: Scaling Domain-Specific LLMs for Multilingual E-Commerce in Southeast Asia](https://arxiv.org/abs/2509.09121)
*Sophia Maria*

Main category: cs.CL

TL;DR: Compass-v3是一个245B参数的垂直领域MoE模型，专门针对东南亚电商场景设计，通过硬件优化和OTPO对齐方法，在电商任务和多语言处理上达到SOTA性能，已在Shopee平台广泛应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在通用领域表现优异，但在需要领域专业知识的专门任务中性能下降。电商领域数据嘈杂、异构、多语言且高度动态，需要专门的模型来解决这些挑战。

Method: 采用更少但更大的专家设计MoE架构（245B总参数，71B活跃参数），使用硬件高效优化（节点内专家并行和定制memcpy操作符），在12T token的多语言语料和合成电商指令上训练，提出OTPO方法增强对齐能力。

Result: 在电商性能上超越DeepSeek-V3.1、GPT-4系列和Qwen3-235B，在东南亚低资源语言（印尼语、泰语、菲律宾语等）和葡萄牙语上表现出强大的多语言能力，同时在通用基准测试中保持竞争力。

Conclusion: Compass-v3在专业电商知识和广泛语言能力方面具有双重优势，已在Shopee工业级电商平台广泛应用，取代了70%以上的OpenAI流量，证明了其在垂直领域的实用价值。

Abstract: Large language models (LLMs) excel in general-domain applications, yet their
performance often degrades in specialized tasks requiring domain-specific
knowledge. E-commerce is particularly challenging, as its data are noisy,
heterogeneous, multilingual, and highly dynamic. We present Compass-v3, a
vertical-domain Mixture-of-Experts (MoE) model with 245B total parameters and
71B active per token, designed for Southeast Asian e-commerce. Compass-v3
adopts fewer but larger experts, combined with hardware-efficient
optimizations-such as intra-node expert parallelism and a customized memcpy
operator-to maximize GPU utilization. The model is trained on 12T tokens of
curated multilingual corpora and large-scale synthetic e-commerce instructions
using a mixed-training strategy. To enhance alignment, we propose
Optimal-Transport Direct Preference Optimization (OTPO), which captures
token-level distinctions and improves instruction adherence in
commerce-specific scenarios. Extensive evaluations demonstrate that Compass-v3
delivers state-of-the-art e-commerce performance, surpassing DeepSeek-V3.1,
GPT-4 series, and Qwen3-235B. Moreover, Compass-v3 demonstrates strong
multilingual capability across low-resource Southeast Asian languages
(Indonesian, Thai, Filipino, Vietnamese, Malay, Taglog) and Portuguese while
sustaining competitive performance on general benchmarks. It has already been
widely applied in Shopee's industrial-scale e-commerce platform and is
gradually replacing OpenAI's traffic, now accounting for over 70\% of total LLM
usage, highlighting its dual strengths in specialized commerce expertise and
broad linguistic competence.

</details>


### [12] [Automated Classification of Tutors' Dialogue Acts Using Generative AI: A Case Study Using the CIMA Corpus](https://arxiv.org/abs/2509.09125)
*Liqun He,Jiaqi Xu*

Main category: cs.CL

TL;DR: 使用GPT-4自动分类教育对话中教师的话语行为，达到80%准确率，显著提高了分析效率


<details>
  <summary>Details</summary>
Motivation: 减少传统手工编码教育对话中教师话语行为分类的时间和精力消耗

Method: 使用CIMA语料库，通过GPT-3.5-turbo和GPT-4模型进行话语行为分类测试，使用精心设计的提示词

Result: GPT-4达到80%准确率、加权F1分0.81、Cohen's Kappa系数0.74，超越基准绩效并与人工标注实现实质一致

Conclusion: 生成式AI在教育对话分析中具有强大潜力，任务特定标签定义和上下文信息对自动标注质量至关重要，需要关注使用的伦理问题

Abstract: This study explores the use of generative AI for automating the
classification of tutors' Dialogue Acts (DAs), aiming to reduce the time and
effort required by traditional manual coding. This case study uses the
open-source CIMA corpus, in which tutors' responses are pre-annotated into four
DA categories. Both GPT-3.5-turbo and GPT-4 models were tested using tailored
prompts. Results show that GPT-4 achieved 80% accuracy, a weighted F1-score of
0.81, and a Cohen's Kappa of 0.74, surpassing baseline performance and
indicating substantial agreement with human annotations. These findings suggest
that generative AI has strong potential to provide an efficient and accessible
approach to DA classification, with meaningful implications for educational
dialogue analysis. The study also highlights the importance of task-specific
label definitions and contextual information in enhancing the quality of
automated annotation. Finally, it underscores the ethical considerations
associated with the use of generative AI and the need for responsible and
transparent research practices. The script of this research is publicly
available at
https://github.com/liqunhe27/Generative-AI-for-educational-dialogue-act-tagging.

</details>


### [13] [ViRanker: A BGE-M3 & Blockwise Parallel Transformer Cross-Encoder for Vietnamese Reranking](https://arxiv.org/abs/2509.09131)
*Phuong-Nam Dang,Kieu-Linh Nguyen,Thanh-Hieu Pham*

Main category: cs.CL

TL;DR: ViRanker是一个针对越南语的交叉编码器重排序模型，基于BGE-M3编码器构建，采用Blockwise Parallel Transformer增强，在MMARCO-VI基准测试中表现出色，超越了多语言基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决越南语作为低资源语言缺乏竞争性重排序器的问题，越南语具有复杂语法和音调符号，需要专门优化的模型。

Method: 基于BGE-M3编码器，使用Blockwise Parallel Transformer架构，在8GB精选语料上训练，采用混合硬负采样进行微调以增强鲁棒性。

Result: 在MMARCO-VI基准测试中实现了强大的早期排名准确性，超越了多语言基线模型，与PhoRanker竞争表现接近。

Conclusion: 通过精心设计的架构适应和数据策展，可以推动其他代表性不足语言的重排序技术发展，模型已在Hugging Face开源发布以支持可复现性和实际应用。

Abstract: This paper presents ViRanker, a cross-encoder reranking model tailored to the
Vietnamese language. Built on the BGE-M3 encoder and enhanced with the
Blockwise Parallel Transformer, ViRanker addresses the lack of competitive
rerankers for Vietnamese, a low-resource language with complex syntax and
diacritics. The model was trained on an 8 GB curated corpus and fine-tuned with
hybrid hard-negative sampling to strengthen robustness. Evaluated on the
MMARCO-VI benchmark, ViRanker achieves strong early-rank accuracy, surpassing
multilingual baselines and competing closely with PhoRanker. By releasing the
model openly on Hugging Face, we aim to support reproducibility and encourage
wider adoption in real-world retrieval systems. Beyond Vietnamese, this study
illustrates how careful architectural adaptation and data curation can advance
reranking in other underrepresented languages.

</details>


### [14] [LITcoder: A General-Purpose Library for Building and Comparing Encoding Models](https://arxiv.org/abs/2509.09152)
*Taha Binhuraib,Ruimin Gao,Anna A. Ivanova*

Main category: cs.CL

TL;DR: LITcoder是一个开源神经编码模型构建和基准测试库，提供标准化工具来处理连续刺激与脑数据的对齐、特征转换、映射和模型评估，支持模块化流程和多种方法选择。


<details>
  <summary>Details</summary>
Motivation: 降低神经编码模型实现的技术门槛，促进模型和数据集之间的系统比较，提高方法严谨性，加速高质量脑活动预测模型的开发。

Method: 采用模块化流水线设计，支持多种方法选择（脑数据集、脑区域、刺激特征、下采样方法等），内置日志记录、绘图功能，并与实验跟踪平台无缝集成。

Result: 通过在三个故事聆听数据集（LeBel et al. 2023、Narratives、Little Prince）上拟合多种编码模型，验证了框架的可扩展性和多功能性。

Conclusion: LITcoder有效降低了编码模型实现的技术障碍，促进了系统比较和方法严谨性，加速了高质量脑活动预测模型的发展。

Abstract: We introduce LITcoder, an open-source library for building and benchmarking
neural encoding models. Designed as a flexible backend, LITcoder provides
standardized tools for aligning continuous stimuli (e.g., text and speech) with
brain data, transforming stimuli into representational features, mapping those
features onto brain data, and evaluating the predictive performance of the
resulting model on held-out data. The library implements a modular pipeline
covering a wide array of methodological design choices, so researchers can
easily compose, compare, and extend encoding models without reinventing core
infrastructure. Such choices include brain datasets, brain regions, stimulus
feature (both neural-net-based and control, such as word rate), downsampling
approaches, and many others. In addition, the library provides built-in
logging, plotting, and seamless integration with experiment tracking platforms
such as Weights & Biases (W&B). We demonstrate the scalability and versatility
of our framework by fitting a range of encoding models to three story listening
datasets: LeBel et al. (2023), Narratives, and Little Prince. We also explore
the methodological choices critical for building encoding models for continuous
fMRI data, illustrating the importance of accounting for all tokens in a TR
scan (as opposed to just taking the last one, even when contextualized),
incorporating hemodynamic lag effects, using train-test splits that minimize
information leakage, and accounting for head motion effects on encoding model
predictivity. Overall, LITcoder lowers technical barriers to encoding model
implementation, facilitates systematic comparisons across models and datasets,
fosters methodological rigor, and accelerates the development of high-quality
high-performance predictive models of brain activity.
  Project page: https://litcoder-brain.github.io

</details>


### [15] [Target-oriented Multimodal Sentiment Classification with Counterfactual-enhanced Debiasing](https://arxiv.org/abs/2509.09160)
*Zhiyue Liu,Fanrong Ma,Xin Ling*

Main category: cs.CL

TL;DR: 这篇论文提出了一种反事实增强的去偏架构，用于减少目标导向多模态情感分类中文本特征与输出标签间的假相关性，提升分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法过度依赖文本内容且忽视了数据集偏见，导致文本特征与输出标签间的假相关性，影响分类准确性。

Method: 提出反事实数据增强策略，最小化改变情感相关因果特征以生成详细匹配的图像-文本样本，并为学习稳健特征和提示模型决策而引入适应性去偏对比学习机制。

Result: 在多个标准数据集上的实验结果显示，所提方法超越了最先进的基准方法。

Conclusion: 该框架通过反事实增强和对比学习有效减少了偏见词的影响，提升了目标导向多模态情感分类的性能。

Abstract: Target-oriented multimodal sentiment classification seeks to predict
sentiment polarity for specific targets from image-text pairs. While existing
works achieve competitive performance, they often over-rely on textual content
and fail to consider dataset biases, in particular word-level contextual
biases. This leads to spurious correlations between text features and output
labels, impairing classification accuracy. In this paper, we introduce a novel
counterfactual-enhanced debiasing framework to reduce such spurious
correlations. Our framework incorporates a counterfactual data augmentation
strategy that minimally alters sentiment-related causal features, generating
detail-matched image-text samples to guide the model's attention toward content
tied to sentiment. Furthermore, for learning robust features from
counterfactual data and prompting model decisions, we introduce an adaptive
debiasing contrastive learning mechanism, which effectively mitigates the
influence of biased words. Experimental results on several benchmark datasets
show that our proposed method outperforms state-of-the-art baselines.

</details>


### [16] [Efficient Trie-based Biasing using K-step Prediction for Rare Word Recognition](https://arxiv.org/abs/2509.09196)
*Chin Yuen Kwok,Jia Qi yip*

Main category: cs.CL

TL;DR: 提出一种新的上下文偏置方法，通过多步预测避免传统Trie偏置中的分数撤销步骤，显著降低计算成本并提升罕见词识别准确率


<details>
  <summary>Details</summary>
Motivation: 传统Trie偏置方法在beam search中需要撤销部分假设的奖励分数，计算开销大且仅限于beam search，限制了在大解码器模型中的应用

Method: 通过让ASR模型进行多步前瞻预测，直接估计部分假设是否会导致完整罕见词的生成，从而避免分数撤销步骤。使用仅10小时合成数据对Whisper模型进行微调

Result: 在NSC Part 2测试集上，词错误率从30.86%降至12.19%，性能提升显著

Conclusion: 多步预测方法有效解决了传统上下文偏置的计算效率问题，在罕见词识别方面取得了显著改进

Abstract: Contextual biasing improves rare word recognition of ASR models by
prioritizing the output of rare words during decoding. A common approach is
Trie-based biasing, which gives "bonus scores" to partial hypothesis (e.g.
"Bon") that may lead to the generation of the rare word (e.g. "Bonham"). If the
full word ("Bonham") isn't ultimately recognized, the system revokes those
earlier bonuses. This revocation is limited to beam search and is
computationally expensive, particularly for models with large decoders. To
overcome these limitations, we propose adapting ASR models to look ahead and
predict multiple steps at once. This avoids the revocation step entirely by
better estimating whether a partial hypothesis will lead to the generation of
the full rare word. By fine-tuning Whisper with only 10 hours of synthetic
data, our method reduces the word error rate on the NSC Part 2 test set from
30.86% to 12.19%.

</details>


### [17] [Improving Synthetic Data Training for Contextual Biasing Models with a Keyword-Aware Cost Function](https://arxiv.org/abs/2509.09197)
*Chin Yuen Kwok,Jia Qi Yip,Eng Siong Chng*

Main category: cs.CL

TL;DR: 通过具有关键词意识损失函数的TCPGen上下文偏置方法，在合成语音数据上训练Whisper模型，显著降低罕见词识别错误率


<details>
  <summary>Details</summary>
Motivation: 解决在合成语音数据上训练上下文偏置模块时可能出现的过拟合问题，提高罕见词识别性能

Method: 提出关键词意识损失函数，包含对偏置词预测的掩码交叉瑣损失和检测偏置词位置的二元分类损失，在TCPGen基础上增强上下文偏置方法

Result: 在NSC Part 2测试集上，将词语识别错误率从29.71%降低至11.81%

Conclusion: 关键词意识损失函数能够有效提升上下文偏置模块的训练效果，显著改善罕见词识别性能

Abstract: Rare word recognition can be improved by adapting ASR models to synthetic
data that includes these words. Further improvements can be achieved through
contextual biasing, which trains and adds a biasing module into the model
architecture to prioritize rare words. While training the module on synthetic
rare word data is more effective than using non-rare-word data, it can lead to
overfitting due to artifacts in the synthetic audio. To address this, we
enhance the TCPGen-based contextual biasing approach and propose a
keyword-aware loss function that additionally focuses on biased words when
training biasing modules. This loss includes a masked cross-entropy term for
biased word prediction and a binary classification term for detecting biased
word positions. These two terms complementarily support the decoding of biased
words during inference. By adapting Whisper to 10 hours of synthetic data, our
method reduced the word error rate on the NSC Part 2 test set from 29.71% to
11.81%.

</details>


### [18] [GmSLM : Generative Marmoset Spoken Language Modeling](https://arxiv.org/abs/2509.09198)
*Talia Sternberg,Michael London,David Omer,Yossi Adi*

Main category: cs.CL

TL;DR: GmSLM是一个针对狨猴叫声的生成式语音语言模型，通过无监督野外数据和弱标记对话数据评估，在声学匹配和下游任务中表现优异，为研究发声交流的神经基础提供了实用框架。


<details>
  <summary>Details</summary>
Motivation: 狨猴表现出复杂的发声交流能力，具有类似人类语言的特征，但由于其主要通过叫声交流，标准LLM方法不适用，需要专门模型来链接发声与大脑活动研究。

Method: 开发了GmSLM生成式狨猴语音语言模型管道，使用无监督野外数据和弱标记对话数据进行零样本评估，并与基于人类语音的基线进行比较。

Result: GmSLM生成的叫声在声学上与实际重合成样本高度匹配，在下游任务中表现良好，能有效区分真实与人工对话，尽管完全无监督。

Conclusion: GmSLM为研究发声交流的神经基础提供了实用框架，有望在神经科学、生物声学和进化生物学领域发挥重要作用。

Abstract: Marmoset monkeys exhibit complex vocal communication, challenging the view
that nonhuman primates vocal communication is entirely innate, and show similar
features of human speech, such as vocal labeling of others and turn-taking.
Studying their vocal communication offers a unique opportunity to link it with
brain activity-especially given the difficulty of accessing the human brain in
speech and language research. Since Marmosets communicate primarily through
vocalizations, applying standard LLM approaches is not straightforward. We
introduce Generative Marmoset Spoken Language Modeling (GmSLM), an optimized
spoken language model pipeline for Marmoset vocal communication. We designed a
novel zero-shot evaluation metrics using unsupervised in-the-wild data,
alongside weakly labeled conversational data, to assess GmSLM and demonstrate
its advantage over a basic human-speech-based baseline. GmSLM generated
vocalizations closely matched real resynthesized samples acoustically and
performed well on downstream tasks. Despite being fully unsupervised, GmSLM
effectively distinguish real from artificial conversations and may support
further investigations of the neural basis of vocal communication and provides
a practical framework linking vocalization and brain activity. We believe GmSLM
stands to benefit future work in neuroscience, bioacoustics, and evolutionary
biology. Samples are provided under: pages.cs.huji.ac.il/adiyoss-lab/GmSLM.

</details>


### [19] [CCF: A Context Compression Framework for Efficient Long-Sequence Language Modeling](https://arxiv.org/abs/2509.09199)
*Wenhao Li,Bangcheng Sun,Weihao Ye,Tianyi Zhang,Daohai Yu,Fei Chao,Rongrong Ji*

Main category: cs.CL

TL;DR: CCF是一个新颖的上下文压缩框架，通过分层潜在表示学习来高效处理长上下文建模，在保持全局语义的同时显著减少冗余，提高了计算和内存效率。


<details>
  <summary>Details</summary>
Motivation: 扩展语言模型到更长上下文对于捕获扩展语篇中的丰富依赖关系至关重要，但简单的上下文扩展会带来显著的计算和内存负担，导致训练和推理效率低下。

Method: 提出CCF框架，整合分段语义聚合与键值记忆编码，形成紧凑表示；引入训练高效的优化策略，结合增量分段解码和稀疏储层采样来减少内存开销。

Result: 在多个长上下文语言建模基准测试中，CCF在高压缩比下实现了有竞争力的困惑度，相比现有方法显著提高了吞吐量和内存效率。

Conclusion: 结构化压缩对于可扩展且有效的长上下文语言建模具有巨大潜力，CCF框架为解决长上下文处理中的效率问题提供了有效方案。

Abstract: Scaling language models to longer contexts is essential for capturing rich
dependencies across extended discourse. However, na\"ive context extension
imposes significant computational and memory burdens, often resulting in
inefficiencies during both training and inference. In this work, we propose
CCF, a novel context compression framework designed to enable efficient
long-context modeling by learning hierarchical latent representations that
preserve global semantics while aggressively reducing input redundancy. CCF
integrates segment-wise semantic aggregation with key-value memory encoding,
forming compact representations that support accurate reconstruction and
long-range understanding. To further enhance scalability, we introduce a
training-efficient optimization strategy that couples incremental segment
decoding with sparse reservoir sampling, substantially reducing memory overhead
without degrading performance. Empirical results on multiple long-context
language modeling benchmarks demonstrate that CCF achieves competitive
perplexity under high compression ratios, and significantly improves throughput
and memory efficiency compared to existing approaches. These findings highlight
the potential of structured compression for scalable and effective long-context
language modeling.

</details>


### [20] [Reading Between the Lines: Classifying Resume Seniority with Large Language Models](https://arxiv.org/abs/2509.09229)
*Matan Cohen,Shira Shani,Eden Menahem,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CL

TL;DR: 本研究探讨了使用大型语言模型（包括微调BERT架构）来自动化简历中资历分类的有效性，通过混合真实简历和合成困难样本的数据集来评估模型性能。


<details>
  <summary>Details</summary>
Motivation: 准确评估简历中的候选人资历是一个关键但具有挑战性的任务，由于普遍存在经验夸大和模糊自我描述的情况，需要自动化解决方案。

Method: 引入包含真实简历和合成困难样本的混合数据集，使用大型语言模型（包括微调BERT）来检测与资历夸大相关的微妙语言线索。

Result: 研究结果显示了AI驱动候选人评估系统增强的潜力，并能够减轻自我推销语言引入的偏见。

Conclusion: 该方法为改进自动化资历评估提供了有前景的方向，数据集已公开供研究社区使用。

Abstract: Accurately assessing candidate seniority from resumes is a critical yet
challenging task, complicated by the prevalence of overstated experience and
ambiguous self-presentation. In this study, we investigate the effectiveness of
large language models (LLMs), including fine-tuned BERT architectures, for
automating seniority classification in resumes. To rigorously evaluate model
performance, we introduce a hybrid dataset comprising both real-world resumes
and synthetically generated hard examples designed to simulate exaggerated
qualifications and understated seniority. Using the dataset, we evaluate the
performance of Large Language Models in detecting subtle linguistic cues
associated with seniority inflation and implicit expertise. Our findings
highlight promising directions for enhancing AI-driven candidate evaluation
systems and mitigating bias introduced by self-promotional language. The
dataset is available for the research community at https://bit.ly/4mcTovt

</details>


### [21] [Agentic LLMs for Question Answering over Tabular Data](https://arxiv.org/abs/2509.09234)
*Rishit Tyagi,Mohit Gupta,Rahul Bouri*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型的多阶段NL-to-SQL方法，在SemEval 2025 Task 8的DataBench基准测试中取得了显著优于基线的性能表现。


<details>
  <summary>Details</summary>
Motivation: 解决表格问答任务中由于表格结构、大小和数据类型的多样性带来的挑战，评估模型处理结构化查询的能力。

Method: 使用GPT-4o、GPT-4o-mini和DeepSeek v2:16b等大语言模型，采用多阶段流水线方法，包括示例选择、SQL查询生成、答案提取、验证和迭代优化。

Result: 在DataBench QA上达到70.5%准确率，在DataBench Lite QA上达到71.6%准确率，显著超过26%和27%的基线分数。

Conclusion: LLM驱动的表格问答方法有效，论文详细分析了方法的优势和局限性，为相关研究提供了重要见解。

Abstract: Question Answering over Tabular Data (Table QA) presents unique challenges
due to the diverse structure, size, and data types of real-world tables. The
SemEval 2025 Task 8 (DataBench) introduced a benchmark composed of large-scale,
domain-diverse datasets to evaluate the ability of models to accurately answer
structured queries. We propose a Natural Language to SQL (NL-to-SQL) approach
leveraging large language models (LLMs) such as GPT-4o, GPT-4o-mini, and
DeepSeek v2:16b to generate SQL queries dynamically. Our system follows a
multi-stage pipeline involving example selection, SQL query generation, answer
extraction, verification, and iterative refinement. Experiments demonstrate the
effectiveness of our approach, achieving 70.5\% accuracy on DataBench QA and
71.6\% on DataBench Lite QA, significantly surpassing baseline scores of 26\%
and 27\% respectively. This paper details our methodology, experimental
results, and alternative approaches, providing insights into the strengths and
limitations of LLM-driven Table QA.

</details>


### [22] [From scratch to silver: Creating trustworthy training data for patent-SDG classification using Large Language Models](https://arxiv.org/abs/2509.09303)
*Grazia Sveva Ascione,Nicolò Tamagnone*

Main category: cs.CL

TL;DR: 使用弱监督方法通过专利引文和LLM提取结构化概念，构建专利与联合国可持续发展目标(SDGs)的软多标签分类数据集，解决了标注数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 缺乏大规模标注数据集限制了监督学习在专利-SDG分类中的应用，现有方法缺乏可扩展性和泛化性。

Method: 将专利-SDG分类构建为弱监督问题，利用专利对SDG标记科学文献的引文作为噪声信号，开发复合标注函数，使用LLM从专利和SDG论文中提取结构化概念，计算跨域相似度得分。

Result: 内部验证显示方法优于包括transformer模型和零样本LLM在内的多个基线；外部验证显示标签在专利引用、共同发明人和共同申请人网络中展现出更好的主题、认知和组织一致性。

Conclusion: 弱监督和语义对齐可以大规模增强SDG分类，为跟踪创新如何应对全球挑战提供了有效工具。

Abstract: Classifying patents by their relevance to the UN Sustainable Development
Goals (SDGs) is crucial for tracking how innovation addresses global
challenges. However, the absence of a large, labeled dataset limits the use of
supervised learning. Existing methods, such as keyword searches, transfer
learning, and citation-based heuristics, lack scalability and generalizability.
This paper frames patent-to-SDG classification as a weak supervision problem,
using citations from patents to SDG-tagged scientific publications (NPL
citations) as a noisy initial signal. To address its sparsity and noise, we
develop a composite labeling function (LF) that uses large language models
(LLMs) to extract structured concepts, namely functions, solutions, and
applications, from patents and SDG papers based on a patent ontology.
Cross-domain similarity scores are computed and combined using a rank-based
retrieval approach. The LF is calibrated via a custom positive-only loss that
aligns with known NPL-SDG links without penalizing discovery of new SDG
associations. The result is a silver-standard, soft multi-label dataset mapping
patents to SDGs, enabling the training of effective multi-label regression
models. We validate our approach through two complementary strategies: (1)
internal validation against held-out NPL-based labels, where our method
outperforms several baselines including transformer-based models, and zero-shot
LLM; and (2) external validation using network modularity in patent citation,
co-inventor, and co-applicant graphs, where our labels reveal greater thematic,
cognitive, and organizational coherence than traditional technological
classifications. These results show that weak supervision and semantic
alignment can enhance SDG classification at scale.

</details>


### [23] [MetaRAG: Metamorphic Testing for Hallucination Detection in RAG Systems](https://arxiv.org/abs/2509.09360)
*Channdeth Sok,David Luz,Yacine Haddam*

Main category: cs.CL

TL;DR: MetaRAG是一个用于检索增强生成(RAG)系统的幻觉检测框架，通过分解答案、生成变异事实、验证一致性来检测幻觉，无需真实参考或模型内部访问。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法主要针对独立LLM，无法解决RAG系统中响应必须与检索证据一致的特殊挑战，企业应用中需要可靠的无监督检测方案。

Method: 四阶段框架：1)分解答案为原子事实 2)使用同义词/反义词生成受控变异 3)根据检索上下文验证变异(同义词应被蕴含，反义词应被矛盾) 4)聚合不一致性惩罚为响应级幻觉分数

Result: 在企业专有数据集上的实验证明了MetaRAG在检测幻觉方面的有效性，支持RAG对话代理的可信部署。

Conclusion: MetaRAG为RAG系统提供实时、无监督、黑盒的幻觉检测方案，特别适用于身份敏感查询的本地化检测和安全保障配置。

Abstract: Large Language Models (LLMs) are increasingly deployed in enterprise
applications, yet their reliability remains limited by hallucinations, i.e.,
confident but factually incorrect information. Existing detection approaches,
such as SelfCheckGPT and MetaQA, primarily target standalone LLMs and do not
address the unique challenges of Retrieval-Augmented Generation (RAG) systems,
where responses must be consistent with retrieved evidence. We therefore
present MetaRAG, a metamorphic testing framework for hallucination detection in
Retrieval-Augmented Generation (RAG) systems. MetaRAG operates in a real-time,
unsupervised, black-box setting, requiring neither ground-truth references nor
access to model internals, making it suitable for proprietary and high-stakes
domains. The framework proceeds in four stages: (1) decompose answers into
atomic factoids, (2) generate controlled mutations of each factoid using
synonym and antonym substitutions, (3) verify each variant against the
retrieved context (synonyms are expected to be entailed and antonyms
contradicted), and (4) aggregate penalties for inconsistencies into a
response-level hallucination score. Crucially for identity-aware AI, MetaRAG
localizes unsupported claims at the factoid span where they occur (e.g.,
pregnancy-specific precautions, LGBTQ+ refugee rights, or labor eligibility),
allowing users to see flagged spans and enabling system designers to configure
thresholds and guardrails for identity-sensitive queries. Experiments on a
proprietary enterprise dataset illustrate the effectiveness of MetaRAG for
detecting hallucinations and enabling trustworthy deployment of RAG-based
conversational agents. We also outline a topic-based deployment design that
translates MetaRAG's span-level scores into identity-aware safeguards; this
design is discussed but not evaluated in our experiments.

</details>


### [24] [Modelling Analogies and Analogical Reasoning: Connecting Cognitive Science Theory and NLP Research](https://arxiv.org/abs/2509.09381)
*Molly R Petersen,Claire E Stevenson,Lonneke van der Plas*

Main category: cs.CL

TL;DR: 本文从认知科学角度总结类比推理的理论过程，并将其与NLP研究关联，指出认知视角在NLP中的缺失，强调关系理解优于实体相似性的重要性


<details>
  <summary>Details</summary>
Motivation: 将认知科学中类比推理的理论过程与自然语言处理研究联系起来，填补认知视角在NLP中的空白，指导研究者更好地优化文本中的关系理解

Method: 总结认知科学文献中关于类比推理过程的关键理论，分析这些过程与NLP概念的关联，并探讨其对NLP主要挑战的相关性

Result: 发现认知科学的类比推理过程可以轻松与NLP概念关联，但这些关联通常缺乏认知视角；证明了这些概念对NLP研究中多个主要挑战具有相关性

Conclusion: 认知科学的类比推理理论为NLP研究提供了重要指导，有助于研究者减少对实体层面相似性的依赖，转而更注重关系理解，从而更好地解决NLP挑战

Abstract: Analogical reasoning is an essential aspect of human cognition. In this
paper, we summarize key theory about the processes underlying analogical
reasoning from the cognitive science literature and relate it to current
research in natural language processing. While these processes can be easily
linked to concepts in NLP, they are generally not viewed through a cognitive
lens. Furthermore, we show how these notions are relevant for several major
challenges in NLP research, not directly related to analogy solving. This may
guide researchers to better optimize relational understanding in text, as
opposed to relying heavily on entity-level similarity.

</details>


### [25] [Hierarchical Bracketing Encodings Work for Dependency Graphs](https://arxiv.org/abs/2509.09388)
*Ana Ezquerro,Carlos Gómez-Rodríguez,David Vilares*

Main category: cs.CL

TL;DR: 该论文提出了一种实用的层次括号编码方法，用于依赖图解析，将图编码为序列，实现线性时间解析并支持重入、循环和空节点。


<details>
  <summary>Details</summary>
Motivation: 现有的图线性化方法标签空间较大，需要减少标签空间同时保持结构信息，提高依赖图解析的效率和准确性。

Method: 使用层次括号编码将依赖图表示为序列，通过n个标注动作实现线性时间解析，支持重入、循环和空节点等复杂结构。

Result: 在多语言多形式基准测试中表现出竞争力，在精确匹配准确率上相比其他方法有持续改进。

Conclusion: 层次括号编码是一种实用的依赖图解析方法，能有效减少标签空间并保持结构完整性，在多语言场景下具有竞争优势。

Abstract: We revisit hierarchical bracketing encodings from a practical perspective in
the context of dependency graph parsing. The approach encodes graphs as
sequences, enabling linear-time parsing with $n$ tagging actions, and still
representing reentrancies, cycles, and empty nodes. Compared to existing graph
linearizations, this representation substantially reduces the label space while
preserving structural information. We evaluate it on a multilingual and
multi-formalism benchmark, showing competitive results and consistent
improvements over other methods in exact match accuracy.

</details>


### [26] [GrACE: A Generative Approach to Better Confidence Elicitation in Large Language Models](https://arxiv.org/abs/2509.09438)
*Zhaohan Zhang,Ziquan Liu,Ioannis Patras*

Main category: cs.CL

TL;DR: GrACE是一种新的LLM置信度估计方法，通过隐藏状态与特殊标记嵌入的相似性来实时评估模型置信度，无需额外采样或辅助模型，在准确性和校准方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM置信度估计方法要么计算开销大，要么校准效果差，难以在实际高风险应用中可靠部署。

Method: 提出GrACE方法，通过模型最后一个隐藏状态与词汇表中特殊标记嵌入的相似性来实时表达置信度，并通过与准确性相关的校准目标进行微调。

Result: 在三个LLM和两个基准数据集上的实验表明，GrACE在开放生成任务中具有最佳判别能力和校准效果，优于六种竞争方法，并能显著减少测试时缩放所需的样本数量。

Conclusion: GrACE为LLM部署提供了可扩展、可靠且实时的置信度估计实用解决方案，能够提高最终决策准确性并减少计算开销。

Abstract: Assessing the reliability of Large Language Models (LLMs) by confidence
elicitation is a prominent approach to AI safety in high-stakes applications,
such as healthcare and finance. Existing methods either require expensive
computational overhead or suffer from poor calibration, making them impractical
and unreliable for real-world deployment. In this work, we propose GrACE, a
Generative Approach to Confidence Elicitation that enables scalable and
reliable confidence elicitation for LLMs. GrACE adopts a novel mechanism in
which the model expresses confidence by the similarity between the last hidden
state and the embedding of a special token appended to the vocabulary, in
real-time. We fine-tune the model for calibrating the confidence with
calibration targets associated with accuracy. Experiments with three LLMs and
two benchmark datasets show that the confidence produced by GrACE achieves the
best discriminative capacity and calibration on open-ended generation tasks,
outperforming six competing methods without resorting to additional sampling or
an auxiliary model. Moreover, we propose two strategies for improving test-time
scaling based on confidence induced by GrACE. Experimental results show that
using GrACE not only improves the accuracy of the final decision but also
significantly reduces the number of required samples in the test-time scaling
scheme, indicating the potential of GrACE as a practical solution for deploying
LLMs with scalable, reliable, and real-time confidence estimation.

</details>


### [27] [Mitigating Language Barriers in Education: Developing Multilingual Digital Learning Materials with Machine Translation](https://arxiv.org/abs/2509.09473)
*Lucie Poláková,Martin Popel,Věra Kloudová,Michal Novák,Mariia Anisimova,Jiří Balhar*

Main category: cs.CL

TL;DR: EdUKate项目开发捷克-乌克兰机器翻译系统，为捷克学校创建多语言教育材料，将9000个互动练习翻译成乌克兰语、英语和德语。


<details>
  <summary>Details</summary>
Motivation: 满足捷克学校中非捷克语学生的教育需求，通过机器翻译技术提供多语言学习材料，特别关注乌克兰语学生的需求。

Method: 结合数字教育、语言学和机器翻译技术，开发专门的捷克-乌克兰机器翻译系统，处理XML和PDF格式内容，并针对教育领域的科技术语进行优化。

Result: 成功开发了面向教育领域的机器翻译系统，完成了多语言材料的翻译，所有应用免费向学生、教师和研究人员开放。

Conclusion: 该项目展示了机器翻译在教育领域的有效应用，为多语言教育提供了可行解决方案，特别有助于乌克兰语学生的教育融入。

Abstract: The EdUKate project combines digital education, linguistics, translation
studies, and machine translation to develop multilingual learning materials for
Czech primary and secondary schools. Launched through collaboration between a
major Czech academic institution and the country's largest educational
publisher, the project is aimed at translating up to 9,000 multimodal
interactive exercises from Czech into Ukrainian, English, and German for an
educational web portal. It emphasizes the development and evaluation of a
direct Czech-Ukrainian machine translation system tailored to the educational
domain, with special attention to processing formatted content such as XML and
PDF and handling technical and scientific terminology. We present findings from
an initial survey of Czech teachers regarding the needs of non-Czech-speaking
students and describe the system's evaluation and implementation on the web
portal. All resulting applications are freely available to students, educators,
and researchers.

</details>


### [28] [Towards Explainable Job Title Matching: Leveraging Semantic Textual Relatedness and Knowledge Graphs](https://arxiv.org/abs/2509.09522)
*Vadim Zadykian,Bruno Andrade,Haithem Afli*

Main category: cs.CL

TL;DR: 提出了一种结合知识图谱和句子嵌入的自监督混合架构，用于语义文本相关性分析，通过分层评估方法在招聘职位匹配任务中显著提升了高相关性区域的性能。


<details>
  <summary>Details</summary>
Motivation: 解决简历推荐系统中职位匹配的挑战，传统方法依赖词汇重叠但往往有限或误导，需要捕捉超越表面相似性的语义关系。

Method: 自监督混合架构，结合稠密句子嵌入和领域特定知识图谱，使用图神经网络进行集成，并采用分层评估方法将STR分数连续体划分为低、中、高三个区域进行分析。

Result: 经过知识图谱增强的微调SBERT模型在高STR区域表现最佳，RMSE相比强基线降低了25%，在语义对齐和可解释性方面都有显著改善。

Conclusion: 知识图谱与文本嵌入的结合以及分层性能分析方法对于理解模型行为至关重要，这种方法揭示了全局指标隐藏的优势和弱点，支持在人力资源系统中进行更有针对性的模型选择。

Abstract: Semantic Textual Relatedness (STR) captures nuanced relationships between
texts that extend beyond superficial lexical similarity. In this study, we
investigate STR in the context of job title matching - a key challenge in
resume recommendation systems, where overlapping terms are often limited or
misleading. We introduce a self-supervised hybrid architecture that combines
dense sentence embeddings with domain-specific Knowledge Graphs (KGs) to
improve both semantic alignment and explainability. Unlike previous work that
evaluated models on aggregate performance, our approach emphasizes data
stratification by partitioning the STR score continuum into distinct regions:
low, medium, and high semantic relatedness. This stratified evaluation enables
a fine-grained analysis of model performance across semantically meaningful
subspaces. We evaluate several embedding models, both with and without KG
integration via graph neural networks. The results show that fine-tuned SBERT
models augmented with KGs produce consistent improvements in the high-STR
region, where the RMSE is reduced by 25% over strong baselines. Our findings
highlight not only the benefits of combining KGs with text embeddings, but also
the importance of regional performance analysis in understanding model
behavior. This granular approach reveals strengths and weaknesses hidden by
global metrics, and supports more targeted model selection for use in Human
Resources (HR) systems and applications where fairness, explainability, and
contextual matching are essential.

</details>


### [29] [DeMeVa at LeWiDi-2025: Modeling Perspectives with In-Context Learning and Label Distribution Learning](https://arxiv.org/abs/2509.09524)
*Daniil Ignatev,Nan Li,Hugh Mee Wong,Anh Dang,Shane Kaszefski Yaschuk*

Main category: cs.CL

TL;DR: DeMeVa团队在LeWiDi 2025任务中探索了两种方法：基于大语言模型的上下文学习和基于RoBERTa的标签分布学习方法，证明这两种方法都能有效预测观点主义标注


<details>
  <summary>Details</summary>
Motivation: 探索在观点主义标注任务中，如何利用上下文学习和标签分布学习方法来处理标注者之间的分歧，预测软标签

Method: 1) 使用大语言模型进行上下文学习，比较不同示例采样策略；2) 使用RoBERTa进行标签分布学习，评估多种微调方法

Result: 上下文学习能有效预测标注者特定的标注，将这些预测聚合成软标签可获得有竞争力的性能；标签分布学习方法在软标签预测方面表现良好

Conclusion: 上下文学习和标签分布学习方法都是处理观点主义标注任务的有效途径，值得进一步探索

Abstract: This system paper presents the DeMeVa team's approaches to the third edition
of the Learning with Disagreements shared task (LeWiDi 2025; Leonardelli et
al., 2025). We explore two directions: in-context learning (ICL) with large
language models, where we compare example sampling strategies; and label
distribution learning (LDL) methods with RoBERTa (Liu et al., 2019b), where we
evaluate several fine-tuning methods. Our contributions are twofold: (1) we
show that ICL can effectively predict annotator-specific annotations
(perspectivist annotations), and that aggregating these predictions into soft
labels yields competitive performance; and (2) we argue that LDL methods are
promising for soft label predictions and merit further exploration by the
perspectivist community.

</details>


### [30] [Prompting the Market? A Large-Scale Meta-Analysis of GenAI in Finance NLP (2022-2025)](https://arxiv.org/abs/2509.09544)
*Paolo Pedinotti,Peter Baumann,Nathan Jessurun,Leslie Barrett,Enrico Santus*

Main category: cs.CL

TL;DR: MetaGraph是一个从科学文献中提取知识图谱的方法论，用于分析金融NLP研究趋势，揭示了LLM在金融领域的三个发展阶段


<details>
  <summary>Details</summary>
Motivation: LLM快速重塑金融NLP领域，产生了大量数据集和数据源，传统调查方法已无法跟上这种变革速度，需要新的分析工具

Method: 定义金融NLP研究本体论，基于LLM的提取管道处理681篇论文(2022-2025)，构建可查询的知识图谱进行大规模数据分析

Result: 揭示了金融NLP发展的三个阶段：早期LLM采用和任务/数据集创新；对LLM局限性的批判性反思；外围技术向模块化系统的集成

Conclusion: MetaGraph为从业者和研究者提供了对金融NLP演变的清晰理解，展示了可重用的科学进展映射方法，适用于其他领域

Abstract: Large Language Models (LLMs) have rapidly reshaped financial NLP, enabling
new tasks and driving a proliferation of datasets and diversification of data
sources. Yet, this transformation has outpaced traditional surveys. In this
paper, we present MetaGraph, a generalizable methodology for extracting
knowledge graphs from scientific literature and analyzing them to obtain a
structured, queryable view of research trends. We define an ontology for
financial NLP research and apply an LLM-based extraction pipeline to 681 papers
(2022-2025), enabling large-scale, data-driven analysis. MetaGraph reveals
three key phases: early LLM adoption and task/dataset innovation; critical
reflection on LLM limitations; and growing integration of peripheral techniques
into modular systems. This structured view offers both practitioners and
researchers a clear understanding of how financial NLP has evolved -
highlighting emerging trends, shifting priorities, and methodological
shifts-while also demonstrating a reusable approach for mapping scientific
progress in other domains.

</details>


### [31] [Personality-Enhanced Social Recommendations in SAMI: Exploring the Role of Personality Detection in Matchmaking](https://arxiv.org/abs/2509.09583)
*Brittany Harbison,Samuel Taubman,Travis Taylor,Ashok. K. Goel*

Main category: cs.CL

TL;DR: 利用GPT零样本能力从论坛介绍帖推断大五人格特质，集成到SAMI匹配系统中提供人格感知的社交推荐


<details>
  <summary>Details</summary>
Motivation: 在线课程环境阻碍社交群体自然形成，SAMI系统因缺乏完整心智理论而无法有效建模学生个性，影响推荐相关性

Method: 提出基于GPT零样本能力的人格检测模型，从论坛介绍帖推断大五人格特质，并集成到SAMI的实体匹配系统中

Result: 模型在人格检测任务上表现有效，初步集成表明人格特质可以补充现有匹配因素

Conclusion: 人格特质能够增强社交推荐系统，但需要进一步评估其对学生参与度和匹配质量的全面影响

Abstract: Social connection is a vital part of learning, yet online course environments
present barriers to the organic formation of social groups. SAMI offers one
solution by facilitating student connections, but its effectiveness is
constrained by an incomplete Theory of Mind, limiting its ability to create an
effective mental model of a student. One facet of this is its inability to
intuit personality, which may influence the relevance of its recommendations.
To explore this, we propose a personality detection model utilizing GPTs
zero-shot capability to infer Big-Five personality traits from forum
introduction posts, often encouraged in online courses. We benchmark its
performance against established models, demonstrating its efficacy in this
task. Furthermore, we integrate this model into SAMIs entity-based matchmaking
system, enabling personality-informed social recommendations. Initial
integration suggests personality traits can complement existing matching
factors, though additional evaluation is required to determine their full
impact on student engagement and match quality.

</details>


### [32] [Fluent but Unfeeling: The Emotional Blind Spots of Language Models](https://arxiv.org/abs/2509.09593)
*Bangzhao Shu,Isha Joshi,Melissa Karnaze,Anh C. Pham,Ishita Kakkar,Sindhu Kothe,Arpine Hovasapian,Mai ElSherief*

Main category: cs.CL

TL;DR: EXPRESS基准数据集评估LLM在细粒度情感识别方面与人类自我披露情感的对齐能力，发现现有模型在准确预测与人类情感一致方面仍存在挑战


<details>
  <summary>Details</summary>
Motivation: 现有研究主要将情感分类为预定义的有限类别，忽略了更细微的情感表达，需要评估LLM是否能在细粒度层面与人类情感对齐

Method: 引入EXPRESS基准数据集（包含251个细粒度情感标签），通过综合评估框架分析预测情感术语并将其分解为八种基本情感，系统测试主流LLM在不同提示设置下的表现

Result: 准确预测与人类自我披露情感一致的情感仍然具有挑战性；某些LLM能生成符合情感理论和定义的情感术语，但在捕捉上下文线索方面不如人类自我披露有效

Conclusion: LLM在细粒度情感对齐方面存在局限性，未来研究需要增强其上下文理解能力

Abstract: The versatility of Large Language Models (LLMs) in natural language
understanding has made them increasingly popular in mental health research.
While many studies explore LLMs' capabilities in emotion recognition, a
critical gap remains in evaluating whether LLMs align with human emotions at a
fine-grained level. Existing research typically focuses on classifying emotions
into predefined, limited categories, overlooking more nuanced expressions. To
address this gap, we introduce EXPRESS, a benchmark dataset curated from Reddit
communities featuring 251 fine-grained, self-disclosed emotion labels. Our
comprehensive evaluation framework examines predicted emotion terms and
decomposes them into eight basic emotions using established emotion theories,
enabling a fine-grained comparison. Systematic testing of prevalent LLMs under
various prompt settings reveals that accurately predicting emotions that align
with human self-disclosed emotions remains challenging. Qualitative analysis
further shows that while certain LLMs generate emotion terms consistent with
established emotion theories and definitions, they sometimes fail to capture
contextual cues as effectively as human self-disclosures. These findings
highlight the limitations of LLMs in fine-grained emotion alignment and offer
insights for future research aimed at enhancing their contextual understanding.

</details>


### [33] [LAVA: Language Model Assisted Verbal Autopsy for Cause-of-Death Determination](https://arxiv.org/abs/2509.09602)
*Yiqun T. Chen,Tyler H. McCormick,Li Liu,Abhirup Datta*

Main category: cs.CL

TL;DR: LA-VA目标是通过结合大语言模型（LLMs）与传统算法方法来提高质量缺乏地区的语言查尻（VA）决策准确性，以优化全球健康监测。


<details>
  <summary>Details</summary>
Motivation: 语言查尻（VA）在资源有限地区对估计死因至关重要，但传统算法方法的准确性有限。研究者尝试利用大语言模型的强大能力来提升这一过程的效果。

Method: 研究构建了LA-VA流水线，结合了GPT-5模型预测、LCVA基准、文本嵌入分类以及元学习集成等多种方法。使用PHMRC数据集，涉及三个年龄段：成人（7,580例）、儿童（1,960例）和新生儿（2,438例）。

Result: GPT-5在三个年龄组中都表现最佳，平均测试站点准确率分别为48.6%（成人）、50.5%（儿童）和53.5%（新生儿），较传统统计机器学习基准提高5-10%。

Conclusion: 简单的商用大语言模型辅助方法可显著提高语言查尻的准确性，对低资源设置中的全球健康监测具有重要意义。

Abstract: Verbal autopsy (VA) is a critical tool for estimating causes of death in
resource-limited settings where medical certification is unavailable. This
study presents LA-VA, a proof-of-concept pipeline that combines Large Language
Models (LLMs) with traditional algorithmic approaches and embedding-based
classification for improved cause-of-death prediction. Using the Population
Health Metrics Research Consortium (PHMRC) dataset across three age categories
(Adult: 7,580; Child: 1,960; Neonate: 2,438), we evaluate multiple approaches:
GPT-5 predictions, LCVA baseline, text embeddings, and meta-learner ensembles.
Our results demonstrate that GPT-5 achieves the highest individual performance
with average test site accuracies of 48.6% (Adult), 50.5% (Child), and 53.5%
(Neonate), outperforming traditional statistical machine learning baselines by
5-10%. Our findings suggest that simple off-the-shelf LLM-assisted approaches
could substantially improve verbal autopsy accuracy, with important
implications for global health surveillance in low-resource settings.

</details>


### [34] [Bridging the Capability Gap: Joint Alignment Tuning for Harmonizing LLM-based Multi-Agent Systems](https://arxiv.org/abs/2509.09629)
*Minghang Zhu,Zhengliang Shi,Zhiwei Xu,Shiguang Wu,Lingjie Wang,Pengjie Ren,Zhaochun Ren,Zhumin Chen*

Main category: cs.CL

TL;DR: MOAT是一个多智能体联合对齐调优框架，通过迭代对齐提升智能体协作能力，在多个基准测试中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有方法通常独立微调多智能体系统中的各个智能体，导致能力差距和协调性差的问题

Method: MOAT框架包含两个交替阶段：规划智能体对齐（优化子目标生成）和接地智能体改进（使用自生成数据增强泛化能力）

Result: 在六个基准测试中平均提升3.1%（held-in任务）和4.4%（held-out任务），理论分析证明训练过程非递减且渐进收敛

Conclusion: MOAT通过联合对齐调优有效解决了多智能体系统协调问题，显著提升了任务性能

Abstract: The advancement of large language models (LLMs) has enabled the construction
of multi-agent systems to solve complex tasks by dividing responsibilities
among specialized agents, such as a planning agent for subgoal generation and a
grounding agent for executing tool-use actions. Most existing methods typically
fine-tune these agents independently, leading to capability gaps among them
with poor coordination. To address this, we propose MOAT, a Multi-Agent Joint
Alignment Tuning framework that improves agents collaboration through iterative
alignment. MOAT alternates between two key stages: (1) Planning Agent
Alignment, which optimizes the planning agent to generate subgoal sequences
that better guide the grounding agent; and (2) Grounding Agent Improving, which
fine-tunes the grounding agent using diverse subgoal-action pairs generated by
the agent itself to enhance its generalization capablity. Theoretical analysis
proves that MOAT ensures a non-decreasing and progressively convergent training
process. Experiments across six benchmarks demonstrate that MOAT outperforms
state-of-the-art baselines, achieving average improvements of 3.1% on held-in
tasks and 4.4% on held-out tasks.

</details>


### [35] [All for One: LLMs Solve Mental Math at the Last Token With Information Transferred From Other Tokens](https://arxiv.org/abs/2509.09650)
*Siddarth Mamidanna,Daking Rai,Ziyu Yao,Yilun Zhou*

Main category: cs.CL

TL;DR: 该论文通过Context-Aware Mean Ablation (CAMA)和Attention-Based Peeking (ABP)技术，在大语言模型的心算任务中发现了一个All-for-One子图(AF1)，该子图在深层且仅在最后一个token处进行计算，通过特定中间层接收其他token信息，对模型性能至关重要且可跨模型迁移。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在计算任务上表现出色，但其内部工作机制仍不明确。研究旨在探索模型在实际心算任务中如何通过自注意力和MLP层进行信息处理和计算。

Method: 采用三步骤方法：抑制初始层的输入特定token计算、限制中间层跨token位置的信息传递路径、强制剩余层在最后一个token处进行计算。提出CAMA和ABP两种技术来识别关键的All-for-One子图。

Result: 实验发现AF1子图在各种心算任务中具有高准确性，计算发生在深层且仅最后一个token处，通过特定中间层接收信息。该子图对模型性能既充分又必要，可跨模型迁移，适用于多种输入风格。

Conclusion: 研究揭示了LLMs在心算任务中的特定计算模式，AF1子图的发现有助于理解模型内部工作机制，CAMA和ABP技术的优势也为相关研究提供了新方法。

Abstract: Large language models (LLMs) demonstrate proficiency across numerous
computational tasks, yet their inner workings remain unclear. In theory, the
combination of causal self-attention and multilayer perceptron layers allows
every token to access and compute information based on all preceding tokens. In
practice, to what extent are such operations present? In this paper, on mental
math tasks (i.e., direct math calculation via next-token prediction without
explicit reasoning), we investigate this question in three steps: inhibiting
input-specific token computations in the initial layers, restricting the routes
of information transfer across token positions in the next few layers, and
forcing all computation to happen at the last token in the remaining layers.
With two proposed techniques, Context-Aware Mean Ablation (CAMA) and
Attention-Based Peeking (ABP), we identify an All-for-One subgraph (AF1) with
high accuracy on a wide variety of mental math tasks, where meaningful
computation occurs very late (in terms of layer depth) and only at the last
token, which receives information of other tokens in few specific middle
layers. Experiments on a variety of models and arithmetic expressions show that
this subgraph is sufficient and necessary for high model performance, transfers
across different models, and works on a variety of input styles. Ablations on
different CAMA and ABP alternatives reveal their unique advantages over other
methods, which may be of independent interest.

</details>


### [36] [Steering MoE LLMs via Expert (De)Activation](https://arxiv.org/abs/2509.09660)
*Mohsen Fayyaz,Ali Modarressi,Hanieh Deilamsalehy,Franck Dernoncourt,Ryan Rossi,Trung Bui,Hinrich Schütze,Nanyun Peng*

Main category: cs.CL

TL;DR: SteerMoE框架通过检测和控制MoE模型中的行为相关专家，无需重新训练即可调控LLM的忠实性和安全性行为，既能提升安全性+20%和忠实性+27%，也能在对抗模式下完全绕过安全防护


<details>
  <summary>Details</summary>
Motivation: 现有MoE模型中的专家网络可能包含特定行为模式，但缺乏对这些专家进行检测和控制的方法，无法在不重新训练的情况下调控模型行为

Method: 通过对比分析不同行为输入的专家激活模式来检测行为相关专家，在推理时选择性激活或停用这些专家来控制模型行为

Result: 在11个基准测试和6个LLM上，安全性提升最高+20%，忠实性提升+27%；对抗模式下安全性下降-41%，结合越狱方法可完全绕过所有安全防护(-100%)

Conclusion: MoE模型中存在隐藏的对齐伪造维度，专家网络包含可被操控的行为模式，这暴露了新的安全风险

Abstract: Mixture-of-Experts (MoE) in Large Language Models (LLMs) routes each token
through a subset of specialized Feed-Forward Networks (FFN), known as experts.
We present SteerMoE, a framework for steering MoE models by detecting and
controlling behavior-linked experts. Our detection method identifies experts
with distinct activation patterns across paired inputs exhibiting contrasting
behaviors. By selectively (de)activating such experts during inference, we
control behaviors like faithfulness and safety without retraining or modifying
weights. Across 11 benchmarks and 6 LLMs, our steering raises safety by up to
+20% and faithfulness by +27%. In adversarial attack mode, it drops safety by
-41% alone, and -100% when combined with existing jailbreak methods, bypassing
all safety guardrails and exposing a new dimension of alignment faking hidden
within experts.

</details>


### [37] [CDE: Curiosity-Driven Exploration for Efficient Reinforcement Learning in Large Language Models](https://arxiv.org/abs/2509.09675)
*Runpeng Dai,Linfeng Song,Haolin Liu,Zhenwen Liang,Dian Yu,Haitao Mi,Zhaopeng Tu,Rui Liu,Tong Zheng,Hongtu Zhu,Dong Yu*

Main category: cs.CL

TL;DR: 提出好奇心驱动探索(CDE)框架，通过演员困惑度和评论家价值估计方差作为内在奖励，解决RLVR方法探索不足和熵崩溃问题，在AIME基准上比标准RLVR提升约3分


<details>
  <summary>Details</summary>
Motivation: 当前RLVR方法存在探索不足、过早收敛和熵崩溃的问题，需要更好的探索机制来提升大语言模型的推理能力

Method: 使用演员困惑度(对生成响应的困惑度)和评论家价值估计方差(多头架构)作为好奇心信号，作为RLVR框架中的探索奖励

Result: 在AIME基准上相比标准RLVR(GRPO/PPO)获得约3分的提升，并识别出RLVR中的校准崩溃机制

Conclusion: CDE框架通过内在好奇心信号有效提升探索能力，理论分析显示该方法惩罚过度自信错误并促进正确响应的多样性

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful paradigm
for enhancing the reasoning ability of Large Language Models (LLMs). Yet
current RLVR methods often explore poorly, leading to premature convergence and
entropy collapse. To address this challenge, we introduce Curiosity-Driven
Exploration (CDE), a framework that leverages the model's own intrinsic sense
of curiosity to guide exploration. We formalize curiosity with signals from
both the actor and the critic: for the actor, we use perplexity over its
generated response, and for the critic, we use the variance of value estimates
from a multi-head architecture. Both signals serve as an exploration bonus
within the RLVR framework to guide the model. Our theoretical analysis shows
that the actor-wise bonus inherently penalizes overconfident errors and
promotes diversity among correct responses; moreover, we connect the
critic-wise bonus to the well-established count-based exploration bonus in RL.
Empirically, our method achieves an approximate +3 point improvement over
standard RLVR using GRPO/PPO on AIME benchmarks. Further analysis identifies a
calibration collapse mechanism within RLVR, shedding light on common LLM
failure modes.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [38] [In situ estimation of the acoustic surface impedance using simulation-based inference](https://arxiv.org/abs/2509.08873)
*Jonas M. Schmid,Johannes D. Schmid,Martin Eser,Steffen Marburg*

Main category: cs.SD

TL;DR: 提出基于贝叶斯框架和神经网络的方法，从稀疏声压测量中准确估计频率相关的声学表面阻抗，克服传统测量方法的局限性


<details>
  <summary>Details</summary>
Motivation: 传统声学边界条件测量方法依赖于对声场和安装条件的简化假设，限制了其在真实场景中的有效性，需要更精确的现场阻抗估计方法

Method: 采用贝叶斯框架和基于模拟推理的方法，利用神经网络架构直接将模拟数据映射到模型参数的后验分布，使用带分数阶微积分项的阻尼振荡器模型建模阻抗行为

Result: 在长方体房间有限元模型上验证，通过阻抗管测量作为参考，成功估计所有六个独立阻抗，在数值汽车座舱模型中展示可靠的uncertainty量化和高预测精度

Conclusion: 该方法具有良好校准的推理能力，为真实室内环境中的声学边界条件提供了可推广、高效且物理一致的表征方法

Abstract: Accurate acoustic simulations of enclosed spaces require precise boundary
conditions, typically expressed through surface impedances for wave-based
methods. Conventional measurement techniques often rely on simplifying
assumptions about the sound field and mounting conditions, limiting their
validity for real-world scenarios. To overcome these limitations, this study
introduces a Bayesian framework for the in situ estimation of
frequency-dependent acoustic surface impedances from sparse interior sound
pressure measurements. The approach employs simulation-based inference, which
leverages the expressiveness of modern neural network architectures to directly
map simulated data to posterior distributions of model parameters, bypassing
conventional sampling-based Bayesian approaches and offering advantages for
high-dimensional inference problems. Impedance behavior is modeled using a
damped oscillator model extended with a fractional calculus term. The framework
is verified on a finite element model of a cuboid room and further tested with
impedance tube measurements used as reference, achieving robust and accurate
estimation of all six individual impedances. Application to a numerical car
cabin model further demonstrates reliable uncertainty quantification and high
predictive accuracy even for complex-shaped geometries. Posterior predictive
checks and coverage diagnostics confirm well-calibrated inference, highlighting
the method's potential for generalizable, efficient, and physically consistent
characterization of acoustic boundary conditions in real-world interior
environments.

</details>


### [39] [MoLEx: Mixture of LoRA Experts in Speech Self-Supervised Models for Audio Deepfake Detection](https://arxiv.org/abs/2509.09175)
*Zihan Pan,Sailor Hardik Bhupendra,Jinyang Wu*

Main category: cs.SD

TL;DR: 提出MoLEx框架，结合LoRA和混合专家路由，实现参数高效的音频深度伪造检测，在ASVSpoof 5数据集上达到5.56%的SOTA EER


<details>
  <summary>Details</summary>
Motivation: 解决自监督学习模型完全微调计算成本高的问题，同时保持预训练知识并降低训练成本

Method: 结合低秩适应(LoRA)和混合专家路由，只微调选定的专家模块，保持预训练模型参数不变

Result: 在ASVSpoof 5评估集上达到5.56%的等错误率(EER)，无需数据增强即可实现最先进性能

Conclusion: MoLEx框架具有参数高效、领域感知适应性强、支持灵活扩展等优势，为音频深度伪造检测提供了有效的解决方案

Abstract: While self-supervised learning (SSL)-based models have boosted audio deepfake
detection accuracy, fully finetuning them is computationally expensive. To
address this, we propose a parameter-efficient framework that combines Low-Rank
Adaptation with a Mixture-of-Experts router, called Mixture of LoRA Experts
(MoLEx). It preserves pre-trained knowledge of SSL models while efficiently
finetuning only selected experts, reducing training costs while maintaining
robust performance. The observed utility of experts during inference shows the
router reactivates the same experts for similar attacks but switches to other
experts for novel spoofs, confirming MoLEx's domain-aware adaptability. MoLEx
additionally offers flexibility for domain adaptation by allowing extra experts
to be trained without modifying the entire model. We mainly evaluate our
approach on the ASVSpoof 5 dataset and achieve the state-of-the-art (SOTA)
equal error rate (EER) of 5.56% on the evaluation set without augmentation.

</details>


### [40] [DeCodec: Rethinking Audio Codecs as Universal Disentangled Representation Learners](https://arxiv.org/abs/2509.09201)
*Xiaoxue Luo,Jinwei Huang,Runyan Yang,Yingying Gao,Junlan Feng,Chao Deng,Shilei Zhang*

Main category: cs.SD

TL;DR: DeCodec是一个新颖的神经编解码器，通过学习将音频表示解耦到正交子空间，分别处理语音和背景声音，并在语音内部进一步分解为语义和副语言成分，实现可控的特征选择。


<details>
  <summary>Details</summary>
Motivation: 现实世界音频通常包含混合的语音和背景声音，而下游任务需要选择性访问这些组件。现有通用音频编解码器学习纠缠表示，特定编解码器虽然提供解耦表示但仅限于语音。

Method: 基于编解码器框架，引入两个关键创新：子空间正交投影模块将输入分解为两个解耦的正交子空间；表示交换训练程序确保这两个子空间分别与语音和背景声音相关。使用并行RVQ独立量化语音和背景声音组件，并对语音RVQ应用语义指导实现语义和副语言分解。

Result: DeCodec在保持先进信号重建的同时实现了新功能：通过表示重组在噪声语音上实现优异的语音增强和有效的一次性语音转换；通过干净的语义特征提高ASR鲁棒性；在TTS中实现可控的背景声音保留/抑制。

Conclusion: DeCodec作为一个通用的解耦表示学习器，通过层次化解耦实现了灵活的特征选择，使其成为多个音频应用的通用前端。

Abstract: Universal audio codecs learn entangled representations across audio types,
whereas some specific codecs offer decoupled representations but are limited to
speech. Real-world audio, however, often contains mixed speech and background
sounds, and downstream tasks require selective access to these components.
Therefore, we rethink the audio codec as a universal disentangled
representation learner to enable controllable feature selection across
different audio tasks. To this end, we introduce DeCodec, a novel neural codec
that learns to decouple audio representations into orthogonal subspaces
dedicated to speech and background sound, and within speech, representations
are further decomposed into semantic and paralinguistic components. This
hierarchical disentanglement allows flexible feature selection, making DeCodec
a universal front-end for multiple audio applications. Technically, built upon
a codec framework, DeCodec incorporates two key innovations: a subspace
orthogonal projection module that factorizes the input into two decoupled
orthogonal subspaces, and a representation swap training procedure that ensures
these two subspaces are correlate to the speech and background sound,
respectively. These allows parallel RVQs to quantize speech and background
sound components independently. Furthermore, we employ semantic guidance to the
speech RVQ to achieve semantic and paralinguistic decomposition. Experimental
results show that DeCodec maintains advanced signal reconstruction while
enabling new capabilities: superior speech enhancement and effective one-shot
voice conversion on noisy speech via representation recombination, improved ASR
robustness through clean semantic features, and controllable background sound
preservation/suppression in TTS. Demo Page: https://luo404.github.io/DeCodecV2/

</details>


### [41] [Bona fide Cross Testing Reveals Weak Spot in Audio Deepfake Detection Systems](https://arxiv.org/abs/2509.09204)
*Chin Yuen Kwok,Jia Qi Yip,Zhen Qiu,Chi Hung Chi,Kwok Yan Lam*

Main category: cs.SD

TL;DR: 提出了一种新的音频深度伪造检测评估框架——真实语音交叉测试，通过整合多样化的真实语音数据集和聚合EER来提供更平衡的评估，解决了传统方法中合成器样本不平衡和真实语音多样性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统音频深度伪造检测评估方法存在两个主要问题：1）使用单一EER指标会因合成器样本数量不平衡而降低评估可靠性；2）大多数数据集缺乏真实语音的多样性，通常只包含单一环境和语音风格，无法模拟真实世界条件。

Method: 提出了真实语音交叉测试框架，整合了多样化的真实语音数据集，采用聚合EER的方式进行更平衡的评估。该方法在9种不同类型的真实语音上对超过150个合成器进行了基准测试。

Result: 开发并发布了一个新的数据集，提供了更全面的评估基准。相比传统评估方法，该方法提高了鲁棒性和可解释性。

Conclusion: 真实语音交叉测试框架为音频深度伪造检测提供了更可靠、更全面的评估方法，有助于推动该领域的进一步发展研究。

Abstract: Audio deepfake detection (ADD) models are commonly evaluated using datasets
that combine multiple synthesizers, with performance reported as a single Equal
Error Rate (EER). However, this approach disproportionately weights
synthesizers with more samples, underrepresenting others and reducing the
overall reliability of EER. Additionally, most ADD datasets lack diversity in
bona fide speech, often featuring a single environment and speech style (e.g.,
clean read speech), limiting their ability to simulate real-world conditions.
To address these challenges, we propose bona fide cross-testing, a novel
evaluation framework that incorporates diverse bona fide datasets and
aggregates EERs for more balanced assessments. Our approach improves robustness
and interpretability compared to traditional evaluation methods. We benchmark
over 150 synthesizers across nine bona fide speech types and release a new
dataset to facilitate further research at
https://github.com/cyaaronk/audio_deepfake_eval.

</details>


### [42] [Adaptive Knowledge Distillation using a Device-Aware Teacher for Low-Complexity Acoustic Scene Classification](https://arxiv.org/abs/2509.09262)
*Seung Gyu Jeong,Seong Eun Kim*

Main category: cs.SD

TL;DR: 基于知识蒸馏的轻量级音频场景分类系统，使用双教师集成（标准教师+设备鲁棒专家）训练学生网络，并通过设备特定微调提升性能，在DCASE 2025挑战赛中取得57.93%的准确率


<details>
  <summary>Details</summary>
Motivation: 解决低复杂度设备鲁棒音频场景分类的双重挑战：严格的计算复杂度约束和对已知/未知设备的鲁棒泛化能力，同时利用测试时设备标签的新规则

Method: 提出知识蒸馏框架：高效CP-MobileNet学生网络从紧凑的双教师集成学习（标准PaSST教师+设备感知特征对齐专家），最后进行设备特定微调

Result: 在开发集上达到57.93%的最终准确率，相比官方基线有显著提升，特别是在未知设备上表现优异

Conclusion: 所提出的知识蒸馏结合设备感知特征对齐和设备特定微调的方法，有效解决了低复杂度设备鲁棒音频场景分类问题，在DCASE挑战中表现出色

Abstract: In this technical report, we describe our submission for Task 1,
Low-Complexity Device-Robust Acoustic Scene Classification, of the DCASE 2025
Challenge. Our work tackles the dual challenges of strict complexity
constraints and robust generalization to both seen and unseen devices, while
also leveraging the new rule allowing the use of device labels at test time.
Our proposed system is based on a knowledge distillation framework where an
efficient CP-MobileNet student learns from a compact, specialized two-teacher
ensemble. This ensemble combines a baseline PaSST teacher, trained with
standard cross-entropy, and a 'generalization expert' teacher. This expert is
trained using our novel Device-Aware Feature Alignment (DAFA) loss, adapted
from prior work, which explicitly structures the feature space for device
robustness. To capitalize on the availability of test-time device labels, the
distilled student model then undergoes a final device-specific fine-tuning
stage. Our proposed system achieves a final accuracy of 57.93\% on the
development set, demonstrating a significant improvement over the official
baseline, particularly on unseen devices.

</details>


### [43] [Efficient Transformer-Based Piano Transcription With Sparse Attention Mechanisms](https://arxiv.org/abs/2509.09318)
*Weixing Wei,Kazuyoshi Yoshii*

Main category: cs.SD

TL;DR: 通过稀疏注意力机制改进Transformer模型，在保持钢琴转译性能的同时大幅降低计算成本和内存占用，支持更长音频上下文处理。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型在钢琴转译中表现优异，但自注意力机制的平方复杂度导致无法处理整个音乐作品，通常需要滑动窗口方式处理，影响效果。

Method: 提出了一种高效稀疏注意力机制：编码器和解码器都采用滑动窗口自注意力，以及混合全局-局部交叉注意力机制，根据MIDI标签类型关注不同范围。还使用了层次池化策略来进一步降低计算负担。

Result: 在MAESTRO数据集上实验显示，该模型在保持与全注意力基线相似转译性能的同时，实现了计算成本和内存使用的显著降低，加快了推理速度。

Conclusion: 稀疏注意力机制可以建立高效且高性能的钢琴转译系统，允许在同样硬件上训练更长音频上下文，具有实际应用价值。

Abstract: This paper investigates automatic piano transcription based on
computationally-efficient yet high-performant variants of the Transformer that
can capture longer-term dependency over the whole musical piece. Recently,
transformer-based sequence-to-sequence models have demonstrated excellent
performance in piano transcription. These models, however, fail to deal with
the whole piece at once due to the quadratic complexity of the self-attention
mechanism, and music signals are thus typically processed in a sliding-window
manner in practice. To overcome this limitation, we propose an efficient
architecture with sparse attention mechanisms. Specifically, we introduce
sliding-window self-attention mechanisms for both the encoder and decoder, and
a hybrid global-local cross-attention mechanism that attends to various spans
according to the MIDI token types. We also use a hierarchical pooling strategy
between the encoder and decoder to further reduce computational load. Our
experiments on the MAESTRO dataset showed that the proposed model achieved a
significant reduction in computational cost and memory usage, accelerating
inference speed, while maintaining transcription performance comparable to the
full-attention baseline. This allows for training with longer audio contexts on
the same hardware, demonstrating the viability of sparse attention for building
efficient and high-performance piano transcription systems. The code is
available at https://github.com/WX-Wei/efficient-seq2seq-piano-trans.

</details>


### [44] [Finite Scalar Quantization Enables Redundant and Transmission-Robust Neural Audio Compression at Low Bit-rates](https://arxiv.org/abs/2509.09550)
*Harry Julia,Rachel Beeson,Lohith Konathala,Johanna Ulin,Jiameng Gao*

Main category: cs.SD

TL;DR: NeuCodec是基于FSQ的神经音频编解码器，相比传统RVQ方法具有更好的抗噪性能和编码冗余特性，能在噪声信道中保持更好的音频重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有的神经音频编解码器大多基于RVQ，而FSQ作为新兴的量化方法具有训练简单和单码本支持的优势，但需要验证其在音频编码中的实际性能，特别是在噪声环境下的鲁棒性。

Method: 提出基于FSQ的NeuCodec编解码器，通过编码器蒸馏实验验证不同编码器能产生不同但等价的编码序列，并比较FSQ和RVQ在模拟噪声信道传输时的比特级扰动鲁棒性。

Result: FSQ编码具有内置冗余特性，两个不同编码器能学习到完全不同的编码序列但保持相同的重建质量；FSQ在噪声信道中的比特级扰动鲁棒性显著优于RVQ。

Conclusion: FSQ是RVQ的有力替代方案，NeuCodec展示了FSQ在音频编码中的优越性，特别是在噪声信道传输场景下具有更好的鲁棒性表现。

Abstract: Neural Audio Codecs (NACs) have become increasingly adopted in speech
processing tasks due to their excellent rate-distortion performance and
compatibility with Large Language Models (LLMs) as discrete feature
representations for audio generation. While most existing codecs rely on
Residual Vector Quantization (RVQ), Finite Scalar Quantization (FSQ) has
recently emerged as a compelling alternative that simplifies training and
natively supports single codebooks. We introduce NeuCodec, an FSQ-based NAC,
and show that FSQ encodes baked-in redundancy which produces an encoding which
is robust when transmitted through noisy channels. First, through an encoder
distillation experiment, we show that two different encoders can learn to
encode identical audio into vastly different code sequences whilst maintaining
comparable reconstruction quality with the same quantizer and decoder. Second,
we demonstrate that FSQ has vastly superior bit-level perturbation robustness
by comparing the performance of RVQ and FSQ codecs when simulating the
transmission of code sequences through a noisy channel.

</details>


### [45] [DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for Low-Latency Zero-Shot Text-To-Speech](https://arxiv.org/abs/2509.09631)
*Ngoc-Son Nguyen,Hieu-Nghia Huynh-Nguyen,Thanh V. T. Tran,Truong-Son Hy,Van Nguyen*

Main category: cs.SD

TL;DR: DiFlow-TTS是首个探索纯离散流匹配的语音合成模型，通过显式建模分解的语音属性，在零样本设置下实现高质量语音合成，推理速度比现有基线快25.8倍


<details>
  <summary>Details</summary>
Motivation: 解决现有零样本TTS方法推理速度慢、存在重复伪影的问题，充分利用离散表示的优势，避免将离散token嵌入连续空间的做法

Method: 采用纯离散流匹配方法，通过上下文学习机制，基于文本内容和参考语音提取的韵律、声学属性进行条件生成，使用分解的流预测机制分别处理韵律和声学细节

Result: 在自然度、韵律、说话人风格保持和能量控制等关键指标上表现优异，模型紧凑且实现低延迟推理，生成速度比最新基线快25.8倍

Conclusion: DiFlow-TTS证明了纯离散流匹配在语音合成中的有效性，为高效高质量的零样本TTS提供了新的解决方案

Abstract: Zero-shot Text-to-Speech (TTS) aims to synthesize high-quality speech that
mimics the voice of an unseen speaker using only a short reference sample,
requiring not only speaker adaptation but also accurate modeling of prosodic
attributes. Recent approaches based on language models, diffusion, and flow
matching have shown promising results in zero-shot TTS, but still suffer from
slow inference and repetition artifacts. Discrete codec representations have
been widely adopted for speech synthesis, and recent works have begun to
explore diffusion models in purely discrete settings, suggesting the potential
of discrete generative modeling for speech synthesis. However, existing
flow-matching methods typically embed these discrete tokens into a continuous
space and apply continuous flow matching, which may not fully leverage the
advantages of discrete representations. To address these challenges, we
introduce DiFlow-TTS, which, to the best of our knowledge, is the first model
to explore purely Discrete Flow Matching for speech synthesis. DiFlow-TTS
explicitly models factorized speech attributes within a compact and unified
architecture. It leverages in-context learning by conditioning on textual
content, along with prosodic and acoustic attributes extracted from a reference
speech, enabling effective attribute cloning in a zero-shot setting. In
addition, the model employs a factorized flow prediction mechanism with
distinct heads for prosody and acoustic details, allowing it to learn
aspect-specific distributions. Experimental results demonstrate that DiFlow-TTS
achieves promising performance in several key metrics, including naturalness,
prosody, preservation of speaker style, and energy control. It also maintains a
compact model size and achieves low-latency inference, generating speech up to
25.8 times faster than the latest existing baselines.

</details>
