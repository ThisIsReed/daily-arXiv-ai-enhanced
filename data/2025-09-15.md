<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 52]
- [cs.SD](#cs.SD) [Total: 10]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MultimodalHugs: Enabling Sign Language Processing in Hugging Face](https://arxiv.org/abs/2509.09729)
*Gerard Sant,Zifan Jiang,Carlos Escolano,Amit Moryossef,Mathias Müller,Rico Sennrich,Sarah Ebling*

Main category: cs.CL

TL;DR: MultimodalHugs是一个基于Hugging Face构建的框架，旨在解决手语处理研究中存在的代码复杂、可复现性低和比较不公平等问题，支持更多样化的数据模态和任务。


<details>
  <summary>Details</summary>
Motivation: 手语处理研究相比口语语言研究面临更多挑战，包括复杂的临时代码、低可复现性和不公平比较。现有工具如Hugging Face在手语实验集成方面不够灵活，无法满足研究需求。

Method: 在Hugging Face基础上构建MultimodalHugs框架，增加抽象层以支持更多数据模态和任务，特别是针对手语处理的姿态估计数据和文本字符的像素数据等多样化模态。

Result: 通过定量实验证明MultimodalHugs能够有效适应手语姿态估计数据和文本字符像素数据等多种模态，提高了实验的可复现性和公平性。

Conclusion: MultimodalHugs框架成功解决了手语处理研究中的技术障碍，不仅适用于手语研究，还可广泛应用于其他不符合Hugging Face标准模板的用例，促进了多模态研究的可复现性和公平比较。

Abstract: In recent years, sign language processing (SLP) has gained importance in the
general field of Natural Language Processing. However, compared to research on
spoken languages, SLP research is hindered by complex ad-hoc code,
inadvertently leading to low reproducibility and unfair comparisons. Existing
tools that are built for fast and reproducible experimentation, such as Hugging
Face, are not flexible enough to seamlessly integrate sign language
experiments. This view is confirmed by a survey we conducted among SLP
researchers.
  To address these challenges, we introduce MultimodalHugs, a framework built
on top of Hugging Face that enables more diverse data modalities and tasks,
while inheriting the well-known advantages of the Hugging Face ecosystem. Even
though sign languages are our primary focus, MultimodalHugs adds a layer of
abstraction that makes it more widely applicable to other use cases that do not
fit one of the standard templates of Hugging Face. We provide quantitative
experiments to illustrate how MultimodalHugs can accommodate diverse modalities
such as pose estimation data for sign languages, or pixel data for text
characters.

</details>


### [2] [Structured Information Matters: Explainable ICD Coding with Patient-Level Knowledge Graphs](https://arxiv.org/abs/2509.09699)
*Mingyang Li,Viktor Schlegel,Tingting Mu,Warren Del-Pinto,Goran Nenadic*

Main category: cs.CL

TL;DR: 该论文提出使用知识图谱(KG)结构化表示临床文档，用于自动化ICD编码任务，在保持90%信息的同时减少23%文本量，在PLM-ICD架构上实现Macro-F1分数提升3.20%


<details>
  <summary>Details</summary>
Motivation: 临床文档标准化编码是重要但耗时的任务，现有方法主要利用外部知识增强输出表示，但对输入文档的外部知识表示利用不足

Method: 构建文档级知识图谱来结构化表示患者状况，将KG集成到最先进的PLM-ICD编码架构中

Result: 知识图谱用23%的原始文本保留了90%的信息，在ICD-9编码任务上Macro-F1分数提升达3.20%，同时提高了训练效率

Conclusion: 基于知识图谱的结构化文档表示能有效提升自动化临床编码性能，并提供了比纯文本基线更好的可解释性

Abstract: Mapping clinical documents to standardised clinical vocabularies is an
important task, as it provides structured data for information retrieval and
analysis, which is essential to clinical research, hospital administration and
improving patient care. However, manual coding is both difficult and
time-consuming, making it impractical at scale. Automated coding can
potentially alleviate this burden, improving the availability and accuracy of
structured clinical data. The task is difficult to automate, as it requires
mapping to high-dimensional and long-tailed target spaces, such as the
International Classification of Diseases (ICD). While external knowledge
sources have been readily utilised to enhance output code representation, the
use of external resources for representing the input documents has been
underexplored. In this work, we compute a structured representation of the
input documents, making use of document-level knowledge graphs (KGs) that
provide a comprehensive structured view of a patient's condition. The resulting
knowledge graph efficiently represents the patient-centred input documents with
23\% of the original text while retaining 90\% of the information. We assess
the effectiveness of this graph for automated ICD-9 coding by integrating it
into the state-of-the-art ICD coding architecture PLM-ICD. Our experiments
yield improved Macro-F1 scores by up to 3.20\% on popular benchmarks, while
improving training efficiency. We attribute this improvement to different types
of entities and relationships in the KG, and demonstrate the improved
explainability potential of the approach over the text-only baseline.

</details>


### [3] [Cross-Layer Attention Probing for Fine-Grained Hallucination Detection](https://arxiv.org/abs/2509.09700)
*Malavika Suresh,Rahaf Aljundi,Ikechukwu Nkisi-Orji,Nirmalie Wiratunga*

Main category: cs.CL

TL;DR: 提出Cross-Layer Attention Probing (CLAP)方法，通过处理LLM整个残差流的激活作为联合序列，改进幻觉检测效果，支持细粒度检测和检测后缓解策略。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在各种应用中的大规模采用，其生成不准确文本（幻觉）的倾向引发了可靠性担忧，需要有效的检测和缓解方法。

Method: 提出CLAP激活探测技术，将LLM整个残差流的激活作为联合序列进行处理，用于幻觉检测。支持对贪婪解码和高温采样响应的检测，并能区分不同采样响应中的幻觉和非幻觉。

Result: 在五个LLM和三个任务上的实证评估显示，CLAP相比基线方法在幻觉检测方面有显著改进，即使在分布外应用时仍保持高可靠性。

Conclusion: CLAP方法能够有效检测和缓解LLM幻觉问题，通过检测后缓解策略相比直接缓解方法能更好地提高LLM可靠性，且具有良好的泛化能力。

Abstract: With the large-scale adoption of Large Language Models (LLMs) in various
applications, there is a growing reliability concern due to their tendency to
generate inaccurate text, i.e. hallucinations. In this work, we propose
Cross-Layer Attention Probing (CLAP), a novel activation probing technique for
hallucination detection, which processes the LLM activations across the entire
residual stream as a joint sequence. Our empirical evaluations using five LLMs
and three tasks show that CLAP improves hallucination detection compared to
baselines on both greedy decoded responses as well as responses sampled at
higher temperatures, thus enabling fine-grained detection, i.e. the ability to
disambiguate hallucinations and non-hallucinations among different sampled
responses to a given prompt. This allows us to propose a detect-then-mitigate
strategy using CLAP to reduce hallucinations and improve LLM reliability
compared to direct mitigation approaches. Finally, we show that CLAP maintains
high reliability even when applied out-of-distribution.

</details>


### [4] [Optimal Multi-Task Learning at Regularization Horizon for Speech Translation Task](https://arxiv.org/abs/2509.09701)
*JungHo Jung,Junhyun Lee*

Main category: cs.CL

TL;DR: 本文从正则化角度研究端到端语音翻译中的多任务学习，探索跨模态一致性正则化和同模态R-drop正则化，提出正则化地平线概念来优化超参数配置。


<details>
  <summary>Details</summary>
Motivation: 端到端语音翻译面临配对语音-文本数据稀缺问题，希望通过利用机器翻译的双语数据和多任务学习来克服这一限制。

Method: 从正则化视角构建多任务学习框架，研究跨模态一致性正则化和同模态R-drop正则化，分析MT损失系数作为正则化源的作用，提出正则化地平线概念来指导超参数调优。

Result: 在MuST-C数据集上，通过在正则化地平线内调优超参数，达到了接近最先进的性能表现。

Conclusion: 多任务学习中的三种正则化源（跨模态一致性、同模态R-drop、MT损失系数）共同构成了有效的正则化机制，正则化地平线为超参数优化提供了理论指导框架。

Abstract: End-to-end speech-to-text translation typically suffers from the scarcity of
paired speech-text data. One way to overcome this shortcoming is to utilize the
bitext data from the Machine Translation (MT) task and perform Multi-Task
Learning (MTL). In this paper, we formulate MTL from a regularization
perspective and explore how sequences can be regularized within and across
modalities. By thoroughly investigating the effect of consistency
regularization (different modality) and R-drop (same modality), we show how
they respectively contribute to the total regularization. We also demonstrate
that the coefficient of MT loss serves as another source of regularization in
the MTL setting. With these three sources of regularization, we introduce the
optimal regularization contour in the high-dimensional space, called the
regularization horizon. Experiments show that tuning the hyperparameters within
the regularization horizon achieves near state-of-the-art performance on the
MuST-C dataset.

</details>


### [5] [Creativity Benchmark: A benchmark for marketing creativity for LLM models](https://arxiv.org/abs/2509.09702)
*Ninad Bhat,Kieran Browne,Pip Bingemann*

Main category: cs.CL

TL;DR: 本文介绍了Creativity Benchmark评估框架，用于评估大语言模型在营销创意生成方面的表现。通过678名专业创意人员的11,012次匿名比较，发现各模型表现相近，没有明显优势模型，且自动评估无法替代人类专家评估。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在创意生成领域的应用日益广泛，需要建立可靠的评估标准来测试模型在营销创意任务中的表现，特别是品牌约束条件下的创意能力。

Method: 构建包含100个品牌（12个类别）和三种提示类型的评估框架，收集678名专业创意人员的11,012次匿名成对偏好数据，使用Bradley-Terry模型分析，并计算余弦距离来评估模型多样性和对提示重构的敏感性。

Result: 各模型表现紧密聚集，没有单一模型在所有品牌或提示类型中占主导地位（最高与最低模型的对战胜率仅为61%）。自动评估与人类排名相关性弱且不一致，传统创造力测试在品牌约束任务中仅部分有效。

Conclusion: 研究强调了专家人类评估的必要性，以及需要采用多样性感知的工作流程，自动评估方法目前无法替代人类专业判断。

Abstract: We introduce Creativity Benchmark, an evaluation framework for large language
models (LLMs) in marketing creativity. The benchmark covers 100 brands (12
categories) and three prompt types (Insights, Ideas, Wild Ideas). Human
pairwise preferences from 678 practising creatives over 11,012 anonymised
comparisons, analysed with Bradley-Terry models, show tightly clustered
performance with no model dominating across brands or prompt types: the
top-bottom spread is $\Delta\theta \approx 0.45$, which implies a head-to-head
win probability of $0.61$; the highest-rated model beats the lowest only about
$61\%$ of the time. We also analyse model diversity using cosine distances to
capture intra- and inter-model variation and sensitivity to prompt reframing.
Comparing three LLM-as-judge setups with human rankings reveals weak,
inconsistent correlations and judge-specific biases, underscoring that
automated judges cannot substitute for human evaluation. Conventional
creativity tests also transfer only partially to brand-constrained tasks.
Overall, the results highlight the need for expert human evaluation and
diversity-aware workflows.

</details>


### [6] [CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor](https://arxiv.org/abs/2509.09703)
*Zhenhua Xu,Xixiang Zhao,Xubin Yue,Shengwei Tian,Changting Lin,Meng Han*

Main category: cs.CL

TL;DR: CTCC是一个新颖的基于规则的语言模型指纹框架，通过多轮对话上下文关联编码来实现隐蔽且鲁棒的所有权验证


<details>
  <summary>Details</summary>
Motivation: 解决现有语言模型指纹方法在隐蔽性、鲁棒性和泛化性之间的权衡问题，防止模型被盗用和未经授权的重新分发

Method: 采用规则驱动的指纹框架，编码多轮对话中的上下文关联（如反事实关系），而不是依赖词级或单轮触发机制

Result: 在多种LLM架构上的广泛实验表明，CTCC相比现有方法具有更强的隐蔽性和鲁棒性，能够有效减少误报和指纹泄露

Conclusion: CTCC为现实世界LLM部署场景中的所有权验证提供了一个可靠且实用的解决方案

Abstract: The widespread deployment of large language models (LLMs) has intensified
concerns around intellectual property (IP) protection, as model theft and
unauthorized redistribution become increasingly feasible. To address this,
model fingerprinting aims to embed verifiable ownership traces into LLMs.
However, existing methods face inherent trade-offs between stealthness,
robustness, and generalizability, being either detectable via distributional
shifts, vulnerable to adversarial modifications, or easily invalidated once the
fingerprint is revealed. In this work, we introduce CTCC, a novel rule-driven
fingerprinting framework that encodes contextual correlations across multiple
dialogue turns, such as counterfactual, rather than relying on token-level or
single-turn triggers. CTCC enables fingerprint verification under black-box
access while mitigating false positives and fingerprint leakage, supporting
continuous construction under a shared semantic rule even if partial triggers
are exposed. Extensive experiments across multiple LLM architectures
demonstrate that CTCC consistently achieves stronger stealth and robustness
than prior work. Our findings position CTCC as a reliable and practical
solution for ownership verification in real-world LLM deployment scenarios. Our
code and data are publicly available at <https://github.com/Xuzhenhua55/CTCC>.

</details>


### [7] [Temporal Preferences in Language Models for Long-Horizon Assistance](https://arxiv.org/abs/2509.09704)
*Ali Mazyaki,Mohammad Naghizadeh,Samaneh Ranjkhah Zonouzaghi,Hossein Setareh*

Main category: cs.CL

TL;DR: 研究语言模型在跨期选择中是否表现出未来导向偏好，以及这些偏好是否可被系统性操纵。通过引入MTO指标评估模型的时间偏好可操纵性，发现推理型模型在未来导向提示下更倾向于选择延迟选项。


<details>
  <summary>Details</summary>
Motivation: 探究语言模型的时间偏好特征及其可操纵性，为AI助手与人类异质性长期目标的对齐提供设计依据，推动个性化情境校准和社会意识部署的研究议程。

Method: 采用改编的人类实验协议，在时间权衡任务中评估多个语言模型，并与人类决策者进行基准比较。定义MTO（时间导向可操纵性）指标来衡量模型在面向未来和面向当前提示下时间偏好的变化。

Result: 推理型模型（如DeepSeek-Reasoner和grok-3-mini）在未来导向提示下更倾向于选择延迟选项，但在跨身份或地理位置的个性化决策方面表现有限。能够正确推理时间导向的模型会内化作为AI决策者的未来导向。

Conclusion: 研究揭示了语言模型时间偏好的可操纵性特征，强调了AI助手设计需要与异质性长期目标对齐的重要性，并提出了个性化情境校准和社会意识部署的研究方向。

Abstract: We study whether language models (LMs) exhibit future- versus
present-oriented preferences in intertemporal choice and whether those
preferences can be systematically manipulated. Using adapted human experimental
protocols, we evaluate multiple LMs on time-tradeoff tasks and benchmark them
against a sample of human decision makers. We introduce an operational metric,
the Manipulability of Time Orientation (MTO), defined as the change in an LM's
revealed time preference between future- and present-oriented prompts. In our
tests, reasoning-focused models (e.g., DeepSeek-Reasoner and grok-3-mini)
choose later options under future-oriented prompts but only partially
personalize decisions across identities or geographies. Moreover, models that
correctly reason about time orientation internalize a future orientation for
themselves as AI decision makers. We discuss design implications for AI
assistants that should align with heterogeneous, long-horizon goals and outline
a research agenda on personalized contextual calibration and socially aware
deployment.

</details>


### [8] [The Non-Determinism of Small LLMs: Evidence of Low Answer Consistency in Repetition Trials of Standard Multiple-Choice Benchmarks](https://arxiv.org/abs/2509.09705)
*Claudio Pinhanez,Paulo Cavalin,Cassia Sanctos,Marcelo Grave,Yago Primerano*

Main category: cs.CL

TL;DR: 本研究探讨了小型LLM（2B-8B参数）在多次回答相同问题时的答案一致性，分析了不同温度设置、模型大小、微调状态等因素对一致性和准确性的影响。


<details>
  <summary>Details</summary>
Motivation: 评估小型LLM在重复回答相同问题时的表现一致性，为模型选择提供参考依据，特别是在需要稳定输出的应用场景中。

Method: 使用开源LLM对MMLU-Redux和MedQA基准测试中的问题进行10次重复回答，分析不同推理温度、模型规模（2B-8B vs 50B-80B）、微调状态等参数的影响，并开发了新的分析和可视化工具。

Result: 小型模型在低推理温度下，能够一致回答的问题比例通常在50%-80%之间，一致答案的准确性与整体准确性有合理相关性。中型模型显示出更高的答案一致性水平。

Conclusion: 模型的一致性和准确性存在权衡关系，不同模型在一致性表现上差异显著，中型模型通常比小型模型具有更好的一致性表现，这为实际应用中的模型选择提供了重要参考。

Abstract: This work explores the consistency of small LLMs (2B-8B parameters) in
answering multiple times the same question. We present a study on known,
open-source LLMs responding to 10 repetitions of questions from the
multiple-choice benchmarks MMLU-Redux and MedQA, considering different
inference temperatures, small vs. medium models (50B-80B), finetuned vs. base
models, and other parameters. We also look into the effects of requiring
multi-trial answer consistency on accuracy and the trade-offs involved in
deciding which model best provides both of them. To support those studies, we
propose some new analytical and graphical tools. Results show that the number
of questions which can be answered consistently vary considerably among models
but are typically in the 50%-80% range for small models at low inference
temperatures. Also, accuracy among consistent answers seems to reasonably
correlate with overall accuracy. Results for medium-sized models seem to
indicate much higher levels of answer consistency.

</details>


### [9] [Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal](https://arxiv.org/abs/2509.09708)
*Nirmalendu Prakash,Yeo Wei Jie,Amir Abdullah,Ranjan Satapathy,Erik Cambria,Roy Ka Wei Lee*

Main category: cs.CL

TL;DR: 本文通过稀疏自编码器分析LLM拒绝有害提示的内部机制，发现了导致安全行为翻转的关键特征集，并揭示了特征冗余现象


<details>
  <summary>Details</summary>
Motivation: 理解指令调优大语言模型拒绝有害提示的内部因果机制，现有研究对此认识不足

Method: 使用稀疏自编码器分析残差流激活，通过三阶段搜索流程（拒绝方向识别、贪婪过滤、交互发现）寻找导致拒绝行为翻转的关键特征

Result: 成功识别出能够将模型从拒绝转为顺从的关键特征集，发现了特征冗余现象，即某些特征在早期特征被抑制时才会激活

Conclusion: 该方法为细粒度审计和针对性干预安全行为提供了可能，通过操作可解释的潜在空间来实现安全控制

Abstract: Refusal on harmful prompts is a key safety behaviour in instruction-tuned
large language models (LLMs), yet the internal causes of this behaviour remain
poorly understood. We study two public instruction-tuned models, Gemma-2-2B-IT
and LLaMA-3.1-8B-IT, using sparse autoencoders (SAEs) trained on
residual-stream activations. Given a harmful prompt, we search the SAE latent
space for feature sets whose ablation flips the model from refusal to
compliance, demonstrating causal influence and creating a jailbreak. Our search
proceeds in three stages: (1) Refusal Direction: find a refusal-mediating
direction and collect SAE features near that direction; (2) Greedy Filtering:
prune to a minimal set; and (3) Interaction Discovery: fit a factorization
machine (FM) that captures nonlinear interactions among the remaining active
features and the minimal set. This pipeline yields a broad set of
jailbreak-critical features, offering insight into the mechanistic basis of
refusal. Moreover, we find evidence of redundant features that remain dormant
unless earlier features are suppressed. Our findings highlight the potential
for fine-grained auditing and targeted intervention in safety behaviours by
manipulating the interpretable latent space.

</details>


### [10] [Assisting Research Proposal Writing with Large Language Models: Evaluation and Refinement](https://arxiv.org/abs/2509.09709)
*Jing Ren,Weiqi Wang*

Main category: cs.CL

TL;DR: 本研究提出内容质量和参考文献有效性两个量化指标，以及基于这些指标的迭代提示方法，用于客观评估和提升ChatGPT等大语言模型在学术写作中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在学术写作中存在错误或捏造参考文献等伦理问题，且内容质量评估主要依赖主观人工判断，缺乏客观性和一致性。

Method: 提出内容质量和参考文献有效性两个关键评估指标，并基于这些指标的得分设计迭代提示方法。

Result: 实验表明，所提指标为ChatGPT写作性能提供了客观量化评估框架，迭代提示显著提升了内容质量并减少了参考文献错误和捏造问题。

Conclusion: 该方法有效解决了学术背景下大语言模型写作的关键伦理挑战，为客观评估和提升模型学术写作能力提供了可行方案。

Abstract: Large language models (LLMs) like ChatGPT are increasingly used in academic
writing, yet issues such as incorrect or fabricated references raise ethical
concerns. Moreover, current content quality evaluations often rely on
subjective human judgment, which is labor-intensive and lacks objectivity,
potentially compromising the consistency and reliability. In this study, to
provide a quantitative evaluation and enhance research proposal writing
capabilities of LLMs, we propose two key evaluation metrics--content quality
and reference validity--and an iterative prompting method based on the scores
derived from these two metrics. Our extensive experiments show that the
proposed metrics provide an objective, quantitative framework for assessing
ChatGPT's writing performance. Additionally, iterative prompting significantly
enhances content quality while reducing reference inaccuracies and
fabrications, addressing critical ethical challenges in academic contexts.

</details>


### [11] [Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data](https://arxiv.org/abs/2509.09710)
*Sepehr Golrokh Amin,Devin Rhoads,Fatemeh Fakhrmoosavi,Nicholas E. Lownes,John N. Ivan*

Main category: cs.CL

TL;DR: 本研究提出使用大型语言模型生成基于代理的交通模型中个体出行日记的新方法，通过开源数据生成虚拟人物并合成日记，验证显示与传统方法相比具有可比性的真实性和更好的统计代表性。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖大量专有家庭出行调查数据，成本高且获取困难，需要开发一种基于开源数据的替代方案来生成个体出行日记。

Method: 使用开源美国社区调查和智能位置数据库数据随机生成虚拟人物，通过直接提示LLM合成出行日记，并采用包含四个指标（出行次数、间隔、目的、方式）的综合真实度评分体系进行验证。

Result: LLM生成的日记与传统方法（负二项式出行生成+多项式逻辑回归模式/目的）相比具有可比的整体真实度（0.485 vs 0.455），在确定出行目的方面表现优异且一致性更好，同时在统计代表性方面显著优于传统方法（0.612 vs 0.435）。

Conclusion: LLM方法在零样本条件下可行，为未来合成出行日记评估系统建立了可量化的真实度指标，展示了在交通建模中的应用潜力。

Abstract: This study introduces a Large Language Model (LLM) scheme for generating
individual travel diaries in agent-based transportation models. While
traditional approaches rely on large quantities of proprietary household travel
surveys, the method presented in this study generates personas stochastically
from open-source American Community Survey (ACS) and Smart Location Database
(SLD) data, then synthesizes diaries through direct prompting. This study
features a novel one-to-cohort realism score: a composite of four metrics (Trip
Count Score, Interval Score, Purpose Score, and Mode Score) validated against
the Connecticut Statewide Transportation Study (CSTS) diaries, matched across
demographic variables. The validation utilizes Jensen-Shannon Divergence to
measure distributional similarities between generated and real diaries. When
compared to diaries generated with classical methods (Negative Binomial for
trip generation; Multinomial Logit for mode/purpose) calibrated on the
validation set, LLM-generated diaries achieve comparable overall realism (LLM
mean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and
demonstrates greater consistency (narrower realism score distribution), while
classical models lead in numerical estimates of trip count and activity
duration. Aggregate validation confirms the LLM's statistical
representativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot
viability and establishing a quantifiable metric of diary realism for future
synthetic diary evaluation systems.

</details>


### [12] [Psychiatry-Bench: A Multi-Task Benchmark for LLMs in Psychiatry](https://arxiv.org/abs/2509.09711)
*Aya E. Fouda,Abdelrahamn A. Hassan,Radwa J. Hanafy,Mohammed E. Fouda*

Main category: cs.CL

TL;DR: PsychiatryBench是一个基于权威精神病学教科书和案例集构建的临床基准测试，包含5300多个专家标注项目，评估显示前沿LLM在临床一致性和安全性方面存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有评估资源主要依赖小型临床访谈语料库、社交媒体帖子或合成对话，限制了临床有效性，无法捕捉精神病学推理的复杂性。

Method: 基于权威专家验证的精神病学教科书和案例集构建基准测试，包含11个不同的问答任务，使用传统指标和"LLM-as-judge"相似性评分框架评估多种前沿LLM。

Result: 结果显示在临床一致性和安全性方面存在显著差距，特别是在多轮随访和管理任务中。

Conclusion: 需要专门的模型调优和更强大的评估范式，PsychiatryBench为高风险心理健康应用中的LLM性能基准测试和改进提供了模块化、可扩展的平台。

Abstract: Large language models (LLMs) hold great promise in enhancing psychiatric
practice, from improving diagnostic accuracy to streamlining clinical
documentation and therapeutic support. However, existing evaluation resources
heavily rely on small clinical interview corpora, social media posts, or
synthetic dialogues, which limits their clinical validity and fails to capture
the full complexity of psychiatric reasoning. In this work, we introduce
PsychiatryBench, a rigorously curated benchmark grounded exclusively in
authoritative, expert-validated psychiatric textbooks and casebooks.
PsychiatryBench comprises eleven distinct question-answering tasks ranging from
diagnostic reasoning and treatment planning to longitudinal follow-up,
management planning, clinical approach, sequential case analysis, and
multiple-choice/extended matching formats totaling over 5,300 expert-annotated
items. We evaluate a diverse set of frontier LLMs (including Google Gemini,
DeepSeek, LLaMA 3, and QWQ-32) alongside leading open-source medical models
(e.g., OpenBiloLLM, MedGemma) using both conventional metrics and an
"LLM-as-judge" similarity scoring framework. Our results reveal substantial
gaps in clinical consistency and safety, particularly in multi-turn follow-up
and management tasks, underscoring the need for specialized model tuning and
more robust evaluation paradigms. PsychiatryBench offers a modular, extensible
platform for benchmarking and improving LLM performance in high-stakes mental
health applications.

</details>


### [13] [The Thinking Therapist: Training Large Language Models to Deliver Acceptance and Commitment Therapy using Supervised Fine-Tuning and Odds Ratio Policy Optimization](https://arxiv.org/abs/2509.09712)
*Talha Tahir*

Main category: cs.CL

TL;DR: 本研究比较了SFT和ORPO两种训练方法对小型LLM进行ACT治疗能力的影响，发现ORPO方法在治疗忠诚度和共情方面显著优于SFT和基础模型，而思维链推理仅对SFT模型有显著帮助。


<details>
  <summary>Details</summary>
Motivation: 研究第三代认知行为疗法ACT在小型开源大语言模型中的应用效果，探索不同训练方法和显式推理对模型治疗能力的影响。

Method: 使用Mistral-Large生成的50组合成ACT转录本，对Llama-3.2-3b-Instruct进行两种训练：监督微调(SFT)和几率比策略优化(ORPO)，每种方法都包含有/无思维链推理的变体。通过模拟治疗会话评估性能，使用ACT忠诚度量表和治疗师共情量表进行量化评估。

Result: ORPO训练模型在ACT忠诚度(χ²=185.15, p<.001)和治疗共情(χ²=140.37, p<.001)方面显著优于SFT和基础模型。思维链推理仅对SFT模型有显著帮助，平均提高ACT-FM得分2.68分(p<.001)，但对ORPO模型无显著优势。

Conclusion: 偏好对齐策略优化能有效培养小型LLM的ACT能力，显式推理的效用高度依赖于底层训练范式。ORPO通过学习治疗"过程"而非模仿"内容"表现出优势，而思维链推理为仅通过模仿训练的模型提供了必要的支架。

Abstract: Acceptance and Commitment Therapy (ACT) is a third-wave cognitive behavioral
therapy with emerging evidence of efficacy in several psychiatric conditions.
This study investigates the impact of post-training methodology and explicit
reasoning on the ability of a small open-weight large language model (LLM) to
deliver ACT. Using 50 sets of synthetic ACT transcripts generated by
Mistral-Large, we trained Llama-3.2-3b-Instruct with two distinct approaches,
supervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), each
with and without an explicit chain-of-thought (COT) reasoning step. Performance
was evaluated by comparing these four post-trained variants against the base
Instruct model. These models were benchmarked in simulated therapy sessions,
with performance quantitatively assessed on the ACT Fidelity Measure (ACT-FM)
and the Therapist Empathy Scale (TES) by an LLM judge that had been fine-tuned
on human evaluations. Our findings demonstrate that the ORPO-trained models
significantly outperformed both their SFT and Instruct counterparts on ACT
fidelity ($\chi^2(5) = 185.15, p < .001$) and therapeutic empathy ($\chi^2(5) =
140.37, p < .001$). The effect of COT was conditional as it provided a
significant benefit to SFT models, improving ACT-FM scores by an average of
2.68 points ($p < .001$), while offering no discernible advantage to the
superior ORPO or instruct-tuned variants. We posit that the superiority of ORPO
stems from its ability to learn the therapeutic `process' over imitating
`content,' a key aspect of ACT, while COT acts as a necessary scaffold for
models trained only via imitation. This study establishes that
preference-aligned policy optimization can effectively instill ACT competencies
in small LLMs, and that the utility of explicit reasoning is highly dependent
on the underlying training paradigm.

</details>


### [14] [HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering](https://arxiv.org/abs/2509.09713)
*Duolin Sun,Dan Yang,Yue Shen,Yihan Jiao,Zhehao Tan,Jie Feng,Lianzhen Zhong,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: HANRAG是一个基于启发式的RAG框架，通过查询路由、子查询分解和噪声过滤来高效处理多跳查询问题，在单跳和多跳问答任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 当前RAG方法在处理多跳查询时面临迭代检索步骤浪费、复杂查询检索效果差、噪声累积等问题，需要更高效的解决方案

Method: 提出HANRAG框架，使用强大的revelator进行查询路由、将复杂查询分解为子查询、对检索文档进行噪声过滤，提高系统适应性和抗噪能力

Result: 在多个基准测试中与业界领先方法比较，结果显示该框架在单跳和多跳问答任务中都取得了优越性能

Conclusion: HANRAG框架有效解决了多跳查询处理中的关键问题，通过启发式方法提升了RAG系统的效率和准确性

Abstract: The Retrieval-Augmented Generation (RAG) approach enhances question-answering
systems and dialogue generation tasks by integrating information retrieval (IR)
technologies with large language models (LLMs). This strategy, which retrieves
information from external knowledge bases to bolster the response capabilities
of generative models, has achieved certain successes. However, current RAG
methods still face numerous challenges when dealing with multi-hop queries. For
instance, some approaches overly rely on iterative retrieval, wasting too many
retrieval steps on compound queries. Additionally, using the original complex
query for retrieval may fail to capture content relevant to specific
sub-queries, resulting in noisy retrieved content. If the noise is not managed,
it can lead to the problem of noise accumulation. To address these issues, we
introduce HANRAG, a novel heuristic-based framework designed to efficiently
tackle problems of varying complexity. Driven by a powerful revelator, HANRAG
routes queries, decomposes them into sub-queries, and filters noise from
retrieved documents. This enhances the system's adaptability and noise
resistance, making it highly capable of handling diverse queries. We compare
the proposed framework against other leading industry methods across various
benchmarks. The results demonstrate that our framework obtains superior
performance in both single-hop and multi-hop question-answering tasks.

</details>


### [15] [How Small Transformation Expose the Weakness of Semantic Similarity Measures](https://arxiv.org/abs/2509.09714)
*Serge Lionel Nikiema,Albérick Euraste Djire,Abdoul Aziz Bonkoungou,Micheline Bénédicte Moumoula,Jordan Samhi,Abdoul Kader Kabore,Jacques Klein,Tegawendé F. Bissyande*

Main category: cs.CL

TL;DR: 本研究系统评估了18种语义相似度测量方法，发现常用指标存在显著问题，某些嵌入方法将语义对立内容误判为相似的概率高达99.9%，而转换距离计算方式可提升性能24-66%。


<details>
  <summary>Details</summary>
Motivation: 评估不同语义相似度测量方法在软件工程应用中的有效性，探究大语言模型是否真正理解语义关系而非仅识别表面模式。

Method: 创建系统性测试框架，对文本和代码应用受控变化，测试18种方法（基于词、嵌入技术、LLM系统和结构感知算法）处理不同类型语义关系的能力。

Result: 嵌入方法经常错误识别语义对立内容为相似（最高99.9%），转换器方法有时将相反含义评为比同义词更相似。从欧几里得距离切换到余弦相似度使结果提升24-66%。LLM方法在区分语义差异方面表现更好。

Conclusion: 当前常用的语义相似度度量方法存在严重缺陷，需要更可靠的评估方法。LLM在语义理解方面表现优于传统嵌入方法，但仍有改进空间。

Abstract: This research examines how well different methods measure semantic
similarity, which is important for various software engineering applications
such as code search, API recommendations, automated code reviews, and
refactoring tools. While large language models are increasingly used for these
similarity assessments, questions remain about whether they truly understand
semantic relationships or merely recognize surface patterns.
  The study tested 18 different similarity measurement approaches, including
word-based methods, embedding techniques, LLM-based systems, and
structure-aware algorithms. The researchers created a systematic testing
framework that applies controlled changes to text and code to evaluate how well
each method handles different types of semantic relationships.
  The results revealed significant issues with commonly used metrics. Some
embedding-based methods incorrectly identified semantic opposites as similar up
to 99.9 percent of the time, while certain transformer-based approaches
occasionally rated opposite meanings as more similar than synonymous ones. The
study found that embedding methods' poor performance often stemmed from how
they calculate distances; switching from Euclidean distance to cosine
similarity improved results by 24 to 66 percent. LLM-based approaches performed
better at distinguishing semantic differences, producing low similarity scores
(0.00 to 0.29) for genuinely different meanings, compared to embedding methods
that incorrectly assigned high scores (0.82 to 0.99) to dissimilar content.

</details>


### [16] [Investigating Symbolic Triggers of Hallucination in Gemma Models Across HaluEval and TruthfulQA](https://arxiv.org/abs/2509.09715)
*Naveen Lamba,Sanju Tiwari,Manas Gaur*

Main category: cs.CL

TL;DR: 本研究识别并表征了导致大语言模型产生幻觉的关键符号属性，发现即使模型规模增大，符号元素（如修饰语和命名实体）仍会持续导致高幻觉率。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM的幻觉问题已被广泛研究，但导致模型内在易产生幻觉的属性尚未被识别和研究，本研究旨在填补这一空白。

Method: 使用HaluEval和TruthfulQA两个数据集，将原有的问答格式转换为多种其他格式，以确定导致幻觉的关键属性。

Result: Gemma-2-2B模型在各项任务和数据集上的平均幻觉率为79.0%，随着模型规模增大，Gemma-2-9B降至73.6%，Gemma-2-27B降至63.9%。修饰语和命名实体在所有Gemma模型中都导致84.76%-94.98%的高幻觉率。

Conclusion: 符号元素持续混淆模型，表明LLM在处理此类输入时存在根本性弱点，且这种弱点与模型规模无关。

Abstract: Hallucination in Large Language Models (LLMs) is a well studied problem.
However, the properties that make LLM intrinsically vulnerable to
hallucinations have not been identified and studied. This research identifies
and characterizes the key properties, allowing us to pinpoint vulnerabilities
within the model's internal mechanisms. To solidify on these properties, we
utilized two established datasets, HaluEval and TruthfulQA and convert their
existing format of question answering into various other formats to narrow down
these properties as the reason for the hallucinations. Our findings reveal that
hallucination percentages across symbolic properties are notably high for
Gemma-2-2B, averaging 79.0% across tasks and datasets. With increased model
scale, hallucination drops to 73.6% for Gemma-2-9B and 63.9% for Gemma-2-27B,
reflecting a 15 percentage point reduction overall. Although the hallucination
rate decreases as the model size increases, a substantial amount of
hallucination caused by symbolic properties still persists. This is especially
evident for modifiers (ranging from 84.76% to 94.98%) and named entities
(ranging from 83.87% to 93.96%) across all Gemma models and both datasets.
These findings indicate that symbolic elements continue to confuse the models,
pointing to a fundamental weakness in how these LLMs process such
inputs--regardless of their scale.

</details>


### [17] [ALIGNS: Unlocking nomological networks in psychological measurement through a large language model](https://arxiv.org/abs/2509.09723)
*Kai R. Larsen,Sen Yan,Roland Müller,Lan Sang,Mikko Rönkkö,Ravi Starzl,Donald Edmondson*

Main category: cs.CL

TL;DR: ALIGNS是一个基于大语言模型的系统，用于生成包含55万+指标的综合理论网络，解决心理学测量中理论网络构建的长期挑战。


<details>
  <summary>Details</summary>
Motivation: 解决70年来理论网络构建的难题，避免临床试验检测不到治疗效果和公共政策目标错误等实际问题。

Method: 使用经过验证的问卷测量训练大语言模型，开发ALIGNS系统，提供三个综合理论网络。

Result: 系统在三个评估中表现良好：发现焦虑抑郁测量收敛为单一情绪困扰维度；识别儿童气质测量的四个新维度；专家评估显示系统重要且适用。

Conclusion: ALIGNS是首个应用大语言模型解决测量验证基础问题的系统，可免费使用，为传统验证方法提供大规模理论分析补充。

Abstract: Psychological measurement is critical to many disciplines. Despite advances
in measurement, building nomological networks, theoretical maps of how concepts
and measures relate to establish validity, remains a challenge 70 years after
Cronbach and Meehl proposed them as fundamental to validation. This limitation
has practical consequences: clinical trials may fail to detect treatment
effects, and public policy may target the wrong outcomes. We introduce Analysis
of Latent Indicators to Generate Nomological Structures (ALIGNS), a large
language model-based system trained with validated questionnaire measures.
ALIGNS provides three comprehensive nomological networks containing over
550,000 indicators across psychology, medicine, social policy, and other
fields. This represents the first application of large language models to solve
a foundational problem in measurement validation. We report classification
accuracy tests used to develop the model, as well as three evaluations. In the
first evaluation, the widely used NIH PROMIS anxiety and depression instruments
are shown to converge into a single dimension of emotional distress. The second
evaluation examines child temperament measures and identifies four potential
dimensions not captured by current frameworks, and questions one existing
dimension. The third evaluation, an applicability check, engages expert
psychometricians who assess the system's importance, accessibility, and
suitability. ALIGNS is freely available at nomologicalnetwork.org,
complementing traditional validation methods with large-scale nomological
analysis.

</details>


### [18] [DiTTO-LLM: Framework for Discovering Topic-based Technology Opportunities via Large Language Model](https://arxiv.org/abs/2509.09724)
*Wonyoung Kim,Sujeong Seo,Juhyun Lee*

Main category: cs.CL

TL;DR: 基于技术间时间关系识别新兴技术机会的框架，利用专利数据和大语言模型提取技术主题并追踪其演变


<details>
  <summary>Details</summary>
Motivation: 技术机会是推动技术、产业和创新进步的关键信息，需要系统化方法来识别新兴技术机会

Method: 从专利数据提取文本，映射文本主题发现技术间关系，追踪主题随时间变化，利用大语言模型提取主题和聊天模型提示来支持技术机会发现

Result: 使用美国专利商标局AI专利数据集评估，实验结果表明AI技术正朝着便于日常访问的形式发展

Conclusion: 该框架展示了识别未来技术机会的潜力

Abstract: Technology opportunities are critical information that serve as a foundation
for advancements in technology, industry, and innovation. This paper proposes a
framework based on the temporal relationships between technologies to identify
emerging technology opportunities. The proposed framework begins by extracting
text from a patent dataset, followed by mapping text-based topics to discover
inter-technology relationships. Technology opportunities are then identified by
tracking changes in these topics over time. To enhance efficiency, the
framework leverages a large language model to extract topics and employs a
prompt for a chat-based language model to support the discovery of technology
opportunities. The framework was evaluated using an artificial intelligence
patent dataset provided by the United States Patent and Trademark Office. The
experimental results suggest that artificial intelligence technology is
evolving into forms that facilitate everyday accessibility. This approach
demonstrates the potential of the proposed framework to identify future
technology opportunities.

</details>


### [19] [BIBERT-Pipe on Biomedical Nested Named Entity Linking at BioASQ 2025](https://arxiv.org/abs/2509.09725)
*Chunyu Li,Xindi Zheng,Siqi Liu*

Main category: cs.CL

TL;DR: 提出了一种轻量级双阶段检索-排序管道系统BIBERT-Pipe，用于处理生物医学文本中的多语言嵌套实体链接任务，在BioNNE 2025多语言赛道中排名第三


<details>
  <summary>Details</summary>
Motivation: 当前生物医学实体链接主要基于英语语料库和平坦提及，缺乏对嵌套和多语言提及的现实场景研究

Method: 采用两阶段检索-排序架构：检索阶段使用原始预训练模型，排序阶段进行领域特定微调；使用可学习的[Ms]/[Me]标签包装提及；通过三种数据源自动扩展排序训练语料

Result: 在BioNNE 2025多语言排行榜中排名第三，证明了这些最小但原则性修改的有效性和竞争力

Conclusion: 该方法通过保持原始实体链接模型完整，仅修改三个任务对齐组件，成功解决了生物医学多语言嵌套实体链接的挑战

Abstract: Entity linking (EL) for biomedical text is typically benchmarked on
English-only corpora with flat mentions, leaving the more realistic scenario of
nested and multilingual mentions largely unexplored. We present our system for
the BioNNE 2025 Multilingual Biomedical Nested Named Entity Linking shared task
(English & Russian), closing this gap with a lightweight pipeline that keeps
the original EL model intact and modifies only three task-aligned components:
Two-stage retrieval-ranking. We leverage the same base encoder model in both
stages: the retrieval stage uses the original pre-trained model, while the
ranking stage applies domain-specific fine-tuning. Boundary cues. In the
ranking stage, we wrap each mention with learnable [Ms] / [Me] tags, providing
the encoder with an explicit, language-agnostic span before robustness to
overlap and nesting. Dataset augmentation. We also automatically expand the
ranking training corpus with three complementary data sources, enhancing
coverage without extra manual annotation. On the BioNNE 2025 leaderboard, our
two stage system, bilingual bert (BIBERT-Pipe), ranks third in the multilingual
track, demonstrating the effectiveness and competitiveness of these minimal yet
principled modifications. Code are publicly available at
https://github.com/Kaggle-Competitions-Code/BioNNE-L.

</details>


### [20] [Natural Language Translation of Formal Proofs through Informalization of Proof Steps and Recursive Summarization along Proof Structure](https://arxiv.org/abs/2509.09726)
*Seiji Hattori,Takuya Matsuzaki,Makoto Fujiwara*

Main category: cs.CL

TL;DR: 提出一种利用LLM将机器可验证的形式化证明翻译为自然语言的方法，通过非形式化和总结能力生成高质量的自然语言证明


<details>
  <summary>Details</summary>
Motivation: 为了解决形式化证明难以阅读和理解的问题，利用大语言模型的能力将机器验证的形式化证明转换为更易读的自然语言描述

Method: 利用LLM的非形式化（形式语言证明步骤的言语化）和总结能力，将形式化证明翻译为自然语言。方法应用于从本科教科书自然语言证明创建的形式化证明数据，并与原始自然语言证明进行质量对比分析

Result: 该方法能够生成高度可读且准确的自然语言证明，在Lean证明助手的现有形式化证明库上验证了有效性

Conclusion: 提出的基于LLM的自然语言翻译方法能够有效将形式化证明转换为高质量的自然语言描述，提高了证明的可读性和可理解性

Abstract: This paper proposes a natural language translation method for
machine-verifiable formal proofs that leverages the informalization
(verbalization of formal language proof steps) and summarization capabilities
of LLMs. For evaluation, it was applied to formal proof data created in
accordance with natural language proofs taken from an undergraduate-level
textbook, and the quality of the generated natural language proofs was analyzed
in comparison with the original natural language proofs. Furthermore, we will
demonstrate that this method can output highly readable and accurate natural
language proofs by applying it to existing formal proof library of the Lean
proof assistant.

</details>


### [21] [A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs](https://arxiv.org/abs/2509.09727)
*Andy Zhu,Yingjun Du*

Main category: cs.CL

TL;DR: 提出多智能体框架提升金融问答性能，通过角色提示和检索增强生成技术，在金融教育问题上比零样本思维链基线准确率提升6.6-8.3%


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在金融领域问答中难以捕捉专业推理需求，金融问题需要多步定量推理、领域专业术语理解和现实场景理解

Method: 多智能体框架包含基础生成器、证据检索器和专家评审器，采用检索增强生成技术从6本金融教材获取上下文证据，使用单次迭代生成精炼答案

Result: 在3,532个专家设计的金融教育问题上，基于批判的优化方法比零样本思维链基线准确率提升6.6-8.3%，Gemini-2.0-Flash表现最佳，GPT-4o-mini达到与金融调优模型相当的性能

Conclusion: 该方法提供了一种成本效益高的金融问答增强方案，为多智能体金融大语言模型系统的进一步研究提供了见解

Abstract: Question answering (QA) plays a central role in financial education, yet
existing large language model (LLM) approaches often fail to capture the
nuanced and specialized reasoning required for financial problem-solving. The
financial domain demands multistep quantitative reasoning, familiarity with
domain-specific terminology, and comprehension of real-world scenarios. We
present a multi-agent framework that leverages role-based prompting to enhance
performance on domain-specific QA. Our framework comprises a Base Generator, an
Evidence Retriever, and an Expert Reviewer agent that work in a single-pass
iteration to produce a refined answer. We evaluated our framework on a set of
3,532 expert-designed finance education questions from Study.com, an online
learning platform. We leverage retrieval-augmented generation (RAG) for
contextual evidence from 6 finance textbooks and prompting strategies for a
domain-expert reviewer. Our experiments indicate that critique-based refinement
improves answer accuracy by 6.6-8.3% over zero-shot Chain-of-Thought baselines,
with the highest performance from Gemini-2.0-Flash. Furthermore, our method
enables GPT-4o-mini to achieve performance comparable to the finance-tuned
FinGPT-mt_Llama3-8B_LoRA. Our results show a cost-effective approach to
enhancing financial QA and offer insights for further research in multi-agent
financial LLM systems.

</details>


### [22] [A meta-analysis on the performance of machine-learning based language models for sentiment analysis](https://arxiv.org/abs/2509.09728)
*Elena Rohde,Jonas Klingwort,Christian Borgs*

Main category: cs.CL

TL;DR: 对Twitter情感分析中机器学习性能的元分析显示平均准确率为0.80，强调需要标准化性能报告和规范化准确率指标以避免类别不平衡的误导。


<details>
  <summary>Details</summary>
Motivation: 评估Twitter情感分析中机器学习模型的平均性能，分析研究间的异质性，并探讨研究特征如何影响模型性能，以提供更可靠的模型比较基准。

Method: 采用PRISMA指南进行文献检索，从20项研究中筛选195个试验，使用双反正弦变换和三水平随机效应模型分析最常报告的整体准确率指标。

Result: AIC优化模型的平均整体准确率为0.80 [0.76, 0.84]，发现整体准确率因对类别不平衡和情感类别数量的敏感性而容易产生误导。

Conclusion: 需要规范化准确率指标以解决类别不平衡问题，并建立标准化的模型性能报告规范，包括为独立测试集报告混淆矩阵，以实现跨研究的可靠比较。

Abstract: This paper presents a meta-analysis evaluating ML performance in sentiment
analysis for Twitter data. The study aims to estimate the average performance,
assess heterogeneity between and within studies, and analyze how study
characteristics influence model performance. Using PRISMA guidelines, we
searched academic databases and selected 195 trials from 20 studies with 12
study features. Overall accuracy, the most reported performance metric, was
analyzed using double arcsine transformation and a three-level random effects
model. The average overall accuracy of the AIC-optimized model was 0.80 [0.76,
0.84]. This paper provides two key insights: 1) Overall accuracy is widely used
but often misleading due to its sensitivity to class imbalance and the number
of sentiment classes, highlighting the need for normalization. 2) Standardized
reporting of model performance, including reporting confusion matrices for
independent test sets, is essential for reliable comparisons of ML classifiers
across studies, which seems far from common practice.

</details>


### [23] [Benchmarking Vision-Language Models on Chinese Ancient Documents: From OCR to Knowledge Reasoning](https://arxiv.org/abs/2509.09731)
*Haiyang Yu,Yuchuan Wu,Fan Shi,Lei Liao,Jinghui Lu,Xiaodong Ge,Han Wang,Minghan Zhuo,Xuecheng Wu,Xiang Fei,Hao Feng,Guozhi Tang,An-Lan Wang,Hanshen Zhu,Yangfan He,Quanhuan Liang,Liyuan Meng,Chao Feng,Can Huang,Jingqun Tang,Bin Li*

Main category: cs.CL

TL;DR: AncientDoc是首个针对中文古籍文档的基准测试，包含五个任务（页面级OCR、白话翻译、推理问答、知识问答、语言变体问答），涵盖14种文档类型、100多本书籍和约3000页内容，用于评估视觉语言模型在中文古籍处理方面的能力。


<details>
  <summary>Details</summary>
Motivation: 中文古籍作为中华历史文化的重要载体，在数字化和理解方面面临挑战。传统方法仅扫描图像，而现有的视觉语言模型难以处理古籍的视觉和语言复杂性。现有文档基准主要关注英文印刷文本或简体中文，缺乏评估视觉语言模型在中文古籍上表现的基准。

Method: 构建AncientDoc基准测试，包含五个核心任务：页面级OCR、白话翻译、推理问答、知识问答、语言变体问答。数据集涵盖14种文档类型、100多本书籍和约3000页内容。使用多种指标评估主流视觉语言模型，并采用人类对齐的大语言模型进行评分补充。

Result: 基于AncientDoc基准对主流视觉语言模型进行了全面评估，揭示了当前模型在中文古籍处理方面的表现和局限性。

Conclusion: AncientDoc填补了中文古籍文档评估基准的空白，为评估和改进视觉语言模型在复杂中文古籍处理能力提供了重要工具，有助于推动古籍数字化和理解技术的发展。

Abstract: Chinese ancient documents, invaluable carriers of millennia of Chinese
history and culture, hold rich knowledge across diverse fields but face
challenges in digitization and understanding, i.e., traditional methods only
scan images, while current Vision-Language Models (VLMs) struggle with their
visual and linguistic complexity. Existing document benchmarks focus on English
printed texts or simplified Chinese, leaving a gap for evaluating VLMs on
ancient Chinese documents. To address this, we present AncientDoc, the first
benchmark for Chinese ancient documents, designed to assess VLMs from OCR to
knowledge reasoning. AncientDoc includes five tasks (page-level OCR, vernacular
translation, reasoning-based QA, knowledge-based QA, linguistic variant QA) and
covers 14 document types, over 100 books, and about 3,000 pages. Based on
AncientDoc, we evaluate mainstream VLMs using multiple metrics, supplemented by
a human-aligned large language model for scoring.

</details>


### [24] [MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools](https://arxiv.org/abs/2509.09734)
*Zikang Guo,Benfeng Xu,Chiwei Zhu,Wentao Hong,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: MCP-AgentBench是一个专门为评估语言代理在MCP协议下的工具交互能力而设计的综合基准测试，包含33个服务器、188个工具和600个查询，采用结果导向的评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试无法准确评估MCP协议下AI代理的真实性能，导致对其实际操作价值的认知偏差，无法可靠区分不同代理的能力差异。

Method: 建立包含33个操作服务器和188个不同工具的MCP测试床；开发包含600个系统设计查询的基准测试，分布在6个不同复杂度的交互类别；引入MCP-Eval结果导向评估方法。

Result: 通过对领先语言代理的广泛实证评估，提供了基础性见解，展示了不同代理在MCP环境下的性能表现。

Conclusion: MCP-AgentBench为研究社区提供了一个标准化、可靠的框架，用于构建、验证和推进能够充分利用MCP变革性优势的AI代理，加速实现真正有能力且可互操作的AI系统。

Abstract: The Model Context Protocol (MCP) is rapidly emerging as a pivotal open
standard, designed to enhance agent-tool integration and interoperability, and
is positioned to unlock a new era of powerful, interconnected, and genuinely
utilitarian agentic AI. However, despite MCP's growing adoption, existing
benchmarks often fail to capture real-world agent performance within this new
paradigm, leading to a distorted perception of their true operational value and
an inability to reliably differentiate proficiencies. To bridge this critical
evaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark
specifically engineered to rigorously assess language agent capabilities in
MCP-mediated tool interactions. Core contributions of MCP-AgentBench include:
the establishment of a robust MCP testbed comprising 33 operational servers
with 188 distinct tools; the development of a benchmark featuring 600
systematically designed queries distributed across 6 distinct categories of
varying interaction complexity; and the introduction of MCP-Eval, a novel
outcome-oriented evaluation methodology prioritizing real-world task success.
Through extensive empirical evaluation of leading language agents, we provide
foundational insights. MCP-AgentBench aims to equip the research community with
a standardized and reliable framework to build, validate, and advance agents
capable of fully leveraging MCP's transformative benefits, thereby accelerating
progress toward truly capable and interoperable AI systems.

</details>


### [25] [Discrimination by LLMs: Cross-lingual Bias Assessment and Mitigation in Decision-Making and Summarisation](https://arxiv.org/abs/2509.09735)
*Willem Huijzer,Jieying Chen*

Main category: cs.CL

TL;DR: 本研究分析GPT-3.5和GPT-4o在决策和摘要任务中的偏见问题，发现决策任务存在显著的性别、年龄和背景偏见，而摘要任务偏见较小。研究还测试了跨语言偏见传播和提示指令缓解策略的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在各领域的快速应用，人们对其可能加剧社会不平等和信息偏见的担忧日益增加，需要系统研究模型偏见及其缓解策略。

Method: 使用Tamkin等人(2023)数据集的荷兰语翻译版本，创建了151,200个决策任务提示和176,400个摘要任务提示，测试不同人口统计变量、指令、显著度水平和语言在GPT-3.5和GPT-4o上的表现。

Result: 两个模型在决策任务中都存在显著偏见，偏向女性、年轻年龄和特定背景（如非裔美国人）。摘要任务偏见较小，但GPT-3.5在英语中显示出显著的年龄相关差异。跨语言分析显示英语和荷兰语的偏见模式大体相似。提示指令缓解策略平均能减少27%的最有利和最不利人口统计群体之间的差距。

Conclusion: 研究强调需要谨慎采用大语言模型并进行特定情境的偏见测试，同时需要持续开发有效的缓解策略以确保AI的负责任部署。GPT-4o在所有英语提示中都显示出偏见减少，表明新模型在基于提示的缓解方面具有特定潜力。

Abstract: The rapid integration of Large Language Models (LLMs) into various domains
raises concerns about societal inequalities and information bias. This study
examines biases in LLMs related to background, gender, and age, with a focus on
their impact on decision-making and summarization tasks. Additionally, the
research examines the cross-lingual propagation of these biases and evaluates
the effectiveness of prompt-instructed mitigation strategies. Using an adapted
version of the dataset by Tamkin et al. (2023) translated into Dutch, we
created 151,200 unique prompts for the decision task and 176,400 for the
summarisation task. Various demographic variables, instructions, salience
levels, and languages were tested on GPT-3.5 and GPT-4o. Our analysis revealed
that both models were significantly biased during decision-making, favouring
female gender, younger ages, and certain backgrounds such as the
African-American background. In contrast, the summarisation task showed minimal
evidence of bias, though significant age-related differences emerged for
GPT-3.5 in English. Cross-lingual analysis showed that bias patterns were
broadly similar between English and Dutch, though notable differences were
observed across specific demographic categories. The newly proposed mitigation
instructions, while unable to eliminate biases completely, demonstrated
potential in reducing them. The most effective instruction achieved a 27\% mean
reduction in the gap between the most and least favorable demographics.
Notably, contrary to GPT-3.5, GPT-4o displayed reduced biases for all prompts
in English, indicating the specific potential for prompt-based mitigation
within newer models. This research underscores the importance of cautious
adoption of LLMs and context-specific bias testing, highlighting the need for
continued development of effective mitigation strategies to ensure responsible
deployment of AI.

</details>


### [26] [HEFT: A Coarse-to-Fine Hierarchy for Enhancing the Efficiency and Accuracy of Language Model Reasoning](https://arxiv.org/abs/2509.09801)
*Brennen Hill*

Main category: cs.CL

TL;DR: HEFT是一种分层高效微调策略，结合了LoRA和ReFT两种参数高效微调方法，在BoolQ推理基准上以更少训练轮次实现了更好的性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的专业化推理任务适配受计算资源限制，不同PEFT方法各有优势，研究假设协同组合这些方法可以解锁更好的性能和效率

Method: 提出HEFT分层适配策略：先在权重空间使用LoRA进行广泛基础适配，然后在表示空间使用ReFT进行精确细化调整

Result: 在Llama-2-7B模型上，仅训练3个epoch的HEFT达到85.17%准确率，优于训练20个epoch的LoRA-only(85.05%)和ReFT-only(83.36%)方法

Conclusion: PEFT方法的精心组合是强大的算法创新，为提升语言模型推理能力提供了更高效有效的路径，以更少计算预算获得更好结果

Abstract: The adaptation of large language models (LLMs) to specialized reasoning tasks
is fundamentally constrained by computational resources. Parameter-Efficient
Fine-Tuning (PEFT) methods have emerged as a powerful solution, yet the
landscape of these techniques is diverse, with distinct methods operating in
either the model's weight space or its representation space. This paper
investigates the hypothesis that a synergistic combination of these paradigms
can unlock superior performance and efficiency. We introduce HEFT (Hierarchical
Efficient Fine-Tuning), a novel hierarchical adaptation strategy that composes
two distinct PEFT methods in a coarse-to-fine manner: first, a broad,
foundational adaptation in the weight space using Low-Rank Adaptation (LoRA),
followed by a precise, surgical refinement of internal activations using
Representation Fine-Tuning (ReFT). We evaluate this approach by fine-tuning a
Llama-2-7B model on the BoolQ benchmark, a challenging dataset for inferential
reasoning. Our results reveal a profound synergistic effect. A model fine-tuned
for only three epochs with our HEFT strategy achieves an accuracy of 85.17\%,
exceeding the performance of models trained for 20 epochs with either LoRA-only
(85.05\%) or ReFT-only (83.36\%) methodologies. This work demonstrates that the
thoughtful composition of PEFT methods is a potent algorithmic innovation,
offering a more efficient and effective path toward advancing the reasoning
capabilities of language models. By achieving superior results with a fraction
of the computational budget, our findings present a principled approach to
overcoming the obstacles inherent in adapting large-scale models for complex
cognitive tasks.

</details>


### [27] [Pragmatic Frames Evoked by Gestures: A FrameNet Brasil Approach to Multimodality in Turn Organization](https://arxiv.org/abs/2509.09804)
*Helen de Andrade Abreu,Tiago Timponi Torrent,Ely Edison da Silva Matos*

Main category: cs.CL

TL;DR: 提出了一个通过语言和交互手势关联来建模多模态对话轮次组织的框架，基于语用框架如何被概念化和唤起的分析，并在Frame2数据集中增加了手势标注来验证


<details>
  <summary>Details</summary>
Motivation: 填补对话轮次组织中特定策略（特别是手势）在机器学习可用数据集中的编码空白，研究面对面对话中手势如何用于传递、获取和保持对话轮次

Method: 开发了标注方法，在已标注语义框架的多模态数据集Frame2基础上增加语用框架标注，分析巴西电视剧中的10集内容，观察非实验室环境下的交互手势使用

Result: 确认了面对面对话中手势作为对话轮次管理工具的使用，发现了之前未记录的手势变体，证明了语用框架标注有助于更深入理解人类认知和语言

Conclusion: 手势使用源于语用框架的概念化，涉及心理空间、概念整合和概念隐喻，语用框架标注为理解人类认知和语言提供了重要洞见

Abstract: This paper proposes a framework for modeling multimodal conversational turn
organization via the proposition of correlations between language and
interactive gestures, based on analysis as to how pragmatic frames are
conceptualized and evoked by communicators. As a means to provide evidence for
the analysis, we developed an annotation methodology to enrich a multimodal
dataset (annotated for semantic frames) with pragmatic frames modeling
conversational turn organization. Although conversational turn organization has
been studied by researchers from diverse fields, the specific strategies,
especially gestures used by communicators, had not yet been encoded in a
dataset that can be used for machine learning. To fill this gap, we enriched
the Frame2 dataset with annotations of gestures used for turn organization. The
Frame2 dataset features 10 episodes from the Brazilian TV series Pedro Pelo
Mundo annotated for semantic frames evoked in both video and text. This dataset
allowed us to closely observe how communicators use interactive gestures
outside a laboratory, in settings, to our knowledge, not previously recorded in
related literature. Our results have confirmed that communicators involved in
face-to-face conversation make use of gestures as a tool for passing, taking
and keeping conversational turns, and also revealed variations of some gestures
that had not been documented before. We propose that the use of these gestures
arises from the conceptualization of pragmatic frames, involving mental spaces,
blending and conceptual metaphors. In addition, our data demonstrate that the
annotation of pragmatic frames contributes to a deeper understanding of human
cognition and language.

</details>


### [28] [Topic-Guided Reinforcement Learning with LLMs for Enhancing Multi-Document Summarization](https://arxiv.org/abs/2509.09852)
*Chuyuan Li,Austin Xu,Shafiq Joty,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 提出基于主题引导的强化学习方法，通过主题奖励机制在多文档摘要中提升内容选择效果，在Multi-News和Multi-XScience数据集上表现优于基线方法


<details>
  <summary>Details</summary>
Motivation: 多文档摘要中如何有效整合多个来源的信息同时保持连贯性和主题相关性是一个关键挑战，虽然大语言模型在单文档摘要中表现优异，但在多文档摘要方面仍有改进空间

Method: 首先证明显式使用主题标签提示模型可以增强生成摘要的信息量，在此基础上提出在GRPO框架内使用新颖的主题奖励来衡量生成摘要与源文档之间的主题对齐度

Result: 在Multi-News和Multi-XScience数据集上的实验结果表明，该方法持续优于强基线方法

Conclusion: 利用主题线索在多文档摘要中是有效的，主题引导的强化学习方法能够显著提升多文档摘要的内容选择质量

Abstract: A key challenge in Multi-Document Summarization (MDS) is effectively
integrating information from multiple sources while maintaining coherence and
topical relevance. While Large Language Models have shown impressive results in
single-document summarization, their performance on MDS still leaves room for
improvement. In this paper, we propose a topic-guided reinforcement learning
approach to improve content selection in MDS. We first show that explicitly
prompting models with topic labels enhances the informativeness of the
generated summaries. Building on this insight, we propose a novel topic reward
within the Group Relative Policy Optimization (GRPO) framework to measure topic
alignment between the generated summary and source documents. Experimental
results on the Multi-News and Multi-XScience datasets demonstrate that our
method consistently outperforms strong baselines, highlighting the
effectiveness of leveraging topical cues in MDS.

</details>


### [29] [Emulating Public Opinion: A Proof-of-Concept of AI-Generated Synthetic Survey Responses for the Chilean Case](https://arxiv.org/abs/2509.09871)
*Bastián González-Bustamante,Nando Verelst,Carla Cisternas*

Main category: cs.CL

TL;DR: 该研究评估了大型语言模型生成合成调查回复的可靠性，发现LLM在信任项目上表现优异，GPT-4o等模型表现相当，但与人类回答仍存在项目级异质性。


<details>
  <summary>Details</summary>
Motivation: 评估LLM生成合成调查回复的可靠性，检验其是否能准确模拟人类回答行为，同时避免复制训练数据中的社会刻板印象和偏见。

Method: 使用128个提示-模型-问题三元组生成189,696个合成配置文件，通过元分析评估准确性、精确度、召回率和F1分数等性能指标，测试关键社会人口统计维度上的偏差。

Result: 合成回复在信任项目上表现优异（F1分数和准确率>0.90）；GPT-4o、GPT-4o-mini和Llama 4 Maverick表现相当；45-59岁受访者的合成-人类对齐度最高。

Conclusion: LLM生成的合成样本能够近似概率样本的回答，但仍存在显著的项目级异质性，需要仔细校准和额外的分布测试来确保算法保真度和减少误差。

Abstract: Large Language Models (LLMs) offer promising avenues for methodological and
applied innovations in survey research by using synthetic respondents to
emulate human answers and behaviour, potentially mitigating measurement and
representation errors. However, the extent to which LLMs recover aggregate item
distributions remains uncertain and downstream applications risk reproducing
social stereotypes and biases inherited from training data. We evaluate the
reliability of LLM-generated synthetic survey responses against ground-truth
human responses from a Chilean public opinion probabilistic survey.
Specifically, we benchmark 128 prompt-model-question triplets, generating
189,696 synthetic profiles, and pool performance metrics (i.e., accuracy,
precision, recall, and F1-score) in a meta-analysis across 128
question-subsample pairs to test for biases along key sociodemographic
dimensions. The evaluation spans OpenAI's GPT family and o-series reasoning
models, as well as Llama and Qwen checkpoints. Three results stand out. First,
synthetic responses achieve excellent performance on trust items (F1-score and
accuracy > 0.90). Second, GPT-4o, GPT-4o-mini and Llama 4 Maverick perform
comparably on this task. Third, synthetic-human alignment is highest among
respondents aged 45-59. Overall, LLM-based synthetic samples approximate
responses from a probabilistic sample, though with substantial item-level
heterogeneity. Capturing the full nuance of public opinion remains challenging
and requires careful calibration and additional distributional tests to ensure
algorithmic fidelity and reduce errors.

</details>


### [30] [Large Language Models Meet Legal Artificial Intelligence: A Survey](https://arxiv.org/abs/2509.09969)
*Zhitian Hou,Zihan Ye,Nanli Zeng,Tianyong Hao,Kun Zeng*

Main category: cs.CL

TL;DR: 本文对法律AI领域的大语言模型进行了系统性综述，涵盖了16个法律LLM系列、47个基于LLM的法律任务框架、15个基准测试和29个数据集，并分析了挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在Legal AI领域的快速发展，需要系统性地梳理和总结现有研究成果，为初学者提供系统介绍并推动该领域的未来发展。

Method: 通过全面调研和综述的方法，收集和分析16个法律LLM系列、47个LLM框架、15个基准测试和29个数据集，并进行系统性整理和分析。

Result: 构建了一个完整的法律AI资源体系，包括模型、框架、基准和数据集，为研究者和实践者提供了全面的参考资源。

Conclusion: LLM在法律AI领域具有巨大潜力，但仍面临诸多挑战，需要进一步研究和发展。该综述为领域发展提供了重要基础和未来方向指引。

Abstract: Large Language Models (LLMs) have significantly advanced the development of
Legal Artificial Intelligence (Legal AI) in recent years, enhancing the
efficiency and accuracy of legal tasks. To advance research and applications of
LLM-based approaches in legal domain, this paper provides a comprehensive
review of 16 legal LLMs series and 47 LLM-based frameworks for legal tasks, and
also gather 15 benchmarks and 29 datasets to evaluate different legal
capabilities. Additionally, we analyse the challenges and discuss future
directions for LLM-based approaches in the legal domain. We hope this paper
provides a systematic introduction for beginners and encourages future research
in this field. Resources are available at
https://github.com/ZhitianHou/LLMs4LegalAI.

</details>


### [31] [CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China](https://arxiv.org/abs/2509.09990)
*Guixian Xu,Zeli Su,Ziyin Zhang,Jianing Liu,XU Han,Ting Zhang,Yushuang Dong*

Main category: cs.CL

TL;DR: 该论文提出了一个针对中国少数民族语言（藏语、维吾尔语、蒙古语）的新闻标题生成数据集CMHG，包含20万条数据，并提供了由母语者标注的高质量测试集作为基准。


<details>
  <summary>Details</summary>
Motivation: 中国少数民族语言由于书写系统与国际标准不同，导致相关语料库严重缺乏，特别是在监督学习任务如标题生成方面存在明显空白。

Method: 构建了CMHG数据集，包含10万条藏语数据和各5万条维吾尔语、蒙古语数据，专门用于标题生成任务，并提供了由母语者标注的高质量测试集。

Result: 成功创建了一个包含20万条数据的少数民族语言标题生成数据集，为相关研究提供了宝贵的资源。

Conclusion: 该数据集将成为推进中国少数民族语言标题生成研究的重要资源，并为相关基准测试的发展做出贡献。

Abstract: Minority languages in China, such as Tibetan, Uyghur, and Traditional
Mongolian, face significant challenges due to their unique writing systems,
which differ from international standards. This discrepancy has led to a severe
lack of relevant corpora, particularly for supervised tasks like headline
generation. To address this gap, we introduce a novel dataset, Chinese Minority
Headline Generation (CMHG), which includes 100,000 entries for Tibetan, and
50,000 entries each for Uyghur and Mongolian, specifically curated for headline
generation tasks. Additionally, we propose a high-quality test set annotated by
native speakers, designed to serve as a benchmark for future research in this
domain. We hope this dataset will become a valuable resource for advancing
headline generation in Chinese minority languages and contribute to the
development of related benchmarks.

</details>


### [32] [Unsupervised Hallucination Detection by Inspecting Reasoning Processes](https://arxiv.org/abs/2509.10004)
*Ponhvoan Srey,Xiaobao Wu,Anh Tuan Luu*

Main category: cs.CL

TL;DR: IRIS是一个无监督幻觉检测框架，利用LLM内部表征来识别生成内容的事实正确性，无需标注数据，计算成本低且适用于实时检测


<details>
  <summary>Details</summary>
Motivation: 现有无监督方法依赖与事实正确性无关的代理信号，导致检测偏向表面特征，限制了跨数据集和场景的泛化能力

Method: 通过提示LLM仔细验证给定陈述的真实性，获取其情境化嵌入作为训练特征，并将每个响应的不确定性作为真实性的软伪标签

Result: 实验结果表明IRIS consistently outperforms existing unsupervised methods，在少量训练数据下表现良好

Conclusion: IRIS是一个完全无监督、计算成本低的框架，能够有效检测LLM生成的幻觉内容，适用于实时应用场景

Abstract: Unsupervised hallucination detection aims to identify hallucinated content
generated by large language models (LLMs) without relying on labeled data.
While unsupervised methods have gained popularity by eliminating
labor-intensive human annotations, they frequently rely on proxy signals
unrelated to factual correctness. This misalignment biases detection probes
toward superficial or non-truth-related aspects, limiting generalizability
across datasets and scenarios. To overcome these limitations, we propose IRIS,
an unsupervised hallucination detection framework, leveraging internal
representations intrinsic to factual correctness. IRIS prompts the LLM to
carefully verify the truthfulness of a given statement, and obtain its
contextualized embedding as informative features for training. Meanwhile, the
uncertainty of each response is considered a soft pseudolabel for truthfulness.
Experimental results demonstrate that IRIS consistently outperforms existing
unsupervised methods. Our approach is fully unsupervised, computationally low
cost, and works well even with few training data, making it suitable for
real-time detection.

</details>


### [33] [Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs](https://arxiv.org/abs/2509.10010)
*Adnan Ahmad,Philine Kowol,Stefan Hillmann,Sebastian Möller*

Main category: cs.CL

TL;DR: 本文对开源大语言模型在多标签意图分类任务上的性能进行了全面分析，比较了LLama2-7B、Mistral-7B和Yi-6B在MultiWOZ 2.1数据集上的few-shot表现，并与BERT监督学习基线进行对比。


<details>
  <summary>Details</summary>
Motivation: 研究开源大语言模型在消费级硬件上处理复杂多意图对话分类任务的有效性，为任务导向聊天机器人的自然语言理解提供实用框架。

Method: 使用MultiWOZ 2.1数据集，在few-shot设置下（提示中包含20个示例）测试三个开源LLM模型，并与基于BERT的监督分类器进行性能比较，评估指标包括准确率、精确率、召回率和多种F1分数。

Result: Mistral-7B-v0.1在14个意图类别中的11个上F分数表现最佳，加权平均F1为0.50，具有较低的Hamming Loss和较高的Jaccard相似度。但BERT监督分类器的性能仍优于最佳few-shot生成式LLM。

Conclusion: 虽然Mistral-7B在few-shot设置中表现最佳，但监督学习的BERT模型在性能上仍具有优势。研究为小型开源LLM在复杂多意图对话检测中的应用提供了实用框架。

Abstract: In this paper, we provide an extensive analysis of multi-label intent
classification using Large Language Models (LLMs) that are open-source,
publicly available, and can be run in consumer hardware. We use the MultiWOZ
2.1 dataset, a benchmark in the dialogue system domain, to investigate the
efficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf,
Mistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot
setup, giving 20 examples in the prompt with some instructions. Our approach
focuses on the differences in performance of these models across several
performance metrics by methodically assessing these models on multi-label
intent classification tasks. Additionally, we compare the performance of the
instruction-based fine-tuning approach with supervised learning using the
smaller transformer model BertForSequenceClassification as a baseline. To
evaluate the performance of the models, we use evaluation metrics like
accuracy, precision, and recall as well as micro, macro, and weighted F1 score.
We also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1
outperforms two other generative models on 11 intent classes out of 14 in terms
of F-Score, with a weighted average of 0.50. It also has relatively lower
Humming Loss and higher Jaccard Similarity, making it the winning model in the
few-shot setting. We find BERT based supervised classifier having superior
performance compared to the best performing few-shot generative LLM. The study
provides a framework for small open-source LLMs in detecting complex
multi-intent dialogues, enhancing the Natural Language Understanding aspect of
task-oriented chatbots.

</details>


### [34] [Linguistic trajectories of bipolar disorder on social media](https://arxiv.org/abs/2509.10035)
*Laurin Plank,Armin Zlomuzica*

Main category: cs.CL

TL;DR: 通过社交媒体语言分析双相情感障碍的诊断前后语言变化，发现诊断后出现广泛的语言改变，包括情绪障碍、精神共病等特征，并观察到长达20年的周期性情绪变化


<details>
  <summary>Details</summary>
Motivation: 传统临床评估双相情感障碍规模有限，而社交媒体语言分析具有高时间分辨率和纵向范围的优势，可以更好地研究诊断前后的语言轨迹变化

Method: 引入确定用户诊断时间的方法，分析从诊断前3年到诊断后21年的语言轨迹，与单相抑郁症用户和非受影响用户进行对比

Result: 双相情感障碍诊断伴随广泛的语言改变，反映情绪障碍、精神共病、物质滥用等特征；诊断后20年内观察到反复出现的情绪相关语言变化，具有明显的12个月周期性；女性用户可能表现出更强的周期性

Conclusion: 研究证实了双相情感障碍急性和慢性期的语言改变，验证并扩展了利用社交媒体进行心理健康可扩展监测的最新努力

Abstract: Language provides valuable markers of affective disorders such as bipolar
disorder (BD), yet clinical assessments remain limited in scale. In response,
analyses of social media (SM) language have gained prominence due to their high
temporal resolution and longitudinal scope. Here, we introduce a method to
determine the timing of users' diagnoses and apply it to study language
trajectories from 3 years before to 21 years after BD diagnosis - contrasted
with uses reporting unipolar depression (UD) and non-affected users (HC). We
show that BD diagnosis is accompanied by pervasive linguistic alterations
reflecting mood disturbance, psychiatric comorbidity, substance abuse,
hospitalization, medical comorbidities, unusual thought content, and
disorganized thought. We further observe recurring mood-related language
changes across two decades after the diagnosis, with a pronounced 12-month
periodicity suggestive of seasonal mood episodes. Finally, trend-level evidence
suggests an increased periodicity in users estimated to be female. In sum, our
findings provide evidence for language alterations in the acute and chronic
phase of BD. This validates and extends recent efforts leveraging SM for
scalable monitoring of mental health.

</details>


### [35] [!MSA at BAREC Shared Task 2025: Ensembling Arabic Transformers for Readability Assessment](https://arxiv.org/abs/2509.10040)
*Mohamed Basem,Mohamed Younes,Seif Ahmed,Abdelrahman Moustafa*

Main category: cs.CL

TL;DR: MSA团队在BAREC 2025阿拉伯语细粒度可读性评估共享任务中取得六项第一，通过集成四种Transformer模型、处理类别不平衡和数据稀缺问题，实现了87.5%的QWK分数


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语可读性评估中的类别不平衡和数据稀缺问题，提升细粒度可读性预测的准确性

Method: 使用四种Transformer模型（AraBERTv2、AraELECTRA、MARBERT、CAMeLBERT）集成，采用加权训练、SAMER语料库重标注、Gemini 2.5 Flash生成约10,000个稀有级别样本的合成数据，并进行针对性后处理

Result: 在句子级别达到87.5%的QWK，文档级别达到87.4%的QWK，后处理带来6.3%的QWK增益

Conclusion: 模型多样性、损失函数多样性、置信度融合和智能数据增强对阿拉伯语可读性预测具有显著效果

Abstract: We present MSAs winning system for the BAREC 2025 Shared Task on fine-grained
Arabic readability assessment, achieving first place in six of six tracks. Our
approach is a confidence-weighted ensemble of four complementary transformer
models (AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT) each fine-tuned with
distinct loss functions to capture diverse readability signals. To tackle
severe class imbalance and data scarcity, we applied weighted training,
advanced preprocessing, SAMER corpus relabeling with our strongest model, and
synthetic data generation via Gemini 2.5 Flash, adding about 10,000 rare-level
samples. A targeted post-processing step corrected prediction distribution
skew, delivering a 6.3 percent Quadratic Weighted Kappa (QWK) gain. Our system
reached 87.5 percent QWK at the sentence level and 87.4 percent at the document
level, demonstrating the power of model and loss diversity, confidence-informed
fusion, and intelligent augmentation for robust Arabic readability prediction.

</details>


### [36] [Established Psychometric vs. Ecologically Valid Questionnaires: Rethinking Psychological Assessments in Large Language Models](https://arxiv.org/abs/2509.10078)
*Dongmin Choi,Woojung Song,Jongwook Han,Eun-Ju Lee,Yohan Jo*

Main category: cs.CL

TL;DR: 本文比较了传统心理测量问卷与生态效度问卷在测量大语言模型个性特征时的差异，发现传统问卷存在测量不稳定、产生误导性结果等问题，建议避免使用传统心理问卷评估LLMs。


<details>
  <summary>Details</summary>
Motivation: 现有研究使用人类设计的心理问卷（如BFI、PVQ）来测量大语言模型的个性特征和价值观，但这些问卷缺乏生态效度，无法反映LLMs在真实用户查询场景中的文本生成行为。需要明确两种问卷的差异及其提供的洞察。

Method: 对两种类型的问卷进行全面的比较分析：传统心理测量问卷和生态效度问卷，评估它们在测量LLMs个性特征时的表现差异。

Result: 分析发现传统问卷存在四个主要问题：1）产生与生态效度问卷显著不同的LLMs特征剖面；2）项目数量不足导致测量不稳定；3）造成LLMs具有稳定构念的误导印象；4）对角色提示的LLMs产生夸大的特征剖面。

Conclusion: 研究警示不要使用传统心理问卷来评估大语言模型，因为这些问卷缺乏生态效度，无法准确反映LLMs在真实应用场景中的心理特征表现。

Abstract: Researchers have applied established psychometric questionnaires (e.g., BFI,
PVQ) to measure the personality traits and values reflected in the responses of
Large Language Models (LLMs). However, concerns have been raised about applying
these human-designed questionnaires to LLMs. One such concern is their lack of
ecological validity--the extent to which survey questions adequately reflect
and resemble real-world contexts in which LLMs generate texts in response to
user queries. However, it remains unclear how established questionnaires and
ecologically valid questionnaires differ in their outcomes, and what insights
these differences may provide. In this paper, we conduct a comprehensive
comparative analysis of the two types of questionnaires. Our analysis reveals
that established questionnaires (1) yield substantially different profiles of
LLMs from ecologically valid ones, deviating from the psychological
characteristics expressed in the context of user queries, (2) suffer from
insufficient items for stable measurement, (3) create misleading impressions
that LLMs possess stable constructs, and (4) yield exaggerated profiles for
persona-prompted LLMs. Overall, our work cautions against the use of
established psychological questionnaires for LLMs. Our code will be released
upon publication.

</details>


### [37] [Querying Climate Knowledge: Semantic Retrieval for Scientific Discovery](https://arxiv.org/abs/2509.10087)
*Mustapha Adamu,Qi Zhang,Huitong Pan,Longin Jan Latecki,Eduard C. Dragut*

Main category: cs.CL

TL;DR: 构建了一个气候科学领域的知识图谱，支持语义查询和RAG系统集成，帮助研究人员发现模型、数据集和区域之间的精确联系


<details>
  <summary>Details</summary>
Motivation: 气候科学文献日益复杂和庞大，研究人员难以跨模型、数据集、区域和变量找到相关信息，需要更有效的知识访问方式

Method: 从气候出版物和科学文本构建领域特定知识图谱，支持Cypher查询，并与大语言模型集成构建RAG系统

Result: 知识图谱能够回答关于模型验证、数据集使用等精确问题，提高了气候相关问答的透明度和可靠性

Conclusion: 这项工作展示了知识图谱在气候研究中的实际应用价值，为研究人员和模型开发者提供了准确、情境化的科学信息访问方式

Abstract: The growing complexity and volume of climate science literature make it
increasingly difficult for researchers to find relevant information across
models, datasets, regions, and variables. This paper introduces a
domain-specific Knowledge Graph (KG) built from climate publications and
broader scientific texts, aimed at improving how climate knowledge is accessed
and used. Unlike keyword based search, our KG supports structured, semantic
queries that help researchers discover precise connections such as which models
have been validated in specific regions or which datasets are commonly used
with certain teleconnection patterns. We demonstrate how the KG answers such
questions using Cypher queries, and outline its integration with large language
models in RAG systems to improve transparency and reliability in
climate-related question answering. This work moves beyond KG construction to
show its real world value for climate researchers, model developers, and others
who rely on accurate, contextual scientific information.

</details>


### [38] [Arabic Large Language Models for Medical Text Generation](https://arxiv.org/abs/2509.10095)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Ammar Mohammed*

Main category: cs.CL

TL;DR: 本研究提出了一种针对阿拉伯语医疗文本生成的LLM微调方法，通过收集社交媒体医疗对话数据，微调Mistral-7B等模型，在医疗咨询、诊断和药物推荐方面取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 现有医院管理系统缺乏对不规则输入和少数语言提供准确实时医疗建议的能力，特别是在阿拉伯语环境下。为解决医疗资源紧张、过度拥挤和紧急医疗服务可用性差等问题，需要开发能够处理多方言阿拉伯语的医疗AI系统。

Method: 收集社交媒体上患者与医生之间的真实医疗对话数据，进行数据清洗和预处理以处理多种阿拉伯方言。微调先进的生成模型（Mistral-7B-Instruct-v0.2、LLaMA-2-7B和GPT-2 Medium），优化系统生成可靠医疗文本的能力。

Result: 微调后的Mistral-7B模型表现最佳，在精确率、召回率和F1分数上的平均BERT Score值分别达到68.5%、69.08%和68.5%。比较基准测试和定性评估验证了系统对非正式输入产生连贯相关医疗回复的能力。

Conclusion: 该研究展示了生成式AI在医院管理系统中的潜力，为全球医疗挑战提供了可扩展和适应性强的解决方案，特别是在语言和文化多样化的环境中。

Abstract: Efficient hospital management systems (HMS) are critical worldwide to address
challenges such as overcrowding, limited resources, and poor availability of
urgent health care. Existing methods often lack the ability to provide
accurate, real-time medical advice, particularly for irregular inputs and
underrepresented languages. To overcome these limitations, this study proposes
an approach that fine-tunes large language models (LLMs) for Arabic medical
text generation. The system is designed to assist patients by providing
accurate medical advice, diagnoses, drug recommendations, and treatment plans
based on user input. The research methodology required the collection of a
unique dataset from social media platforms, capturing real-world medical
conversations between patients and doctors. The dataset, which includes patient
complaints together with medical advice, was properly cleaned and preprocessed
to account for multiple Arabic dialects. Fine-tuning state-of-the-art
generative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2
Medium, optimized the system's ability to generate reliable medical text.
Results from evaluations indicate that the fine-tuned Mistral-7B model
outperformed the other models, achieving average BERT (Bidirectional Encoder
Representations from Transformers) Score values in precision, recall, and
F1-scores of 68.5\%, 69.08\%, and 68.5\%, respectively. Comparative
benchmarking and qualitative assessments validate the system's ability to
produce coherent and relevant medical replies to informal input. This study
highlights the potential of generative artificial intelligence (AI) in
advancing HMS, offering a scalable and adaptable solution for global healthcare
challenges, especially in linguistically and culturally diverse environments.

</details>


### [39] [Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing Generative AI with Synthetic Patient Records](https://arxiv.org/abs/2509.10108)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Khaled Shaban*

Main category: cs.CL

TL;DR: 本研究提出了一种可扩展的合成数据增强策略，使用ChatGPT-4o和Gemini 2.5 Pro生成了8万条阿拉伯语医疗问答对，将训练语料扩展到10万条记录，显著提升了阿拉伯医疗聊天机器人的性能。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语医疗聊天机器人的发展受到大规模高质量标注数据集稀缺的限制，先前基于2万条社交媒体医患交互数据训练的模型在可扩展性和泛化能力方面存在局限。

Method: 使用ChatGPT-4o和Gemini 2.5 Pro生成8万条上下文相关且医学连贯的合成问答对，经过语义过滤和人工验证后整合到训练流程中，对包括Mistral-7B和AraGPT2在内的5个LLM进行微调。

Result: ChatGPT-4o生成的数据在所有模型中始终获得更高的F1分数和更少的幻觉现象，消融研究进一步证实了ChatGPT-4o生成数据的有效性。

Conclusion: 合成数据增强是提升低资源医疗NLP领域特定语言模型性能的可行解决方案，为构建更具包容性、可扩展性和准确性的阿拉伯语医疗聊天机器人系统铺平了道路。

Abstract: The development of medical chatbots in Arabic is significantly constrained by
the scarcity of large-scale, high-quality annotated datasets. While prior
efforts compiled a dataset of 20,000 Arabic patient-doctor interactions from
social media to fine-tune large language models (LLMs), model scalability and
generalization remained limited. In this study, we propose a scalable synthetic
data augmentation strategy to expand the training corpus to 100,000 records.
Using advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated
80,000 contextually relevant and medically coherent synthetic question-answer
pairs grounded in the structure of the original dataset. These synthetic
samples were semantically filtered, manually validated, and integrated into the
training pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2,
and evaluated their performance using BERTScore metrics and expert-driven
qualitative assessments. To further analyze the effectiveness of synthetic
sources, we conducted an ablation study comparing ChatGPT-4o and
Gemini-generated data independently. The results showed that ChatGPT-4o data
consistently led to higher F1-scores and fewer hallucinations across all
models. Overall, our findings demonstrate the viability of synthetic
augmentation as a practical solution for enhancing domain-specific language
models in-low resource medical NLP, paving the way for more inclusive,
scalable, and accurate Arabic healthcare chatbot systems.

</details>


### [40] [Prominence-aware automatic speech recognition for conversational speech](https://arxiv.org/abs/2509.10116)
*Julian Linke,Barbara Schuppler*

Main category: cs.CL

TL;DR: 该论文研究了结合重音检测和语音识别的显著性感知自动语音识别系统，针对奥地利德语对话开发了基于wav2vec2的重音检测器，并训练了同时转录单词及其重音水平的ASR系统。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发能够同时处理语音转录和重音检测的自动语音识别系统，为语言学研究和基于韵律的对话系统提供支持。

Method: 方法包括：1）微调wav2vec2模型进行词级重音分类；2）使用检测器自动标注大型语料库中的韵律重音；3）训练新颖的显著性感知ASR系统，同时转录单词和重音水平。

Result: 结果显示：集成重音信息并未改变ASR系统性能（与基线相当），但在识别正确的语句中重音检测准确率达到85.53%。基于transformer的模型能有效编码韵律信息。

Conclusion: 结论是该方法为韵律增强的ASR提供了新颖贡献，展示了transformer模型编码韵律信息的有效性，在语言学研究和韵律感知对话系统中具有应用潜力。

Abstract: This paper investigates prominence-aware automatic speech recognition (ASR)
by combining prominence detection and speech recognition for conversational
Austrian German. First, prominence detectors were developed by fine-tuning
wav2vec2 models to classify word-level prominence. The detector was then used
to automatically annotate prosodic prominence in a large corpus. Based on those
annotations, we trained novel prominence-aware ASR systems that simultaneously
transcribe words and their prominence levels. The integration of prominence
information did not change performance compared to our baseline ASR system,
while reaching a prominence detection accuracy of 85.53% for utterances where
the recognized word sequence was correct. This paper shows that
transformer-based models can effectively encode prosodic information and
represents a novel contribution to prosody-enhanced ASR, with potential
applications for linguistic research and prosody-informed dialogue systems.

</details>


### [41] [Population-Aligned Persona Generation for LLM-based Social Simulation](https://arxiv.org/abs/2509.10127)
*Zhengyu Hu,Zheyuan Xiao,Max Xiong,Yuxuan Lei,Tianfu Wang,Jianxun Lian,Kaize Ding,Ziang Xiao,Nicholas Jing Yuan,Xing Xie*

Main category: cs.CL

TL;DR: 提出一个系统框架，用于生成高质量、与人口分布对齐的AI角色集，以减少大语言模型社会模拟中的偏见问题


<details>
  <summary>Details</summary>
Motivation: 现有LLM社会模拟研究主要关注代理框架和模拟环境设计，忽视了角色生成复杂性以及非代表性角色集带来的潜在偏见问题

Method: 利用LLM从长期社交媒体数据生成叙事角色，通过质量评估筛选，应用重要性采样实现与心理测量分布（如大五人格）的全局对齐，并引入任务特定模块适应目标子群体

Result: 实验表明该方法显著减少了群体层面的偏见，能够为广泛的研究和政策应用提供准确灵活的社会模拟

Conclusion: 该框架为LLM驱动的社会模拟提供了高质量、人口对齐的角色集生成方法，解决了现有研究中的偏见问题

Abstract: Recent advances in large language models (LLMs) have enabled human-like
social simulations at unprecedented scale and fidelity, offering new
opportunities for computational social science. A key challenge, however, is
the construction of persona sets that authentically represent the diversity and
distribution of real-world populations. Most existing LLM-based social
simulation studies focus primarily on designing agentic frameworks and
simulation environments, often overlooking the complexities of persona
generation and the potential biases introduced by unrepresentative persona
sets. In this paper, we propose a systematic framework for synthesizing
high-quality, population-aligned persona sets for LLM-driven social simulation.
Our approach begins by leveraging LLMs to generate narrative personas from
long-term social media data, followed by rigorous quality assessment to filter
out low-fidelity profiles. We then apply importance sampling to achieve global
alignment with reference psychometric distributions, such as the Big Five
personality traits. To address the needs of specific simulation contexts, we
further introduce a task-specific module that adapts the globally aligned
persona set to targeted subpopulations. Extensive experiments demonstrate that
our method significantly reduces population-level bias and enables accurate,
flexible social simulation for a wide range of research and policy
applications.

</details>


### [42] [Towards Reliable and Interpretable Document Question Answering via VLMs](https://arxiv.org/abs/2509.10129)
*Alessio Chen,Simone Giovannini,Andrea Gemelli,Fabio Coppini,Simone Marinai*

Main category: cs.CL

TL;DR: DocExplainerV0是一个即插即用的边界框预测模块，将答案生成与空间定位解耦，旨在解决视觉语言模型在文档理解中准确位置定位的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在文档理解方面表现出强大能力，但准确在文档中定位答案仍然是一个主要挑战，这限制了模型的可解释性和实际应用。

Method: 引入DocExplainerV0模块，该模块与现有VLM解耦，专门负责边界框预测，适用于包括无法微调的专有系统在内的各种VLM。

Result: 系统评估显示文本准确性与空间定位之间存在显著差距，正确答案往往缺乏可靠的位置定位，该框架为此类问题建立了基准。

Conclusion: DocExplainerV0为解决文档信息提取中的空间定位问题提供了标准化框架，为未来开发更可解释和鲁棒的VLM奠定了基础。

Abstract: Vision-Language Models (VLMs) have shown strong capabilities in document
understanding, particularly in identifying and extracting textual information
from complex documents. Despite this, accurately localizing answers within
documents remains a major challenge, limiting both interpretability and
real-world applicability. To address this, we introduce
\textit{DocExplainerV0}, a plug-and-play bounding-box prediction module that
decouples answer generation from spatial localization. This design makes it
applicable to existing VLMs, including proprietary systems where fine-tuning is
not feasible. Through systematic evaluation, we provide quantitative insights
into the gap between textual accuracy and spatial grounding, showing that
correct answers often lack reliable localization. Our standardized framework
highlights these shortcomings and establishes a benchmark for future research
toward more interpretable and robust document information extraction VLMs.

</details>


### [43] [Benchmark of stylistic variation in LLM-generated texts](https://arxiv.org/abs/2509.10179)
*Jiří Milička,Anna Marklová,Václav Cvrček*

Main category: cs.CL

TL;DR: 该研究使用Biber多维分析法比较人类写作与大型语言模型生成文本的语域差异，创建了AI-Brown和AI-Koditex语料库，分析了16个前沿模型在不同设置下的表现，并建立了可解释的模型评估基准。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索大型语言模型生成文本与人类写作在语域特征上的系统性差异，特别是由于前沿LLMs训练数据中非英语语言的代表性不足问题。

Method: 采用Biber多维分析法，使用AI-Brown语料库（对应BE-21布朗家族语料库）和AI-Koditex捷克语料库，分析16个前沿模型在不同提示和设置下的文本生成表现，重点比较基础模型和指令调优模型的差异。

Result: 研究发现LLMs在多个语域维度上与人类写作存在显著系统性差异，并建立了可用于模型比较和排名的可解释维度基准。

Conclusion: 该研究为评估LLMs文本生成质量提供了新的多维分析框架，揭示了模型与人类写作的语域差异特征，对模型改进和评估具有重要意义。

Abstract: This study investigates the register variation in texts written by humans and
comparable texts produced by large language models (LLMs). Biber's
multidimensional analysis (MDA) is applied to a sample of human-written texts
and AI-created texts generated to be their counterparts to find the dimensions
of variation in which LLMs differ most significantly and most systematically
from humans. As textual material, a new LLM-generated corpus AI-Brown is used,
which is comparable to BE-21 (a Brown family corpus representing contemporary
British English). Since all languages except English are underrepresented in
the training data of frontier LLMs, similar analysis is replicated on Czech
using AI-Koditex corpus and Czech multidimensional model. Examined were 16
frontier models in various settings and prompts, with emphasis placed on the
difference between base models and instruction-tuned models. Based on this, a
benchmark is created through which models can be compared with each other and
ranked in interpretable dimensions.

</details>


### [44] [Incongruent Positivity: When Miscalibrated Positivity Undermines Online Supportive Conversations](https://arxiv.org/abs/2509.10184)
*Leen Almajed,Abeer ALdayel*

Main category: cs.CL

TL;DR: 本研究分析了情感支持对话中不协调的积极性现象，发现在高风险情境下LLM更容易产生不现实的积极回应，提出了改进检测方法和平衡情感支持的建议。


<details>
  <summary>Details</summary>
Motivation: 研究情感支持对话中善意但可能适得其反的积极回应现象，特别是在人类和LLM生成回应中的不协调积极性问题，旨在改善在线支持性对话的情感对齐。

Method: 收集Reddit真实用户-助手对话，按情感强度分类为轻度（关系紧张、一般建议）和重度（悲伤、焦虑），使用LLM生成额外回应，微调LLM并开发弱监督多标签分类器集成（DeBERTa和MentalBERT）。

Result: 发现LLM在高风险情境下更容易通过轻视和最小化语气表现出不现实的积极性，开发的分类器在检测不协调积极性类型方面表现改善。

Conclusion: 需要超越生成通用积极回应，研究协调的支持措施来平衡积极情感与情感认同，为构建情境感知和信任保持的在线对话系统提供方向。

Abstract: In emotionally supportive conversations, well-intended positivity can
sometimes misfire, leading to responses that feel dismissive, minimizing, or
unrealistically optimistic. We examine this phenomenon of incongruent
positivity as miscalibrated expressions of positive support in both human and
LLM generated responses. To this end, we collected real user-assistant
dialogues from Reddit across a range of emotional intensities and generated
additional responses using large language models for the same context. We
categorize these conversations by intensity into two levels: Mild, which covers
relationship tension and general advice, and Severe, which covers grief and
anxiety conversations. This level of categorization enables a comparative
analysis of how supportive responses vary across lower and higher stakes
contexts. Our analysis reveals that LLMs are more prone to unrealistic
positivity through dismissive and minimizing tone, particularly in high-stakes
contexts. To further study the underlying dimensions of this phenomenon, we
finetune LLMs on datasets with strong and weak emotional reactions. Moreover,
we developed a weakly supervised multilabel classifier ensemble (DeBERTa and
MentalBERT) that shows improved detection of incongruent positivity types
across two sorts of concerns (Mild and Severe). Our findings shed light on the
need to move beyond merely generating generic positive responses and instead
study the congruent support measures to balance positive affect with emotional
acknowledgment. This approach offers insights into aligning large language
models with affective expectations in the online supportive dialogue, paving
the way toward context-aware and trust preserving online conversation systems.

</details>


### [45] [Beyond Token Limits: Assessing Language Model Performance on Long Text Classification](https://arxiv.org/abs/2509.10199)
*Miklós Sebők,Viktor Kovács,Martin Bánóczy,Daniel Møller Eriksen,Nathalie Neptune,Philippe Roussille*

Main category: cs.CL

TL;DR: 比较不同大语言模型在处理长文本分类任务（特别是法律文件）时的表现，发现专门为长文本设计的Longformer模型并无优势，开源模型表现优于GPT变体


<details>
  <summary>Details</summary>
Motivation: 现有主流语言模型（如BERT、RoBERTa）存在输入长度限制，无法有效处理像法律草案这样长达数百页的长文本分类任务

Method: 在5种语言上实验比较XLM-RoBERTa、Longformer、GPT-3.5、GPT-4模型，使用比较议程项目的21个政策主题标签进行多分类任务

Result: 专门为长文本预训练的Longformer模型没有表现出明显优势；开源模型表现优于GPT变体；类别间的支持度和内容重叠度影响长文本处理性能

Conclusion: 对于长文本分类任务，专门的长文本预训练模型并非必需，开源模型表现更佳，分类性能受类别间相似性影响较大

Abstract: The most widely used large language models in the social sciences (such as
BERT, and its derivatives, e.g. RoBERTa) have a limitation on the input text
length that they can process to produce predictions. This is a particularly
pressing issue for some classification tasks, where the aim is to handle long
input texts. One such area deals with laws and draft laws (bills), which can
have a length of multiple hundred pages and, therefore, are not particularly
amenable for processing with models that can only handle e.g. 512 tokens. In
this paper, we show results from experiments covering 5 languages with
XLM-RoBERTa, Longformer, GPT-3.5, GPT-4 models for the multiclass
classification task of the Comparative Agendas Project, which has a codebook of
21 policy topic labels from education to health care. Results show no
particular advantage for the Longformer model, pre-trained specifically for the
purposes of handling long inputs. The comparison between the GPT variants and
the best-performing open model yielded an edge for the latter. An analysis of
class-level factors points to the importance of support and substance overlaps
between specific categories when it comes to performance on long text inputs.

</details>


### [46] [SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning](https://arxiv.org/abs/2509.10208)
*Shengqiang Fu*

Main category: cs.CL

TL;DR: 提出Self Improving Faithfulness Aware Contrastive Tuning框架，通过自指导机制自动生成对比学习数据，提升LLM在知识冲突任务中的忠实性


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在知识密集型任务中由于知识冲突而倾向于依赖内部参数知识而非提供上下文的问题

Method: 使用自指导机制自动生成高质量结构化对比学习数据（锚样本、语义等价正样本、模拟不忠实场景的负样本），然后应用对比学习训练模型

Result: 在ECARE KRE和COSE KRE基准测试中，基于Llama3 8B Instruct的SI FACT模型将上下文召回率提高了6.2%，显著减少了对内部记忆的依赖

Conclusion: SI FACT在增强LLM上下文忠实性方面提供了强大的有效性和高数据效率，为构建更主动和可信的语言模型提供了实用途径

Abstract: Large Language Models often generate unfaithful responses in knowledge
intensive tasks due to knowledge conflict,that is,a preference for relying on
internal parametric knowledge rather than the provided context.To address this
issue,we propose a novel self improving framework,Self Improving Faithfulness
Aware Contrastive Tuning.The framework uses a self instruct mechanism that
allows the base LLM to automatically generate high quality,structured
contrastive learning data,including anchor samples,semantically equivalent
positive samples,and negative samples simulating unfaithful scenarios.This
approach significantly reduces the cost of manual
annotation.Subsequently,contrastive learning is applied to train the
model,enabling it to pull faithful responses closer and push unfaithful
responses farther apart in the representation space.Experiments on knowledge
conflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT
model based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2%
over the best baseline method,while significantly reducing dependence on
internal memory.The results indicate that SI FACT provides strong effectiveness
and high data efficiency in enhancing the contextual faithfulness of
LLMs,offering a practical pathway toward building more proactive and
trustworthy language models.

</details>


### [47] [Dropping Experts, Recombining Neurons: Retraining-Free Pruning for Sparse Mixture-of-Experts LLMs](https://arxiv.org/abs/2509.10377)
*Yixiao Zhou,Ziyu Zhao,Dongzhou Cheng,zhiliang wu,Jie Gui,Yi Yang,Fei Wu,Yu Cheng,Hehe Fan*

Main category: cs.CL

TL;DR: DERN是一种无需重新训练的任务无关框架，通过专家剪枝和神经元重组来减少SMoE模型的内存使用，在保持性能的同时显著降低专家数量和内存占用。


<details>
  <summary>Details</summary>
Motivation: 稀疏混合专家(SMoE)架构虽然计算高效，但仍需要加载所有专家参数，导致内存使用高且部署困难。现有方法主要关注专家级操作，忽略了神经元级结构。

Method: DERN采用三步框架：1)使用路由器统计剪枝冗余专家；2)将专家分解为神经元级片段，分配给最兼容的保留专家；3)在保留专家内合并片段构建紧凑表示。

Result: 在Mixtral、Qwen和DeepSeek SMoE模型上，DERN在50%专家稀疏度下，常识推理和MMLU基准性能提升超过5%，无需额外训练，同时大幅减少专家数量和内存使用。

Conclusion: DERN通过神经元级重组有效解决了专家间语义冲突问题，为SMoE LLMs的实际部署提供了高效解决方案，在保持性能的同时显著降低了内存需求。

Abstract: Sparse Mixture-of-Experts (SMoE) architectures are widely used in large
language models (LLMs) due to their computational efficiency. However, though
only a few experts are activated for each token, SMoE still requires loading
all expert parameters, leading to high memory usage and challenges in
deployment. Previous work has tried to reduce the overhead by pruning and
merging experts, but primarily focused on expert-level operations, leaving
neuron-level structure underexplored. We propose DERN (Dropping Experts,
Recombining Neurons), a task-agnostic and retraining-free framework for expert
pruning and reconstruction. We observe that experts are often misaligned and
contain semantic conflicts at the neuron level, which poses challenges for
direct merging. To solve this, DERN works in three steps: it first prunes
redundant experts using router statistics; then it decomposes them into
neuron-level expert segments, assigning each segment to its most compatible
retained expert; and finally, it merges segments within each retained expert to
build a compact representation. Experiments on Mixtral, Qwen, and DeepSeek SMoE
models show that DERN improves performance by more than 5% on commonsense
reasoning and MMLU benchmarks under 50% expert sparsity, without extra
training. It also greatly reduces the number of experts and memory usage,
making SMoE LLMs easier to deploy in practice.

</details>


### [48] [Is In-Context Learning Learning?](https://arxiv.org/abs/2509.10414)
*Adrian de Wynter*

Main category: cs.CL

TL;DR: 本文通过大规模分析证明，上下文学习(ICL)确实构成学习机制，但其泛化能力有限，对提示格式和分布变化敏感，自回归编码机制不够鲁棒。


<details>
  <summary>Details</summary>
Motivation: 探讨上下文学习(ICL)是否真正构成学习过程，而非仅仅是基于先验知识的推理，需要实证研究来全面表征ICL的学习特性。

Method: 进行大规模ICL分析，通过消融实验排除记忆效应、预训练影响，考察分布偏移、提示风格和措辞等因素对ICL效果的影响。

Result: ICL是有效的学习范式，但学习未见任务和泛化能力有限；当示例增多时，准确率对示例分布、模型、提示风格和语言特征不敏感，主要从提示中的规律性推断模式。

Conclusion: 自回归的临时编码机制不够鲁棒，表明其通用泛化能力有限，特别是在思维链等提示风格中对分布变化敏感。

Abstract: In-context learning (ICL) allows some autoregressive models to solve tasks
via next-token prediction and without needing further training. This has led to
claims about these model's ability to solve (learn) unseen tasks with only a
few shots (exemplars) in the prompt. However, deduction does not always imply
learning, as ICL does not explicitly encode a given observation. Instead, the
models rely on their prior knowledge and the exemplars given, if any. We argue
that, mathematically, ICL does constitute learning, but its full
characterisation requires empirical work. We then carry out a large-scale
analysis of ICL ablating out or accounting for memorisation, pretraining,
distributional shifts, and prompting style and phrasing. We find that ICL is an
effective learning paradigm, but limited in its ability to learn and generalise
to unseen tasks. We note that, in the limit where exemplars become more
numerous, accuracy is insensitive to exemplar distribution, model, prompt
style, and the input's linguistic features. Instead, it deduces patterns from
regularities in the prompt, which leads to distributional sensitivity,
especially in prompting styles such as chain-of-thought. Given the varied
accuracies on formally similar tasks, we conclude that autoregression's ad-hoc
encoding is not a robust mechanism, and suggests limited all-purpose
generalisability.

</details>


### [49] [Long Context Automated Essay Scoring with Language Models](https://arxiv.org/abs/2509.10417)
*Christopher Ormerod,Gitit Kehat*

Main category: cs.CL

TL;DR: 评估多种改进的Transformer架构模型用于长文本自动作文评分，解决传统模型因长度限制需要截断文本而导致评分有效性问题


<details>
  <summary>Details</summary>
Motivation: 传统Transformer模型有固定最大长度限制，高年级学生作文经常超过这个限制，截断处理会影响模型对组织结构等评分标准的完整评估能力

Method: 使用Kaggle ASAP 2.0数据集，评估包括XLNet、Longformer、ModernBERT、Mamba和Llama等经过架构改进的模型，这些模型能够处理更长文本

Result: 研究比较了多种能够处理长文本的改进模型在自动作文评分任务上的表现

Conclusion: 需要采用能够处理长文本的改进架构模型来解决自动作文评分中的文本截断问题，确保评分有效性

Abstract: Transformer-based language models are architecturally constrained to process
text of a fixed maximum length. Essays written by higher-grade students
frequently exceed the maximum allowed length for many popular open-source
models. A common approach to addressing this issue when using these models for
Automated Essay Scoring is to truncate the input text. This raises serious
validity concerns as it undermines the model's ability to fully capture and
evaluate organizational elements of the scoring rubric, which requires long
contexts to assess. In this study, we evaluate several models that incorporate
architectural modifications of the standard transformer architecture to
overcome these length limitations using the Kaggle ASAP 2.0 dataset. The models
considered in this study include fine-tuned versions of XLNet, Longformer,
ModernBERT, Mamba, and Llama models.

</details>


### [50] [RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment](https://arxiv.org/abs/2509.10436)
*Shadikur Rahman,Aroosa Hameed,Gautam Srivastava,Syed Muhammad Danish*

Main category: cs.CL

TL;DR: 提出云边协作的多智能体提示框架，包含GuideLLM、SolverLLM和JudgeLLM三个组件，并创建RefactorCoderQA基准测试，在多个编程领域达到76.84%的最优准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在局限性，需要优化大语言模型的推理和问题解决能力，特别是在多领域编程任务中的表现。

Method: 采用云边协作架构，包含三个专门组件：边缘部署的轻量级GuideLLM提供方法指导，云端强大SolverLLM生成代码解决方案，以及自动评估器JudgeLLM。创建RefactorCoderQA基准测试，涵盖软件工程、数据科学、机器学习和自然语言处理等多个技术领域。

Result: 微调模型RefactorCoder-MoE达到76.84%的整体准确率，显著优于领先的开源和商业基线模型。人类评估验证了生成解决方案的可解释性、准确性和实际相关性。系统级指标如吞吐量和延迟也得到评估。

Conclusion: 提出的云边协作多智能体框架有效提升了LLMs在编程任务中的性能，RefactorCoderQA基准测试为多领域编码能力评估提供了全面标准。

Abstract: To optimize the reasoning and problem-solving capabilities of Large Language
Models (LLMs), we propose a novel cloud-edge collaborative architecture that
enables a structured, multi-agent prompting framework. This framework comprises
three specialized components: GuideLLM, a lightweight model deployed at the
edge to provide methodological guidance; SolverLLM, a more powerful model
hosted in the cloud responsible for generating code solutions; and JudgeLLM, an
automated evaluator for assessing solution correctness and quality. To evaluate
and demonstrate the effectiveness of this architecture in realistic settings,
we introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate
and enhance the performance of Large Language Models (LLMs) across multi-domain
coding tasks. Motivated by the limitations of existing benchmarks,
RefactorCoderQA systematically covers various technical domains, including
Software Engineering, Data Science, Machine Learning, and Natural Language
Processing, using authentic coding challenges from Stack Overflow. Extensive
experiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves
state-of-the-art performance, significantly outperforming leading open-source
and commercial baselines with an overall accuracy of 76.84%. Human evaluations
further validate the interpretability, accuracy, and practical relevance of the
generated solutions. In addition, we evaluate system-level metrics, such as
throughput and latency, to gain deeper insights into the performance
characteristics and trade-offs of the proposed architecture.

</details>


### [51] [DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL](https://arxiv.org/abs/2509.10446)
*Rui Lu,Zhenyu Hou,Zihan Wang,Hanchen Zhang,Xiao Liu,Yujiang Li,Shi Feng,Jie Tang,Yuxiao Dong*

Main category: cs.CL

TL;DR: DeepDive是一个通过自动合成复杂问题和多轮强化学习来增强大语言模型深度搜索能力的系统，在BrowseComp基准测试中取得了开源模型的最佳性能


<details>
  <summary>Details</summary>
Motivation: 现有开源大语言模型在深度搜索任务中表现不佳，主要受限于长时程推理能力和缺乏足够难度的监督数据

Method: 1. 从开放知识图谱自动合成复杂、困难且难以找到的问题；2. 应用端到端多轮强化学习来增强大语言模型的长时程深度搜索推理能力

Result: DeepDive-32B在BrowseComp基准测试中超越了WebSailor、DeepSeek-R1-Browse和Search-o1等竞争对手，取得了开源竞争性结果。多轮RL训练显著提升了深度搜索能力，并支持测试时的工具调用扩展和并行采样

Conclusion: DeepDive通过自动数据合成和多轮强化学习的结合，有效提升了开源大语言模型在深度搜索任务中的性能，为构建更强大的深度搜索智能体提供了可行方案

Abstract: Augmenting large language models (LLMs) with browsing tools substantially
improves their potential as deep search agents to solve complex, real-world
tasks. Yet, open LLMs still perform poorly in such settings due to limited
long-horizon reasoning capacity with browsing tools and the lack of
sufficiently difficult supervised data. To address these challenges, we present
DeepDive to advance deep search agents. First, we propose a strategy to
automatically synthesize complex, difficult, and hard-to-find questions from
open knowledge graphs. Second, we apply end-to-end multi-turn reinforcement
learning (RL) to enhance LLMs' long-horizon reasoning with deep search.
Experiments show that DeepDive-32B achieves a new open-source competitive
result on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and
Search-o1. We demonstrate that multi-turn RL training improves deep search
ability and significantly contributes to the performance improvements across
multiple benchmarks. We observe that DeepDive enables test-time scaling of tool
calls and parallel sampling. All datasets, models, and code are publicly
available at https://github.com/THUDM/DeepDive.

</details>


### [52] [WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers](https://arxiv.org/abs/2509.10452)
*Akshat Pandey,Karun Kumar,Raphael Tang*

Main category: cs.CL

TL;DR: WhisTLE是一种仅使用文本数据进行预训练ASR模型领域适应的深度监督方法，通过变分自编码器建模编码器输出并微调解码器，无需额外推理成本，在多个数据集上显著降低词错误率。


<details>
  <summary>Details</summary>
Motivation: 预训练ASR模型如Whisper在未见词汇和方言上表现不佳，但在实际应用中收集语音数据困难，需要仅使用文本数据进行领域适应。

Method: 提出WhisTLE方法：1）训练变分自编码器从文本建模编码器输出；2）使用学习的文本到潜在编码器微调解码器；3）可选结合文本到语音适应；4）推理时恢复原始编码器。

Result: 在4个域外数据集和4个ASR模型上，WhisTLE结合TTS相比仅使用TTS适应相对降低12.3%的词错误率，在32个场景中的27个超越所有非WhisTLE基线方法。

Conclusion: WhisTLE提供了一种有效的文本only领域适应方法，显著提升ASR模型在未见领域的性能，且不增加推理时的计算成本。

Abstract: Pretrained automatic speech recognition (ASR) models such as Whisper perform
well but still need domain adaptation to handle unseen vocabulary and parlance.
In many real-world settings, collecting speech data is impractical,
necessitating text-only adaptation. We propose WhisTLE, a deeply supervised,
text-only adaptation method for pretrained encoder-decoder ASR models. WhisTLE
trains a variational autoencoder (VAE) to model encoder outputs from text and
fine-tunes the decoder using the learned text-to-latent encoder, optionally
combined with text-to-speech (TTS) adaptation. At inference, the original
encoder is restored, incurring no extra runtime cost. Across four out-of-domain
datasets and four ASR models, WhisTLE with TTS reduces word error rate (WER) by
12.3% relative to TTS-only adaptation and outperforms all non-WhisTLE baselines
in 27 of 32 scenarios.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [53] [VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions](https://arxiv.org/abs/2509.09716)
*Jun Zhan,Mingyang Han,Yuxuan Xie,Chen Wang,Dong Zhang,Kexin Huang,Haoxiang Shi,DongXiao Wang,Tengtao Song,Qinyuan Cheng,Shimin Li,Jun Song,Xipeng Qiu,Bo Zheng*

Main category: cs.SD

TL;DR: 该论文提出了语音风格适应(VSA)新任务，研究语音语言模型能否根据自然语言语音指令调整说话风格，并发布了双语基准VStyle和评估框架LALM as a Judge。


<details>
  <summary>Details</summary>
Motivation: 当前语音语言模型主要关注语义准确性和指令跟随，但在根据语音指令调整说话风格方面的能力研究有限，需要探索更自然的人机语音交互。

Method: 提出VSA任务，构建双语基准VStyle覆盖4类语音生成，开发LALM as a Judge框架从文本忠实度、风格遵循度和自然度三个维度进行渐进式评估。

Result: 实验表明当前商业系统和开源SLM在可控风格适应方面存在明显局限性，验证了该任务的新颖性和挑战性。

Conclusion: 通过发布VStyle基准和评估工具包，为推进以人为中心的语音交互研究提供了基础，数据集和代码已公开。

Abstract: Spoken language models (SLMs) have emerged as a unified paradigm for speech
understanding and generation, enabling natural human machine interaction.
However, while most progress has focused on semantic accuracy and instruction
following, the ability of SLMs to adapt their speaking style based on spoken
instructions has received limited attention. We introduce Voice Style
Adaptation (VSA), a new task that examines whether SLMs can modify their
speaking style, such as timbre, prosody, or persona following natural language
spoken commands. To study this task, we present VStyle, a bilingual (Chinese &
English) benchmark covering four categories of speech generation: acoustic
attributes, natural language instruction, role play, and implicit empathy. We
also introduce the Large Audio Language Model as a Judge (LALM as a Judge)
framework, which progressively evaluates outputs along textual faithfulness,
style adherence, and naturalness, ensuring reproducible and objective
assessment. Experiments on commercial systems and open source SLMs demonstrate
that current models face clear limitations in controllable style adaptation,
highlighting both the novelty and challenge of this task. By releasing VStyle
and its evaluation toolkit, we aim to provide the community with a foundation
for advancing human centered spoken interaction. The dataset and code are
publicly available at
\href{https://junzhan2000.github.io/VStyle.github.io/}{project's homepage}.

</details>


### [54] [Testing chatbots on the creation of encoders for audio conditioned image generation](https://arxiv.org/abs/2509.09717)
*Jorge E. León,Miguel Carrasco*

Main category: cs.SD

TL;DR: 研究探索利用对话机器人设计音频编码器替代Stable Diffusion 1.5中的CLIP文本编码器，实现从声音直接生成图像，但所有对话机器人的设计均未达到满意效果。


<details>
  <summary>Details</summary>
Motivation: 鉴于聊天机器人在编码任务中的流行，以及现有图像生成模型主要依赖文本编码器，本研究探索是否可以利用最先进的对话代理设计有效的音频编码器，实现从声音直接合成图像。

Method: 提示五个公开可用的聊天机器人提出神经网络架构作为音频编码器，在超过200万个相关音频-图像-文本观测数据上训练每个有效建议的编码器，并使用多种指标在验证集和测试集上进行评估。

Result: 虽然几乎所有聊天机器人都生成了有效的模型设计，但没有一个达到令人满意的结果，表明它们的音频嵌入无法与原始文本编码器的嵌入可靠对齐。Gemini音频编码器在定量指标上表现最佳，而Grok音频编码器生成更连贯的图像。

Conclusion: 研究发现聊天机器人存在共享的架构偏见，并强调了这些模型未来版本需要弥合的编码差距。建议未来研究应专注于更专业化的任务，以充分测试聊天机器人的创造力和推理能力。

Abstract: On one hand, recent advances in chatbots has led to a rising popularity in
using these models for coding tasks. On the other hand, modern generative image
models primarily rely on text encoders to translate semantic concepts into
visual representations, even when there is clear evidence that audio can be
employed as input as well. Given the previous, in this work, we explore whether
state-of-the-art conversational agents can design effective audio encoders to
replace the CLIP text encoder from Stable Diffusion 1.5, enabling image
synthesis directly from sound. We prompted five publicly available chatbots to
propose neural architectures to work as these audio encoders, with a set of
well-explained shared conditions. Each valid suggested encoder was trained on
over two million context related audio-image-text observations, and evaluated
on held-out validation and test sets using various metrics, together with a
qualitative analysis of their generated images. Although almost all chatbots
generated valid model designs, none achieved satisfactory results, indicating
that their audio embeddings failed to align reliably with those of the original
text encoder. Among the proposals, the Gemini audio encoder showed the best
quantitative metrics, while the Grok audio encoder produced more coherent
images (particularly, when paired with the text encoder). Our findings reveal a
shared architectural bias across chatbots and underscore the remaining coding
gap that needs to be bridged in future versions of these models. We also
created a public demo so everyone could study and try out these audio encoders.
Finally, we propose research questions that should be tackled in the future,
and encourage other researchers to perform more focused and highly specialized
tasks like this one, so the respective chatbots cannot make use of well-known
solutions and their creativity/reasoning is fully tested.

</details>


### [55] [AI-enabled tuberculosis screening in a high-burden setting using cough sound analysis and speech foundation models](https://arxiv.org/abs/2509.09746)
*Ning Ma,Bahman Mirheidari,Guy J. Brown,Minyoi M. Maimbolwa,Nsala Sanjase,Solomon Chifwamba,Seke Muzazu,Monde Muyoyeta,Mary Kagujje*

Main category: cs.SD

TL;DR: 使用基于语音基础模型的深度学习分析咳嗽声，结合人口统计学和临床数据，能够有效筛查结核病，达到WHO目标性能标准。


<details>
  <summary>Details</summary>
Motivation: 在结核病高负担、低资源地区，需要一种可扩展的筛查方法。人工智能可以通过分析咳嗽声中的疾病相关声学模式来实现这一目标，但之前的研究受限于数据集小、模型简单等问题。

Method: 在赞比亚两家医院招募512名参与者，分为确诊结核病组、其他呼吸道疾病组和健康对照组。使用基于语音基础模型的深度学习分类器分析咳嗽录音，并进一步结合人口统计学和临床特征进行多模态建模。

Result: 仅音频分类器对TB+/Rest的AUROC达到85.2%，TB+/OR达到80.1%。加入人口统计学和临床特征后，性能分别提升至92.1%和84.2%。多模态模型在TB+/Rest上达到90.3%敏感性和73.1%特异性。

Conclusion: 咳嗽声分析结合人口统计学和临床数据显示出作为结核病分诊工具的强大潜力，满足WHO目标产品标准。模型对背景噪声、录音时间和设备变化具有鲁棒性，检测到真实的疾病相关声学模式。

Abstract: Background
  Artificial intelligence (AI) can detect disease-related acoustic patterns in
cough sounds, offering a scalable approach to tuberculosis (TB) screening in
high-burden, low-resource settings. Previous studies have been limited by small
datasets, under-representation of symptomatic non-TB patients, reliance on
simple models, and recordings collected under idealised conditions.
  Methods
  We enrolled 512 participants at two hospitals in Zambia, grouped as
bacteriologically confirmed TB (TB+), symptomatic patients with other
respiratory diseases (OR), and healthy controls (HC). Usable cough recordings
plus demographic and clinical data were obtained from 500 participants. Deep
learning classifiers based on speech foundation models were trained on cough
recordings. The best-performing model, trained on 3-second segments, was
further evaluated with demographic and clinical features.
  Findings
  The best audio-only classifier achieved an AUROC of 85.2% for distinguishing
TB+ from all others (TB+/Rest) and 80.1% for TB+ versus OR. Adding demographic
and clinical features improved performance to 92.1% (TB+/Rest) and 84.2%
(TB+/OR). At a threshold of 0.38, the multimodal model reached 90.3%
sensitivity and 73.1% specificity for TB+/Rest, and 80.6% and 73.1% for TB+/OR.
  Interpretation
  Cough analysis using speech foundation models, especially when combined with
demographic and clinical data, showed strong potential as a TB triage tool,
meeting WHO target product profile benchmarks. The model was robust to
confounding factors including background noise, recording time, and device
variability, indicating detection of genuine disease-related acoustic patterns.
Further validation across diverse regions and case definitions, including
subclinical TB, is required before clinical use.

</details>


### [56] [DiTReducio: A Training-Free Acceleration for DiT-Based TTS via Progressive Calibration](https://arxiv.org/abs/2509.09748)
*Yanru Huo,Ziyue Jiang,Zuoli Tang,Qingyang Hong,Zhou Zhao*

Main category: cs.SD

TL;DR: DiTReducio是一个无需训练的加速框架，通过时间跳过和分支跳过两种压缩方法，结合模式引导策略，在保持生成质量的同时显著降低DiT-based TTS模型的计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器(DiT)在非自回归语音合成中表现出色，但计算需求高。现有加速方法主要依赖蒸馏技术减少采样步骤，但仍受训练成本限制，需要一种无需训练的加速方案。

Method: 提出DiTReducio框架：1) 时间跳过和分支跳过两种计算压缩方法；2) 基于DiT层中发现的两种注意力模式，设计模式引导策略选择性应用压缩；3) 通过可调压缩阈值灵活平衡生成质量和计算效率。

Result: 在F5-TTS和MegaTTS 3上的实验表明：FLOPs减少75.4%，实时因子(RTF)提升37.1%，同时保持生成质量。

Conclusion: DiTReducio提供了一种有效的训练免费加速方案，通过渐进式校准和模式感知压缩，显著提升了DiT-based TTS模型的推理效率。

Abstract: While Diffusion Transformers (DiT) have advanced non-autoregressive (NAR)
speech synthesis, their high computational demands remain an limitation.
Existing DiT-based text-to-speech (TTS) model acceleration approaches mainly
focus on reducing sampling steps through distillation techniques, yet they
remain constrained by training costs. We introduce DiTReducio, a training-free
acceleration framework that compresses computations in DiT-based TTS models via
progressive calibration. We propose two compression methods, Temporal Skipping
and Branch Skipping, to eliminate redundant computations during inference.
Moreover, based on two characteristic attention patterns identified within DiT
layers, we devise a pattern-guided strategy to selectively apply the
compression methods. Our method allows flexible modulation between generation
quality and computational efficiency through adjustable compression thresholds.
Experimental evaluations conducted on F5-TTS and MegaTTS 3 demonstrate that
DiTReducio achieves a 75.4% reduction in FLOPs and improves the Real-Time
Factor (RTF) by 37.1%, while preserving generation quality.

</details>


### [57] [Combining Textual and Spectral Features for Robust Classification of Pilot Communications](https://arxiv.org/abs/2509.09752)
*Abdullah All Tanvir,Chenyu Huang,Moe Alahmad,Chuyang Yang,Xin Zhong*

Main category: cs.SD

TL;DR: 提出基于双管道机器学习框架的飞机操作意图分类系统，结合文本和频谱特征分析飞行员无线电通信，在非塔台机场实现91%以上F1分数的准确分类


<details>
  <summary>Details</summary>
Motivation: 非塔台机场缺乏专用监控基础设施，飞机起降操作估计困难，需要一种成本效益高且可扩展的监控解决方案

Method: 使用双管道机器学习框架：文本管道（自动语音识别）和频谱管道（梅尔频谱图提取），评估传统分类器、集成方法、LSTM和CNN模型

Result: 频谱特征结合深度学习架构表现最佳，F1分数超过91%，数据增强进一步提高了对真实音频变化的鲁棒性

Conclusion: 该方法无需额外基础设施即可部署，为通用航空机场空中交通监控提供了实用、可扩展且成本效益高的解决方案

Abstract: Accurate estimation of aircraft operations, such as takeoffs and landings, is
critical for effective airport management, yet remains challenging, especially
at non-towered facilities lacking dedicated surveillance infrastructure. This
paper presents a novel dual pipeline machine learning framework that classifies
pilot radio communications using both textual and spectral features. Audio data
collected from a non-towered U.S. airport was annotated by certified pilots
with operational intent labels and preprocessed through automatic speech
recognition and Mel-spectrogram extraction. We evaluate a wide range of
traditional classifiers and deep learning models, including ensemble methods,
LSTM, and CNN across both pipelines. To our knowledge, this is the first system
to classify operational aircraft intent using a dual-pipeline ML framework on
real-world air traffic audio. Our results demonstrate that spectral features
combined with deep architectures consistently yield superior classification
performance, with F1-scores exceeding 91%. Data augmentation further improves
robustness to real-world audio variability. The proposed approach is scalable,
cost-effective, and deployable without additional infrastructure, offering a
practical solution for air traffic monitoring at general aviation airports.

</details>


### [58] [SoilSound: Smartphone-based Soil Moisture Estimation](https://arxiv.org/abs/2509.09823)
*Yixuan Gao,Tanvir Ahmed,Shuang He,Zhongqi Cheng,Rajalakshmi Nandakumar*

Main category: cs.SD

TL;DR: SoilSound是一个基于智能手机的声学传感系统，通过内置扬声器和麦克风进行垂直扫描，无需校准即可非侵入式测量土壤湿度，平均绝对误差为2.39%。


<details>
  <summary>Details</summary>
Motivation: 现有土壤湿度监测方法需要侵入式探头或专业设备，限制了公众使用。需要开发一种无需扰动土壤、易于获取的监测方案。

Method: 利用智能手机内置扬声器和麦克风，通过发送声学啁啾信号并记录反射，基于表面粗糙度效应的声学反射模型，使用卷积神经网络进行设备端湿度估计。

Result: 在10个不同地点测试，平均绝对误差为2.39%，能够准确跟踪15.9%到34.0%的土壤湿度范围，适用于多种土壤类型和环境。

Conclusion: SoilSound无需校准或扰动土壤即可实现准确的土壤湿度监测，为家庭园丁、城市农民和资源有限地区的农业社区提供了广泛可用的监测方案。

Abstract: Soil moisture monitoring is essential for agriculture and environmental
management, yet existing methods require either invasive probes disturbing the
soil or specialized equipment, limiting access to the public. We present
SoilSound, an ubiquitous accessible smartphone-based acoustic sensing system
that can measure soil moisture without disturbing the soil. We leverage the
built-in speaker and microphone to perform a vertical scan mechanism to
accurately measure moisture without any calibration. Unlike existing work that
use transmissive properties, we propose an alternate model for acoustic
reflections in soil based on the surface roughness effect to enable moisture
sensing without disturbing the soil. The system works by sending acoustic
chirps towards the soil and recording the reflections during a vertical scan,
which are then processed and fed to a convolutional neural network for
on-device soil moisture estimation with negligible computational, memory, or
power overhead. We evaluated the system by training with curated soils in boxes
in the lab and testing in the outdoor fields and show that SoilSound achieves a
mean absolute error (MAE) of 2.39% across 10 different locations. Overall, the
evaluation shows that SoilSound can accurately track soil moisture levels
ranging from 15.9% to 34.0% across multiple soil types, environments, and
users; without requiring any calibration or disturbing the soil, enabling
widespread moisture monitoring for home gardeners, urban farmers, citizen
scientists, and agricultural communities in resource-limited settings.

</details>


### [59] [CoDiCodec: Unifying Continuous and Discrete Compressed Representations of Audio](https://arxiv.org/abs/2509.09836)
*Marco Pasini,Stefan Lattner,George Fazekas*

Main category: cs.SD

TL;DR: CoDiCodec是一种新颖的音频自编码器，通过有限标量量化和FSQ-dropout技术，在同一模型中同时生成压缩连续嵌入和离散标记，在保持音频保真度的同时实现高压缩比。


<details>
  <summary>Details</summary>
Motivation: 现有的音频自编码器往往需要在连续嵌入和离散标记之间做出选择，且在保持音频保真度的同时实现高压缩比仍然是一个挑战。

Method: 采用有限标量量化(FSQ)和新型FSQ-dropout技术，通过单一一致性损失进行端到端训练，支持自回归解码和并行解码策略。

Result: 在相似比特率下，CoDiCodec在重建音频质量方面优于现有的连续和离散自编码器，并行解码策略实现了更优的音频质量和更快的解码速度。

Conclusion: CoDiCodec为音频压缩提供了统一的方法，弥合了连续和离散生成建模范式之间的差距。

Abstract: Efficiently representing audio signals in a compressed latent space is
critical for latent generative modelling. However, existing autoencoders often
force a choice between continuous embeddings and discrete tokens. Furthermore,
achieving high compression ratios while maintaining audio fidelity remains a
challenge. We introduce CoDiCodec, a novel audio autoencoder that overcomes
these limitations by both efficiently encoding global features via summary
embeddings, and by producing both compressed continuous embeddings at ~ 11 Hz
and discrete tokens at a rate of 2.38 kbps from the same trained model,
offering unprecedented flexibility for different downstream generative tasks.
This is achieved through Finite Scalar Quantization (FSQ) and a novel
FSQ-dropout technique, and does not require additional loss terms beyond the
single consistency loss used for end-to-end training. CoDiCodec supports both
autoregressive decoding and a novel parallel decoding strategy, with the latter
achieving superior audio quality and faster decoding. CoDiCodec outperforms
existing continuous and discrete autoencoders at similar bitrates in terms of
reconstruction audio quality. Our work enables a unified approach to audio
compression, bridging the gap between continuous and discrete generative
modelling paradigms.

</details>


### [60] [Prototypical Contrastive Learning For Improved Few-Shot Audio Classification](https://arxiv.org/abs/2509.10074)
*Christos Sgouropoulos,Christos Nikou,Stefanos Vlachos,Vasileios Theiou,Christos Foukanelis,Theodoros Giannakopoulos*

Main category: cs.SD

TL;DR: 本文提出了一种将监督对比损失集成到原型少样本音频分类训练中的方法，使用角度损失和SpecAugment增强技术，在MetaAudio基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 虽然少样本学习在图像领域已有广泛研究，但在音频分类领域相对未被充分探索。本文旨在解决音频分类中少样本学习的挑战，特别是在标注数据有限的情况下。

Method: 方法整合了监督对比损失到原型少样本训练中，使用角度损失替代标准对比损失，并采用SpecAugment数据增强和自注意力机制，将增强输入版本的不同信息封装到统一的嵌入表示中。

Result: 在MetaAudio基准测试（包含五个数据集）的5-way 5-shot设置中，所提出的方法达到了最先进的性能表现。

Conclusion: 研究表明，将监督对比损失与原型少样本训练相结合，特别是使用角度损失，能够有效提升音频分类任务的性能，为少样本音频学习提供了新的解决方案。

Abstract: Few-shot learning has emerged as a powerful paradigm for training models with
limited labeled data, addressing challenges in scenarios where large-scale
annotation is impractical. While extensive research has been conducted in the
image domain, few-shot learning in audio classification remains relatively
underexplored. In this work, we investigate the effect of integrating
supervised contrastive loss into prototypical few shot training for audio
classification. In detail, we demonstrate that angular loss further improves
the performance compared to the standard contrastive loss. Our method leverages
SpecAugment followed by a self-attention mechanism to encapsulate diverse
information of augmented input versions into one unified embedding. We evaluate
our approach on MetaAudio, a benchmark including five datasets with predefined
splits, standardized preprocessing, and a comprehensive set of few-shot
learning models for comparison. The proposed approach achieves state-of-the-art
performance in a 5-way, 5-shot setting.

</details>


### [61] [Data-independent Beamforming for End-to-end Multichannel Multi-speaker ASR](https://arxiv.org/abs/2509.10234)
*Can Cui,Paul Magron,Mostafa Sadeghi,Emmanuel Vincent*

Main category: cs.SD

TL;DR: 提出了一种基于球坐标角度扇区的波束形成方法，用于多通道多说话人语音识别，无需训练且数据独立，显著降低了词错误率和提高了说话人计数准确率。


<details>
  <summary>Details</summary>
Motivation: 多通道多说话人场景中的自动语音识别面临环境噪声、混响和说话人重叠等挑战，需要有效处理多通道信号以提高识别性能。

Method: 基于球面极坐标处理特定角度扇区的波束形成方法，生成一组波束形成信号后输入端到端多通道多说话人ASR系统，该方法无需训练且数据独立。

Result: 在AMI会议语料库上的实验表明，该方法相比未使用波束形成的多通道ASR基线系统，词错误率相对降低11%，说话人计数准确率相对提高27%。

Conclusion: 通过波束形成处理多通道信号可以显著提升多说话人ASR性能，增加波束形成信号数量能进一步提高识别准确率，同时减少ASR系统的整体输入负载。

Abstract: Automatic speech recognition (ASR) in multichannel, multi-speaker scenarios
remains challenging due to ambient noise, reverberation and overlapping
speakers. In this paper, we propose a beamforming approach that processes
specific angular sectors based on their spherical polar coordinates before
applying an end-to-end multichannel, multi-speaker ASR system. This method is
data-independent and training-free. We demonstrate that using a group of
beamformed signals improves ASR performance compared to using the same number
of raw microphone signals. Moreover, increasing the number of signals used for
beamforming further enhances recognition accuracy, leading to a more efficient
use of multichannel signals while reducing the overall input load for the ASR
system. We conduct experiments on the AMI meeting corpus, where the proposed
method reduces word error rate by up to 11% and improves speaker counting
accuracy by up to 27% relative compared to a multichannel ASR baseline system
that does not exploit beamforming.

</details>


### [62] [Improving Audio Event Recognition with Consistency Regularization](https://arxiv.org/abs/2509.10391)
*Shanmuka Sadhu,Weiran Wang*

Main category: cs.SD

TL;DR: 本文提出将一致性正则化(CR)应用于音频事件识别，通过在AudioSet数据集上的实验证明CR能持续提升性能，特别是在小训练集和半监督设置中效果显著


<details>
  <summary>Details</summary>
Motivation: 一致性正则化在自动语音识别中已显示出优势，作者希望探索其在音频事件识别领域的应用潜力，特别是在数据增强和半监督学习场景下的效果

Method: 使用一致性正则化技术，强制模型对增强视图的预测保持一致。进行了广泛的消融研究，包括小规模(~20k)和大规模(~1.8M)监督训练集，以及半监督设置(20K标注样本+1.8M未标注样本)

Result: CR在已经大量使用数据增强的监督基线上带来了持续改进；使用更强增强和多重增强的CR为小训练集带来了额外增益；在半监督设置中获得了比小训练集最佳模型更好的性能

Conclusion: 一致性正则化是音频事件识别中有效的技术，能够提升模型性能，特别是在数据有限或半监督学习场景下表现突出

Abstract: Consistency regularization (CR), which enforces agreement between model
predictions on augmented views, has found recent benefits in automatic speech
recognition [1]. In this paper, we propose the use of consistency
regularization for audio event recognition, and demonstrate its effectiveness
on AudioSet. With extensive ablation studies for both small ($\sim$20k) and
large ($\sim$1.8M) supervised training sets, we show that CR brings consistent
improvement over supervised baselines which already heavily utilize data
augmentation, and CR using stronger augmentation and multiple augmentations
leads to additional gain for the small training set. Furthermore, we extend the
use of CR into the semi-supervised setup with 20K labeled samples and 1.8M
unlabeled samples, and obtain performance improvement over our best model
trained on the small set.

</details>
