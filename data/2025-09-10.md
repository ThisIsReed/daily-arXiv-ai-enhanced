<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 38]
- [cs.SD](#cs.SD) [Total: 11]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MedBench-IT: A Comprehensive Benchmark for Evaluating Large Language Models on Italian Medical Entrance Examinations](https://arxiv.org/abs/2509.07135)
*Ruggero Marino Lazzaroni,Alessandro Angioi,Michelangelo Puliga,Davide Sanna,Roberto Marras*

Main category: cs.CL

TL;DR: MedBench-IT是首个针对意大利医学大学入学考试的LLM基准测试，包含17,410个专家编写的选择题，涵盖6个学科和3个难度级别，为意大利NLP社区提供标准化评估方法。


<details>
  <summary>Details</summary>
Motivation: LLM在教育领域潜力日益增长，但非英语专业领域基准测试稀缺，特别是意大利语医学入学考试缺乏标准化评估工具。

Method: 从Edizioni Simone获取17,410个选择题，评估包括GPT-4o、Claude系列等专有模型和<30B参数的开源模型，进行准确性、可重复性、排序偏差和推理提示评估。

Result: 模型响应一致性达88.86%（因学科而异），排序偏差影响极小，问题可读性与模型性能存在统计显著但较小的负相关关系。

Conclusion: MedBench-IT为意大利NLP社区、教育技术开发者和从业者提供了关键资源，揭示了当前模型能力并为这一重要领域提供了标准化评估方法。

Abstract: Large language models (LLMs) show increasing potential in education, yet
benchmarks for non-English languages in specialized domains remain scarce. We
introduce MedBench-IT, the first comprehensive benchmark for evaluating LLMs on
Italian medical university entrance examinations. Sourced from Edizioni Simone,
a leading preparatory materials publisher, MedBench-IT comprises 17,410
expert-written multiple-choice questions across six subjects (Biology,
Chemistry, Logic, General Culture, Mathematics, Physics) and three difficulty
levels. We evaluated diverse models including proprietary LLMs (GPT-4o, Claude
series) and resource-efficient open-source alternatives (<30B parameters)
focusing on practical deployability.
  Beyond accuracy, we conducted rigorous reproducibility tests (88.86% response
consistency, varying by subject), ordering bias analysis (minimal impact), and
reasoning prompt evaluation. We also examined correlations between question
readability and model performance, finding a statistically significant but
small inverse relationship. MedBench-IT provides a crucial resource for Italian
NLP community, EdTech developers, and practitioners, offering insights into
current capabilities and standardized evaluation methodology for this critical
domain.

</details>


### [2] [The ML-SUPERB 2.0 Challenge: Towards Inclusive ASR Benchmarking for All Language Varieties](https://arxiv.org/abs/2509.07139)
*William Chen,Chutong Meng,Jiatong Shi,Martijn Bartelds,Shih-Heng Wang,Hsiu-Hsuan Wang,Rafael Mosquera,Sara Hincapie,Dan Jurafsky,Antonis Anastasopoulos,Hung-yi Lee,Karen Livescu,Shinji Watanabe*

Main category: cs.CL

TL;DR: Interspeech 2025 ML-SUPERB 2.0挑战赛构建了包含200+语言、口音和方言的新测试套件，最佳提交在LID准确率上提升23%，CER降低18%，在口音和方言数据上CER降低30.2%，LID准确率提升15.7%。


<details>
  <summary>Details</summary>
Motivation: 当前多语言ASR技术的改进在不同语言和语言变体间分布不均，需要推动更包容的语音技术发展。

Method: 构建包含200+语言、口音和方言的新测试套件，基于DynaBench建立在线评估服务器，允许参与者灵活设计模型架构。

Result: 收到3个团队的5份提交，所有提交均优于基线。最佳提交在通用多语言测试集上LID准确率提升23%，CER降低18%；在口音和方言数据上CER降低30.2%，LID准确率提升15.7%。

Conclusion: 社区挑战赛对于使语音技术更加包容具有重要意义，展示了在多语言ASR方面的显著改进。

Abstract: Recent improvements in multilingual ASR have not been equally distributed
across languages and language varieties. To advance state-of-the-art (SOTA) ASR
models, we present the Interspeech 2025 ML-SUPERB 2.0 Challenge. We construct a
new test suite that consists of data from 200+ languages, accents, and dialects
to evaluate SOTA multilingual speech models. The challenge also introduces an
online evaluation server based on DynaBench, allowing for flexibility in model
design and architecture for participants. The challenge received 5 submissions
from 3 teams, all of which outperformed our baselines. The best-performing
submission achieved an absolute improvement in LID accuracy of 23% and a
reduction in CER of 18% when compared to the best baseline on a general
multilingual test set. On accented and dialectal data, the best submission
obtained 30.2% lower CER and 15.7% higher LID accuracy, showing the importance
of community challenges in making speech technologies more inclusive.

</details>


### [3] [Toward Purpose-oriented Topic Model Evaluation enabled by Large Language Models](https://arxiv.org/abs/2509.07142)
*Zhiyin Tan,Jennifer D'Souza*

Main category: cs.CL

TL;DR: 提出了一个基于大语言模型的动态主题模型自动化评估框架，包含9个LLM指标，覆盖四个关键质量维度，相比传统指标能更好地发现语义缺陷。


<details>
  <summary>Details</summary>
Motivation: 传统主题模型评估指标（如连贯性和多样性）只能捕捉狭窄的统计模式，无法解释实际应用中的语义失败，需要更全面、可解释的评估方法。

Method: 开发了一个面向目的的评估框架，使用9个基于LLM的指标，涵盖词汇有效性、主题内语义合理性、主题间结构合理性和文档-主题对齐合理性四个维度，并通过对抗性和抽样协议进行验证。

Result: LLM指标提供了可解释、稳健且与任务相关的评估，能够发现传统指标经常忽略的关键弱点，如冗余和语义漂移。

Conclusion: 该框架支持开发可扩展的细粒度评估工具，用于维护动态数据集中的主题相关性，为数字图书馆系统的主题模型评估提供了有效解决方案。

Abstract: This study presents a framework for automated evaluation of dynamically
evolving topic models using Large Language Models (LLMs). Topic modeling is
essential for organizing and retrieving scholarly content in digital library
systems, helping users navigate complex and evolving knowledge domains.
However, widely used automated metrics, such as coherence and diversity, often
capture only narrow statistical patterns and fail to explain semantic failures
in practice. We introduce a purpose-oriented evaluation framework that employs
nine LLM-based metrics spanning four key dimensions of topic quality: lexical
validity, intra-topic semantic soundness, inter-topic structural soundness, and
document-topic alignment soundness. The framework is validated through
adversarial and sampling-based protocols, and is applied across datasets
spanning news articles, scholarly publications, and social media posts, as well
as multiple topic modeling methods and open-source LLMs. Our analysis shows
that LLM-based metrics provide interpretable, robust, and task-relevant
assessments, uncovering critical weaknesses in topic models such as redundancy
and semantic drift, which are often missed by traditional metrics. These
results support the development of scalable, fine-grained evaluation tools for
maintaining topic relevance in dynamic datasets. All code and data supporting
this work are accessible at
https://github.com/zhiyintan/topic-model-LLMjudgment.

</details>


### [4] [Towards EnergyGPT: A Large Language Model Specialized for the Energy Sector](https://arxiv.org/abs/2509.07177)
*Amal Chebbi,Babajide Kolade*

Main category: cs.CL

TL;DR: EnergyGPT是基于LLaMA 3.1-8B微调的专业能源领域语言模型，在能源相关任务上表现优于基础模型


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在能源等专业领域效果有限，需要深度技术专业知识和精确领域知识

Method: 使用监督微调方法，在高质量能源文本语料上微调LLaMA 3.1-8B模型，包括数据收集整理、模型微调、基准设计和评估部署的完整流程

Result: EnergyGPT在大多数能源相关语言理解和生成任务上超越了基础模型的表现

Conclusion: 通过专门的训练策略，可以在不需要大规模基础设施的情况下提升模型在特定领域的相关性和性能

Abstract: Large Language Models have demonstrated impressive capabilities across
various domains. However, their general-purpose nature often limits their
effectiveness in specialized fields such as energy, where deep technical
expertise and precise domain knowledge are essential. In this paper, we
introduce EnergyGPT, a domain-specialized language model tailored for the
energy sector, developed by fine-tuning LLaMA 3.1-8B model using Supervised
Fine-Tuning on a high-quality, curated corpus of energy-related texts. We
present a complete development pipeline, including data collection and
curation, model fine-tuning, benchmark design and LLM-judge choice, evaluation
and deployment. Through this work, we demonstrate that our training strategy
enables improvements in domain relevance and performance without the need for
large-scale infrastructure. By evaluating the performance of the model using
domain-specific question-answering benchmarks, our results demonstrate that
EnergyGPT outperforms the base model in most of the energy-related language
understanding and generation tasks.

</details>


### [5] [Dual Knowledge-Enhanced Two-Stage Reasoner for Multimodal Dialog Systems](https://arxiv.org/abs/2509.07817)
*Xiaolin Chen,Xuemeng Song,Haokun Wen,Weili Guan,Xiangyu Zhao,Liqiang Nie*

Main category: cs.CL

TL;DR: 这篇论文提出了DK2R模型，通过利用双重知识（结构化属性和非结构化评论）和大语言模型，提升多模态任务对话系统的文本响应生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了非结构化评论知识并没有充分利用大语言模型的潜力，需要更好地结合双重知识来提升响应生成质量。

Method: 设计了两阶段的DK2R模型：先从外部知识库提取结构化属性和非结构化评论知识，然后利用LLM评估各种知识类型的有用性，分离总结意图关键线索并作为辅助信号来增强响应生成。

Result: 在公开数据集上进行的实验验证了DK2R的优势性，表明方法能够有效提升多模态任务对话系统的文本响应生成质量。

Conclusion: DK2R通过创新地结合双重知识和大语言模型，成功解决了动态知识类型选择和意图-响应解耦的挑战，为多模态对话系统的文本生成提供了有效解决方案。

Abstract: Textual response generation is pivotal for multimodal \mbox{task-oriented}
dialog systems, which aims to generate proper textual responses based on the
multimodal context. While existing efforts have demonstrated remarkable
progress, there still exist the following limitations: 1) \textit{neglect of
unstructured review knowledge} and 2) \textit{underutilization of large
language models (LLMs)}. Inspired by this, we aim to fully utilize dual
knowledge (\textit{i.e., } structured attribute and unstructured review
knowledge) with LLMs to promote textual response generation in multimodal
task-oriented dialog systems. However, this task is non-trivial due to two key
challenges: 1) \textit{dynamic knowledge type selection} and 2)
\textit{intention-response decoupling}. To address these challenges, we propose
a novel dual knowledge-enhanced two-stage reasoner by adapting LLMs for
multimodal dialog systems (named DK2R). To be specific, DK2R first extracts
both structured attribute and unstructured review knowledge from external
knowledge base given the dialog context. Thereafter, DK2R uses an LLM to
evaluate each knowledge type's utility by analyzing LLM-generated provisional
probe responses. Moreover, DK2R separately summarizes the intention-oriented
key clues via dedicated reasoning, which are further used as auxiliary signals
to enhance LLM-based textual response generation. Extensive experiments
conducted on a public dataset verify the superiority of DK2R. We have released
the codes and parameters.

</details>


### [6] [DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge](https://arxiv.org/abs/2509.07188)
*Zonghai Yao,Michael Sun,Won Seok Jang,Sunjae Kwon,Soie Kwon,Hong Yu*

Main category: cs.CL

TL;DR: DischargeSim是一个新的基准测试，用于评估大语言模型在出院沟通中作为个性化教育者的能力，通过模拟医患对话来测试模型在对话质量、个性化文档生成和患者理解方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM基准测试主要关注诊断推理，但忽视了出院后患者教育这一关键环节。出院沟通对患者护理至关重要，需要评估模型在这方面的能力。

Method: 创建DischargeSim基准，模拟出院后多轮医患对话，使用LLM驱动的医生代理和具有不同心理社会特征的患者代理进行交互，涵盖六个临床主题，并从三个维度进行评估。

Result: 测试18个LLM发现出院教育能力存在显著差距，性能因患者特征而异，模型大小并不总是带来更好的教育效果。

Conclusion: DischargeSim为评估LLM在临床后访教育中的表现提供了首个基准，有助于促进公平、个性化的患者支持。

Abstract: Discharge communication is a critical yet underexplored component of patient
care, where the goal shifts from diagnosis to education. While recent large
language model (LLM) benchmarks emphasize in-visit diagnostic reasoning, they
fail to evaluate models' ability to support patients after the visit. We
introduce DischargeSim, a novel benchmark that evaluates LLMs on their ability
to act as personalized discharge educators. DischargeSim simulates post-visit,
multi-turn conversations between LLM-driven DoctorAgents and PatientAgents with
diverse psychosocial profiles (e.g., health literacy, education, emotion).
Interactions are structured across six clinically grounded discharge topics and
assessed along three axes: (1) dialogue quality via automatic and LLM-as-judge
evaluation, (2) personalized document generation including free-text summaries
and structured AHRQ checklists, and (3) patient comprehension through a
downstream multiple-choice exam. Experiments across 18 LLMs reveal significant
gaps in discharge education capability, with performance varying widely across
patient profiles. Notably, model size does not always yield better education
outcomes, highlighting trade-offs in strategy use and content prioritization.
DischargeSim offers a first step toward benchmarking LLMs in post-visit
clinical education and promoting equitable, personalized patient support.

</details>


### [7] [Rule-Based Moral Principles for Explaining Uncertainty in Natural Language Generation](https://arxiv.org/abs/2509.07190)
*Zahra Atf,Peter R Lewis*

Main category: cs.CL

TL;DR: 基于道德原则的规则系统用于处理LLM中的不确定性，通过预防、尊重、责任等道德规则来提高透明度和可解释性


<details>
  <summary>Details</summary>
Motivation: 概率方法在高风险场景中不透明且与透明性期望不一致，需要一种更透明、可解释的不确定性处理方案

Method: 基于道德心理学和美德伦理学，定义预防、尊重、责任等道德规则，通过轻量级Prolog引擎编码，根据不确定性级别触发相应系统动作并提供理由

Result: 通过场景模拟测试规则覆盖率、公平性和信任检验，在临床和法律领域的应用案例证明道德推理能够提高信任和可解释性

Conclusion: 该方法提供了一种透明、轻量级的替代方案，可以在社会责任职责的自然语言生成中更好地处理不确定性

Abstract: Large language models (LLMs) are increasingly used in high-stakes settings,
where explaining uncertainty is both technical and ethical. Probabilistic
methods are often opaque and misaligned with expectations of transparency. We
propose a framework based on rule-based moral principles for handling
uncertainty in LLM-generated text. Using insights from moral psychology and
virtue ethics, we define rules such as precaution, deference, and
responsibility to guide responses under epistemic or aleatoric uncertainty.
These rules are encoded in a lightweight Prolog engine, where uncertainty
levels (low, medium, high) trigger aligned system actions with plain-language
rationales. Scenario-based simulations benchmark rule coverage, fairness, and
trust calibration. Use cases in clinical and legal domains illustrate how moral
reasoning can improve trust and interpretability. Our approach offers a
transparent, lightweight alternative to probabilistic models for socially
responsible natural language generation.

</details>


### [8] [LLM Analysis of 150+ years of German Parliamentary Debates on Migration Reveals Shift from Post-War Solidarity to Anti-Solidarity in the Last Decade](https://arxiv.org/abs/2509.07274)
*Aida Kostikova,Ole Pütz,Steffen Eger,Olga Sabelfeld,Benjamin Paassen*

Main category: cs.CL

TL;DR: 使用大型语言模型自动标注德国议会辩论中的(反)团结类型，与传统人工标注对比，发现LLM在政治文本分析中的潜力，并揭示了德国战后移民团结度较高而2015年后反团结趋势增强的现象


<details>
  <summary>Details</summary>
Motivation: 传统人工标注政治演讲中的(反)团结类型耗时耗力，限制了大规模数据分析。研究旨在评估LLM在自动化复杂标注任务中的能力，并深入分析德国战后移民政策辩论中的团结趋势

Method: 使用多种大型语言模型对德国议会辩论进行(反)团结子类型标注，与数千个人工参考标注对比，评估模型大小、提示差异、微调、历史与当代数据的影响，并分析系统错误

Result: LLM在政治文本分析中表现出良好潜力，数据揭示战后时期对移民的高度团结，以及2015年以来德国议会中强烈的反团结趋势

Conclusion: LLM为政治文本分析提供了有前景的工具，德国移民辩论在人口衰退和劳动力短缺与日益极化的背景下具有重要意义，这些发现激励进一步研究

Abstract: Migration has been a core topic in German political debate, from millions of
expellees post World War II over labor migration to refugee movements in the
recent past. Studying political speech regarding such wide-ranging phenomena in
depth traditionally required extensive manual annotations, limiting the scope
of analysis to small subsets of the data. Large language models (LLMs) have the
potential to partially automate even complex annotation tasks. We provide an
extensive evaluation of a multiple LLMs in annotating (anti-)solidarity
subtypes in German parliamentary debates compared to a large set of thousands
of human reference annotations (gathered over a year). We evaluate the
influence of model size, prompting differences, fine-tuning, historical versus
contemporary data; and we investigate systematic errors. Beyond methodological
evaluation, we also interpret the resulting annotations from a social science
lense, gaining deeper insight into (anti-)solidarity trends towards migrants in
the German post-World War II period and recent past. Our data reveals a high
degree of migrant-directed solidarity in the postwar period, as well as a
strong trend towards anti-solidarity in the German parliament since 2015,
motivating further research. These findings highlight the promise of LLMs for
political text analysis and the importance of migration debates in Germany,
where demographic decline and labor shortages coexist with rising polarization.

</details>


### [9] [Causal Attention with Lookahead Keys](https://arxiv.org/abs/2509.07301)
*Zhuoqing Song,Peng Sun,Huizhuo Yuan,Quanquan Gu*

Main category: cs.CL

TL;DR: CASTLE是一种新颖的注意力机制，通过动态更新token的keys来整合后续上下文信息，同时保持自回归特性，在语言建模任务中表现优于标准因果注意力。


<details>
  <summary>Details</summary>
Motivation: 标准因果注意力中每个token的QKV是静态的，只能编码前文信息。作者希望开发一种能够整合后续上下文信息但仍保持自回归特性的注意力机制。

Method: 提出CASTLE机制，持续更新每个token的keys（称为lookahead keys），这些keys属于较早位置但整合了相对这些位置之后出现的token信息。通过数学等价性避免显式存储lookahead keys，实现高效并行训练。

Result: 在语言建模基准测试中，CASTLE在不同模型规模下始终优于标准因果注意力，降低了验证困惑度，并在多个下游任务上提升了性能。

Conclusion: CASTLE通过动态更新keys整合后续信息的方法有效提升了语言模型的性能，同时保持了训练效率。

Abstract: In standard causal attention, each token's query, key, and value (QKV) are
static and encode only preceding context. We introduce CAuSal aTtention with
Lookahead kEys (CASTLE), an attention mechanism that continually updates each
token's keys as the context unfolds. We term these updated keys lookahead keys
because they belong to earlier positions yet integrate information from tokens
that appear later relative to those positions, while strictly preserving the
autoregressive property. Although the mechanism appears sequential, we derive a
mathematical equivalence that avoids explicitly materializing lookahead keys at
each position and enables efficient parallel training. On language modeling
benchmarks, CASTLE consistently outperforms standard causal attention across
model scales, reducing validation perplexity and improving performance on a
range of downstream tasks.

</details>


### [10] [Basis Vector Metric: A Method for Robust Open-Ended State Change Detection](https://arxiv.org/abs/2509.07308)
*David Oprea,Sam Powers*

Main category: cs.CL

TL;DR: BVM方法在MIT-States数据集上测试图像状态判断能力，在名词分类方面表现最佳，但在形容词区分方面不如逻辑回归模型


<details>
  <summary>Details</summary>
Motivation: 测试BVM方法在语言嵌入中判断图像状态变化的能力，特别是对名词状态分类和形容词区分的性能

Method: 使用BVM（基向量方法）在MIT-States数据集（53,000张图像，225个名词和115个形容词）上进行实验，与余弦相似度、点积、乘积量化、二进制索引、朴素贝叶斯和自定义神经网络等方法进行比较

Result: BVM在名词状态分类方面表现最佳，但在形容词区分方面未能超越逻辑回归模型

Conclusion: BVM在名词分类方面有效，但在形容词区分方面需要方法改进以提高准确性

Abstract: We test a new method, which we will abbreviate using the acronym BVM (Basis
Vectors Method), in its ability to judge the state changes in images through
using language embeddings. We used the MIT-States dataset, containing about
53,000 images, to gather all of our data, which has 225 nouns and 115
adjectives, with each noun having about 9 different adjectives, forming
approximately 1000 noun-adjective pairs. For our first experiment, we test our
method's ability to determine the state of each noun class separately against
other metrics for comparison. These metrics are cosine similarity, dot product,
product quantization, binary index, Naive Bayes, and a custom neural network.
Among these metrics, we found that our proposed BVM performs the best in
classifying the states for each noun. We then perform a second experiment where
we try using BVM to determine if it can differentiate adjectives from one
another for each adjective separately. We compared the abilities of BVM to
differentiate adjectives against the proposed method the MIT-States paper
suggests: using a logistic regression model. In the end, we did not find
conclusive evidence that our BVM metric could perform better than the logistic
regression model at discerning adjectives. Yet, we were able to find evidence
for possible improvements to our method; this leads to the chance of increasing
our method's accuracy through certain changes in our methodologies.

</details>


### [11] [Instance-level Performance Prediction for Long-form Generation Tasks](https://arxiv.org/abs/2509.07309)
*Chi-Yang Hsu,Alexander Braylan,Yiheng Su,Omar Alonso,Matthew Lease*

Main category: cs.CL

TL;DR: 提出了一个新的长文本生成任务的实例级性能预测测试标准，支持多维度评价指标和不确定性预测，仅需16个训练示例即可实现有效预测。


<details>
  <summary>Details</summary>
Motivation: 为长文本生成任务构建一个任务、模型和评价指标无关的性能预测标准，支持黑盒模型的输入输出分析，并能够量化预测不确定性。

Method: 通过黑盒模型的输入和输出来预测连续的评价指标分数，还包括预测区间以量化不确定性。测试覆盖11个长文本数据集/任务，多个LLM模型和多种评价指标。

Result: 结果显示，仅使用16个训练示例即可在各种长文本生成任务中有效预测性能指标。

Conclusion: 该研究提出了一个新题且实用的任务，为性能预测领域提供了价值较高的测试标准和可直接应用的基线方法。

Abstract: We motivate and share a new benchmark for instance-level performance
prediction of long-form generation tasks having multi-faceted, fine-grained
quality metrics. Our task-, model- and metric-agnostic formulation predicts
continuous evaluation metric scores given only black-box model inputs and
outputs. Beyond predicting point estimates of metric scores, the benchmark also
requires inferring prediction intervals to quantify uncertainty around point
estimates. Evaluation spans 11 long-form datasets/tasks with multiple LLMs,
baselines, and metrics per task. We show that scores can be effectively
predicted across long-form generation tasks using as few as 16 training
examples. Overall, we introduce a novel and useful task, a valuable benchmark
to drive progress, and baselines ready for practical adoption today.

</details>


### [12] [Does This Look Familiar to You? Knowledge Analysis via Model Internal Representations](https://arxiv.org/abs/2509.07311)
*Sihyun Park*

Main category: cs.CL

TL;DR: KAMIR是一种基于模型内部表示的数据选择方法，通过分析隐藏状态相似度来评估数据，无需提示工程即可有效选择训练数据


<details>
  <summary>Details</summary>
Motivation: 解决SFT训练数据选择缺乏明确方法的问题，传统方法依赖提示工程且成本高，需要更高效的数据选择技术

Method: KAMIR通过计算每层隐藏状态与最终隐藏状态的相似度来评估数据，基于模型对输入的熟悉程度选择训练数据

Result: 实验表明使用不太熟悉的数据进行训练能获得更好的泛化性能，方法适用于多种任务类型

Conclusion: KAMIR提供了一种有效的数据选择方法，无需复杂提示工程，在小数据集和简单分类器架构下也能有效工作

Abstract: Recent advances in large language models (LLMs) have been driven by
pretraining, supervised fine tuning (SFT), and alignment tuning. Among these,
SFT plays a crucial role in transforming a model 's general knowledge into
structured responses tailored to specific tasks. However, there is no clearly
established methodology for effective training data selection. Simply
increasing the volume of data does not guarantee performance improvements,
while preprocessing, sampling, and validation require substantial time and
cost.
  To address this issue, a variety of data selection methods have been
proposed. Among them, knowledge based selection approaches identify suitable
training data by analyzing the model 's responses. Nevertheless, these methods
typically rely on prompt engineering, making them sensitive to variations and
incurring additional costs for prompt design.
  In this study, we propose Knowledge Analysis via Model Internal
Representations (KAMIR), a novel approach that overcomes these limitations by
analyzing data based on the model 's internal representations. KAMIR computes
similarities between the hidden states of each layer (block) and the final
hidden states for a given input to assess the data. Unlike prior methods that
were largely limited to multiple choice tasks, KAMIR can be applied to a wide
range of tasks such as machine reading comprehension and summarization.
Moreover, it selects data useful for training based on the model 's familiarity
with the input, even with a small dataset and a simple classifier architecture.
Experiments across diverse task datasets demonstrate that training with less
familiar data leads to better generalization performance.

</details>


### [13] [Mitigating Attention Localization in Small Scale: Self-Attention Refinement via One-step Belief Propagation](https://arxiv.org/abs/2509.07324)
*Nakyung Lee,Yeongoon Kim,Minhae Oh,Suhwan Kim,Jin Woo Koo,Hyewon Jo,Jungwoo Lee*

Main category: cs.CL

TL;DR: 提出SAOBP框架，通过信念传播注入多跳关系来解决自注意力机制中的定位问题，防止熵崩溃并提升模型性能，特别在小型模型中表现优异


<details>
  <summary>Details</summary>
Motivation: Transformer自注意力机制存在定位问题，注意力集中在有限token子集上，难以捕获长距离依赖关系

Method: 提出Self-Attention One-step Belief Propagation (SAOBP)框架，通过信念传播过程注入多跳关系，并引入Global Token Dependency (GTD)来量化和解释这些交互

Result: SAOBP能防止深层网络中的熵崩溃，自适应地维持任务适当的GTD水平，提升模型性能，在小型模型中表现尤其突出

Conclusion: SAOBP框架有效解决了自注意力机制的定位问题，特别适合资源受限场景下的推理质量提升

Abstract: Transformer-based self-attention mechanism serves as the core of modern
language models, yet it often suffers from localization, where attentions
collapse onto a limited subset of tokens and fail to capture long-range
dependencies. To address this issue, we propose Self-Attention One-step Belief
Propagation (SAOBP), a refinement framework that injects multi-hop
relationships through a belief propagation process. To interpret and quantify
these interactions, we introduce Global Token Dependency (GTD) that captures
the relative contribution of multihop connections within the attention graph.
Empirical results indicate that SAOBP helps prevent entropy collapse in deeper
layers and adaptively maintains GTD at task-appropriate levels, thereby
supporting improvements in model performance. Importantly, we observe
competitive gains in small-scale models, highlighting its potential for
improving inference quality in resource-constrained scenarios.

</details>


### [14] [PersonaFuse: A Personality Activation-Driven Framework for Enhancing Human-LLM Interactions](https://arxiv.org/abs/2509.07370)
*Yixuan Tang,Yi Yang,Ahmed Abbasi*

Main category: cs.CL

TL;DR: PersonaFuse是一个基于大五人格模型和特质激活理论的LLM后训练框架，通过混合专家架构使模型能够根据不同情境自适应表达不同人格特质，显著提升社交情感智能而不损害通用推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在真实对话中表现出情感感知和社交能力的局限性，无法根据不同的社交和任务情境调整沟通风格和情感表达，这限制了它们在社交陪伴和心理支持等人类中心应用中的效果。

Method: 基于特质激活理论和大五人格模型，采用混合专家架构，结合人格适配器和动态路由网络，实现情境化的特质表达。

Result: 实验结果显示PersonaFuse在社交情感智能的多个维度上显著优于基线模型，在下游应用如心理健康咨询和客户服务中表现一致提升，人类偏好评估显示其响应质量与GPT-4o和DeepSeek等领先模型相当。

Conclusion: PersonaFuse提供了一个理论基础扎实且实用的方法，用于开发社交情感增强的大语言模型，标志着向更人性化AI系统的重要进展，且不牺牲模型安全性或通用推理能力。

Abstract: Recent advancements in Large Language Models (LLMs) demonstrate remarkable
capabilities across various fields. These developments have led to more direct
communication between humans and LLMs in various situations, such as social
companionship and psychological support. However, LLMs often exhibit
limitations in emotional perception and social competence during real-world
conversations. These limitations partly originate from their inability to adapt
their communication style and emotional expression to different social and task
contexts. In this work, we introduce PersonaFuse, a novel LLM post-training
framework that enables LLMs to adapt and express different personalities for
varying situations. Inspired by Trait Activation Theory and the Big Five
personality model, PersonaFuse employs a Mixture-of-Expert architecture that
combines persona adapters with a dynamic routing network, enabling contextual
trait expression. Experimental results show that PersonaFuse substantially
outperforms baseline models across multiple dimensions of social-emotional
intelligence. Importantly, these gains are achieved without sacrificing general
reasoning ability or model safety, which remain common limitations of direct
prompting and supervised fine-tuning approaches. PersonaFuse also delivers
consistent improvements in downstream human-centered applications, such as
mental health counseling and review-based customer service. Finally, human
preference evaluations against leading LLMs, including GPT-4o and DeepSeek,
demonstrate that PersonaFuse achieves competitive response quality despite its
comparatively smaller model size. These findings demonstrate that
PersonaFuse~offers a theoretically grounded and practical approach for
developing social-emotional enhanced LLMs, marking a significant advancement
toward more human-centric AI systems.

</details>


### [15] [Talking with Oompa Loompas: A novel framework for evaluating linguistic acquisition of LLM agents](https://arxiv.org/abs/2509.07389)
*Sankalp Tattwadarshi Swain,Anshika Krishnatray,Dhruv Kumar,Jagat Sesh Challa*

Main category: cs.CL

TL;DR: 大语言模型在通过模式识别和交互反馈学习新语言方面的语言获得能力评估，发现模型无法在100次回应内建立对话，但采用了类似人类的语言学习策略。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要测试语言模型的词汇学习、语法规则归纳等能力，但缺乏对通过模式识别和交互反馈学习语言的评估，这是人类语言获得的核心特征。

Method: 提出了一种新的实验框架，让语言模型与一个仅理解新构建语言(Tinkatongue)的机器人进行对话，评估其学习和使用新语言的能力。

Result: 语言模型在100次回应内无法成功建立对话，但它们采用了与人类类似的语言学习策略，显示了一定的学习行为。

Conclusion: 这个研究为语言模型评估标准开启了新方向，并为设计能够更有效从交互反馈中学习的模型提供了途径。

Abstract: Existing evaluation studies on linguistic competence of large language models
(LLM agents) have focused primarily on vocabulary learning, morphological rule
induction, syntactic generalization, pragmatic inference, and cross-linguistic
transfer. However, none assess whether LLM agents can acquire a language
through pattern recognition and interactive feedback, a central feature of
human language acquisition. We propose a novel experimental framework in which
an LLM agent is evaluated on its ability to acquire and use a newly constructed
language (Tinkatongue) in conversation with a bot that understands only
Tinkatongue. Our findings show that LLM agents fail to establish a conversation
within 100 responses, yet they adopt distinct strategies that mirror human
approaches to language learning. The results suggest a new direction for
evaluation benchmarks and open pathways to model designs that learn more
effectively from interactive feedback.

</details>


### [16] [The Role of Exploration Modules in Small Language Models for Knowledge Graph Question Answering](https://arxiv.org/abs/2509.07399)
*Yi-Jie Cheng,Oscar Chew,Yun-Nung Chen*

Main category: cs.CL

TL;DR: 该研究提出使用轻量级探索模块替代小语言模型进行知识图谱遍历，有效提升了小模型在知识图谱问答任务上的性能


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖大型或专有模型，限制了知识图谱与语言模型结合的可访问性和可扩展性，且小模型在图遍历和推理方面存在局限

Method: 利用简单高效的探索模块来处理知识图谱遍历，替代语言模型自身的图遍历能力

Result: 实验结果表明这些轻量级模块有效提升了小语言模型在知识图谱问答任务上的性能

Conclusion: 通过外部探索模块辅助小语言模型进行知识图谱遍历是提升其问答性能的有效方法，具有更好的可访问性和可扩展性

Abstract: Integrating knowledge graphs (KGs) into the reasoning processes of large
language models (LLMs) has emerged as a promising approach to mitigate
hallucination. However, existing work in this area often relies on proprietary
or extremely large models, limiting accessibility and scalability. In this
study, we investigate the capabilities of existing integration methods for
small language models (SLMs) in KG-based question answering and observe that
their performance is often constrained by their limited ability to traverse and
reason over knowledge graphs. To address this limitation, we propose leveraging
simple and efficient exploration modules to handle knowledge graph traversal in
place of the language model itself. Experiment results demonstrate that these
lightweight modules effectively improve the performance of small language
models on knowledge graph question answering tasks. Source code:
https://github.com/yijie-cheng/SLM-ToG/.

</details>


### [17] [LongEmotion: Measuring Emotional Intelligence of Large Language Models in Long-Context Interaction](https://arxiv.org/abs/2509.07403)
*Weichu Liu,Jing Xiong,Yuxuan Hu,Zixuan Li,Minghuan Tan,Ningning Mao,Chenyang Zhao,Zhongwei Wan,Chaofan Tao,Wendong Xu,Hui Shen,Chengming Li,Lingpeng Kong,Ngai Wong*

Main category: cs.CL

TL;DR: LongEmotion是一个专门为长上下文情感智能任务设计的基准测试，涵盖6类情感任务，平均输入长度8777个token，提出了RAG和CoEM方法来提升LLMs在现实场景中的情感智能表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试忽视了长上下文场景下的情感智能评估，特别是在现实应用中存在长文本、多样性和噪声的复杂交互场景。

Method: 提出了LongEmotion基准测试，包含情感分类、检测、问答、对话、总结和表达6类任务；开发了两种方法：RAG（利用对话上下文和LLM自身作为检索源）和CoEM（五阶段任务分解，结合检索增强和有限知识注入）。

Result: 实验结果表明RAG和CoEM方法在大多数长上下文任务中都能持续提升情感智能相关性能，推动LLMs向更实用的现实世界情感智能应用发展。

Conclusion: LongEmotion基准测试填补了长上下文情感智能评估的空白，提出的RAG和CoEM方法有效提升了LLMs在现实场景中的情感理解能力，为实际应用提供了重要参考。

Abstract: Large language models (LLMs) make significant progress in Emotional
Intelligence (EI) and long-context understanding. However, existing benchmarks
tend to overlook certain aspects of EI in long-context scenarios, especially
under realistic, practical settings where interactions are lengthy, diverse,
and often noisy. To move towards such realistic settings, we present
LongEmotion, a benchmark specifically designed for long-context EI tasks. It
covers a diverse set of tasks, including Emotion Classification, Emotion
Detection, Emotion QA, Emotion Conversation, Emotion Summary, and Emotion
Expression. On average, the input length for these tasks reaches 8,777 tokens,
with long-form generation required for Emotion Expression. To enhance
performance under realistic constraints, we incorporate Retrieval-Augmented
Generation (RAG) and Collaborative Emotional Modeling (CoEM), and compare them
with standard prompt-based methods. Unlike conventional approaches, our RAG
method leverages both the conversation context and the large language model
itself as retrieval sources, avoiding reliance on external knowledge bases. The
CoEM method further improves performance by decomposing the task into five
stages, integrating both retrieval augmentation and limited knowledge
injection. Experimental results show that both RAG and CoEM consistently
enhance EI-related performance across most long-context tasks, advancing LLMs
toward more practical and real-world EI applications. Furthermore, we conducted
a comparative case study experiment on the GPT series to demonstrate the
differences among various models in terms of EI. Code is available on GitHub at
https://github.com/LongEmotion/LongEmotion, and the project page can be found
at https://longemotion.github.io/.

</details>


### [18] [AIxcellent Vibes at GermEval 2025 Shared Task on Candy Speech Detection: Improving Model Performance by Span-Level Training](https://arxiv.org/abs/2509.07459)
*Christian Rene Thelen,Patrick Gustav Blaneck,Tobias Bornheim,Niklas Grieger,Stephan Bialonski*

Main category: cs.CL

TL;DR: 多语言XLM-RoBERTa-Large模型在德语YouTube评论的糖果语音检测任务中表现最佳，通过span级别训练实现了优秀的检测性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中积极支持性的在线交流（糖果语音）有助于培养文明礼貌，但此类语言的自动检测研究不足，限制了对其影响的系统性分析。

Method: 使用单语和多语言语言模型（包括GBERT、Qwen3 Embedding和XLM-RoBERTa）在46k条德语YouTube评论语料库中检测糖果语音，采用span级别的训练方法。

Result: 多语言XLM-RoBERTa-Large模型在GermEval 2025糖果语音检测共享任务中表现最佳，二元阳性F1得分0.8906，分类span检测严格F1得分0.6307。

Conclusion: 研究证明了多语言模型在识别积极支持性语言方面的有效性，span级别训练、多语言能力和表情符号感知分词器提升了检测性能。

Abstract: Positive, supportive online communication in social media (candy speech) has
the potential to foster civility, yet automated detection of such language
remains underexplored, limiting systematic analysis of its impact. We
investigate how candy speech can be reliably detected in a 46k-comment German
YouTube corpus by monolingual and multilingual language models, including
GBERT, Qwen3 Embedding, and XLM-RoBERTa. We find that a multilingual
XLM-RoBERTa-Large model trained to detect candy speech at the span level
outperforms other approaches, ranking first in both binary positive F1: 0.8906)
and categorized span-based detection (strict F1: 0.6307) subtasks at the
GermEval 2025 Shared Task on Candy Speech Detection. We speculate that
span-based training, multilingual capabilities, and emoji-aware tokenizers
improved detection performance. Our results demonstrate the effectiveness of
multilingual models in identifying positive, supportive language.

</details>


### [19] [Understanding Stigmatizing Language Lexicons: A Comparative Analysis in Clinical Contexts](https://arxiv.org/abs/2509.07462)
*Yiliang Zhou,Di Hu,Tianchu Lyu,Jasmine Dhillon,Alexandra L. Beck,Gelareh Sadigh,Kai Zheng*

Main category: cs.CL

TL;DR: 系统文献回顾发现医疗领域污名化语言词典存在中等语义相似性，主要包含临床医生描述负面行为的评判性表达，多为负面情感词汇，凸显标准化词典的需求和挑战。


<details>
  <summary>Details</summary>
Motivation: 医疗污名化语言导致健康不平等，但目前缺乏统一标准化的污名化语言词典来明确定义医疗环境中的污名化词汇和短语。

Method: 通过系统文献检索识别现有污名化语言词典，进行对比分析：1) 比较词典间的相似性和差异；2) 基于既定情感数据集分析正面、负面或中性词汇的分布。

Result: 识别出4个词典，分析显示它们具有中等语义相似性，大多数污名化术语涉及临床医生描述感知负面行为的评判性表达。情感分析显示负面分类词汇占主导地位，但各词典间存在差异。

Conclusion: 研究结果强调了标准化词典的必要性，并突显了在临床文本中定义污名化语言所面临的挑战。

Abstract: Stigmatizing language results in healthcare inequities, yet there is no
universally accepted or standardized lexicon defining which words, terms, or
phrases constitute stigmatizing language in healthcare. We conducted a
systematic search of the literature to identify existing stigmatizing language
lexicons and then analyzed them comparatively to examine: 1) similarities and
discrepancies between these lexicons, and 2) the distribution of positive,
negative, or neutral terms based on an established sentiment dataset. Our
search identified four lexicons. The analysis results revealed moderate
semantic similarity among them, and that most stigmatizing terms are related to
judgmental expressions by clinicians to describe perceived negative behaviors.
Sentiment analysis showed a predominant proportion of negatively classified
terms, though variations exist across lexicons. Our findings underscore the
need for a standardized lexicon and highlight challenges in defining
stigmatizing language in clinical texts.

</details>


### [20] [From Scarcity to Efficiency: Investigating the Effects of Data Augmentation on African Machine Translation](https://arxiv.org/abs/2509.07471)
*Mardiyyah Oduwole,Oluwatosin Olajide,Jamiu Suleiman,Faith Hunja,Busayo Awobade,Fatimo Adebanjo,Comfort Akanni,Chinonyelum Igwe,Peace Ododo,Promise Omoigui,Steven Kolawole,Abraham Owodunni*

Main category: cs.CL

TL;DR: 数据增强技术显著提升非洲低资源语言机器翻译性能，BLEU分数最低提升25%


<details>
  <summary>Details</summary>
Motivation: 非洲大陆的语言多样性为机器翻译带来挑战和机遇，需要解决低资源语言翻译系统性能不足的问题

Method: 使用两种数据增强技术：句子拼接与回译、switch-out技术，在六种非洲语言上进行实验

Result: 所有六种语言的机器翻译性能都有显著提升，BLEU分数最低增加25%

Conclusion: 这些技术有潜力改善低资源语言的机器翻译系统，为资源匮乏语言开发更鲁棒的翻译系统做出贡献

Abstract: The linguistic diversity across the African continent presents different
challenges and opportunities for machine translation. This study explores the
effects of data augmentation techniques in improving translation systems in
low-resource African languages. We focus on two data augmentation techniques:
sentence concatenation with back translation and switch-out, applying them
across six African languages. Our experiments show significant improvements in
machine translation performance, with a minimum increase of 25\% in BLEU score
across all six languages.We provide a comprehensive analysis and highlight the
potential of these techniques to improve machine translation systems for
low-resource languages, contributing to the development of more robust
translation systems for under-resourced languages.

</details>


### [21] [HALT-RAG: A Task-Adaptable Framework for Hallucination Detection with Calibrated NLI Ensembles and Abstention](https://arxiv.org/abs/2509.07475)
*Saumya Goswami,Siddharth Kurra*

Main category: cs.CL

TL;DR: HALT-RAG是一个后验验证系统，使用NLI模型和词汇特征来检测RAG输出中的幻觉，在多个任务上取得优异性能并支持可靠的弃权机制。


<details>
  <summary>Details</summary>
Motivation: 检测生成语言模型输出中与源文本矛盾或不受支持的内容对于安全部署至关重要，需要有效的幻觉识别系统。

Method: 使用两个冻结的现成NLI模型和轻量级词汇信号构建通用特征集，训练简单校准的任务适应元分类器，采用严格的5折交叉验证协议防止数据泄露。

Result: 在HaluEval基准测试中，HALT-RAG在摘要、QA和对话任务上分别获得0.7756、0.9786和0.7391的F1分数，具有良好校准的概率。

Conclusion: HALT-RAG通过通用特征集和轻量级分类器提供强大的幻觉检测能力，其校准概率支持实用的弃权机制，平衡模型性能与安全需求。

Abstract: Detecting content that contradicts or is unsupported by a given source text
is a critical challenge for the safe deployment of generative language models.
We introduce HALT-RAG, a post-hoc verification system designed to identify
hallucinations in the outputs of Retrieval-Augmented Generation (RAG)
pipelines. Our flexible and task-adaptable framework uses a universal feature
set derived from an ensemble of two frozen, off-the-shelf Natural Language
Inference (NLI) models and lightweight lexical signals. These features are used
to train a simple, calibrated, and task-adapted meta-classifier. Using a
rigorous 5-fold out-of-fold (OOF) training protocol to prevent data leakage and
produce unbiased estimates, we evaluate our system on the HaluEval benchmark.
By pairing our universal feature set with a lightweight, task-adapted
classifier and a precision-constrained decision policy, HALT-RAG achieves
strong OOF F1-scores of 0.7756, 0.9786, and 0.7391 on the summarization, QA,
and dialogue tasks, respectively. The system's well-calibrated probabilities
enable a practical abstention mechanism, providing a reliable tool for
balancing model performance with safety requirements.

</details>


### [22] [ALLabel: Three-stage Active Learning for LLM-based Entity Recognition using Demonstration Retrieval](https://arxiv.org/abs/2509.07512)
*Zihan Chen,Lei Shi,Weize Wu,Qiji Zhou,Yue Zhang*

Main category: cs.CL

TL;DR: ALLabel是一个三阶段主动学习框架，通过选择最具信息量和代表性的样本来构建LLM的上下文学习演示，在相同标注预算下优于所有基线方法，仅需标注5%-10%数据即可达到全数据集标注的性能。


<details>
  <summary>Details</summary>
Motivation: 解决科学领域实体识别任务中LLM微调成本高昂的问题，寻求性能与成本之间的最佳平衡。

Method: 提出三阶段主动学习框架，依次采用三种不同的主动学习策略选择最具信息量和代表性的样本，构建真实检索语料库用于LLM的上下文学习。

Result: 在三个专业领域数据集上，ALLabel在相同标注预算下始终优于所有基线方法，仅标注5%-10%数据即可达到全数据集标注的相当性能。

Conclusion: ALLabel框架有效且具有通用性，能够显著降低LLM实体识别的标注成本，同时保持高性能。

Abstract: Many contemporary data-driven research efforts in the natural sciences, such
as chemistry and materials science, require large-scale, high-performance
entity recognition from scientific datasets. Large language models (LLMs) have
increasingly been adopted to solve the entity recognition task, with the same
trend being observed on all-spectrum NLP tasks. The prevailing entity
recognition LLMs rely on fine-tuned technology, yet the fine-tuning process
often incurs significant cost. To achieve a best performance-cost trade-off, we
propose ALLabel, a three-stage framework designed to select the most
informative and representative samples in preparing the demonstrations for LLM
modeling. The annotated examples are used to construct a ground-truth retrieval
corpus for LLM in-context learning. By sequentially employing three distinct
active learning strategies, ALLabel consistently outperforms all baselines
under the same annotation budget across three specialized domain datasets.
Experimental results also demonstrate that selectively annotating only 5\%-10\%
of the dataset with ALLabel can achieve performance comparable to the method
annotating the entire dataset. Further analyses and ablation studies verify the
effectiveness and generalizability of our proposal.

</details>


### [23] [VeriOS: Query-Driven Proactive Human-Agent-GUI Interaction for Trustworthy OS Agents](https://arxiv.org/abs/2509.07553)
*Zheng Wu,Heyuan Huang,Xingyu Lou,Xiangmou Qu,Pengzhou Cheng,Zongru Wu,Weiwen Liu,Weinan Zhang,Jun Wang,Zhaoxiang Wang,Zhuosheng Zhang*

Main category: cs.CL

TL;DR: 提出VeriOS-Agent，一个可信的操作系统代理，通过查询驱动的人机交互框架在不可信环境下主动询问人类，提高任务执行安全性


<details>
  <summary>Details</summary>
Motivation: 现有操作系统代理在理想环境下设计，但真实环境往往存在不可信条件，需要防止过度执行的风险

Method: 采用两阶段学习范式的查询驱动人机-GUI交互框架，在正常条件下自主执行，在不可信场景主动查询人类

Result: 在不可信场景中平均步骤成功率比最先进方法提高20.64%，且不影响正常性能

Conclusion: VeriOS-Agent展现出合理性、泛化性和可扩展性，为可信操作系统代理提供了有效解决方案

Abstract: With the rapid progress of multimodal large language models, operating system
(OS) agents become increasingly capable of automating tasks through on-device
graphical user interfaces (GUIs). However, most existing OS agents are designed
for idealized settings, whereas real-world environments often present
untrustworthy conditions. To mitigate risks of over-execution in such
scenarios, we propose a query-driven human-agent-GUI interaction framework that
enables OS agents to decide when to query humans for more reliable task
completion. Built upon this framework, we introduce VeriOS-Agent, a trustworthy
OS agent trained with a two-stage learning paradigm that falicitate the
decoupling and utilization of meta-knowledge. Concretely, VeriOS-Agent
autonomously executes actions in normal conditions while proactively querying
humans in untrustworthy scenarios. Experiments show that VeriOS-Agent improves
the average step-wise success rate by 20.64\% in untrustworthy scenarios over
the state-of-the-art, without compromising normal performance. Analysis
highlights VeriOS-Agent's rationality, generalizability, and scalability. The
codes, datasets and models are available at
https://github.com/Wuzheng02/VeriOS.

</details>


### [24] [Avoiding Knowledge Edit Skipping in Multi-hop Question Answering with Guided Decomposition](https://arxiv.org/abs/2509.07555)
*Yi Liu,Xiangrong Zhu,Xiangyu Liu,Wei Wei,Wei Hu*

Main category: cs.CL

TL;DR: 本文提出IRAKE方法，通过引导分解和迭代检索来解决多跳问答中知识编辑的"编辑跳过"问题，在知识编辑任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型快速发展的背景下，知识更新频繁但重新训练成本高昂，需要无需修改参数的知识编辑方法。现有基于检索增强生成的方法在简单知识编辑上表现良好，但在多跳问答中存在编辑跳过问题。

Method: 提出IRAKE方法，通过单编辑事实和完整编辑案例的引导进行迭代检索增强知识编辑，采用引导分解策略来解决粒度不匹配问题。

Result: 实验结果表明IRAKE有效缓解了编辑跳过导致的编辑失败问题，在多跳问答的知识编辑任务上超越了最先进的方法。

Conclusion: IRAKE通过迭代检索和引导分解成功解决了多跳问答中的知识编辑挑战，为无需参数修改的知识更新提供了有效解决方案。

Abstract: In a rapidly evolving world where information updates swiftly, knowledge in
large language models (LLMs) becomes outdated quickly. Retraining LLMs is not a
cost-effective option, making knowledge editing (KE) without modifying
parameters particularly necessary. We find that although existing
retrieval-augmented generation (RAG)-based KE methods excel at editing simple
knowledge, they struggle with KE in multi-hop question answering due to the
issue of "edit skipping", which refers to skipping the relevant edited fact in
inference. In addition to the diversity of natural language expressions of
knowledge, edit skipping also arises from the mismatch between the granularity
of LLMs in problem-solving and the facts in the edited memory. To address this
issue, we propose a novel Iterative Retrieval-Augmented Knowledge Editing
method with guided decomposition (IRAKE) through the guidance from single
edited facts and entire edited cases. Experimental results demonstrate that
IRAKE mitigates the failure of editing caused by edit skipping and outperforms
state-of-the-art methods for KE in multi-hop question answering.

</details>


### [25] [BALI: Enhancing Biomedical Language Representations through Knowledge Graph and Language Model Alignment](https://arxiv.org/abs/2509.07588)
*Andrey Sakhovskiy,Elena Tutubalina*

Main category: cs.CL

TL;DR: BALI是一种新颖的联合语言模型和知识图谱预训练方法，通过同时学习专用KG编码器和对齐LM与图谱表示，将外部知识增强到语言模型中，提升生物医学文本理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有生物医学LLM对复杂领域特定概念结构和生物医学知识图谱中编码的事实信息理解有限，需要更好的方法来整合外部知识。

Method: 提出BALI方法：将生物医学概念提及链接到UMLS知识图谱，利用局部KG子图作为跨模态正样本，同时训练KG编码器并对齐LM和图谱表示。

Result: 在PubMedBERT和BioLinkBERT等领先生物医学LM上实施该方法，即使在小规模PubMed摘要对齐数据集上进行最小预训练，也能提升语言理解任务性能和实体表示质量。

Conclusion: BALI方法有效增强了生物医学语言模型对领域知识的理解能力，通过知识图谱对齐显著改善了模型性能。

Abstract: In recent years, there has been substantial progress in using pretrained
Language Models (LMs) on a range of tasks aimed at improving the understanding
of biomedical texts. Nonetheless, existing biomedical LLMs show limited
comprehension of complex, domain-specific concept structures and the factual
information encoded in biomedical Knowledge Graphs (KGs). In this work, we
propose BALI (Biomedical Knowledge Graph and Language Model Alignment), a novel
joint LM and KG pre-training method that augments an LM with external knowledge
by the simultaneous learning of a dedicated KG encoder and aligning the
representations of both the LM and the graph. For a given textual sequence, we
link biomedical concept mentions to the Unified Medical Language System (UMLS)
KG and utilize local KG subgraphs as cross-modal positive samples for these
mentions. Our empirical findings indicate that implementing our method on
several leading biomedical LMs, such as PubMedBERT and BioLinkBERT, improves
their performance on a range of language understanding tasks and the quality of
entity representations, even with minimal pre-training on a small alignment
dataset sourced from PubMed scientific abstracts.

</details>


### [26] [MaLei at MultiClinSUM: Summarisation of Clinical Documents using Perspective-Aware Iterative Self-Prompting with LLMs](https://arxiv.org/abs/2509.07622)
*Libo Ren,Yee Man Ng,Lifeng Han*

Main category: cs.CL

TL;DR: 这篇论文提出了一种迭代自提示技术(ISP)，通过大语言模型生成任务特定提示并精炼，用于临床报告摘要，在MultiClinSUM任务中获得了较高的BERTscore评分。


<details>
  <summary>Details</summary>
Motivation: 临床报告通常长缠且充满专业术语，影响医生与患者之间的有效沟通和共同决策。需要一种能够高效识别重要信息的摘要方法。

Method: 采用迭代自提示技术(ISP)，让大语言模型通过少样本学习生成和精炼任务特定提示。使用ROUGE和BERT-score指标指导模型微调。

Result: 在3,396份多学科临床案例报告上，使用GPT-4和GPT-4o的视角感知ISP方法获得了ROUGE(46.53, 24.68, 30.77)和BERTscore(87.84, 83.25, 85.46)的高分。高BERTscore表明模型生成了语义等价的摘要。

Conclusion: 视角感知迭代自提示技术(PA-ISP)可以有效应用于临床报告摘要，支持更好的医患沟通，虽然词汇层面的重合度较低，但语义等价性较高。

Abstract: Efficient communication between patients and clinicians plays an important
role in shared decision-making. However, clinical reports are often lengthy and
filled with clinical jargon, making it difficult for domain experts to identify
important aspects in the document efficiently. This paper presents the
methodology we applied in the MultiClinSUM shared task for summarising clinical
case documents. We used an Iterative Self-Prompting technique on large language
models (LLMs) by asking LLMs to generate task-specific prompts and refine them
via example-based few-shot learning. Furthermore, we used lexical and embedding
space metrics, ROUGE and BERT-score, to guide the model fine-tuning with
epochs. Our submission using perspective-aware ISP on GPT-4 and GPT-4o achieved
ROUGE scores (46.53, 24.68, 30.77) and BERTscores (87.84, 83.25, 85.46) for (P,
R, F1) from the official evaluation on 3,396 clinical case reports from various
specialties extracted from open journals. The high BERTscore indicates that the
model produced semantically equivalent output summaries compared to the
references, even though the overlap at the exact lexicon level is lower, as
reflected in the lower ROUGE scores. This work sheds some light on how
perspective-aware ISP (PA-ISP) can be deployed for clinical report
summarisation and support better communication between patients and clinicians.

</details>


### [27] [MoLoRAG: Bootstrapping Document Understanding via Multi-modal Logic-aware Retrieval](https://arxiv.org/abs/2509.07666)
*Xixi Wu,Yanchao Tan,Nan Hou,Ruiyang Zhang,Hong Cheng*

Main category: cs.CL

TL;DR: MoLoRAG是一个逻辑感知的检索框架，用于多模态多页文档理解，通过构建页面图结合语义和逻辑相关性来提升文档问答性能


<details>
  <summary>Details</summary>
Motivation: 传统方法将文档转为文本处理会丢失多模态信息，而大型视觉语言模型受限于输入长度无法处理多页文档，现有检索方法仅依赖语义相关性而忽略页面间的逻辑连接

Method: 构建页面图捕捉页面间上下文关系，使用轻量级VLM进行图遍历检索相关页面，结合语义和逻辑相关性，提供训练免费和微调两种变体

Result: 在四个DocQA数据集上平均准确率比LVLM直接推理提升9.68%，检索精度比基线方法提升7.44%

Conclusion: MoLoRAG通过逻辑感知的检索框架有效解决了多页文档理解中的逻辑连接问题，显著提升了文档问答性能

Abstract: Document Understanding is a foundational AI capability with broad
applications, and Document Question Answering (DocQA) is a key evaluation task.
Traditional methods convert the document into text for processing by Large
Language Models (LLMs), but this process strips away critical multi-modal
information like figures. While Large Vision-Language Models (LVLMs) address
this limitation, their constrained input size makes multi-page document
comprehension infeasible. Retrieval-augmented generation (RAG) methods mitigate
this by selecting relevant pages, but they rely solely on semantic relevance,
ignoring logical connections between pages and the query, which is essential
for reasoning.
  To this end, we propose MoLoRAG, a logic-aware retrieval framework for
multi-modal, multi-page document understanding. By constructing a page graph
that captures contextual relationships between pages, a lightweight VLM
performs graph traversal to retrieve relevant pages, including those with
logical connections often overlooked. This approach combines semantic and
logical relevance to deliver more accurate retrieval. After retrieval, the
top-$K$ pages are fed into arbitrary LVLMs for question answering. To enhance
flexibility, MoLoRAG offers two variants: a training-free solution for easy
deployment and a fine-tuned version to improve logical relevance checking.
Experiments on four DocQA datasets demonstrate average improvements of 9.68% in
accuracy over LVLM direct inference and 7.44% in retrieval precision over
baselines. Codes and datasets are released at
https://github.com/WxxShirley/MoLoRAG.

</details>


### [28] [M-BRe: Discovering Training Samples for Relation Extraction from Unlabeled Texts with Large Language Models](https://arxiv.org/abs/2509.07730)
*Zexuan Li,Hongliang Dai,Piji Li*

Main category: cs.CL

TL;DR: 本文提出了M-BRe框架，通过关系分组、关系提取和标签决策三个模块，结合多分类和二元分类的优势，从未标注文本中高效提取关系抽取训练样本。


<details>
  <summary>Details</summary>
Motivation: 关系抽取中手动标注训练数据成本高昂，且包含目标关系的句子稀少难找。虽然大语言模型可用于关系抽取，但多分类难以全面捕捉每个关系语义，而二元分类又计算开销过大。

Method: 提出M-BRe框架，包含三个模块：关系分组（将相似关系聚类）、关系提取（对每个关系组进行多分类）、标签决策（确定最终关系标签），结合了多分类和二元分类的优点。

Result: 大量实验证实该框架能够从未标注文本中发现高质量的关系抽取训练样本，表现出优越的性能。

Conclusion: M-BRe框架有效解决了关系抽取中训练数据获取的难题，通过创新的模块设计平衡了分类效果和计算效率，为关系抽取模型的训练提供了高质量的自动标注数据。

Abstract: For Relation Extraction (RE), the manual annotation of training data may be
prohibitively expensive, since the sentences that contain the target relations
in texts can be very scarce and difficult to find. It is therefore beneficial
to develop an efficient method that can automatically extract training
instances from unlabeled texts for training RE models. Recently, large language
models (LLMs) have been adopted in various natural language processing tasks,
with RE also benefiting from their advances. However, when leveraging LLMs for
RE with predefined relation categories, two key challenges arise. First, in a
multi-class classification setting, LLMs often struggle to comprehensively
capture the semantics of every relation, leading to suboptimal results. Second,
although employing binary classification for each relation individually can
mitigate this issue, it introduces significant computational overhead,
resulting in impractical time complexity for real-world applications.
Therefore, this paper proposes a framework called M-BRe to extract training
instances from unlabeled texts for RE. It utilizes three modules to combine the
advantages of both of the above classification approaches: Relation Grouping,
Relation Extraction, and Label Decision. Extensive experiments confirm its
superior capability in discovering high-quality training samples from unlabeled
texts for RE.

</details>


### [29] [Factuality Beyond Coherence: Evaluating LLM Watermarking Methods for Medical Texts](https://arxiv.org/abs/2509.07755)
*Rochana Prih Hastuti,Rian Adam Rajagede,Mansour Al Ghanim,Mengxin Zheng,Qian Lou*

Main category: cs.CL

TL;DR: 医学领域水印技术存在事实性风险，现有方法在低熵度设置下会弱化医学实体表达能力，需要领域谨慎的水印方案来保护医学内容整体性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在医学等敏感领域的应用，水印技术的可靠性成为关键问题。现有评测标准过于关注检测质量的权衡，而忽视了低熵度设置下的事实风险。

Method: 提出了一个医学专门的评估流程，结合评估事实准确性和连贯性。使用GPT-Judger和人工验证，引入了事实性权重分数（FWS）这个组合指标，优先考虑事实准确性而非仅仅是连贯性。

Result: 评估结果显示当前的水印方法在医学事实性方面存在显著问题，熵度偏移会降低医学实体的表达能力。

Conclusion: 医学领域需要更加关注事实准确性的水印技术，现有方法在保护内容整体性方面存在不足，需要领域谨慎的水印方案。

Abstract: As large language models (LLMs) adapted to sensitive domains such as
medicine, their fluency raises safety risks, particularly regarding provenance
and accountability. Watermarking embeds detectable patterns to mitigate these
risks, yet its reliability in medical contexts remains untested. Existing
benchmarks focus on detection-quality tradeoffs, overlooking factual risks
under low-entropy settings often exploited by watermarking's reweighting
strategy. We propose a medical-focused evaluation workflow that jointly
assesses factual accuracy and coherence. Using GPT-Judger and further human
validation, we introduce the Factuality-Weighted Score (FWS), a composite
metric prioritizing factual accuracy beyond coherence to guide watermarking
deployment in medical domains. Our evaluation shows current watermarking
methods substantially compromise medical factuality, with entropy shifts
degrading medical entity representation. These findings underscore the need for
domain-aware watermarking approaches that preserve the integrity of medical
content.

</details>


### [30] [Are LLMs Enough for Hyperpartisan, Fake, Polarized and Harmful Content Detection? Evaluating In-Context Learning vs. Fine-Tuning](https://arxiv.org/abs/2509.07768)
*Michele Joshua Maggini,Dhia Merzougui,Rabiraj Bandyopadhyay,Gaël Dias,Fabrice Maurel,Pablo Gamallo*

Main category: cs.CL

TL;DR: 本研究全面评估了大型语言模型在不同语言和数据集上检测虚假新闻、有害内容和政治偏见的性能，发现微调方法通常优于上下文学习策略。


<details>
  <summary>Details</summary>
Motivation: 在线平台上的虚假新闻、有害内容和政治偏见内容传播严重，但缺乏对不同大语言模型、使用方法和语言的系统性基准测试。

Method: 在10个数据集和5种语言上测试了参数高效微调和多种上下文学习策略（零样本提示、代码本、少样本学习、思维链等），比较了不同模型的表现。

Result: 上下文学习通常表现不如模型微调，即使是较小模型经过任务特定微调后也能超越大型模型的上下文学习表现。

Conclusion: 微调对于虚假新闻检测等任务至关重要，即使对于较小模型，任务特定的微调也能产生比大型模型上下文学习更好的效果。

Abstract: The spread of fake news, polarizing, politically biased, and harmful content
on online platforms has been a serious concern. With large language models
becoming a promising approach, however, no study has properly benchmarked their
performance across different models, usage methods, and languages. This study
presents a comprehensive overview of different Large Language Models adaptation
paradigms for the detection of hyperpartisan and fake news, harmful tweets, and
political bias. Our experiments spanned 10 datasets and 5 different languages
(English, Spanish, Portuguese, Arabic and Bulgarian), covering both binary and
multiclass classification scenarios. We tested different strategies ranging
from parameter efficient Fine-Tuning of language models to a variety of
different In-Context Learning strategies and prompts. These included zero-shot
prompts, codebooks, few-shot (with both randomly-selected and
diversely-selected examples using Determinantal Point Processes), and
Chain-of-Thought. We discovered that In-Context Learning often underperforms
when compared to Fine-Tuning a model. This main finding highlights the
importance of Fine-Tuning even smaller models on task-specific settings even
when compared to the largest models evaluated in an In-Context Learning setup -
in our case LlaMA3.1-8b-Instruct, Mistral-Nemo-Instruct-2407 and
Qwen2.5-7B-Instruct.

</details>


### [31] [SciNLP: A Domain-Specific Benchmark for Full-Text Scientific Entity and Relation Extraction in NLP](https://arxiv.org/abs/2509.07801)
*Decheng Duan,Yingyi Zhang,Jitong Peng,Chengzhi Zhang*

Main category: cs.CL

TL;DR: SciNLP是首个专门针对NLP领域的全文本实体和关系抽取基准数据集，包含60篇人工标注的完整论文，涵盖7,072个实体和1,826个关系，显著提升了现有模型在学术文本抽取方面的性能。


<details>
  <summary>Details</summary>
Motivation: 现有科学文献信息抽取数据集大多只关注特定章节，受限于领域复杂性和标注成本高的问题，需要构建专门针对NLP领域的全文本标注数据集。

Method: 构建包含60篇NLP领域完整论文的人工标注数据集，涵盖实体和关系标注；使用最先进的监督模型进行对比实验；基于SciNLP训练模型自动构建细粒度NLP知识图谱。

Result: 实验显示现有模型在不同长度学术文本上的抽取能力存在差异；与现有数据集相比，SciNLP在某些基线模型上实现了显著性能提升；构建的知识图谱平均节点度为3.2，具有丰富的语义拓扑信息。

Conclusion: SciNLP填补了NLP领域全文本实体关系抽取数据集的空白，为相关研究提供了重要基准，构建的知识图谱对下游应用具有重要价值，数据集已公开可用。

Abstract: Structured information extraction from scientific literature is crucial for
capturing core concepts and emerging trends in specialized fields. While
existing datasets aid model development, most focus on specific publication
sections due to domain complexity and the high cost of annotating scientific
texts. To address this limitation, we introduce SciNLP - a specialized
benchmark for full-text entity and relation extraction in the Natural Language
Processing (NLP) domain. The dataset comprises 60 manually annotated full-text
NLP publications, covering 7,072 entities and 1,826 relations. Compared to
existing research, SciNLP is the first dataset providing full-text annotations
of entities and their relationships in the NLP domain. To validate the
effectiveness of SciNLP, we conducted comparative experiments with similar
datasets and evaluated the performance of state-of-the-art supervised models on
this dataset. Results reveal varying extraction capabilities of existing models
across academic texts of different lengths. Cross-comparisons with existing
datasets show that SciNLP achieves significant performance improvements on
certain baseline models. Using models trained on SciNLP, we implemented
automatic construction of a fine-grained knowledge graph for the NLP domain.
Our KG has an average node degree of 3.2 per entity, indicating rich semantic
topological information that enhances downstream applications. The dataset is
publicly available at https://github.com/AKADDC/SciNLP.

</details>


### [32] [Small Open Models Achieve Near Parity with Large Models in Low Resource Literary Translation at a Fraction of the Cost](https://arxiv.org/abs/2509.07829)
*Mihai Nadas,Laura Diosan,Andreea Tomescu,Andrei Piscoran*

Main category: cs.CL

TL;DR: 提出了TINYFABULIST TRANSLATION FRAMEWORK (TF2)，一个用于英罗文学翻译的统一框架，包括数据集创建、微调和评估，并发布了12B参数的微调模型和大型合成平行数据集。


<details>
  <summary>Details</summary>
Motivation: 解决小规模开放模型在文学翻译这一复杂任务中的性能问题，特别是为低资源语言如罗马尼亚语提供高质量文学数据集的需求。

Method: 采用两阶段微调过程：首先使用高性能LLM生成15k高质量罗马尼亚语参考译文，然后对12B参数模型进行(i)指令调优以捕捉特定体裁叙事风格，(ii)适配器压缩以实现高效部署。

Result: 微调模型在流畅性和充分性方面与顶级专有大模型竞争，同时具有开放性、可访问性和显著的成本效益优势。

Conclusion: TF2提供了一个端到端、可复现的管道，用于研究成本效益高的翻译、跨语言叙事生成，以及在低资源环境中广泛采用开放模型处理具有文化意义的文学内容。

Abstract: Literary translation has recently gained attention as a distinct and complex
task in machine translation research. However, the translation by small open
models remains an open problem. We contribute to this ongoing research by
introducing TINYFABULIST TRANSLATION FRAMEWORK (TF2), a unified framework for
dataset creation, fine tuning, and evaluation in English-Romanian literary
translations, centred on the creation and open release of both a compact, fine
tuned language model (TF2-12B) and large scale synthetic parallel datasets
(DS-TF2-EN-RO-3M and DS-TF2-EN-RO-15K). Building on DS-TF1-EN-3M (TF1), the
largest collection of synthetic English fables to date, we address the need for
rich, high quality literary datasets in low resource languages such as
Romanian. Our pipeline first generates 15k high quality Romanian references
from the TF1 pool using a high performing LLM. We then apply a two stage fine
tuning process to a 12B parameter open weight model: (i) instruction tuning to
capture genre specific narrative style, and (ii) adapter compression for
efficient deployment. Evaluation combines corpus level BLEU and a five
dimension LLM based rubric (accuracy, fluency, coherence, style, cultural
adaptation) to provide a nuanced assessment of translation quality. Results
show that our fine tuned model achieves fluency and adequacy competitive with
top performing large proprietary models, while being open, accessible, and
significantly more cost effective. Alongside the fine tuned model and both
datasets, we publicly release all scripts and evaluation prompts. TF2 thus
provides an end-to-end, reproducible pipeline for research on cost efficient
translation, cross lingual narrative generation, and the broad adoption of open
models for culturally significant literary content in low resource settings.

</details>


### [33] [Are Humans as Brittle as Large Language Models?](https://arxiv.org/abs/2509.07869)
*Jiahui Li,Sean Papay,Roman Klinger*

Main category: cs.CL

TL;DR: 研究发现人类和大型语言模型在提示修改下都表现出脆弱性，特别是在标签集和标签格式变化时，但人类对拼写错误和标签顺序反转的敏感性低于LLM


<details>
  <summary>Details</summary>
Motivation: 探索人类标注者是否对指令修改表现出与LLM类似的敏感性，以判断LLM的提示脆弱性是否反映了人类标注的固有方差

Method: 通过文本分类任务，对LLM和人类标注者使用相同的提示变体，系统比较两者对提示修改的敏感性

Result: 人类和LLM都对特定类型的提示修改（如替代标签集和标签格式变化）表现出增加的脆弱性，但人类对拼写错误和标签顺序反转的敏感性较低

Conclusion: LLM的提示脆弱性在一定程度上反映了人类标注的固有方差，但LLM对某些提示扰动更加敏感

Abstract: The output of large language models (LLM) is unstable, due to both
non-determinism of the decoding process as well as to prompt brittleness. While
the intrinsic non-determinism of LLM generation may mimic existing uncertainty
in human annotations through distributional shifts in outputs, it is largely
assumed, yet unexplored, that the prompt brittleness effect is unique to LLMs.
This raises the question: do human annotators show similar sensitivity to
instruction changes? If so, should prompt brittleness in LLMs be considered
problematic? One may alternatively hypothesize that prompt brittleness
correctly reflects human annotation variances. To fill this research gap, we
systematically compare the effects of prompt modifications on LLMs and
identical instruction modifications for human annotators, focusing on the
question of whether humans are similarly sensitive to prompt perturbations. To
study this, we prompt both humans and LLMs for a set of text classification
tasks conditioned on prompt variations. Our findings indicate that both humans
and LLMs exhibit increased brittleness in response to specific types of prompt
modifications, particularly those involving the substitution of alternative
label sets or label formats. However, the distribution of human judgments is
less affected by typographical errors and reversed label order than that of
LLMs.

</details>


### [34] [From Detection to Mitigation: Addressing Gender Bias in Chinese Texts via Efficient Tuning and Voting-Based Rebalancing](https://arxiv.org/abs/2509.07889)
*Chengyan Wu,Yiqiang Cai,Yufei Cheng,Yun Xue*

Main category: cs.CL

TL;DR: 本文提出了基于大语言模型微调和LoRA的句子级性别偏见检测与缓解方法，通过数据平衡、多模型集成和多温度采样机制，在NLPCC-2025共享任务中获得第四名


<details>
  <summary>Details</summary>
Motivation: 促进自然语言生成中的公平性和可控性，自动检测、分类和缓解中文句子中的性别偏见

Method: 采用基于大语言模型的微调方法，使用LoRA进行高效适配；构建平衡训练集缓解类别不平衡；引入多源异构样本增强泛化；使用多数投票策略集成多个专家模型；设计多温度采样机制捕捉偏见表达风格变化

Result: 在偏见检测、分类和缓解方面表现出有效性，最终获得47.90%的平均得分，在共享任务中排名第四

Conclusion: 所提出的方法在中文性别偏见处理任务中具有较好的效果，多模型集成和多温度采样机制对性能提升有显著贡献

Abstract: This paper presents our team's solution to Shared Task 7 of NLPCC-2025, which
focuses on sentence-level gender bias detection and mitigation in Chinese. The
task aims to promote fairness and controllability in natural language
generation by automatically detecting, classifying, and mitigating gender bias.
To address this challenge, we adopt a fine-tuning approach based on large
language models (LLMs), efficiently adapt to the bias detection task via
Low-Rank Adaptation (LoRA). In terms of data processing, we construct a more
balanced training set to alleviate class imbalance and introduce heterogeneous
samples from multiple sources to enhance model generalization. For the
detection and classification sub-tasks, we employ a majority voting strategy
that integrates outputs from multiple expert models to boost performance.
Additionally, to improve bias generation detection and mitigation, we design a
multi-temperature sampling mechanism to capture potential variations in bias
expression styles. Experimental results demonstrate the effectiveness of our
approach in bias detection, classification, and mitigation. Our method
ultimately achieves an average score of 47.90%, ranking fourth in the shared
task.

</details>


### [35] [Biased Tales: Cultural and Topic Bias in Generating Children's Stories](https://arxiv.org/abs/2509.07908)
*Donya Rooein,Vilém Zouhar,Debora Nozza,Dirk Hovy*

Main category: cs.CL

TL;DR: Biased Tales数据集分析发现LLM生成的故事中存在显著的文化和性别刻板印象，女孩主角的外观相关属性比男孩多55.26%，非西方儿童故事过度强调文化传统主题


<details>
  <summary>Details</summary>
Motivation: 随着家长越来越多地使用大型语言模型创作睡前故事，这些叙事中存在的文化和性别刻板印象问题值得关注，需要系统分析偏见如何影响主角属性和故事元素

Method: 构建Biased Tales综合数据集，分析LLM生成故事中主角性别和文化背景对故事内容的影响，量化比较不同群体主角的属性差异

Result: 发现显著差异：女孩主角的外观相关属性比男孩多55.26%；非西方儿童故事更强调文化遗产、传统和家庭主题，远超西方儿童故事

Conclusion: 研究结果凸显了社会文化偏见在创意AI应用中的影响，强调需要使AI创作更加公平和多样化

Abstract: Stories play a pivotal role in human communication, shaping beliefs and
morals, particularly in children. As parents increasingly rely on large
language models (LLMs) to craft bedtime stories, the presence of cultural and
gender stereotypes in these narratives raises significant concerns. To address
this issue, we present Biased Tales, a comprehensive dataset designed to
analyze how biases influence protagonists' attributes and story elements in
LLM-generated stories. Our analysis uncovers striking disparities. When the
protagonist is described as a girl (as compared to a boy), appearance-related
attributes increase by 55.26%. Stories featuring non-Western children
disproportionately emphasize cultural heritage, tradition, and family themes
far more than those for Western children. Our findings highlight the role of
sociocultural bias in making creative AI use more equitable and diverse.

</details>


### [36] [GENUINE: Graph Enhanced Multi-level Uncertainty Estimation for Large Language Models](https://arxiv.org/abs/2509.07925)
*Tuo Wang,Adithya Kulkarni,Tyler Cody,Peter A. Beling,Yujun Yan,Dawei Zhou*

Main category: cs.CL

TL;DR: GENUINE是一个基于图结构的LLM不确定性估计框架，通过依赖解析树和层次图池化来改进不确定性量化，比语义熵方法AUROC提升29%，校准误差降低15%


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视语义依赖关系，仅依赖词级概率度量，无法捕捉生成文本中的结构关系，影响LLM在高风险应用中的可靠性

Method: 提出GENUINE框架，利用依赖解析树和层次图池化技术，结合监督学习来建模语义和结构关系，改进置信度评估

Result: 在多个NLP任务上，GENUINE比基于语义熵的方法AUROC提升高达29%，校准误差降低超过15%

Conclusion: 基于图结构的不确定性建模方法有效提升了LLM不确定性估计的准确性，证明了结构感知方法在不确定性量化中的重要性

Abstract: Uncertainty estimation is essential for enhancing the reliability of Large
Language Models (LLMs), particularly in high-stakes applications. Existing
methods often overlook semantic dependencies, relying on token-level
probability measures that fail to capture structural relationships within the
generated text. We propose GENUINE: Graph ENhanced mUlti-level uncertaINty
Estimation for Large Language Models, a structure-aware framework that
leverages dependency parse trees and hierarchical graph pooling to refine
uncertainty quantification. By incorporating supervised learning, GENUINE
effectively models semantic and structural relationships, improving confidence
assessments. Extensive experiments across NLP tasks show that GENUINE achieves
up to 29% higher AUROC than semantic entropy-based approaches and reduces
calibration errors by over 15%, demonstrating the effectiveness of graph-based
uncertainty modeling. The code is available at
https://github.com/ODYSSEYWT/GUQ.

</details>


### [37] [SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge](https://arxiv.org/abs/2509.07968)
*Lukas Haas,Gal Yona,Giovanni D'Antonio,Sasha Goldshtein,Dipanjan Das*

Main category: cs.CL

TL;DR: 简介SimpleQA Verified评测标准，通过多阶段筛选解决了OpenAI SimpleQA的标签噪声、主题偏差和问题重复问题，Gemini 2.5 Pro在该标准上达到55.6的F1分数


<details>
  <summary>Details</summary>
Motivation: 解决OpenAI SimpleQA标准中存在的标签噪声、主题偏差和问题重复等限制，提供更可靠的短文本事实性评估工具

Method: 通过严格的多阶段筛选过程，包括去重、主题平衡和来源协调，同时改进了自动评分提示

Result: Gemini 2.5 Pro在该新标准上达到了状态最佳的F1分数55.6，超过了包括GPT-5在内的其他前沿模型

Conclusion: 该工作为研究社区提供了更高保真度的工具，用于跟踪参数模型事实性的真实进展并减少幻觉

Abstract: We introduce SimpleQA Verified, a 1,000-prompt benchmark for evaluating Large
Language Model (LLM) short-form factuality based on OpenAI's SimpleQA. It
addresses critical limitations in OpenAI's benchmark, including noisy and
incorrect labels, topical biases, and question redundancy. SimpleQA Verified
was created through a rigorous multi-stage filtering process involving
de-duplication, topic balancing, and source reconciliation to produce a more
reliable and challenging evaluation set, alongside improvements in the
autorater prompt. On this new benchmark, Gemini 2.5 Pro achieves a
state-of-the-art F1-score of 55.6, outperforming other frontier models,
including GPT-5. This work provides the research community with a
higher-fidelity tool to track genuine progress in parametric model factuality
and to mitigate hallucinations. The benchmark dataset, evaluation code, and
leaderboard are available at:
https://www.kaggle.com/benchmarks/deepmind/simpleqa-verified.

</details>


### [38] [Parallel-R1: Towards Parallel Thinking via Reinforcement Learning](https://arxiv.org/abs/2509.07980)
*Tong Zheng,Hongming Zhang,Wenhao Yu,Xiaoyang Wang,Xinyu Yang,Runpeng Dai,Rui Liu,Huiwen Bao,Chengsong Huang,Heng Huang,Dong Yu*

Main category: cs.CL

TL;DR: Parallel-R1是首个通过强化学习训练大语言模型并行思维能力的框架，采用渐进式课程学习解决冷启动问题，在数学推理任务上相比顺序思维模型提升8.4%准确率，并能作为训练中的探索支架带来42.9%的性能提升


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖监督微调合成数据，鼓励教师强制模仿而非探索和泛化，难以有效训练并行思维能力

Method: 提出Parallel-R1强化学习框架，先使用SFT在简单任务上培养并行思维基础，然后通过RL在困难问题上探索和泛化该能力

Result: 在MATH、AMC23、AIME等数学基准测试中，相比直接RL训练的序列思维模型准确率提升8.4%，在AIME25上相比基线提升42.9%

Conclusion: 并行思维可作为训练中的探索支架，早期用于探索策略，后期用于多视角验证，临时探索阶段能解锁更高的性能上限

Abstract: Parallel thinking has emerged as a novel approach for enhancing the reasoning
capabilities of large language models (LLMs) by exploring multiple reasoning
paths concurrently. However, activating such capabilities through training
remains challenging, as existing methods predominantly rely on supervised
fine-tuning (SFT) over synthetic data, which encourages teacher-forced
imitation rather than exploration and generalization. Different from them, we
propose \textbf{Parallel-R1}, the first reinforcement learning (RL) framework
that enables parallel thinking behaviors for complex real-world reasoning
tasks. Our framework employs a progressive curriculum that explicitly addresses
the cold-start problem in training parallel thinking with RL. We first use SFT
on prompt-generated trajectories from easier tasks to instill the parallel
thinking ability, then transition to RL to explore and generalize this skill on
harder problems. Experiments on various math benchmarks, including MATH, AMC23,
and AIME, show that Parallel-R1 successfully instills parallel thinking,
leading to 8.4% accuracy improvements over the sequential thinking model
trained directly on challenging tasks with RL. Further analysis reveals a clear
shift in the model's thinking behavior: at an early stage, it uses parallel
thinking as an exploration strategy, while in a later stage, it uses the same
capability for multi-perspective verification. Most significantly, we validate
parallel thinking as a \textbf{mid-training exploration scaffold}, where this
temporary exploratory phase unlocks a higher performance ceiling after RL,
yielding a 42.9% improvement over the baseline on AIME25. Our model, data, and
code will be open-source at https://github.com/zhengkid/Parallel-R1.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [39] [Prototype: A Keyword Spotting-Based Intelligent Audio SoC for IoT](https://arxiv.org/abs/2509.06964)
*Huihong Liang,Dongxuan Jia,Youquan Wang,Longtao Huang,Shida Zhong,Luping Xiang,Lei Huang,Tao Yuan*

Main category: cs.SD

TL;DR: 提出了一种集成关键词识别加速器的紧凑智能音频SoC，通过算法-硬件协同设计实现超低延迟、低功耗和低成本的物联网设备语音交互


<details>
  <summary>Details</summary>
Motivation: 为物联网设备提供高效、低成本的语音交互解决方案，满足边缘智能应用对实时性和能效的需求

Method: 采用算法-硬件协同设计方法，集成专用关键词识别加速器，并在FPGA平台上构建原型系统

Result: 系统实现了超低延迟、低功耗和稳定性能，能够支持实时语音交互

Conclusion: 该智能音频SoC系统为物联网设备的语音交互提供了可行的解决方案，展示了边缘智能应用的潜力

Abstract: In this demo, we present a compact intelligent audio system-on-chip (SoC)
integrated with a keyword spotting accelerator, enabling ultra-low latency,
low-power, and low-cost voice interaction in Internet of Things (IoT) devices.
Through algorithm-hardware co-design, the system's energy efficiency is
maximized. We demonstrate the system's capabilities through a live FPGA-based
prototype, showcasing stable performance and real-time voice interaction for
edge intelligence applications.

</details>


### [40] [Controllable Singing Voice Synthesis using Phoneme-Level Energy Sequence](https://arxiv.org/abs/2509.07038)
*Yerin Ryu,Inseop Shin,Chanwoo Kim*

Main category: cs.SD

TL;DR: 通过显式能量序列条件化控制歌唱语音合成的动态特性，实现用户可驱动的音量变化控制


<details>
  <summary>Details</summary>
Motivation: 当前歌唱语音合成系统多依赖概率模型，对动态特性等属性的精确控制有限

Method: 使用从真实语音谱中提取的能量序列显式条件化SVS模型，并提出音素级能量序列用于用户友好控制

Result: 实验显示方法在音素级输入下能量序列的均方差锐减超过50%，且不影响合成质量

Conclusion: 该方法首次实现了SVS中用户可驱动的动态控制，减少了标注成本并提高了控制性

Abstract: Controllable Singing Voice Synthesis (SVS) aims to generate expressive
singing voices reflecting user intent. While recent SVS systems achieve high
audio quality, most rely on probabilistic modeling, limiting precise control
over attributes such as dynamics. We address this by focusing on dynamic
control--temporal loudness variation essential for musical expressiveness--and
explicitly condition the SVS model on energy sequences extracted from
ground-truth spectrograms, reducing annotation costs and improving
controllability. We also propose a phoneme-level energy sequence for
user-friendly control. To the best of our knowledge, this is the first attempt
enabling user-driven dynamics control in SVS. Experiments show our method
achieves over 50% reduction in mean absolute error of energy sequences for
phoneme-level inputs compared to baseline and energy-predictor models, without
compromising synthesis quality.

</details>


### [41] [End-to-End Efficiency in Keyword Spotting: A System-Level Approach for Embedded Microcontrollers](https://arxiv.org/abs/2509.07051)
*Pietro Bartoli,Tommaso Bondini,Christian Veronesi,Andrea Giudici,Niccolò Antonello,Franco Zappa*

Main category: cs.SD

TL;DR: 本文系统性评估多种轻量级神经网络在微控制器上的关键词检测性能，提出了基于MobileNet的TKWS模型，在仅占14.4k参数的情况下达到92.4%的F1分数，并分析了从特征提取到推理的全处理流程。


<details>
  <summary>Details</summary>
Motivation: 关键词检测(KWS)是嵌入式和IoT设备中无手交互的关键技术，但内存和能源约束为AI设备部署带来挑战。需要找到既精确又高效的解决方案。

Method: 系统性评估DS-CNN、LiCoNet、TENet等轻量级网络架构，并提出基于MobileNet的TKWS架构。分析从MFCC特征提取到神经网络推理的全处理流程，在三种STM32平台(N6、H7、U5)上进行测试。

Result: TKWS使用3个殊忍块达到92.4%的F1分数，参数仅占14.4k。集成神经加速的N6 MCU获得最佳能源-延迟乘积(EDP)，能够在高分辨率特征下实现高效低延迟运行。

Conclusion: 模型准确性不是唯一决定因素，最佳的关键词检测部署需要维度考虑特征提取参数和硬件特定优化。

Abstract: Keyword spotting (KWS) is a key enabling technology for hands-free
interaction in embedded and IoT devices, where stringent memory and energy
constraints challenge the deployment of AI-enabeld devices. In this work, we
systematically evaluate and compare several state-of-the-art lightweight neural
network architectures, including DS-CNN, LiCoNet, and TENet, alongside our
proposed Typman-KWS (TKWS) architecture built upon MobileNet, specifically
designed for efficient KWS on microcontroller units (MCUs). Unlike prior
studies focused solely on model inference, our analysis encompasses the entire
processing pipeline, from Mel-Frequency Cepstral Coefficient (MFCC) feature
extraction to neural inference, and is benchmarked across three STM32 platforms
(N6, H7, and U5). Our results show that TKWS with three residual blocks
achieves up to 92.4% F1-score with only 14.4k parameters, reducing memory
footprint without compromising the accuracy. Moreover, the N6 MCU with
integrated neural acceleration achieves the best energy-delay product (EDP),
enabling efficient, low-latency operation even with high-resolution features.
Our findings highlight the model accuracy alone does not determine real-world
effectiveness; rather, optimal keyword spotting deployments require careful
consideration of feature extraction parameters and hardware-specific
optimization.

</details>


### [42] [Adversarial Attacks on Audio Deepfake Detection: A Benchmark and Comparative Study](https://arxiv.org/abs/2509.07132)
*Kutub Uddin,Muhammad Umar Farooq,Awais Khan,Khalid Mahmood Malik*

Main category: cs.SD

TL;DR: 该论文分析了现有音频深度伪造检测方法的效果，并评估它们在反例学攻击下的脆弱性，以指导更稳健的检测器设计。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI产生高伪真深度伪造音频的普及，对语音生物识别应用构成了严重威胁。虽然现有检测方法能识别生成式签名，但反例学攻击可以隐藏这些签名，很大程度上削弱了检测方法的有效性。

Method: 评估现有最先进的音频深度伪造检测方法，包括原始音频和谱图基于的方法。使用5个深度伪造数据集，测试对两类反例学攻击的耐受性：统计修改（如音高变换、筛波、噪声添加、量化）和优化基于攻击（如FGSM、PGD、C&W、DeepFool）。

Result: 对比分析揭示了现有检测方法在识别深度伪造签名方面的优势，以及在各种反例学攻击下的明显脆弱性。这些方法在对抗变化多端的反例学技术时显示出了不同程度的潜在漏洞。

Conclusion: 该研究不仅揭示了音频深度伪造检测方法的安全漏洞，为设计更稳健、通用性更强的检测器提供了重要指导，并将促进未来研究发展能够有效应对日益潜入的反例学技术的适应性防御策略。

Abstract: The widespread use of generative AI has shown remarkable success in producing
highly realistic deepfakes, posing a serious threat to various voice biometric
applications, including speaker verification, voice biometrics, audio
conferencing, and criminal investigations. To counteract this, several
state-of-the-art (SoTA) audio deepfake detection (ADD) methods have been
proposed to identify generative AI signatures to distinguish between real and
deepfake audio. However, the effectiveness of these methods is severely
undermined by anti-forensic (AF) attacks that conceal generative signatures.
These AF attacks span a wide range of techniques, including statistical
modifications (e.g., pitch shifting, filtering, noise addition, and
quantization) and optimization-based attacks (e.g., FGSM, PGD, C \& W, and
DeepFool). In this paper, we investigate the SoTA ADD methods and provide a
comparative analysis to highlight their effectiveness in exposing deepfake
signatures, as well as their vulnerabilities under adversarial conditions. We
conducted an extensive evaluation of ADD methods on five deepfake benchmark
datasets using two categories: raw and spectrogram-based approaches. This
comparative analysis enables a deeper understanding of the strengths and
limitations of SoTA ADD methods against diverse AF attacks. It does not only
highlight vulnerabilities of ADD methods, but also informs the design of more
robust and generalized detectors for real-world voice biometrics. It will
further guide future research in developing adaptive defense strategies that
can effectively counter evolving AF techniques.

</details>


### [43] [When Fine-Tuning is Not Enough: Lessons from HSAD on Hybrid and Adversarial Audio Spoof Detection](https://arxiv.org/abs/2509.07323)
*Bin Hu,Kunyang Huang,Daehan Kwak,Meng Xu,Kuan Huang*

Main category: cs.SD

TL;DR: 这篇论文提出了混合证证音频数据集HSAD，用于处理真实和合成语音混合的欺骗攻击，证明现有模型在混合条件下表现差强，需要专门的数据集来建立稳健的语音认证系统。


<details>
  <summary>Details</summary>
Motivation: 人工智能语音合成和声音克隆技术的快速发展对声音认证、智能助手和通信安全构成了严重威胁。现有的欺骗检测多为二元分类，而真实攻击常包含真实和合成语音的混合内容，使检测更加困难。

Method: 研究人员构建了混合证证音频数据集HSAD，包含41,044个退化语音和1,248个清洁语音，分为四个类别：人类、克隆音频、零样本AI生成音频和混合音频。每个样本都有欺骗方法、说话人身份和退化元数据标签。评估了六种基于transformer的模型，包括谱图编码器和自监督波形模型。

Result: 结果显示：预训练模型在混合条件下存在过度普适和性能呈现突然下降的问题；针对欺骗检测的细调能提高可分离性，但对未见组合效果不佳；在HSAD数据集上进行数据集特定适应能大幅提升性能（AST模型准确率超过97%，F1得分约99%），但复杂混合音频仍有残余错误。

Conclusion: 细调单独不足以建立稳健的混合证证检测系统。HSAD数据集提供了一个重要的测试基准和分析框架，能够曝露模型的校准失败、偏见和影响欺骗检测的因素，为建立可靠和可信赖的声音认证系统提供支持。

Abstract: The rapid advancement of AI has enabled highly realistic speech synthesis and
voice cloning, posing serious risks to voice authentication, smart assistants,
and telecom security. While most prior work frames spoof detection as a binary
task, real-world attacks often involve hybrid utterances that mix genuine and
synthetic speech, making detection substantially more challenging. To address
this gap, we introduce the Hybrid Spoofed Audio Dataset (HSAD), a benchmark
containing 1,248 clean and 41,044 degraded utterances across four classes:
human, cloned, zero-shot AI-generated, and hybrid audio. Each sample is
annotated with spoofing method, speaker identity, and degradation metadata to
enable fine-grained analysis. We evaluate six transformer-based models,
including spectrogram encoders (MIT-AST, MattyB95-AST) and self-supervised
waveform models (Wav2Vec2, HuBERT). Results reveal critical lessons: pretrained
models overgeneralize and collapse under hybrid conditions; spoof-specific
fine-tuning improves separability but struggles with unseen compositions; and
dataset-specific adaptation on HSAD yields large performance gains (AST greater
than 97 percent and F1 score is approximately 99 percent), though residual
errors persist for complex hybrids. These findings demonstrate that fine-tuning
alone is not sufficient-robust hybrid-aware benchmarks like HSAD are essential
to expose calibration failures, model biases, and factors affecting spoof
detection in adversarial environments. HSAD thus provides both a dataset and an
analytic framework for building resilient and trustworthy voice authentication
systems.

</details>


### [44] [Progressive Facial Granularity Aggregation with Bilateral Attribute-based Enhancement for Face-to-Speech Synthesis](https://arxiv.org/abs/2509.07376)
*Yejin Jeon,Youngjae Kim,Jihyun Lee,Hyounghun Kim,Gary Geunbae Lee*

Main category: cs.SD

TL;DR: 通过细粒度面部属性建模和多视角训练策略，提出了一种更有效的面部到声音合成方法，保留了性别和种族等细粒信息，显著提升了面部-声音一致性和合成稳定性。


<details>
  <summary>Details</summary>
Motivation: 为解决中风等伤害后失语情况下的沟通问题，当前的文本到语音(TTS)技术无法保留用户原有声音特征。面部到声音(FTV)合成技术应运而生，但现有方法存在细粒度信息损失和训练效率低的问题。

Method: 将面部图像分解为非重叠分块，逐步集成多粒度表征。通过在视觉和音响领域进行性别、种族等讲者属性的多任务学习来精炼表征。采用多视角训练策略，将不同角度和光照条件下的面部图像与同一语音记录进行匹配。

Result: 经过广泛主观和客观评估，证实该方法显著提升了面部-声音一致性和合成稳定性。

Conclusion: 该研究提出的细粒度面部属性建模和多视角训练策略有效解决了现有FTV合成方法的局限性，为失语病人提供了更保真和高效的沟通帮助方案。

Abstract: For individuals who have experienced traumatic events such as strokes, speech
may no longer be a viable means of communication. While text-to-speech (TTS)
can be used as a communication aid since it generates synthetic speech, it
fails to preserve the user's own voice. As such, face-to-voice (FTV) synthesis,
which derives corresponding voices from facial images, provides a promising
alternative. However, existing methods rely on pre-trained visual encoders, and
finetune them to align with speech embeddings, which strips fine-grained
information from facial inputs such as gender or ethnicity, despite their known
correlation with vocal traits. Moreover, these pipelines are multi-stage, which
requires separate training of multiple components, thus leading to training
inefficiency. To address these limitations, we utilize fine-grained facial
attribute modeling by decomposing facial images into non-overlapping segments
and progressively integrating them into a multi-granular representation. This
representation is further refined through multi-task learning of speaker
attributes such as gender and ethnicity at both the visual and acoustic
domains. Moreover, to improve alignment robustness, we adopt a multi-view
training strategy by pairing various visual perspectives of a speaker in terms
of different angles and lighting conditions, with identical speech recordings.
Extensive subjective and objective evaluations confirm that our approach
substantially enhances face-voice congruence and synthesis stability.

</details>


### [45] [Target matching based generative model for speech enhancement](https://arxiv.org/abs/2509.07521)
*Taihui Wang,Rilin Chen,Tong Lei,Andong Li,Jinzheng Zhao,Meng Yu,Dong Yu*

Main category: cs.SD

TL;DR: 这篇论文提出了一种新的目标基于生成框架，通过消除训练损失中的随机成分、采用逻辑平均调度和桥方差调度，以及设计新的扩散背榜，来提高生成模型的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前生成模型中平均/方差调度设计的挑战，包括流基模型导致的幻觉效应、训练/推理效率低下，以及NCSN++扩散背榜计算复杂度高的问题。

Method: 重构生成语音增强任务为目标信号估计问题，消除训练损失中的随机成分；采用逻辑平均调度和桥方差调度；设计新的音频扩散背榜，显式建模长期帧相关性和跨带依赖性。

Result: 实现了更稳定和高效的训练/推理过程，获得了更优秀的信噪比轨迹，并显著提高了效率。

Conclusion: 该方法有效解决了现有生成模型的限制，提供了更灵活的调度设计和更高效的训练/推理性能。

Abstract: The design of mean and variance schedules for the perturbed signal is a
fundamental challenge in generative models. While score-based and Schr\"odinger
bridge-based models require careful selection of the stochastic differential
equation to derive the corresponding schedules, flow-based models address this
issue via vector field matching. However, this strategy often leads to
hallucination artifacts and inefficient training and inference processes due to
the potential inclusion of stochastic components in the vector field.
Additionally, the widely adopted diffusion backbone, NCSN++, suffers from high
computational complexity. To overcome these limitations, we propose a novel
target-based generative framework that enhances both the flexibility of
mean/variance schedule design and the efficiency of training and inference
processes. Specifically, we eliminate the stochastic components in the training
loss by reformulating the generative speech enhancement task as a target signal
estimation problem, which therefore leads to more stable and efficient training
and inference processes. In addition, we employ a logistic mean schedule and a
bridge variance schedule, which yield a more favorable signal-to-noise ratio
trajectory compared to several widely used schedules and thus leads to a more
efficient perturbation strategy. Furthermore, we propose a new diffusion
backbone for audio, which significantly improves the efficiency over NCSN++ by
explicitly modeling long-term frame correlations and cross-band dependencies.

</details>


### [46] [Competitive Audio-Language Models with Data-Efficient Single-Stage Training on Public Data](https://arxiv.org/abs/2509.07526)
*Gokul Karthik Kumar,Rishabh Saraf,Ludovick Lepauloux,Abdul Muneer,Billel Mokeddem,Hakim Hacid*

Main category: cs.SD

TL;DR: Falcon3-Audio是一个基于指令调优LLM和Whisper编码器的音频-语言模型家族，仅用不到3万小时公开音频数据就在MMAU基准上达到最佳开源模型性能，证明了数据效率和简化架构的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管音频在人类交流中至关重要，但大型语言模型与音频的整合仍未被充分探索。研究者希望开发高效的音频-语言模型，减少对大量数据和复杂架构的依赖。

Method: 基于指令调优的LLM和Whisper编码器构建Falcon3-Audio模型家族，使用少量公开音频数据（<30K小时）进行单阶段训练，避免了课程学习、多编码器和复杂交叉注意力连接器等常见复杂性。

Result: Falcon3-Audio-7B在MMAU基准上获得64.14分，匹配R1-AQA的最佳报告性能，同时展现出卓越的数据和参数效率。最小的1B模型也能与2B-13B参数的大型开源模型竞争。

Conclusion: 研究表明，常见的复杂架构设计对于音频-语言模型的强性能并非必需，即使与使用超过50万小时数据训练的模型相比，简化架构和少量数据也能取得优异结果。

Abstract: Large language models (LLMs) have transformed NLP, yet their integration with
audio remains underexplored -- despite audio's centrality to human
communication. We introduce Falcon3-Audio, a family of Audio-Language Models
(ALMs) built on instruction-tuned LLMs and Whisper encoders. Using a remarkably
small amount of public audio data -- less than 30K hours (5K unique) --
Falcon3-Audio-7B matches the best reported performance among open-weight models
on the MMAU benchmark, with a score of 64.14, matching R1-AQA, while
distinguishing itself through superior data and parameter efficiency,
single-stage training, and transparency. Notably, our smallest 1B model remains
competitive with larger open models ranging from 2B to 13B parameters. Through
extensive ablations, we find that common complexities -- such as curriculum
learning, multiple audio encoders, and intricate cross-attention connectors --
are not required for strong performance, even compared to models trained on
over 500K hours of data.

</details>


### [47] [Neural Proxies for Sound Synthesizers: Learning Perceptually Informed Preset Representations](https://arxiv.org/abs/2509.07635)
*Paolo Combes,Stefan Weinzierl,Klaus Obermayer*

Main category: cs.SD

TL;DR: 通过训练神经网绘制合成器预设到音频嵌入空间的映射，构建神经代理代替非可微的黑盒合成器，为神经基自动合成器编程提供解决方案。


<details>
  <summary>Details</summary>
Motivation: 深度学习在自动合成器编程(ASP)中有应用潜力，但软件合成器的非可微性为训练流程带来挑战。需要找到方法近似任意合成器以解决这一问题。

Method: 训练神经网绘制合成器预设到预训练音频模型的嵌入空间，建立神经代理。测试了前向传播、循环和Transformer等多种网络结构的效果。

Result: 在三款流行软件合成器上进行了评估，包括合成和手工制作的预设。在合成器音效匹配任务中获得了鼓舞人心的结果，为未来研究打开了途径。

Conclusion: 虽然学习表征的优势受到资源需求的影响，但方法在所有测试合成器上都取得了鼓舞人心的结果，证明了神经代理在黑盒合成器自动编程中的可行性。

Abstract: Deep learning appears as an appealing solution for Automatic Synthesizer
Programming (ASP), which aims to assist musicians and sound designers in
programming sound synthesizers. However, integrating software synthesizers into
training pipelines is challenging due to their potential non-differentiability.
This work tackles this challenge by introducing a method to approximate
arbitrary synthesizers. Specifically, we train a neural network to map
synthesizer presets onto an audio embedding space derived from a pretrained
model. This facilitates the definition of a neural proxy that produces compact
yet effective representations, thereby enabling the integration of audio
embedding loss into neural-based ASP systems for black-box synthesizers. We
evaluate the representations derived by various pretrained audio models in the
context of neural-based nASP and assess the effectiveness of several neural
network architectures, including feedforward, recurrent, and transformer-based
models, in defining neural proxies. We evaluate the proposed method using both
synthetic and hand-crafted presets from three popular software synthesizers and
assess its performance in a synthesizer sound matching downstream task. While
the benefits of the learned representation are nuanced by resource
requirements, encouraging results were obtained for all synthesizers, paving
the way for future research into the application of synthesizer proxies for
neural-based ASP systems.

</details>


### [48] [Spectral Masking and Interpolation Attack (SMIA): A Black-box Adversarial Attack against Voice Authentication and Anti-Spoofing Systems](https://arxiv.org/abs/2509.07677)
*Kamel Kamel,Hridoy Sankar Dutta,Keshav Sood,Sunil Aryal*

Main category: cs.SD

TL;DR: 论文提出了一种名为SMIA的新型对抗攻击方法，通过在AI生成音频的不可听频率区域进行策略性操作，成功欺骗了语音认证系统和反欺骗措施，证明了当前安全防护措施的不足。


<details>
  <summary>Details</summary>
Motivation: 语音认证系统在高安全领域应用广泛，但面临深度伪造和对抗攻击的严重威胁。现有的反欺骗措施多为静态检测模型，容易被新型对抗方法绕过，存在关键安全漏洞。

Method: 提出了SMIA（频谱掩蔽和插值攻击）方法，策略性地操纵AI生成音频中人耳不可感知的频率区域，创建听起来真实但能欺骗检测系统的对抗样本。

Result: SMIA在模拟真实世界条件下的综合评估中表现优异：对组合VAS/CM系统的攻击成功率达到至少82%，对独立说话人验证系统达到至少97.5%，对反欺骗措施达到100%。

Conclusion: 当前的安全防护措施无法有效应对自适应对抗攻击，迫切需要向下一代防御范式转变，采用能够随威胁环境演变的动态、上下文感知框架。

Abstract: Voice Authentication Systems (VAS) use unique vocal characteristics for
verification. They are increasingly integrated into high-security sectors such
as banking and healthcare. Despite their improvements using deep learning, they
face severe vulnerabilities from sophisticated threats like deepfakes and
adversarial attacks. The emergence of realistic voice cloning complicates
detection, as systems struggle to distinguish authentic from synthetic audio.
While anti-spoofing countermeasures (CMs) exist to mitigate these risks, many
rely on static detection models that can be bypassed by novel adversarial
methods, leaving a critical security gap. To demonstrate this vulnerability, we
propose the Spectral Masking and Interpolation Attack (SMIA), a novel method
that strategically manipulates inaudible frequency regions of AI-generated
audio. By altering the voice in imperceptible zones to the human ear, SMIA
creates adversarial samples that sound authentic while deceiving CMs. We
conducted a comprehensive evaluation of our attack against state-of-the-art
(SOTA) models across multiple tasks, under simulated real-world conditions.
SMIA achieved a strong attack success rate (ASR) of at least 82% against
combined VAS/CM systems, at least 97.5% against standalone speaker verification
systems, and 100% against countermeasures. These findings conclusively
demonstrate that current security postures are insufficient against adaptive
adversarial attacks. This work highlights the urgent need for a paradigm shift
toward next-generation defenses that employ dynamic, context-aware frameworks
capable of evolving with the threat landscape.

</details>


### [49] [Spectral and Rhythm Feature Performance Evaluation for Category and Class Level Audio Classification with Deep Convolutional Neural Networks](https://arxiv.org/abs/2509.07756)
*Friedrich Wolf-Monheim*

Main category: cs.SD

TL;DR: 这篇论文研究了多种谱和节奏特征在深度卷积神经网络音频分类中的性能对比，发现Mel标度谱图和MFCC在准确性、精度、召回率和F1分数方面显著优于其他特征。


<details>
  <summary>Details</summary>
Motivation: 研究不同谱和节奏特征在深度卷积神经网络音频分类任务中的性能差异，以确定最优的特征表示方式。

Method: 使用ESC-50数据集（2,000个标签环境音频录音），通过端到端深度学习流水线评估多种特征：Mel标度谱图、MFCC、循环节奏图、STFT音阶图、CQT音阶图和CENS音阶图。

Result: Mel标度谱图和MFCC在多类分类任务中显示出显著更高的准确性、精度、召回率和F1分数，性能明显优于其他谱和节奏特征。

Conclusion: 对于使用深度卷积神经网络的音频分类任务，Mel标度谱图和MFCC是最优的特征表示方式，建议在实际应用中优先采用。

Abstract: Next to decision tree and k-nearest neighbours algorithms deep convolutional
neural networks (CNNs) are widely used to classify audio data in many domains
like music, speech or environmental sounds. To train a specific CNN various
spectral and rhythm features like mel-scaled spectrograms, mel-frequency
cepstral coefficients (MFCC), cyclic tempograms, short-time Fourier transform
(STFT) chromagrams, constant-Q transform (CQT) chromagrams and chroma energy
normalized statistics (CENS) chromagrams can be used as digital image input
data for the neural network. The performance of these spectral and rhythm
features for audio category level as well as audio class level classification
is investigated in detail with a deep CNN and the ESC-50 dataset with 2,000
labeled environmental audio recordings using an end-to-end deep learning
pipeline. The evaluated metrics accuracy, precision, recall and F1 score for
multiclass classification clearly show that the mel-scaled spectrograms and the
mel-frequency cepstral coefficients (MFCC) perform significantly better then
the other spectral and rhythm features investigated in this research for audio
classification tasks using deep CNNs.

</details>
