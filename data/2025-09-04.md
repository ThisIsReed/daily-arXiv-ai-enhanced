<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 28]
- [cs.SD](#cs.SD) [Total: 3]
- [cs.MM](#cs.MM) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [DrDiff: Dynamic Routing Diffusion with Hierarchical Attention for Breaking the Efficiency-Quality Trade-off](https://arxiv.org/abs/2509.02785)
*Jusheng Zhang,Yijia Fan,Kaitong Cai,Zimeng Huang,Xiaofei Sun,Jian Wang,Chengpei Tang,Keze Wang*

Main category: cs.CL

TL;DR: DrDiff是一个新颖的长文本生成框架，通过动态专家调度、分层稀疏注意力和软吸收引导优化三项核心技术，解决了效率与质量之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统长文本生成方法存在效率与质量之间的权衡问题，需要一种能够同时保持高质量输出和高效计算的新框架。

Method: 1. 动态专家调度机制：根据文本复杂度智能分配计算资源；2. 分层稀疏注意力机制：将计算复杂度从O(n²)降低到O(n)；3. 软吸收引导优化策略：结合DPM-solver++减少扩散步骤。

Result: 在各种长文本生成基准测试中，DrDiff表现出优于现有最先进方法的性能。

Conclusion: DrDiff框架通过三项创新技术成功解决了长文本生成中的效率-质量权衡问题，为高效高质量的长文本生成提供了有效解决方案。

Abstract: This paper introduces DrDiff, a novel framework for long-text generation that
overcomes the efficiency-quality trade-off through three core technologies.
First, we design a dynamic expert scheduling mechanism that intelligently
allocates computational resources during the diffusion process based on text
complexity, enabling more efficient handling of text generation tasks of
varying difficulty. Second, we introduce a Hierarchical Sparse Attention (HSA)
mechanism that adaptively adjusts attention patterns according to a variety of
input lengths, reducing computational complexity from O($n^2$) to O($n$) while
maintaining model performance. Finally, we propose a soft absorption guidance
optimization strategy that combines with DPM-solver++ to reduce diffusion
steps, significantly improving generation speed. Comprehensive experiments on
various long-text generation benchmarks demonstrate the superiority of our
DrDiff over the existing SOTA methods.

</details>


### [2] [SSVD: Structured SVD for Parameter-Efficient Fine-Tuning and Benchmarking under Domain Shift in ASR](https://arxiv.org/abs/2509.02830)
*Pu Wang,Shinji Watanabe,Hugo Van hamme*

Main category: cs.CL

TL;DR: 这篇论文综述了参数高效微调技术在语音识别中的应用，引入了结构化SVD导向微调方法，并在ESPnet中实现了多种PEFT方泑的综合性能测评。


<details>
  <summary>Details</summary>
Motivation: 虽然LoRA广泛用于语音应用，但最新的PEFT变体主要在语言和视觉任务中开发，在语音领域缺乏充分验证。需要系统性地对比和评估这些方法在语音识别任务中的性能。

Method: 在ESPnet中集成多种PEFT方泑（包括VeRA、DoRA、PiSSA、SVFT），并提出结构化SVD导向微调（SSVD）。SSVD通过选择性旋转输入相关的右奇异向量，保持输出相关向量以维持语义映射，实现高效域适配。

Result: 在域假移语音识别任务上进行了评估，包括儿童语音和方言变体，模型规模从0.1B到2B。SSVD方法在保持最少可训练参数的同时提高了效率和适配性能。

Conclusion: 该研究为语音领域提供了第一个全面的PEFT方泑集成和性能分析，SSVD方法显示了在域适配中的优势。所有实现已在ESPnet中开源，支持可复现性和未来研究。

Abstract: Parameter-efficient fine-tuning (PEFT) has emerged as a scalable solution for
adapting large foundation models. While low-rank adaptation (LoRA) is widely
used in speech applications, its state-of-the-art variants, e.g., VeRA, DoRA,
PiSSA, and SVFT, are developed mainly for language and vision tasks, with
limited validation in speech. This work presents the first comprehensive
integration and benchmarking of these PEFT methods within ESPnet. We further
introduce structured SVD-guided (SSVD) fine-tuning, which selectively rotates
input-associated right singular vectors while keeping output-associated vectors
fixed to preserve semantic mappings. This design enables robust domain
adaptation with minimal trainable parameters and improved efficiency. We
evaluate all methods on domain-shifted speech recognition tasks, including
child speech and dialectal variation, across model scales from 0.1B to 2B. All
implementations are released in ESPnet to support reproducibility and future
work.

</details>


### [3] [Clustering Discourses: Racial Biases in Short Stories about Women Generated by Large Language Models](https://arxiv.org/abs/2509.02834)
*Gustavo Bonil,João Gondim,Marina dos Santos,Simone Hashiguti,Helena Maia,Nadia Silva,Helio Pedrini,Sandra Avila*

Main category: cs.CL

TL;DR: 研究发现LLaMA 3.2-3B模型在生成葡萄牙语短篇小说时，对黑人和白人女性存在殖民化、结构化的叙事框架，强化了历史不平等。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型在生成文本时如何构建关于不同种族女性的叙事，揭示看似中立的文本背后隐藏的殖民化思维框架。

Method: 从2100篇生成文本中应用计算方法进行语义聚类，结合机器学习技术和人工话语分析的混合方法进行定性分析。

Result: 识别出三种主要话语表征：社会超越、祖先神话化和主观自我实现，发现语法连贯的文本实际上体现了固化的殖民化女性身体框架。

Conclusion: 研究表明需要结合计算方法和定性分析来揭示AI文本生成中的偏见，这些看似中立的文本实际上强化了历史不平等结构。

Abstract: This study investigates how large language models, in particular LLaMA
3.2-3B, construct narratives about Black and white women in short stories
generated in Portuguese. From 2100 texts, we applied computational methods to
group semantically similar stories, allowing a selection for qualitative
analysis. Three main discursive representations emerge: social overcoming,
ancestral mythification and subjective self-realization. The analysis uncovers
how grammatically coherent, seemingly neutral texts materialize a crystallized,
colonially structured framing of the female body, reinforcing historical
inequalities. The study proposes an integrated approach, that combines machine
learning techniques with qualitative, manual discourse analysis.

</details>


### [4] [Comparison of End-to-end Speech Assessment Models for the NOCASA 2025 Challenge](https://arxiv.org/abs/2509.03256)
*Aleksei Žavoronkov,Tanel Alumäe*

Main category: cs.CL

TL;DR: 本文分析了三种用于挪威语儿童发音评估的端到端模型，其中基于GOP-CTC的新模型表现最佳，显著超越基线并在排行榜上获得最高分


<details>
  <summary>Details</summary>
Motivation: 为NOCASA 2025挑战赛开发自动单词级发音评估模型，帮助儿童学习挪威语作为第二语言

Method: 开发了三种模型：编码器-解码器孪生架构(E2E-R)、基于预训练wav2vec2.0的前缀调优分类模型、以及整合无对齐GOP特征的GOP-CTC模型，并引入了加权序数交叉熵损失函数

Result: GOP-CTC模型取得了最高性能，显著超越了挑战赛基线模型，并在排行榜上获得最高分数

Conclusion: 基于GOP-CTC特征整合的新模型在挪威语儿童发音评估任务中表现出色，为发音评估提供了有效的解决方案

Abstract: This paper presents an analysis of three end-to-end models developed for the
NOCASA 2025 Challenge, aimed at automatic word-level pronunciation assessment
for children learning Norwegian as a second language. Our models include an
encoder-decoder Siamese architecture (E2E-R), a prefix-tuned direct
classification model leveraging pretrained wav2vec2.0 representations, and a
novel model integrating alignment-free goodness-of-pronunciation (GOP) features
computed via CTC. We introduce a weighted ordinal cross-entropy loss tailored
for optimizing metrics such as unweighted average recall and mean absolute
error. Among the explored methods, our GOP-CTC-based model achieved the highest
performance, substantially surpassing challenge baselines and attaining top
leaderboard scores.

</details>


### [5] [IDEAlign: Comparing Large Language Models to Human Experts in Open-ended Interpretive Annotations](https://arxiv.org/abs/2509.02855)
*Hyunji Nam,Lucia Langlois,James Malamut,Mei Tan,Dorottya Demszky*

Main category: cs.CL

TL;DR: 提出了IDEAlgin评估框架，通过"三选一"任务来评估LLM生成解释性标注与专家标注的相似性，发现基于向量的指标效果不佳，而LLM作为评判者能显著提升与专家判断的一致性。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地应用于开放式解释性标注任务，但缺乏可扩展的方法来评估LLM生成标注与专家标注的相似性。

Method: 提出IDEAlgin基准范式，使用"三选一"三元组判断任务收集专家相似性评分，并比较各种相似性指标（基于向量的方法和LLM作为评判者）与人类基准的一致性。

Result: 基于向量的指标难以捕捉专家关注的细微相似性维度，而通过IDEAlgin提示的LLM相比传统词汇和向量指标，与专家判断的一致性提高了9-30%。

Conclusion: IDEAlgin为大规模评估LLM在开放式专家标注任务中的表现提供了有前景的范式，有助于在教育等领域负责任地部署LLM。

Abstract: Large language models (LLMs) are increasingly applied to open-ended,
interpretive annotation tasks, such as thematic analysis by researchers or
generating feedback on student work by teachers. These tasks involve free-text
annotations requiring expert-level judgments grounded in specific objectives
(e.g., research questions or instructional goals). Evaluating whether
LLM-generated annotations align with those generated by expert humans is
challenging to do at scale, and currently, no validated, scalable measure of
similarity in ideas exists. In this paper, we (i) introduce the scalable
evaluation of interpretive annotation by LLMs as a critical and understudied
task, (ii) propose IDEAlgin, an intuitive benchmarking paradigm for capturing
expert similarity ratings via a "pick-the-odd-one-out" triplet judgment task,
and (iii) evaluate various similarity metrics, including vector-based ones
(topic models, embeddings) and LLM-as-a-judge via IDEAlgin, against these human
benchmarks. Applying this approach to two real-world educational datasets
(interpretive analysis and feedback generation), we find that vector-based
metrics largely fail to capture the nuanced dimensions of similarity meaningful
to experts. Prompting LLMs via IDEAlgin significantly improves alignment with
expert judgments (9-30% increase) compared to traditional lexical and
vector-based metrics. These results establish IDEAlgin as a promising paradigm
for evaluating LLMs against open-ended expert annotations at scale, informing
responsible deployment of LLMs in education and beyond.

</details>


### [6] [A-SEA3L-QA: A Fully Automated Self-Evolving, Adversarial Workflow for Arabic Long-Context Question-Answer Generation](https://arxiv.org/abs/2509.02864)
*Kesen Wang,Daulet Toibazar,Pedro J. Moreno*

Main category: cs.CL

TL;DR: 自治汇编阶段阻寻工作流，通过多个专门的大视觉语言模型协同工作，实现防止人工干预的阻寻问答生成和评估闭环迭代精炼，显著提升阿拉伯语大视觉语言模型的长上下文理解能力。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语大视觉语言模型在长上下文理解方面的挑战，通过自动化的问答生成和评估流程，提高模型的问题难度和相关性。

Method: 构建一个包含问题生成器、评估器和答案生成器群的自治汇编阶段工作流，通过闭环迭代精炼实现持续学习，并将质量指标设置为可调超参数。

Result: 系统显著超越了静态流水线，大大提升了领先阿拉伯语大视觉语言模型的长上下文理解能力，并发布了AraLongBench大规模阿拉伯语测试集。

Conclusion: 自治汇编阶段工作流能够有效提升阿拉伯语大视觉语言模型的长上下文理解能力，为阿拉伯语自然语言处理领域提供了重要技术支撑。

Abstract: We present an end-to-end, self-evolving adversarial workflow for long-context
Question-Answer (QA) Generation in Arabic. By orchestrating multiple
specialized LVLMs: a question generator, an evaluator, and a swarm of answer
generators, our system iteratively refines its own performance without any
human intervention. Starting from raw, multi-page Arabic documents across
diverse domains, the question generator produces fine-grained, context-aware
queries to be tackled by the answer generator swarm, and the evaluator assesses
and feeds back quality metrics. This closed-loop cycle enables continuous
learning: low-confidence outputs trigger automated re-generation and model
updates, progressively enhancing question difficulty and relevance. Moreover,
we set the quality metrics as a tunable hyperparameter, enabling question
generation at controllable and customizable difficulty levels. We release
AraLongBench, a large-scale Arabic benchmark of single- and multi-page
challenges spanning hundreds of pages, and demonstrate that our self-evolving
workflow substantially outperform static pipelines, markedly boosting the
long-context comprehension capabilities of leading Arabic Large Vision Language
Models (LVLMs). Lastly, we also meticulously architect a fully automated
agentic workflow for long-context Arabic document collection.

</details>


### [7] [Advancing Minority Stress Detection with Transformers: Insights from the Social Media Datasets](https://arxiv.org/abs/2509.02908)
*Santosh Chapagain,Cory J Cascalheira,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi,Jillian R. Scheer*

Main category: cs.CL

TL;DR: 本研究首次全面评估了基于Transformer的架构在检测在线话语中少数群体压力方面的表现，发现图结构增强的Transformer模型在检测少数群体压力方面效果最佳。


<details>
  <summary>Details</summary>
Motivation: 性少数群体和性别少数群体相比异性恋和顺性别群体经历着不成比例的高健康问题和精神障碍率，这主要是由于少数群体压力造成的。需要开发有效的方法来检测在线话语中的少数群体压力。

Method: 使用ELECTRA、BERT、RoBERTa和BART等Transformer模型与传统机器学习基线以及图增强变体进行基准测试，评估零样本和少样本学习范式，在两个最大的公开Reddit语料库上进行实验。

Result: 图结构整合持续提升了Transformer-only模型的检测性能，带有关系上下文的监督微调优于零样本和少样本方法，图增强能够帮助模型识别身份隐藏、内化污名等关键语言标记。

Conclusion: 图增强的Transformer模型为数字健康干预和公共卫生政策提供了最可靠的基础，建模社交连接和对话语境能够提升模型检测少数群体压力的能力。

Abstract: Individuals from sexual and gender minority groups experience
disproportionately high rates of poor health outcomes and mental disorders
compared to their heterosexual and cisgender counterparts, largely as a
consequence of minority stress as described by Meyer's (2003) model. This study
presents the first comprehensive evaluation of transformer-based architectures
for detecting minority stress in online discourse. We benchmark multiple
transformer models including ELECTRA, BERT, RoBERTa, and BART against
traditional machine learning baselines and graph-augmented variants. We further
assess zero-shot and few-shot learning paradigms to assess their applicability
on underrepresented datasets. Experiments are conducted on the two largest
publicly available Reddit corpora for minority stress detection, comprising
12,645 and 5,789 posts, and are repeated over five random seeds to ensure
robustness. Our results demonstrate that integrating graph structure
consistently improves detection performance across transformer-only models and
that supervised fine-tuning with relational context outperforms zero and
few-shot approaches. Theoretical analysis reveals that modeling social
connectivity and conversational context via graph augmentation sharpens the
models' ability to identify key linguistic markers such as identity
concealment, internalized stigma, and calls for support, suggesting that
graph-enhanced transformers offer the most reliable foundation for digital
health interventions and public health policy.

</details>


### [8] [English Pronunciation Evaluation without Complex Joint Training: LoRA Fine-tuned Speech Multimodal LLM](https://arxiv.org/abs/2509.02915)
*Taekyung Ahn,Hosung Nam*

Main category: cs.CL

TL;DR: 使用LoRA微调的多模态大语言模型可同时进行发音自动评估和发音错误检测诊断，无需复杂架构修改，性能与传统方法相当


<details>
  <summary>Details</summary>
Motivation: 传统发音评估系统需要为APA和MDD两个不同任务分别设计复杂架构和训练流程，研究旨在通过简单方法实现集成化发音评估

Method: 基于Microsoft Phi-4-multimodal-instruct模型，采用LoRA低秩适应微调方法，在Speechocean762数据集上进行训练

Result: 模型预测分数与人工评分Pearson相关系数>0.7，词错误率和音素错误率均<0.15，仅微调LoRA层即可达到全音频层微调的性能水平

Conclusion: LoRA方法为英语L2学习者提供了更易获取、集成化和高效的计算机辅助发音训练技术路径

Abstract: This study demonstrates that a Multimodal Large Language Model (MLLM) adapted
via Low-Rank Adaptation (LoRA) can perform both Automatic Pronunciation
Assessment (APA) and Mispronunciation Detection and Diagnosis (MDD)
simultaneously. Leveraging Microsoft's Phi-4-multimodal-instruct, our
fine-tuning method eliminates the need for complex architectural changes or
separate training procedures conventionally required for these distinct tasks.
Fine-tuned on the Speechocean762 dataset, the pronunciation evaluation scores
predicted by the model exhibited a strong Pearson Correlation Coefficient (PCC
> 0.7) with human-assigned scores, while achieving low Word Error Rate (WER)
and Phoneme Error Rate (PER) (both < 0.15). Notably, fine-tuning only the LoRA
layers was sufficient to achieve performance levels comparable to those
achieved by fine-tuning all audio layers. This research highlights that an
integrated pronunciation assessment system can be established by adapting large
multimodal models without full fine-tuning, utilizing a significantly simpler
training methodology compared to previous joint models designed for
simultaneous APA and MDD. This efficient LoRA-based approach paves the way for
more accessible, integrated, and effective Computer-Assisted Pronunciation
Training (CAPT) technologies for English L2 learners.

</details>


### [9] [Decoding the Rule Book: Extracting Hidden Moderation Criteria from Reddit Communities](https://arxiv.org/abs/2509.02926)
*Youngwoo Kim,Himanshu Beniwal,Steven L. Johnson,Thomas Hartvigsen*

Main category: cs.CL

TL;DR: 通过可解释的词汇表达式表格从历史审审数据中提取隐式内容审核标准，可以系统性比较不同社区的审核规范并揭示具体的判断标准。


<details>
  <summary>Details</summary>
Motivation: 在线社区如subreddits通常使用多样化的隐式标准进行内容审核，需要一种方法来明确识别和提取这些隐式标准以建立有效的内容审核系统。

Method: 使用可解释的架构从历史审核数据中提取隐式标准，将审核标准表示为与内容删除相关联的词汇表达式评分表。

Result: 实验表明提取的词汇模式能够有效复现神经网络审核模型的性能，同时提供透明的决策见解。标准矩阵揭示了表面共享规范在不同社区的实际执行差异。

Conclusion: 该方法能够发现之前未文档化的审核模式，包括社区特定的语言容忍度、主题限制特征以及有害语言分类的深层子类别。

Abstract: Effective content moderation systems require explicit classification
criteria, yet online communities like subreddits often operate with diverse,
implicit standards. This work introduces a novel approach to identify and
extract these implicit criteria from historical moderation data using an
interpretable architecture. We represent moderation criteria as score tables of
lexical expressions associated with content removal, enabling systematic
comparison across different communities. Our experiments demonstrate that these
extracted lexical patterns effectively replicate the performance of neural
moderation models while providing transparent insights into decision-making
processes. The resulting criteria matrix reveals significant variations in how
seemingly shared norms are actually enforced, uncovering previously
undocumented moderation patterns including community-specific tolerances for
language, features for topical restrictions, and underlying subcategories of
the toxic speech classification.

</details>


### [10] [ProMQA-Assembly: Multimodal Procedural QA Dataset on Assembly](https://arxiv.org/abs/2509.02949)
*Kimihiro Hasegawa,Wiradee Imrattanatrai,Masaki Asada,Susan Holm,Yuran Wang,Vincent Zhou,Ken Fukuda,Teruko Mitamura*

Main category: cs.CL

TL;DR: 提出了一个新的多模态QA数据集ProMQA-Assembly，用于评估装配活动中的助手系统，包含391个QA对，需要理解人类活动记录和说明书。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏支持应用导向系统评估的测试平台，特别是在装配任务中，需要促进相关技术的发展。

Method: 采用半自动QA标注方法，使用LLM生成候选问题并由人工验证，集成细粒度动作标签来多样化问题类型，创建指令任务图来辅助标注过程。

Result: 基准测试显示当前多模态模型仍有很大改进空间，包括竞争性专有模型也存在不足。

Conclusion: 新的评估数据集ProMQA-Assembly能够为程序性活动助手系统的进一步发展做出贡献。

Abstract: Assistants on assembly tasks have a large potential to benefit humans from
everyday tasks to industrial settings. However, no testbeds support
application-oriented system evaluation in a practical setting, especially in
assembly. To foster the development, we propose a new multimodal QA dataset on
assembly activities. Our dataset, ProMQA-Assembly, consists of 391 QA pairs
that require the multimodal understanding of human-activity recordings and
their instruction manuals in an online-style manner. In the development, we
adopt a semi-automated QA annotation approach, where LLMs generate candidates
and humans verify them, as a cost-effective method, and further improve it by
integrating fine-grained action labels to diversify question types.
Furthermore, we create instruction task graphs for the target tasks of
assembling toy vehicles. These newly created task graphs are used in our
benchmarking experiment, as well as to facilitate the human verification
process in the QA annotation. Utilizing our dataset, we benchmark models,
including competitive proprietary multimodal models. Our results suggest great
room for improvement for the current models. We believe our new evaluation
dataset can contribute to the further development of procedural-activity
assistants.

</details>


### [11] [DiaCBT: A Long-Periodic Dialogue Corpus Guided by Cognitive Conceptualization Diagram for CBT-based Psychological Counseling](https://arxiv.org/abs/2509.02999)
*Yougen Zhou,Ningning Zhou,Qin Chen,Jie Zhou,Aimin Zhou,Liang He*

Main category: cs.CL

TL;DR: 这篇论文构建了一个基于认知行为疗法(CBT)的长周期心理咨询对话数据集DiaCBT，用于训练更专业的心理咨询模型。


<details>
  <summary>Details</summary>
Motivation: 解决心理治疗接可性不足的问题，大语言模型缺乏专业心理治疗对话数据集的挑战。

Method: 构建包含多个咨询会议的CBT对话数据集，采用认知概念图(CCDs)指导客户模拟，训练深度咨询模型。

Result: DiaCBT有效提升了LLM模仿CBT专家心理学家的能力，通过综合评估框架验证了其效果。

Conclusion: 该数据集为训练更专业的心理咨询对话机器人提供了重要支撑，拓展了精神健康服务的可达性。

Abstract: Psychotherapy reaches only a small fraction of individuals suffering from
mental disorders due to social stigma and the limited availability of
therapists. Large language models (LLMs), when equipped with professional
psychotherapeutic skills, offer a promising solution to expand access to mental
health services. However, the lack of psychological conversation datasets
presents significant challenges in developing effective psychotherapy-guided
conversational agents. In this paper, we construct a long-periodic dialogue
corpus for counseling based on cognitive behavioral therapy (CBT). Our curated
dataset includes multiple sessions for each counseling and incorporates
cognitive conceptualization diagrams (CCDs) to guide client simulation across
diverse scenarios. To evaluate the utility of our dataset, we train an in-depth
counseling model and present a comprehensive evaluation framework to benchmark
it against established psychological criteria for CBT-based counseling. Results
demonstrate that DiaCBT effectively enhances LLMs' ability to emulate
psychologists with CBT expertise, underscoring its potential for training more
professional counseling agents.

</details>


### [12] [Mitigating Data Imbalance in Automated Speaking Assessment](https://arxiv.org/abs/2509.03010)
*Fong-Chun Tsai,Kuan-Tang Huang,Bi-Cheng Yan,Tien-Hong Lo,Berlin Chen*

Main category: cs.CL

TL;DR: 提出BLV损失函数来解决自动口语评估中的类别不平衡问题，通过扰动模型预测来改善少数类别的特征表示，无需修改数据集


<details>
  <summary>Details</summary>
Motivation: 自动口语评估(ASA)模型在处理第二语言学习者能力评估时经常面临类别不平衡问题，导致预测结果存在偏差

Method: 引入平衡对数变异(BLV)损失函数，通过扰动模型预测来增强少数类别的特征表示能力，并与BERT文本模型结合

Result: 在ICNALE基准数据集上的评估显示，BLV损失显著提高了分类准确性和公平性

Conclusion: BLV损失使自动语音评估对多样化学习者更加鲁棒，为解决ASA中的类别不平衡问题提供了有效方案

Abstract: Automated Speaking Assessment (ASA) plays a crucial role in evaluating
second-language (L2) learners proficiency. However, ASA models often suffer
from class imbalance, leading to biased predictions. To address this, we
introduce a novel objective for training ASA models, dubbed the Balancing Logit
Variation (BLV) loss, which perturbs model predictions to improve feature
representation for minority classes without modifying the dataset. Evaluations
on the ICNALE benchmark dataset show that integrating the BLV loss into a
celebrated text-based (BERT) model significantly enhances classification
accuracy and fairness, making automated speech evaluation more robust for
diverse learners.

</details>


### [13] [Training LLMs to be Better Text Embedders through Bidirectional Reconstruction](https://arxiv.org/abs/2509.03020)
*Chang Su,Dengliang Shi,Siyuan Huang,Jintao Du,Changhua Meng,Yu Cheng,Weiqiang Wang,Zhouhan Lin*

Main category: cs.CL

TL;DR: 提出在对比学习前增加双向生成重建训练阶段，通过EBQ2D和EBD2Q任务增强[EOS]标记的语义表示能力，显著提升LLM在文本嵌入任务上的性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM文本嵌入方法使用最终特殊标记（如[EOS]）的嵌入，但这些标记并未经过专门训练来捕获整个上下文的语义，限制了其在检索和重排序任务中的能力

Method: 在对比学习前增加新的训练阶段，采用双向生成重建任务：EBQ2D（基于嵌入的查询到文档重建）和EBD2Q（基于嵌入的文档到查询重建），交替锚定[EOS]嵌入并重建查询-文档对的两端

Result: 在Massive Text Embedding Benchmark (MTEB)上显著提升LLM性能，在不同LLM基础模型和规模上都达到了新的state-of-the-art结果

Conclusion: 通过增加双向生成重建训练阶段，有效丰富了最终标记嵌入的语义表示能力，为LLM文本嵌入提供了更有效的训练方法

Abstract: Large language models (LLMs) have increasingly been explored as powerful text
embedders. Existing LLM-based text embedding approaches often leverage the
embedding of the final token, typically a reserved special token such as [EOS].
However, these tokens have not been intentionally trained to capture the
semantics of the whole context, limiting their capacity as text embeddings,
especially for retrieval and re-ranking tasks. We propose to add a new training
stage before contrastive learning to enrich the semantics of the final token
embedding. This stage employs bidirectional generative reconstruction tasks,
namely EBQ2D (Embedding-Based Query-to-Document) and EBD2Q (Embedding-Based
Document-to-Query), which interleave to anchor the [EOS] embedding and
reconstruct either side of Query-Document pairs. Experimental results
demonstrate that our additional training stage significantly improves LLM
performance on the Massive Text Embedding Benchmark (MTEB), achieving new
state-of-the-art results across different LLM base models and scales.

</details>


### [14] [Structure-Learnable Adapter Fine-Tuning for Parameter-Efficient Large Language Models](https://arxiv.org/abs/2509.03057)
*Ming Gong,Yingnan Deng,Nia Qi,Yujun Zou,Zhihao Xue,Yun Zi*

Main category: cs.CL

TL;DR: 这篇论文提出了一种基于结构可学习机制的适配器微调方法，通过引入可微分门控函数和结构稀疏控制变量，实现了适配器插入点、激活路径和模块组合的自动优化，在多任务语言理解任务上超过主流参数高效微调技术。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型微调中存在的参数冗余、结构固化和任务适应性局限等问题，提高参数利用率和表示能力。

Method: 基于结构可学习机制的适配器微调方法，使用可微分门控函数和结构稀疏控制变量，在训练过程中动态构建任务特定的高效子结构，保持核心参数冻结。

Result: 在多个多任务自然语言理解任务上超过主流参数高效微调技术，实验结果验证了方法的稳定性和程度性。

Conclusion: 该方法在准确率、压缩率以及对噪声和干扰的程度性方面实现了更好的平衡，为大语言模型的灵活微调提供了有效解决方案。

Abstract: This paper addresses the issues of parameter redundancy, rigid structure, and
limited task adaptability in the fine-tuning of large language models. It
proposes an adapter-based fine-tuning method built on a structure-learnable
mechanism. By introducing differentiable gating functions and structural
sparsity control variables, the method enables automatic optimization of
adapter insertion points, activation paths, and module combinations. This
allows the model to adjust its structure flexibly in multi-task settings to
match different task characteristics. With the backbone parameters kept frozen,
the method uses a structure search mechanism to guide the dynamic construction
of task-specific efficient substructures during training. This significantly
improves parameter utilization and representational capacity. In addition, the
paper designs a set of sensitivity analysis experiments to systematically
evaluate the effects of sparsity weight, noise injection ratio, and data
perturbation on model performance. These experiments verify the stability and
robustness of the proposed method across various multi-task natural language
understanding tasks. The experimental results show that the proposed method
outperforms mainstream parameter-efficient tuning techniques on multiple tasks.
It achieves a better balance among accuracy, compression rate, and robustness
to noise and perturbation.

</details>


### [15] [A Long Short-Term Memory (LSTM) Model for Business Sentiment Analysis Based on Recurrent Neural Network](https://arxiv.org/abs/2509.03060)
*Md. Jahidul Islam Razin,Md. Abdul Karim,M. F. Mridha,S M Rafiuddin,Tahira Alam*

Main category: cs.CL

TL;DR: 本文提出了一种基于LSTM的改进RNN模型用于商业情感分析，相比传统RNN模型取得了91.33%的准确率，能有效帮助企业分析客户反馈。


<details>
  <summary>Details</summary>
Motivation: 商业情感分析是自然语言处理的重要应用领域，传统RNN存在梯度消失问题，需要改进模型来提升情感分析的准确性和实用性。

Method: 使用长短期记忆网络(LSTM)替代传统循环神经网络(RNN)，采用产品评论数据集，70%数据用于训练，30%用于测试。

Result: 改进的RNN模型达到91.33%的准确率，性能优于传统RNN模型。

Conclusion: LSTM-based RNN模型能有效解决梯度消失问题，为商业公司和电商平台提供准确的情感分析工具，帮助优化营销策略。

Abstract: Business sentiment analysis (BSA) is one of the significant and popular
topics of natural language processing. It is one kind of sentiment analysis
techniques for business purposes. Different categories of sentiment analysis
techniques like lexicon-based techniques and different types of machine
learning algorithms are applied for sentiment analysis on different languages
like English, Hindi, Spanish, etc. In this paper, long short-term memory (LSTM)
is applied for business sentiment analysis, where a recurrent neural network is
used. An LSTM model is used in a modified approach to prevent the vanishing
gradient problem rather than applying the conventional recurrent neural network
(RNN). To apply the modified RNN model, product review dataset is used. In this
experiment, 70\% of the data is trained for the LSTM and the rest 30\% of the
data is used for testing. The result of this modified RNN model is compared
with other conventional RNN models, and a comparison is made among the results.
It is noted that the proposed model performs better than the other conventional
RNN models. Here, the proposed model, i.e., the modified RNN model approach has
achieved around 91.33\% of accuracy. By applying this model, any business
company or e-commerce business site can identify the feedback from their
customers about different types of products that customers like or dislike.
Based on the customer reviews, a business company or e-commerce platform can
evaluate its marketing strategy.

</details>


### [16] [Measuring Scalar Constructs in Social Science with LLMs](https://arxiv.org/abs/2509.03116)
*Hauke Licht,Rupak Sarkar,Patrick Y. Wu,Pranav Goel,Niklas Stoehr,Elliott Ash,Alexander Miserlis Hoyle*

Main category: cs.CL

TL;DR: 本文评估了四种基于大语言模型(LLM)的标量构念测量方法，发现通过token概率加权的点式评分效果最佳，且小模型微调可媲美提示LLM的性能


<details>
  <summary>Details</summary>
Motivation: 语言构念如复杂性或情感性具有连续语义结构，LLM虽然适合测量但数值输出处理存在特殊性，需要系统评估最佳应用方法

Method: 使用政治科学文献的多个数据集，评估四种方法：未加权直接点式评分、成对比较聚合、token概率加权点式评分、以及微调方法

Result: 直接点式评分产生不连续分布；成对比较有所改善；token概率加权评分效果更好；小模型仅用1000个训练对微调即可达到或超过提示LLM性能

Conclusion: 为应用研究者提供实用建议：推荐使用token概率加权方法，并考虑对小模型进行微调以获得更好性能

Abstract: Many constructs that characterize language, like its complexity or
emotionality, have a naturally continuous semantic structure; a public speech
is not just "simple" or "complex," but exists on a continuum between extremes.
Although large language models (LLMs) are an attractive tool for measuring
scalar constructs, their idiosyncratic treatment of numerical outputs raises
questions of how to best apply them. We address these questions with a
comprehensive evaluation of LLM-based approaches to scalar construct
measurement in social science. Using multiple datasets sourced from the
political science literature, we evaluate four approaches: unweighted direct
pointwise scoring, aggregation of pairwise comparisons,
token-probability-weighted pointwise scoring, and finetuning. Our study yields
actionable findings for applied researchers. First, LLMs prompted to generate
pointwise scores directly from texts produce discontinuous distributions with
bunching at arbitrary numbers. The quality of the measurements improves with
pairwise comparisons made by LLMs, but it improves even more by taking
pointwise scores and weighting them by token probability. Finally, finetuning
smaller models with as few as 1,000 training pairs can match or exceed the
performance of prompted LLMs.

</details>


### [17] [From Evaluation to Defense: Constructing Persistent Edit-Based Fingerprints for Large Language Models](https://arxiv.org/abs/2509.03122)
*Yue Li,Xin Yi,Dongsheng Shi,Yongyi Cui,Gerard de Melo,Xiaoling Wang,Linlin Wang*

Main category: cs.CL

TL;DR: 本文提出使用知识编辑作为轻量级指纹注入方法保护LLM知识产权，并针对大规模微调导致的指纹退化问题提出了指纹子空间感知微调(FSFT)方法，显著提升了指纹持久性。


<details>
  <summary>Details</summary>
Motivation: 现有通过指令调优注入指纹的方法存在性能下降、计算资源需求大、持久性差等问题，需要更轻量高效的LLM知识产权保护方案。

Method: 首次将知识编辑应用于指纹注入，使用乱码文本作为指纹，并提出FSFT方法通过约束指纹子空间更新来减少指纹退化。

Result: FSFT在最坏情况下性能超过传统微调10%，但发现指纹注入模型难以区分指纹与相似文本，特征相似度高。

Conclusion: 知识编辑是有效的轻量级指纹注入方法，FSFT能显著提升指纹持久性，但需要开发更鲁棒和细粒度的指纹注入技术来解决特征相似性问题。

Abstract: The intellectual property (IP) protection of Large Language Models (LLMs) is
increasingly critical. Injecting specialized fingerprints into LLMs through
instruction tuning is a common IP protection technique. However, this may
significantly degrade model performance, requires substantial computational
resources, and exhibits poor persistence under model modifications. We argue
that knowledge editing offers a lightweight alternative that is more suitable
for fingerprint injection. Accordingly, we apply knowledge editing to
fingerprint injection for the first time and demonstrate its strong capability.
Despite using scrambled text as fingerprints to prevent them from being
overwritten during fine-tuning, degradation still occurs under large-scale
fine-tuning. To address this, we propose Fingerprint Subspace-aware Fine-Tuning
(FSFT), which reduces fingerprint degradation by constraining the update of the
fingerprint subspace. The performance of FSFT exceeds fine-tuning by 10% even
in the worst-case scenario. Additionally, we observe that the
fingerprint-injected models struggle to distinguish between fingerprints and
similar texts due to the high similarity of their features. This finding
underscores the urgent need for more robust and fine-grained fingerprinting
injection methods for LLMs.

</details>


### [18] [An experimental and computational study of an Estonian single-person word naming](https://arxiv.org/abs/2509.03143)
*Kaidi Lõo,Arvi Tavast,Maria Heitmeier,Harald Baayen*

Main category: cs.CL

TL;DR: 本研究通过眼动追踪和命名任务实验，使用广义可加模型分析爱沙尼亚语词汇处理，比较了判别式词典模型(DLM)与传统预测因子(词频、邻域大小等)的预测能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索计算模型(DLM)生成的词汇处理测量是否能够预测眼动和命名反应变量，并与传统预测因子进行比较，以了解词汇处理中形式和意义映射的作用。

Method: 采用大规模单被试实验，结合词汇命名任务和眼动追踪技术，分析五个反应变量(首次注视时长、总注视时长、注视次数、命名潜伏期、口语时长)，使用广义可加模型进行统计分析。

Result: 1) DLM测量是词汇处理的有效预测因子；2) 深度学习DLM不一定比线性映射DLM更精确；3) 传统预测因子通常比DLM预测更精确(总注视时长除外)；4) 命名任务中词汇变量对首次注视时长和总注视次数无预测性。

Conclusion: DLM基于形式到意义映射的测量对总注视时长、命名潜伏期和口语时长的预测性表明，在当前词汇命名任务中意义处理起着重要作用。

Abstract: This study investigates lexical processing in Estonian. A large-scale
single-subject experiment is reported that combines the word naming task with
eye-tracking. Five response variables (first fixation duration, total fixation
duration, number of fixations, word naming latency, and spoken word duration)
are analyzed with the generalized additive model. Of central interest is the
question of whether measures for lexical processing generated by a
computational model of the mental lexicon (the Discriminative Lexicon Model,
DLM) are predictive for these response variables, and how they compare to
classical predictors such as word frequency, neighborhood size, and
inflectional paradigm size. Computational models were implemented both with
linear and deep mappings. Central findings are, first, that DLM-based measures
are powerful predictors for lexical processing, second, that DLM-measures using
deep learning are not necessarily more precise predictors of lexical processing
than DLM-measures using linear mappings, third, that classical predictors tend
to provide somewhat more precise fits compared to DLM-based predictors (except
for total fixation duration, where the two provide equivalent goodness of fit),
and fourth, that in the naming task lexical variables are not predictive for
first fixation duration and the total number of fixations. As the DLM works
with mappings from form to meaning, the predictivity of DLM-based measures for
total fixation duration, naming latencies, and spoken word duration indicates
that meaning is heavily involved in the present word naming task.

</details>


### [19] [Expanding the WMT24++ Benchmark with Rumantsch Grischun, Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader](https://arxiv.org/abs/2509.03148)
*Jannis Vamvas,Ignacio Pérez Prat,Not Battesta Soliva,Sandra Baltermia-Guetg,Andrina Beeli,Simona Beeli,Madlaina Capeder,Laura Decurtins,Gian Peder Gregori,Flavia Hobi,Gabriela Holderegger,Arina Lazzarini,Viviana Lazzarini,Walter Rosselli,Bettina Vital,Anna Rutkiewicz,Rico Sennrich*

Main category: cs.CL

TL;DR: 为瑞士罗曼语语言创建了包括6个变体的机器翻译评估基准，基于WMT24++标准的人工翻译参考文本，评估显示从罗曼语到德语翻译效果较好，但向罗曼语翻译仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 罗曼语语言在机器翻译评估方面资源有限，需要为其各个变体建立标准化的评测基准。

Method: 基于WMT24++标准生成人工翻译参考文本，建立包括Rumantsch Grischun和五个地区变体的评测数据集，并对现有MT系统和LLM进行自动评估。

Result: 翻译出罗曼语到德语的效果相对较好，但向罗曼语翻译仍然存在明显挑战，性能不佳。

Conclusion: 该研究为罗曼语各变体提供了重要的评估基准，并持续的翻译质量挑战显示了该语言在NLP领域需要更多关注。

Abstract: The Romansh language, spoken in Switzerland, has limited resources for
machine translation evaluation. In this paper, we present a benchmark for six
varieties of Romansh: Rumantsch Grischun, a supra-regional variety, and five
regional varieties: Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader. Our
reference translations were created by human translators based on the WMT24++
benchmark, which ensures parallelism with more than 55 other languages. An
automatic evaluation of existing MT systems and LLMs shows that translation out
of Romansh into German is handled relatively well for all the varieties, but
translation into Romansh is still challenging.

</details>


### [20] [Domain Adaptation of LLMs for Process Data](https://arxiv.org/abs/2509.03161)
*Rafael Seidi Oyamada,Jari Peeperkorn,Jochen De Weerdt,Johannes De Smedt*

Main category: cs.CL

TL;DR: 该研究探索了直接使用预训练大语言模型处理流程数据的方法，通过参数高效微调技术，在预测性流程监控任务中取得了优于传统RNN和基于自然语言转换方法的性能表现。


<details>
  <summary>Details</summary>
Motivation: 当前流程挖掘领域主要采用提示工程或将事件日志转换为叙事风格数据集的方法来利用LLMs，但本研究希望直接利用LLMs生成token序列的能力来处理流程数据，避免自然语言重构的步骤。

Method: 采用参数高效微调技术对预训练LLMs进行适配，重点关注预测性流程监控任务，包括单任务和多任务预测场景。

Result: 实验结果显示，该方法在预测性能上优于最先进的RNN方法和基于叙事风格的解决方案，特别是在多任务设置中表现更佳。微调后的模型收敛更快，且需要更少的超参数优化。

Conclusion: 直接微调预训练LLMs处理流程数据是一种有效的方法，能够在减少计算开销的同时获得更好的预测性能，特别是在多任务学习场景中表现出色。

Abstract: In recent years, Large Language Models (LLMs) have emerged as a prominent
area of interest across various research domains, including Process Mining
(PM). Current applications in PM have predominantly centered on prompt
engineering strategies or the transformation of event logs into narrative-style
datasets, thereby exploiting the semantic capabilities of LLMs to address
diverse tasks. In contrast, this study investigates the direct adaptation of
pretrained LLMs to process data without natural language reformulation,
motivated by the fact that these models excel in generating sequences of
tokens, similar to the objective in PM. More specifically, we focus on
parameter-efficient fine-tuning techniques to mitigate the computational
overhead typically associated with such models. Our experimental setup focuses
on Predictive Process Monitoring (PPM), and considers both single- and
multi-task predictions. The results demonstrate a potential improvement in
predictive performance over state-of-the-art recurrent neural network (RNN)
approaches and recent narrative-style-based solutions, particularly in the
multi-task setting. Additionally, our fine-tuned models exhibit faster
convergence and require significantly less hyperparameter optimization.

</details>


### [21] [SinhalaMMLU: A Comprehensive Benchmark for Evaluating Multitask Language Understanding in Sinhala](https://arxiv.org/abs/2509.03162)
*Ashmari Pramodya,Nirasha Nelki,Heshan Shalinda,Chamila Liyanage,Yusuke Sakai,Randil Pushpananda,Ruvan Weerasinghe,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

TL;DR: 首个专门为斯里兰卡低资源语言Sinhala设计的多选题回答测试集SinhalaMMLU，包含7000+问题，评估26个大语言模型发现性能偏低，在文化丰富领域表现尤其差。


<details>
  <summary>Details</summary>
Motivation: 现有多语言测试集依赖自动翻译导致错误和文化上下文失真，需要专门为低资源语言和特定文化设计的评测标准。

Method: 构建SinhalaMMLU测试集，包含7000+个问题，涵盖中学到大学教育水平，对准斯里兰国家课程，涵盖6个领域和30个学科，包括普通学科和文化知识。

Result: 在26个大语言模型评测中，Claude 3.5 sonnet和GPT-4o表现最佳（分别67%和62%准确率），但整体性能仍有限，在人文科学等文化丰富领域表现尤其差。

Conclusion: 大语言模型在低资源语言和特定文化上下文中的适应性仍有很大提升空间，需要更多专门设计的测试集来评估和改善模型表现。

Abstract: Large Language Models (LLMs) demonstrate impressive general knowledge and
reasoning abilities, yet their evaluation has predominantly focused on global
or anglocentric subjects, often neglecting low-resource languages and
culturally specific content. While recent multilingual benchmarks attempt to
bridge this gap, many rely on automatic translation, which can introduce errors
and misrepresent the original cultural context. To address this, we introduce
SinhalaMMLU, the first multiple-choice question answering benchmark designed
specifically for Sinhala, a low-resource language. The dataset includes over
7,000 questions spanning secondary to collegiate education levels, aligned with
the Sri Lankan national curriculum, and covers six domains and 30 subjects,
encompassing both general academic topics and culturally grounded knowledge. We
evaluate 26 LLMs on SinhalaMMLU and observe that, while Claude 3.5 sonnet and
GPT-4o achieve the highest average accuracies at 67% and 62% respectively,
overall model performance remains limited. In particular, models struggle in
culturally rich domains such as the Humanities, revealing substantial room for
improvement in adapting LLMs to low-resource and culturally specific contexts.

</details>


### [22] [LatPhon: Lightweight Multilingual G2P for Romance Languages and English](https://arxiv.org/abs/2509.03300)
*Luis Felipe Chary,Miguel Arjona Ramirez*

Main category: cs.CL

TL;DR: LatPhon是一个7.5M参数的Transformer模型，在6种拉丁语系语言上联合训练，实现了3.5%的平均音素错误率，优于基线模型，接近语言特定的WFST系统，同时模型大小仅30MB，适合设备端部署。


<details>
  <summary>Details</summary>
Motivation: G2P转换是TTS、ASR、S2ST和对齐系统的关键前端组件，特别是在多拉丁语系语言场景下需要高效的通用解决方案。

Method: 使用7.5M参数的Transformer模型，在英语、西班牙语、法语、意大利语、葡萄牙语和罗马尼亚语六种语言上联合训练，基于公开的ipa-dict语料库。

Result: 在ipa-dict语料库上达到3.5%的平均音素错误率，优于字节级ByT5基线(5.4%)，接近语言特定WFST系统(3.2%)，模型大小仅30MB。

Conclusion: 紧凑的多语言G2P模型可以作为拉丁语系语音管道的通用前端组件，具有设备端部署的可行性。

Abstract: Grapheme-to-phoneme (G2P) conversion is a key front-end for text-to-speech
(TTS), automatic speech recognition (ASR), speech-to-speech translation (S2ST)
and alignment systems, especially across multiple Latin-script languages.We
present LatPhon, a 7.5 M - parameter Transformer jointly trained on six such
languages--English, Spanish, French, Italian, Portuguese, and Romanian. On the
public ipa-dict corpus, it attains a mean phoneme error rate (PER) of 3.5%,
outperforming the byte-level ByT5 baseline (5.4%) and approaching
language-specific WFSTs (3.2%) while occupying 30 MB of memory, which makes
on-device deployment feasible when needed. These results indicate that compact
multilingual G2P can serve as a universal front-end for Latin-language speech
pipelines.

</details>


### [23] [AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?](https://arxiv.org/abs/2509.03312)
*Guibin Zhang,Junhao Wang,Junjie Chen,Wangchunshu Zhou,Kun Wang,Shuicheng Yan*

Main category: cs.CL

TL;DR: AgenTracer是一个自动化的多智能体系统故障追踪框架，通过反事实重放和故障注入生成标注数据集，训练出轻量级故障追踪模型AgenTracer-8B，在故障归因任务上超越大型专有LLM，并能提升现有多智能体系统性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)驱动的多智能体系统虽然性能优越，但其复杂性也增加了系统脆弱性，容易发生故障。当前最先进的推理LLM在故障归因任务上准确率低于10%，无法有效定位多智能体执行轨迹中的错误源。

Method: 提出AgenTracer框架：1) 通过反事实重放和编程式故障注入自动标注失败的多智能体轨迹，构建TracerTraj数据集；2) 利用该数据集，采用多粒度强化学习训练轻量级故障追踪模型AgenTracer-8B。

Result: 在Who&When基准测试中，AgenTracer-8B比Gemini-2.5-Pro和Claude-4-Sonnet等大型专有LLM性能提升高达18.18%。更重要的是，它能对MetaGPT和MaAS等现有多智能体系统提供可操作的反馈，带来4.8-14.2%的性能提升。

Conclusion: AgenTracer-8B为多智能体系统故障归因设立了新标准，能够有效诊断冗长多智能体交互中的错误，赋能自校正和自进化的智能体AI系统。

Abstract: Large Language Model (LLM)-based agentic systems, often comprising multiple
models, complex tool invocations, and orchestration protocols, substantially
outperform monolithic agents. Yet this very sophistication amplifies their
fragility, making them more prone to system failure. Pinpointing the specific
agent or step responsible for an error within long execution traces defines the
task of agentic system failure attribution. Current state-of-the-art reasoning
LLMs, however, remain strikingly inadequate for this challenge, with accuracy
generally below 10%. To address this gap, we propose AgenTracer, the first
automated framework for annotating failed multi-agent trajectories via
counterfactual replay and programmed fault injection, producing the curated
dataset TracerTraj. Leveraging this resource, we develop AgenTracer-8B, a
lightweight failure tracer trained with multi-granular reinforcement learning,
capable of efficiently diagnosing errors in verbose multi-agent interactions.
On the Who&When benchmark, AgenTracer-8B outperforms giant proprietary LLMs
like Gemini-2.5-Pro and Claude-4-Sonnet by up to 18.18%, setting a new standard
in LLM agentic failure attribution. More importantly, AgenTracer-8B delivers
actionable feedback to off-the-shelf multi-agent systems like MetaGPT and MaAS
with 4.8-14.2% performance gains, empowering self-correcting and self-evolving
agentic AI.

</details>


### [24] [LMEnt: A Suite for Analyzing Knowledge in Language Models from Pretraining Data to Representations](https://arxiv.org/abs/2509.03405)
*Daniela Gottesman,Alon Gilae-Dotan,Ido Cohen,Yoav Gur-Arieh,Marius Mosbach,Ori Yoran,Mor Geva*

Main category: cs.CL

TL;DR: LMEnt是一个用于分析语言模型预训练过程中知识获取的套件，包含知识丰富的预训练语料库、实体检索方法和预训练模型，为研究知识表示和学习动态提供受控环境


<details>
  <summary>Details</summary>
Motivation: 理解语言模型如何将数据转化为世界知识和信念的内部过程，以开发更一致、稳健和完整的知识表示

Method: 提出LMEnt套件：1）基于Wikipedia的完全实体标注的知识丰富预训练语料库；2）比先前方法提升80.4%的基于实体的检索方法；3）12个最多10亿参数和4000个中间检查点的预训练模型

Result: LMEnt提供了分析预训练中实体提及与下游性能联系的受控环境，发现事实频率是关键因素但不能完全解释学习趋势

Conclusion: LMEnt支持语言模型知识研究，包括知识表示、可塑性、编辑、归因和学习动态，相关资源已发布

Abstract: Language models (LMs) increasingly drive real-world applications that require
world knowledge. However, the internal processes through which models turn data
into representations of knowledge and beliefs about the world, are poorly
understood. Insights into these processes could pave the way for developing LMs
with knowledge representations that are more consistent, robust, and complete.
To facilitate studying these questions, we present LMEnt, a suite for analyzing
knowledge acquisition in LMs during pretraining. LMEnt introduces: (1) a
knowledge-rich pretraining corpus, fully annotated with entity mentions, based
on Wikipedia, (2) an entity-based retrieval method over pretraining data that
outperforms previous approaches by as much as 80.4%, and (3) 12 pretrained
models with up to 1B parameters and 4K intermediate checkpoints, with
comparable performance to popular open-sourced models on knowledge benchmarks.
Together, these resources provide a controlled environment for analyzing
connections between entity mentions in pretraining and downstream performance,
and the effects of causal interventions in pretraining data. We show the
utility of LMEnt by studying knowledge acquisition across checkpoints, finding
that fact frequency is key, but does not fully explain learning trends. We
release LMEnt to support studies of knowledge in LMs, including knowledge
representations, plasticity, editing, attribution, and learning dynamics.

</details>


### [25] [Learning Mechanism Underlying NLP Pre-Training and Fine-Tuning](https://arxiv.org/abs/2509.03407)
*Yarden Tzach,Ronit D. Gross,Ella Koresh,Shalom Rosner,Or Shpringer,Tal Halevi,Ido Kanter*

Main category: cs.CL

TL;DR: 该研究分析了BERT预训练机制，发现准确率随token频率增加，预训练通过transformer块形成强匹配token簇，提升了语言结构理解和下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 理解预训练成功的内在机制，探究预训练准确率与下游分类任务微调之间的相互关系。

Method: 使用BERT-6架构在Wikipedia数据集上进行预训练，然后在FewRel和DBpedia分类任务上进行微调分析。通过token混淆矩阵和准确率分析预训练机制。

Result: token准确率随出现频率增加；预训练形成有限小的强匹配token簇；transformer块增强了语言结构生成能力；预训练成功反映在微调准确率提升上；输出标签预测置信度与平均输入APT无关。

Conclusion: 预训练通过对称性破缺形成token簇结构，即使学习目标仅为识别单个token也能生成高阶语言结构。预训练机制在NLP分类任务中具有普适性，与图像分类的微调机制相似。

Abstract: Natural language processing (NLP) enables the understanding and generation of
meaningful human language, typically using a pre-trained complex architecture
on a large dataset to learn the language and next fine-tune its weights to
implement a specific task. Twofold goals are examined; to understand the
mechanism underlying successful pre-training and to determine the interplay
between the pre-training accuracy and the fine-tuning of classification tasks.
The following main results were obtained; the accuracy per token (APT)
increased with its appearance frequency in the dataset, and its average over
all tokens served as an order parameter to quantify pre-training success, which
increased along the transformer blocks. Pre-training broke the symmetry among
tokens and grouped them into finite, small, strong match token clusters, as
inferred from the presented token confusion matrix. This feature was sharpened
along the transformer blocks toward the output layer, enhancing its performance
considerably compared with that of the embedding layer. Consequently,
higher-order language structures were generated by pre-training, even though
the learning cost function was directed solely at identifying a single token.
These pre-training findings were reflected by the improved fine-tuning accuracy
along the transformer blocks. Additionally, the output label prediction
confidence was found to be independent of the average input APT, as the input
meaning was preserved since the tokens are replaced primarily by strong match
tokens. Finally, although pre-training is commonly absent in image
classification tasks, its underlying mechanism is similar to that used in
fine-tuning NLP classification tasks, hinting at its universality. The results
were based on the BERT-6 architecture pre-trained on the Wikipedia dataset and
fine-tuned on the FewRel and DBpedia classification tasks.

</details>


### [26] [Curse of Knowledge: When Complex Evaluation Context Benefits yet Biases LLM Judges](https://arxiv.org/abs/2509.03419)
*Weiyuan Li,Xintao Wang,Siyu Yuan,Rui Xu,Jiangjie Chen,Qingqing Dong,Yanghua Xiao,Deqing Yang*

Main category: cs.CL

TL;DR: 本文构建了ComplexEval基准测试，系统性地揭示和量化了大型语言模型作为评估者时存在的辅助信息诱导偏见，发现所有模型都对这些偏见表现出显著敏感性，且偏见程度随任务复杂度增加而加剧。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型能力增强，面对日益复杂多样的任务，可靠的评估变得困难。LLM作为评估者的范式虽然可扩展，但在复杂任务中的可靠性研究不足，特别是涉及多维度评分标准、非结构化参考答案和细微评判标准的情况。

Method: 构建ComplexEval挑战基准，系统性地研究和验证6种先前未探索的偏见，涵盖12个基础场景和3个高级场景，对大型推理模型进行深入分析。

Result: 所有评估模型都对这些偏见表现出显著敏感性，偏见程度随任务复杂度增加而加剧；大型推理模型表现出矛盾性的脆弱性。

Conclusion: 研究为提高评估信号的准确性和可验证性提供了关键见解，为开发更通用和鲁棒的评估模型铺平了道路。

Abstract: As large language models (LLMs) grow more capable, they face increasingly
diverse and complex tasks, making reliable evaluation challenging. The paradigm
of LLMs as judges has emerged as a scalable solution, yet prior work primarily
focuses on simple settings. Their reliability in complex tasks--where
multi-faceted rubrics, unstructured reference answers, and nuanced criteria are
critical--remains understudied. In this paper, we constructed ComplexEval, a
challenge benchmark designed to systematically expose and quantify Auxiliary
Information Induced Biases. We systematically investigated and validated 6
previously unexplored biases across 12 basic and 3 advanced scenarios. Key
findings reveal: (1) all evaluated models exhibit significant susceptibility to
these biases, with bias magnitude scaling with task complexity; (2) notably,
Large Reasoning Models (LRMs) show paradoxical vulnerability. Our in-depth
analysis offers crucial insights for improving the accuracy and verifiability
of evaluation signals, paving the way for more general and robust evaluation
models.

</details>


### [27] [Continuous Saudi Sign Language Recognition: A Vision Transformer Approach](https://arxiv.org/abs/2509.03467)
*Soukeina Elhassen,Lama Al Khuzayem,Areej Alhothali,Ohoud Alzamzami,Nahed Alowaidi*

Main category: cs.CL

TL;DR: 这篇论文提出了第一个连续沙特手语语料集KAU-CSSL和一种基于Transformer的模型，为阿拉伯手语识别提供了重要资源和技术方案。


<details>
  <summary>Details</summary>
Motivation: 沙特手语(SSL)作为过万84,000人的主要沟通方式，但现有技术主要集中在非阿拉伯手语，缺乏连续语句级别的资源，导致交流障碍和社会排斥。

Method: 构建第一个连续沙特手语语料集KAU-CSSL，采用预训练ResNet-18进行空间特征提取，结合Transformer Encoder和双向LSTM处理时序依赖关系。

Result: 模型在指定人员模式下达到99.02%准确率，在非指定人员模式下达到77.71%准确率。

Conclusion: 该研究为沙特手语社区提供了重要的沟通工具，并对手语识别领域做出了重要贡献，为阿拉伯手语的进一步研究奠定了基础。

Abstract: Sign language (SL) is an essential communication form for hearing-impaired
and deaf people, enabling engagement within the broader society. Despite its
significance, limited public awareness of SL often leads to inequitable access
to educational and professional opportunities, thereby contributing to social
exclusion, particularly in Saudi Arabia, where over 84,000 individuals depend
on Saudi Sign Language (SSL) as their primary form of communication. Although
certain technological approaches have helped to improve communication for
individuals with hearing impairments, there continues to be an urgent
requirement for more precise and dependable translation techniques, especially
for Arabic sign language variants like SSL. Most state-of-the-art solutions
have primarily focused on non-Arabic sign languages, resulting in a
considerable absence of resources dedicated to Arabic sign language,
specifically SSL. The complexity of the Arabic language and the prevalence of
isolated sign language datasets that concentrate on individual words instead of
continuous speech contribute to this issue. To address this gap, our research
represents an important step in developing SSL resources. To address this, we
introduce the first continuous Saudi Sign Language dataset called KAU-CSSL,
focusing on complete sentences to facilitate further research and enable
sophisticated recognition systems for SSL recognition and translation.
Additionally, we propose a transformer-based model, utilizing a pretrained
ResNet-18 for spatial feature extraction and a Transformer Encoder with
Bidirectional LSTM for temporal dependencies, achieving 99.02\% accuracy at
signer dependent mode and 77.71\% accuracy at signer independent mode. This
development leads the way to not only improving communication tools for the SSL
community but also making a substantial contribution to the wider field of sign
language.

</details>


### [28] [Design and Optimization of Reinforcement Learning-Based Agents in Text-Based Games](https://arxiv.org/abs/2509.03479)
*Haonan Wang,Mingjia Zhao,Junfeng Sun,Wei Liu*

Main category: cs.CL

TL;DR: 通过深度学习和策略梯度增强学习方法，提出了一种在文本游戏中表现优异的智能体设计方案


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的进步，在文本游戏中使用智能体的研究越来越受欢迎，需要提出更有效的代理人设计和学习方法

Method: 首先应用深度学习模型处理游戏文本并建立世界模型，然后通过策略梯度基础的深度增强学习方法学习代理人，促进从状态价值到最优策略的转换

Result: 在多个文本游戏实验中，改进后的代理人表现更好，在游戏完成率和胜利率方面显著超过之前的代理人

Conclusion: 该研究为使用增强学习处理文本游戏提供了新的理论理解和实证基础，为在更普遍领域和问题中开发和优化增强学习代理人奠定了基础

Abstract: As AI technology advances, research in playing text-based games with agents
has becomeprogressively popular. In this paper, a novel approach to agent
design and agent learning ispresented with the context of reinforcement
learning. A model of deep learning is first applied toprocess game text and
build a world model. Next, the agent is learned through a policy gradient-based
deep reinforcement learning method to facilitate conversion from state value to
optimal policy.The enhanced agent works better in several text-based game
experiments and significantlysurpasses previous agents on game completion ratio
and win rate. Our study introduces novelunderstanding and empirical ground for
using reinforcement learning for text games and sets thestage for developing
and optimizing reinforcement learning agents for more general domains
andproblems.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [29] [Multi-level SSL Feature Gating for Audio Deepfake Detection](https://arxiv.org/abs/2509.03409)
*Hoan My Tran,Damien Lolive,Aghilas Sini,Arnaud Delhay,Pierre-François Marteau,David Guennec*

Main category: cs.SD

TL;DR: 通过结合XLS-R基础模型的门控机制和多内核卷积分析，提出了一种能够检测多语言深度伪造语音的新方法，在域内咈域外都取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 随着语音合成技术的发展，高保真度的合成语音可能被欺诈活动、身份盗用等恶意利用，当前的检测技术在应对未见攻击和多语言场景时遇到了性能局限。

Method: 使用XLS-R语音基础模型作为前端特征提取器，通过门控机制提取关键特征；后端采用多内核门控卷积网络(MultiConv)捕捉局部和全局语音伪造特征；引入中心内核对齐(CKA)度量来促进不同层特征的多样性。

Result: 在域内测试集上达到了最佳性能，同时在域外数据集包括多语言语音样本上也表现出了良好的演化性能。

Conclusion: 该方法提供了一种多用途的解决方案，能够有效检测日益发展的语音深度伪造威胁，具有强大的实际应用潜力。

Abstract: Recent advancements in generative AI, particularly in speech synthesis, have
enabled the generation of highly natural-sounding synthetic speech that closely
mimics human voices. While these innovations hold promise for applications like
assistive technologies, they also pose significant risks, including misuse for
fraudulent activities, identity theft, and security threats. Current research
on spoofing detection countermeasures remains limited by generalization to
unseen deepfake attacks and languages. To address this, we propose a gating
mechanism extracting relevant feature from the speech foundation XLS-R model as
a front-end feature extractor. For downstream back-end classifier, we employ
Multi-kernel gated Convolution (MultiConv) to capture both local and global
speech artifacts. Additionally, we introduce Centered Kernel Alignment (CKA) as
a similarity metric to enforce diversity in learned features across different
MultiConv layers. By integrating CKA with our gating mechanism, we hypothesize
that each component helps improving the learning of distinct synthetic speech
patterns. Experimental results demonstrate that our approach achieves
state-of-the-art performance on in-domain benchmarks while generalizing
robustly to out-of-domain datasets, including multilingual speech samples. This
underscores its potential as a versatile solution for detecting evolving speech
deepfake threats.

</details>


### [30] [Analysis of Speaker Verification Performance Trade-offs with Neural Audio Codec Transmission](https://arxiv.org/abs/2509.02771)
*Nirmalya Mallick Thakur,Jia Qi Yip,Eng Siong Chng*

Main category: cs.SD

TL;DR: 神经音频编解码器在低比特率下优于传统编解码器，但在高比特率下由于优化目标不同而略逊于Opus，整体对说话人验证性能影响可控


<details>
  <summary>Details</summary>
Motivation: 研究神经音频编解码器(NACs)在不同比特率下对说话人验证系统性能的影响，比较其与传统编解码器的差异

Method: 在VoxCeleb1数据集上评估三种最先进的说话人验证模型，测试传统和神经音频编解码器在不同比特率下的性能表现

Result: 所有编解码器和模型都随比特率降低而性能下降；NACs在低比特率(<12kbps)下比Opus性能好6-8%，在高比特率(≈24kbps)下仅差0.4-0.7%

Conclusion: NACs是传统编解码器的可行替代方案，特别是在带宽受限情况下；未来需要开发说话人感知的NACs或重新训练适应SV模型

Abstract: Neural audio codecs (NACs) have made significant advancements in recent years
and are rapidly being adopted in many audio processing pipelines. However, they
can introduce audio distortions which degrade speaker verification (SV)
performance. This study investigates the impact of both traditional and neural
audio codecs at varying bitrates on three state of-the-art SV models evaluated
on the VoxCeleb1 dataset. Our findings reveal a consistent degradation in SV
performance across all models and codecs as bitrates decrease. Notably, NACs do
not fundamentally break SV performance when compared to traditional codecs.
They outperform Opus by 6-8% at low-bitrates (< 12 kbps) and remain marginally
behind at higher bitrates ($\approx$ 24 kbps), with an EER increase of only
0.4-0.7%. The disparity at higher bitrates is likely due to the primary
optimization of NACs for perceptual quality, which can inadvertently discard
critical speaker-discriminative features, unlike Opus which was designed to
preserve vocal characteristics. Our investigation suggests that NACs are a
feasible alternative to traditional codecs, especially under bandwidth
limitations. To bridge the gap at higher bitrates, future work should focus on
developing speaker-aware NACs or retraining and adapting SV models.

</details>


### [31] [Speech DF Arena: A Leaderboard for Speech DeepFake Detection Models](https://arxiv.org/abs/2509.02859)
*Sandipana Dowerah,Atharva Kulkarni,Ajinkya Kulkarni,Hoan My Tran,Joonas Kalda,Artem Fedorchenko,Benoit Fauve,Damien Lolive,Tanel Alumäe,Matthew Magimai Doss*

Main category: cs.SD

TL;DR: 语音深度伪造检测综合性评测基准Speech DF Arena，包含14个数据集和15个检测系统的统一评测工具、标准化指标和排行榜


<details>
  <summary>Details</summary>
Motivation: 当前语音深度伪造检测领域缺乏标准化和综合性的评测基准，导致不同系统难以公平比较和评估

Method: 开发Speech DF Arena工具套件，统一评测14个多样化数据集和攻击场景，采用标准化评估指标和协议以确保可复现性

Result: 研究显示许多检测系统在领域外场景中表现出较高的EER（相等错误率），强调了跨领域评测的重要性

Conclusion: Speech DF Arena为语音深度伪造检测领域提供了第一个全面的标准化评测基准，通过实时排行榜和开源工具提升了检测系统的可靠性和稳健性

Abstract: Parallel to the development of advanced deepfake audio generation, audio
deepfake detection has also seen significant progress. However, a standardized
and comprehensive benchmark is still missing. To address this, we introduce
Speech DeepFake (DF) Arena, the first comprehensive benchmark for audio
deepfake detection. Speech DF Arena provides a toolkit to uniformly evaluate
detection systems, currently across 14 diverse datasets and attack scenarios,
standardized evaluation metrics and protocols for reproducibility and
transparency. It also includes a leaderboard to compare and rank the systems to
help researchers and developers enhance their reliability and robustness. We
include 14 evaluation sets, 12 state-of-the-art open-source and 3 proprietary
detection systems. Our study presents many systems exhibiting high EER in
out-of-domain scenarios, highlighting the need for extensive cross-domain
evaluation. The leaderboard is hosted on Huggingface1 and a toolkit for
reproducing results across the listed datasets is available on GitHub.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [32] [Simulacra Naturae: Generative Ecosystem driven by Agent-Based Simulations and Brain Organoid Collective Intelligence](https://arxiv.org/abs/2509.02924)
*Nefeli Manoudaki,Mert Toka,Iason Paterakis,Diarmid Flatley*

Main category: cs.MM

TL;DR: Simulacra Naturae是一个数据驱动的媒体装置，通过生物计算、材料生态和生成系统的融合探索集体关怀。该作品将脑类器官的神经活动转化为包含生成视觉、空间音频、活体植物和人工粘土制品等多感官环境。


<details>
  <summary>Details</summary>
Motivation: 探索通过非人类认知来重新构想可视化作为一种关怀实践，去中心化人类能动性，在混合计算系统中开辟伦理、共情和生态协调的新空间。

Method: 使用预记录的脑类器官神经活动信号，通过实时系统调节受自然系统启发的涌现智能体行为。采用计算制造的嵌入式电磁铁粘土打印品，结合活体热带植物和实时生成AI视觉，创建多感官环境。

Result: 创建了一个由非人类认知塑造的感官场域，将抽象数据锚定在生命材料和具身体验中，实现了生物信号作为共同创造力量而非直接控制输入的艺术表达。

Conclusion: 该作品成功地将生物计算与材料生态相结合，为混合计算系统中的伦理和生态关怀提供了新的可视化范式，强调了去人类中心化的共同创造方法在艺术科技实践中的重要性。

Abstract: Simulacra Naturae is a data-driven media installation that explores
collective care through the entanglement of biological computation, material
ecologies, and generative systems. The work translates pre-recorded neural
activity from brain organoids, lab-grown three-dimensional clusters of neurons,
into a multi-sensory environment composed of generative visuals, spatial audio,
living plants, and fabricated clay artifacts. These biosignals, streamed
through a real-time system, modulate emergent agent behaviors inspired by
natural systems such as termite colonies and slime molds. Rather than using
biosignals as direct control inputs, Simulacra Naturae treats organoid activity
as a co-creative force, allowing neural rhythms to guide the growth, form, and
atmosphere of a generative ecosystem. The installation features computationally
fabricated clay prints embedded with solenoids, adding physical sound
resonances to the generative surround composition. The spatial environment,
filled with live tropical plants and a floor-level projection layer featuring
real-time generative AI visuals, invites participants into a sensory field
shaped by nonhuman cognition. By grounding abstract data in living materials
and embodied experience, Simulacra Naturae reimagines visualization as a
practice of care, one that decentralizes human agency and opens new spaces for
ethics, empathy, and ecological attunement within hybrid computational systems.

</details>


### [33] [Automatically Generating High-Precision Simulated Road Networking in Traffic Scenario](https://arxiv.org/abs/2509.02990)
*Liang Xie,Wenke Huang*

Main category: cs.MM

TL;DR: 自动化生成高精度车道级模拟路网，通过深度学习检测街景图像中的车道线，然后结合坐标变换和地图匹配算法生成精确路网


<details>
  <summary>Details</summary>
Motivation: 解决现有车道级模拟路网生成方法劳动密集、资源消耗大、成本高的问题，需要大规模数据采集和手工后期编辑

Method: 1. 从开源街景地图平台收集真实街道数据并构建大规模车道线数据集 2. 设计基于深度学习的端到端车道线检测方法 3. 结合坐标变换和地图匹配算法融合车道信息与基础路网拓扑

Result: 显著降低了数据采集和手工编辑成本，同时提高了模拟路网生成的效率和准确性

Conclusion: 为城市交通模拟、自动驾驶导航和智能交通系统开发提供了可靠数据支持，为大规模城市路网自动建模提供了新技术路径

Abstract: Existing lane-level simulation road network generation is labor-intensive,
resource-demanding, and costly due to the need for large-scale data collection
and manual post-editing. To overcome these limitations, we propose
automatically generating high-precision simulated road networks in traffic
scenario, an efficient and fully automated solution. Initially, real-world road
street view data is collected through open-source street view map platforms,
and a large-scale street view lane line dataset is constructed to provide a
robust foundation for subsequent analysis. Next, an end-to-end lane line
detection approach based on deep learning is designed, where a neural network
model is trained to accurately detect the number and spatial distribution of
lane lines in street view images, enabling automated extraction of lane
information. Subsequently, by integrating coordinate transformation and map
matching algorithms, the extracted lane information from street views is fused
with the foundational road topology obtained from open-source map service
platforms, resulting in the generation of a high-precision lane-level
simulation road network. This method significantly reduces the costs associated
with data collection and manual editing while enhancing the efficiency and
accuracy of simulation road network generation. It provides reliable data
support for urban traffic simulation, autonomous driving navigation, and the
development of intelligent transportation systems, offering a novel technical
pathway for the automated modeling of large-scale urban road networks.

</details>
