<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 137]
- [cs.MM](#cs.MM) [Total: 3]
- [cs.SD](#cs.SD) [Total: 29]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MultiStream-LLM: Bridging Modalities for Robust Sign Language Translation](https://arxiv.org/abs/2509.00030)
*Marshall Thomas,Edward Fish,Richard Bowden*

Main category: cs.CL

TL;DR: 提出了MultiStream-LLM框架，通过分离专门的手指拼写、唇读和连续手语识别模块，解决了传统端到端手语翻译模型在高速手指拼写和非手动线索整合上的性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 传统端到端手语翻译模型在处理高速手指拼写和面部非手动线索时表现不佳，特别是在翻译姓名、地点和技术术语等关键信息时效果较差。

Method: 采用模块化框架，使用专门的预测器分别处理连续手语、手指拼写和唇读，然后将并行流通过轻量级transformer进行时间对齐和融合，最后使用大语言模型生成句子。

Result: 在How2Sign基准测试中达到BLEU-4分数23.5的新SOTA，在ChicagoFSWildPlus手指拼写数据集上达到73.2%的字母准确率。

Conclusion: 通过分离和专门解决不同的识别任务再进行融合的多专家方法，为鲁棒、高保真的手语翻译提供了更强大有效的途径。

Abstract: Despite progress in gloss-free Sign Language Translation (SLT), monolithic
end-to-end models consistently fail on two critical components of natural
signing: the precise recognition of high-speed fingerspelling and the
integration of asynchronous non-manual cues from the face. Recent progress in
Automated Sign Language Translation with Large Language Models has side stepped
this challenge, forcing a single network to learn these simultaneously
resulting in poor performance when tasked with translating crucial information
such as names,places, and technical terms. We introduce MultiStream-LLM, a
modular framework designed to overcome these limitations. Our approach employs
separate, specialized predictors for continuous signing, fingerspelling, and
lipreading. Each expert network first decodes its specific modality into a
sequence of tokens. These parallel streams are then fused by a lightweight
transformer that resolves temporal misalignments before passing the combined
representation to a Large Language Model (LLM) for final sentence generation.
Our method establishes a new state-of-the-art on the How2Sign benchmark with a
BLEU-4 score of 23.5 and achieves 73.2% letter accuracy on the challenging
ChicagoFSWildPlus fingerspelling dataset. These results validate our core
hypothesis: by isolating and solving distinct recogni tion tasks before fusion,
our multi-expert approach provides a more powerful and effective pathway to
robust, high-fidelity sign language translation.

</details>


### [2] [Compiling Prompts, Not Crafting Them: A Reproducible Workflow for AI-Assisted Evidence Synthesis](https://arxiv.org/abs/2509.00038)
*Teo Susnjak*

Main category: cs.CL

TL;DR: 本文推出了一种声明式提示优化框架，用于改善大语言模型在系统性文献综述中的可靠性和可复现性


<details>
  <summary>Details</summary>
Motivation: 当前使用LLM进行系统性文献综述的方法依赖容易失效的手动制作提示，影响了科学研究的可靠性和可复现性

Method: 采用声明式提示优化技术，构建包含任务声明、测试套件和自动提示调整的领域特定框架

Result: 开发了一种具体的蓝图和工作代码示例，支持建立符合透明性和严谨性原则的可验证LLM流水线

Conclusion: 这是声明式提示优化方法在SLR自动化领域的新颖应用，有助于提高LLM辅助证据综合的科学信心

Abstract: Large language models (LLMs) offer significant potential to accelerate
systematic literature reviews (SLRs), yet current approaches often rely on
brittle, manually crafted prompts that compromise reliability and
reproducibility. This fragility undermines scientific confidence in
LLM-assisted evidence synthesis. In response, this work adapts recent advances
in declarative prompt optimisation, developed for general-purpose LLM
applications, and demonstrates their applicability to the domain of SLR
automation. This research proposes a structured, domain-specific framework that
embeds task declarations, test suites, and automated prompt tuning into a
reproducible SLR workflow. These emerging methods are translated into a
concrete blueprint with working code examples, enabling researchers to
construct verifiable LLM pipelines that align with established principles of
transparency and rigour in evidence synthesis. This is a novel application of
such approaches to SLR pipelines.

</details>


### [3] [What Are Research Hypotheses?](https://arxiv.org/abs/2509.00185)
*Jian Wu,Sarah Rajtmajer*

Main category: cs.CL

TL;DR: 本文综述了自然语言处理中"假设"概念的不同定义，特别关注了近期NLU任务中的定义差异，强调了在机器可解释学术记录背景下明确定义假设的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理技术的发展，各种任务对"假设"的定义偏离了传统科学定义，甚至在NLU领域内部也存在定义差异，需要系统梳理和明确界定。

Method: 通过文献综述方法，对近期发表的NLU任务中使用的假设定义进行系统性的概述和辨析，特别关注定义间的细微差别。

Result: 识别出NLU领域中假设概念存在多重定义和解释，这些定义在不同任务和应用场景中表现出显著差异。

Conclusion: 在向机器可解释学术记录发展的过程中，需要建立结构良好、定义明确的假设概念框架，以确保学术交流的准确性和可解释性。

Abstract: Over the past decades, alongside advancements in natural language processing,
significant attention has been paid to training models to automatically
extract, understand, test, and generate hypotheses in open and scientific
domains. However, interpretations of the term \emph{hypothesis} for various
natural language understanding (NLU) tasks have migrated from traditional
definitions in the natural, social, and formal sciences. Even within NLU, we
observe differences defining hypotheses across literature. In this paper, we
overview and delineate various definitions of hypothesis. Especially, we
discern the nuances of definitions across recently published NLU tasks. We
highlight the importance of well-structured and well-defined hypotheses,
particularly as we move toward a machine-interpretable scholarly record.

</details>


### [4] [Explainable Chain-of-Thought Reasoning: An Empirical Analysis on State-Aware Reasoning Dynamics](https://arxiv.org/abs/2509.00190)
*Sheldon Yu,Yuxin Xiong,Junda Wu,Xintong Li,Tong Yu,Xiang Chen,Ritwik Sinha,Jingbo Shang,Julian McAuley*

Main category: cs.CL

TL;DR: 提出了一个状态感知转换框架，将思维链轨迹抽象为结构化潜在动态，通过谱分析和马尔可夫链建模来提升推理过程的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有思维链提示的推理可解释性有限，主要关注局部词级归因，而推理步骤的高级语义角色和转换关系未被充分探索。

Method: 使用谱分析对词级嵌入进行聚类，将推理步骤表示为语义一致的潜在状态，并通过马尔可夫链建模推理过程的全局结构。

Result: 该框架支持语义角色识别、时间模式可视化和一致性评估等多种分析，提供结构化和可解释的推理过程视图。

Conclusion: 提出的状态感知转换框架能够有效捕捉思维链推理的演化语义，为复杂推理过程提供了更深入的可解释性分析工具。

Abstract: Recent advances in chain-of-thought (CoT) prompting have enabled large
language models (LLMs) to perform multi-step reasoning. However, the
explainability of such reasoning remains limited, with prior work primarily
focusing on local token-level attribution, such that the high-level semantic
roles of reasoning steps and their transitions remain underexplored. In this
paper, we introduce a state-aware transition framework that abstracts CoT
trajectories into structured latent dynamics. Specifically, to capture the
evolving semantics of CoT reasoning, each reasoning step is represented via
spectral analysis of token-level embeddings and clustered into semantically
coherent latent states. To characterize the global structure of reasoning, we
model their progression as a Markov chain, yielding a structured and
interpretable view of the reasoning process. This abstraction supports a range
of analyses, including semantic role identification, temporal pattern
visualization, and consistency evaluation.

</details>


### [5] [The Rarity Blind Spot: A Framework for Evaluating Statistical Reasoning in LLMs](https://arxiv.org/abs/2509.00245)
*Seiji Maekawa,Hayate Iso,Nikita Bhutani*

Main category: cs.CL

TL;DR: 这篇论文提出了区分性特征挖掘(DFM)新任务，评估LLM在全局文档集中识别稀有特征的能力，并发现现有模型在统计推理和稀有性检测方面存在显著缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有测试重点在信息检索和摘要，而忽视了LLM识别全局范围内稀有特征的能力，这在候选人选择、产品差异化等实际场景中很重要。

Method: 提出DiFBench配置性测试框架，可控制文档集大小和区分性阈值等参数，并对十个最新LLM进行大规模评估。

Result: 发现通用模型与推理增强模型间存在显著性能差距；所有模型在任务复杂度和文档数量增加时性能显著下降；常见失败模式是将常见特征误判为区分性特征。

Conclusion: 现代LLM在细粒度统计推理和稀有性检测方面存在核心限制，需要进一步改进模型的统计分析能力。

Abstract: Effective decision-making often relies on identifying what makes each
candidate distinctive. While existing benchmarks for LLMs emphasize retrieving
or summarizing information relevant to a given query, they do not evaluate a
model's ability to identify globally distinctive features across a set of
documents. We introduce Distinctive Feature Mining (DFM), a new task that
challenges models to analyze a small-to-medium collection (10-40 documents) and
surface features that are rare in the global context (e.g., appearing in less
than 10% of documents). This setting mirrors real-world scenarios such as
candidate selection or product differentiation, where statistical reasoning,
not retrieval, is key. To enable systematic evaluation of this capability, we
present DiFBench, a configurable benchmark creation framework with controllable
parameters such as document set size and distinctiveness thresholds. Using
DiFBench, we perform a large-scale assessment of distinctive feature mining
across ten state-of-the-art LLMs. Our findings reveal a significant performance
gap between general-purpose and reasoning-enhanced models. All models, however,
substantially degrade as the task complexity and document count increase. We
also find that a common failure mode is misidentifying frequent features as
distinctive. These insights reveal core limitations in contemporary LLMs'
abilities to perform fine-grained, statistical reasoning and rarity detection.

</details>


### [6] [The Differential Meaning of Models: A Framework for Analyzing the Structural Consequences of Semantic Modeling Decisions](https://arxiv.org/abs/2509.00248)
*Zachary K. Stine,James E. Deitrick*

Main category: cs.CL

TL;DR: 提出了一个基于皮尔士符号学理论的理论框架，用于统一描述和分析各种人类意义建构建模实践，将模型视为符号并关注其语义关系。


<details>
  <summary>Details</summary>
Motivation: 当前人类意义建构建模方法缺乏统一的理论框架来跨模型类型进行标准化描述和分析，需要建立通用的理论体系。

Method: 基于C.S. Peirce的符号学理论构建理论框架，将模型视为测量潜在符号几何的假设，并通过模型间对比关系来理解模型语义。

Result: 提出了一个能够统一描述各种建模实践的理论框架，并通过简要实例展示了该框架的实证应用价值。

Conclusion: 该框架为建模实践提供了理论基础，将模型本身视为符号进行处理，为未来研究方向奠定了基础。

Abstract: The proliferation of methods for modeling of human meaning-making constitutes
a powerful class of instruments for the analysis of complex semiotic systems.
However, the field lacks a general theoretical framework for describing these
modeling practices across various model types in an apples-to-apples way. In
this paper, we propose such a framework grounded in the semiotic theory of C.
S. Peirce. We argue that such models measure latent symbol geometries, which
can be understood as hypotheses about the complex of semiotic agencies
underlying a symbolic dataset. Further, we argue that in contexts where a
model's value cannot be straightforwardly captured by proxy measures of
performance, models can instead be understood relationally, so that the
particular interpretive lens of a model becomes visible through its contrast
with other models. This forms the basis of a theory of model semantics in which
models, and the modeling decisions that constitute them, are themselves treated
as signs. In addition to proposing the framework, we illustrate its empirical
use with a few brief examples and consider foundational questions and future
directions enabled by the framework.

</details>


### [7] [The Temporal Game: A New Perspective on Temporal Relation Extraction](https://arxiv.org/abs/2509.00250)
*Hugo Sousa,Ricardo Campos,Alípio Jorge*

Main category: cs.CL

TL;DR: 本文提出了Temporal Game，一种将时间关系抽取任务转化为交互式游戏的新方法，通过点级比较和时序闭包推理来实现更细粒度的时间标注。


<details>
  <summary>Details</summary>
Motivation: 传统的时间关系标注方法直接标注区间级关系存在局限性，需要一种更细粒度和灵活的方法来同时支持区间和瞬时实体的标注。

Method: 将时间关系分解为时间实体起点和终点的点级比较，玩家在每一步分类单个点关系，系统应用时序闭包推理来推断额外关系并确保一致性。

Result: 开发了包含游戏模式和标注模式的演示系统，支持TempEval-3数据集的标注和自定义文档标注，系统已公开可用并开源。

Conclusion: Temporal Game不仅作为研究工具和标注界面，还为训练强化学习智能体奠定了基础，将时间标注视为顺序决策任务，推动了时间推理和标注研究的进一步发展。

Abstract: In this paper we demo the Temporal Game, a novel approach to temporal
relation extraction that casts the task as an interactive game. Instead of
directly annotating interval-level relations, our approach decomposes them into
point-wise comparisons between the start and end points of temporal entities.
At each step, players classify a single point relation, and the system applies
temporal closure to infer additional relations and enforce consistency. This
point-based strategy naturally supports both interval and instant entities,
enabling more fine-grained and flexible annotation than any previous approach.
The Temporal Game also lays the groundwork for training reinforcement learning
agents, by treating temporal annotation as a sequential decision-making task.
To showcase this potential, the demo presented in this paper includes a Game
mode, in which users annotate texts from the TempEval-3 dataset and receive
feedback based on a scoring system, and an Annotation mode, that allows custom
documents to be annotated and resulting timeline to be exported. Therefore,
this demo serves both as a research tool and an annotation interface. The demo
is publicly available at https://temporal-game.inesctec.pt, and the source code
is open-sourced to foster further research and community-driven development in
temporal reasoning and annotation.

</details>


### [8] [Exploring Reasoning-Infused Text Embedding with Large Language Models for Zero-Shot Dense Retrieval](https://arxiv.org/abs/2509.00276)
*Yuxiang Liu,Tian Wang,Gourab Kundu,Tianyu Cao,Guang Cheng,Zhen Ge,Jianshu Chen,Qingjun Cui,Trishul Chilimbi*

Main category: cs.CL

TL;DR: RITE方法通过生成推理文本来增强文本嵌入，在BRIGHT基准测试中显著提升了零样本检索性能


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的嵌入方法主要关注上下文表示，未能充分利用LLM的推理能力来处理需要复杂推理的检索任务

Method: 提出RITE方法，在计算嵌入之前生成中间推理文本，将逻辑推理融入文本嵌入过程，丰富表示层的推理深度

Result: 在推理密集型检索基准BRIGHT上的实验结果显示，RITE显著提升了跨领域的零样本检索性能

Conclusion: 将推理融入嵌入过程是有效的，RITE方法成功利用了LLM的推理能力来增强文本嵌入质量

Abstract: Transformer-based models such as BERT and E5 have significantly advanced text
embedding by capturing rich contextual representations. However, many complex
real-world queries require sophisticated reasoning to retrieve relevant
documents beyond surface-level lexical matching, where encoder-only retrievers
often fall short. Decoder-only large language models (LLMs), known for their
strong reasoning capabilities, offer a promising alternative. Despite this
potential, existing LLM-based embedding methods primarily focus on contextual
representation and do not fully exploit the reasoning strength of LLMs. To
bridge this gap, we propose Reasoning-Infused Text Embedding (RITE), a simple
but effective approach that integrates logical reasoning into the text
embedding process using generative LLMs. RITE builds upon existing language
model embedding techniques by generating intermediate reasoning texts in the
token space before computing embeddings, thereby enriching representations with
inferential depth. Experimental results on BRIGHT, a reasoning-intensive
retrieval benchmark, demonstrate that RITE significantly enhances zero-shot
retrieval performance across diverse domains, underscoring the effectiveness of
incorporating reasoning into the embedding process.

</details>


### [9] [OpinioRAG: Towards Generating User-Centric Opinion Highlights from Large-scale Online Reviews](https://arxiv.org/abs/2509.00285)
*Mir Tafseer Nayeem,Davood Rafiei*

Main category: cs.CL

TL;DR: 提出OpinioRAG框架，基于RAG和LLM从海量用户评论中生成个性化摘要，无需训练，并设计了新的无参考验证指标用于情感丰富领域的评估。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法处理数千条评论的规模，且生成的摘要过于通用，无法满足个性化需求，需要开发可扩展的个性化摘要生成方案。

Method: 结合RAG证据检索和LLM，构建无需训练的框架OpinioRAG，同时提出针对情感丰富领域的新型无参考验证指标。

Result: 创建了首个大规模长评论数据集，包含每个实体上千条评论，并通过实验验证了框架的有效性，提供了改进系统的可行见解。

Conclusion: OpinioRAG是一个强大的框架，能够大规模生成准确、相关且结构化的摘要，为未来研究奠定了基础。

Abstract: We study the problem of opinion highlights generation from large volumes of
user reviews, often exceeding thousands per entity, where existing methods
either fail to scale or produce generic, one-size-fits-all summaries that
overlook personalized needs. To tackle this, we introduce OpinioRAG, a
scalable, training-free framework that combines RAG-based evidence retrieval
with LLMs to efficiently produce tailored summaries. Additionally, we propose
novel reference-free verification metrics designed for sentiment-rich domains,
where accurately capturing opinions and sentiment alignment is essential. These
metrics offer a fine-grained, context-sensitive assessment of factual
consistency. To facilitate evaluation, we contribute the first large-scale
dataset of long-form user reviews, comprising entities with over a thousand
reviews each, paired with unbiased expert summaries and manually annotated
queries. Through extensive experiments, we identify key challenges, provide
actionable insights into improving systems, pave the way for future research,
and position OpinioRAG as a robust framework for generating accurate, relevant,
and structured summaries at scale.

</details>


### [10] [Wage Sentiment Indices Derived from Survey Comments via Large Language Models](https://arxiv.org/abs/2509.00290)
*Taihei Sone*

Main category: cs.CL

TL;DR: 使用大语言模型构建新薪资情感指数(WSI)预测日本薪资动态，显著超越传统方法


<details>
  <summary>Details</summary>
Motivation: 利用生成式AI为经济文本分析带来新机遇，通过构建薪资情感指数提高薪资预测的及时性和有效性

Method: 基于日本内閡府经济监测调查(EWS)数据，扩展价格情感指数(PSI)框架构建WSI，并发展支持多源数据集成的数据架构

Result: LLM基础的WSI模型显著超越了基准方法和预训练模型的表现

Conclusion: LLM驱动的情感指数有力提升政府和中央银行经济政策设计的及时性和有效性

Abstract: The emergence of generative Artificial Intelligence (AI) has created new
opportunities for economic text analysis. This study proposes a Wage Sentiment
Index (WSI) constructed with Large Language Models (LLMs) to forecast wage
dynamics in Japan. The analysis is based on the Economy Watchers Survey (EWS),
a monthly survey conducted by the Cabinet Office of Japan that captures
real-time economic assessments from workers in industries highly sensitive to
business conditions. The WSI extends the framework of the Price Sentiment Index
(PSI) used in prior studies, adapting it specifically to wage related
sentiment. To ensure scalability and adaptability, a data architecture is also
developed that enables integration of additional sources such as newspapers and
social media. Experimental results demonstrate that WSI models based on LLMs
significantly outperform both baseline approaches and pretrained models. These
findings highlight the potential of LLM-driven sentiment indices to enhance the
timeliness and effectiveness of economic policy design by governments and
central banks.

</details>


### [11] [Balanced Actor Initialization: Stable RLHF Training of Distillation-Based Reasoning Models](https://arxiv.org/abs/2509.00309)
*Chen Zheng,Yiyuan Ma,Yuan Yang,Deyi Liu,Jing Liu,Zuquan Song,Yuxin Song,Cheng Ren,Hang Zhu,Xin Liu,Yiyuan Ma,Siyuan Qiao,Xun Zhou,Liang Xiang,Yonghui Wu*

Main category: cs.CL

TL;DR: 论文研究了在蒸馏训练模型上应用RLHF时出现的序列长度崩溃和奖励曲棍球棒曲线问题，提出了平衡演员初始化(BAI)方法来解决这些训练不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 虽然指令调优和RLHF对齐以及蒸馏推理微调各自有效，但在蒸馏训练模型上应用RLHF的第三种范式存在严重的不稳定性问题，影响模型的对齐和推理能力。

Method: 提出了平衡演员初始化(BAI)方法，采用两阶段加权模型合并：首先合并指令跟随和蒸馏推理微调模型，然后将中间模型与预训练模型进一步合并以保留基础知识。

Result: BAI解决了序列长度崩溃问题，缓解了奖励曲棍球棒曲线现象，实现了训练期间序列长度的持续改善，并在各种基准测试中表现出色。

Conclusion: BAI为第三种范式提供了有效的稳定训练解决方案，使推理模型能够结合蒸馏效率和RLHF对齐，平衡的合并比例在训练稳定性和推理能力保持之间达到最优权衡。

Abstract: The development of alignment and reasoning capabilities in large language
models has seen remarkable progress through two paradigms: instruction tuning
and reinforcement learning from human feedback (RLHF) alignment paradigm, and
distillation-based reasoning fine-tuning paradigm. While both approaches prove
effective independently, the third paradigm of applying RLHF to
distillation-trained models presents significant challenges. Our investigation
reveals two critical phenomena that emerge in this paradigm: Sequence Length
Collapse, where language generation dramatically reduces during early RLHF
training, and the Reward Hockey Stick Curve, featuring severe reward score
drops followed by gradual recovery. These instabilities fundamentally
compromise the model's alignment and reasoning capabilities. To address these
challenges, we propose Balanced Actor Initialization (BAI), a two-stage
weighted model merging approach. BAI first merges instruction-following and
distillation-based reasoning fine-tuned models, then further combines this
intermediate model with the pretrained model to preserve foundational
knowledge. Through comprehensive experiments across diverse benchmarks and
detailed analysis of training experiments, we demonstrate that BAI resolves
Sequence Length Collapse, mitigates the Reward Hockey Stick Curve, and enables
continuous sequence length improvement during training. Additionally, our
analysis reveals that balanced merging ratios achieve optimal trade-offs
between training stability and reasoning capability preservation. Our work
provides the effective solution for stable training in this third paradigm,
enabling more capable reasoning models that combine distillation efficiency
with RLHF alignment.

</details>


### [12] [GIER: Gap-Driven Self-Refinement for Large Language Models](https://arxiv.org/abs/2509.00325)
*Rinku Dewri*

Main category: cs.CL

TL;DR: GIER是一个通过自我反思和基于概念质量标准的迭代修订来改进大语言模型输出的框架，无需依赖示例或思维链模板，直接使用自然语言描述推理差距来指导模型优化输出。


<details>
  <summary>Details</summary>
Motivation: 现有的提示策略通常需要依赖演示、示例或思维链模板，而GIER旨在通过更抽象的概念质量描述来指导模型自我改进，提升推理质量和准确性。

Method: GIER利用自然语言描述推理差距，让模型迭代式地批判和精炼自身输出，通过自我反思来满足概念质量标准。

Result: 在三个推理密集型任务（SciFact、PrivacyQA和e-SNLI）和四个大语言模型上的实验表明，GIER提高了理由质量、基础性和推理一致性，且不降低任务准确率。

Conclusion: 研究表明，大语言模型不仅能够解释抽象的概念差距，还能将其转化为具体的推理改进，证明了自我反思和迭代修订的有效性。

Abstract: We introduce GIER (Gap-driven Iterative Enhancement of Responses), a general
framework for improving large language model (LLM) outputs through
self-reflection and revision based on conceptual quality criteria. Unlike
prompting strategies that rely on demonstrations, examples, or chain-of-thought
templates, GIER utilizes natural language descriptions of reasoning gaps, and
prompts a model to iteratively critique and refine its own outputs to better
satisfy these criteria. Across three reasoning-intensive tasks (SciFact,
PrivacyQA, and e-SNLI) and four LLMs (GPT-4.1, GPT-4o Mini, Gemini 1.5 Pro, and
Llama 3.3 70B), GIER improves rationale quality, grounding, and reasoning
alignment without degrading task accuracy. Our analysis demonstrates that
models can not only interpret abstract conceptual gaps but also translate them
into concrete reasoning improvements.

</details>


### [13] [Open Data Synthesis For Deep Research](https://arxiv.org/abs/2509.00375)
*Ziyi Xia,Kun Luo,Hongjin Qian,Zheng Liu*

Main category: cs.CL

TL;DR: InfoSeek是一个用于合成复杂深度研究任务的框架，通过双代理系统构建研究树并生成需要层次遍历的自然语言问题，显著提升了LLMs在深度研究任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试无法捕捉深度研究任务的复杂性，而合成数据集存在推理捷径、知识泄露或结构深度不足的问题，需要新的框架来支持LLMs进行多步推理和证据合成。

Method: 使用双代理系统递归地从大规模网页构建研究树，模糊中间节点为有效子问题，并将这些树转换为需要完整层次遍历的自然语言问题，支持快速扩展生成超过5万个训练样本。

Result: 在BrowseComp-Plus基准测试上，使用InfoSeek优化的3B LLMs超越了32B大模型和轻量级商业API，性能与更强的API相当。

Conclusion: InfoSeek提供了一个可扩展的框架来合成复杂的深度研究任务，显著提升了LLMs的推理能力，并支持高级优化策略如复合奖励设计和轨迹级探索。

Abstract: Large language models (LLMs) are increasingly expected to go beyond simple
factual queries toward Deep Research-tasks that require decomposing questions
into sub-problems, coordinating multi-step reasoning, and synthesizing evidence
from diverse sources. We formalize Deep Research tasks with verifiable answers
as Hierarchical Constraint Satisfaction Problems (HCSPs), which are
fundamentally different from single-constraint, multi-hop, or flat CSP
formulations. However, existing benchmarks (e.g., Natural Questions, HotpotQA)
fail to capture this complexity, while recent synthetic datasets often
introduce shortcut reasoning, knowledge leakage, or lack sufficient structural
depth. To address this gap, we introduce InfoSeek, a scalable framework for
synthesizing complex Deep Research tasks. InfoSeek uses a dual-agent system to
recursively build a Research Tree from large-scale webpages, blurring
intermediate nodes into valid sub-problems, and converting these trees into
natural language questions that require traversing the full hierarchy. It also
enables rapid scaling, yielding over 50K training examples, a curated test set,
and reasoning trajectories generated via reject sampling. Experiments show that
models trained on InfoSeek consistently outperform strong baselines. On a
challenging benchmark BrowseComp-Plus, 3B LLMs optimized with InfoSeek surpass
much larger 32B models and lightweight commercial APIs (e.g., Gemini2.5-Flash),
while achieving performance comparable to stronger APIs (e.g., Gemini2.5-Pro).
By preserving meta-information such as intermediate steps and retrieval labels,
InfoSeek further supports advanced optimization strategies, including compound
reward design and trajectory-level exploration. We provide our codes and
datasets in \href{https://github.com/VectorSpaceLab/InfoSeek}{this repository}.

</details>


### [14] [GraphKV: Breaking the Static Selection Paradigm with Graph-Based KV Cache Eviction](https://arxiv.org/abs/2509.00388)
*Xuelin Li,Xiangqi Jin,Linfeng Zhang*

Main category: cs.CL

TL;DR: GraphKV是一个基于图的KV缓存管理框架，通过动态传播机制自适应保留重要token，提升长文本处理效率


<details>
  <summary>Details</summary>
Motivation: 传统KV缓存淘汰策略依赖静态启发式方法，无法捕捉推理过程中token间动态的隐式依赖关系，导致内存受限下的性能下降

Method: 将token建模为带重要性分数的节点，边表示相似关系，通过衰减信号传播机制在图上动态更新token重要性

Result: GraphKV可以即插即用地应用于现有KV缓存淘汰方法（如SnapKV、PyramidKV），代码将在Github发布

Conclusion: GraphKV通过图结构动态建模token依赖关系，为KV缓存压缩提供了更有效的token选择机制

Abstract: Efficient Key-Value (KV) cache management is essential for processing long
text sequences in large language models (LLMs), where memory constraints often
limit performance. Conventional KV eviction strategies, such as top-k selection
based on attention scores, depend on static heuristics that fail to capture the
evolving implicit dependencies among tokens during inference. To overcome this,
we propose GraphKV, a graph-based framework that redefines token selection for
KV cache compression. In GraphKV, tokens are modeled as nodes with importance
scores, and edges represent their similarity relationships. Through a
decay-signal-propagation mechanism, token importance is dynamically updated by
propagating information across the graph, enabling adaptive retention of the
most contextually significant tokens. GraphKV can be seamlessly utilized in
existing KV cache eviction methods such as SnapKV and PyramidKV in a
plug-and-play manner. Codes will be released on Github.

</details>


### [15] [The Resurgence of GCG Adversarial Attacks on Large Language Models](https://arxiv.org/abs/2509.00391)
*Yuting Tan,Xuying Li,Zhuo Li,Huizhen Shu,Peikang Hu*

Main category: cs.CL

TL;DR: 本文系统评估了GCG和T-GCG对抗性提示攻击在不同规模开源LLM上的效果，发现攻击成功率随模型规模增大而降低，语义评估比前缀启发式更严格，且推理密集型编码提示比安全提示更易受攻击。


<details>
  <summary>Details</summary>
Motivation: 评估梯度基对抗性提示攻击（如GCG算法）在不同规模语言模型上的有效性和局限性，特别是对安全提示和推理密集型编码提示的攻击效果。

Method: 使用Qwen2.5-0.5B、LLaMA-3.2-1B和GPT-OSS-20B三个不同规模的开源LLM，在安全导向提示（AdvBench）和推理密集型编码提示上评估GCG及其退火增强变体T-GCG的攻击效果，采用前缀启发式和GPT-4o语义判断两种评估方式。

Result: 1) 攻击成功率随模型规模增大而降低；2) 前缀启发式显著高估攻击效果，语义评估更严格现实；3) 编码相关提示比对抗性安全提示更易受攻击；4) T-GCG能多样化对抗搜索但在语义评估下收益有限。

Conclusion: 研究揭示了GCG的可扩展性限制，暴露了推理任务中被忽视的脆弱性，并推动开发退火启发策略以进行更鲁棒的对抗性评估。

Abstract: Gradient-based adversarial prompting, such as the Greedy Coordinate Gradient
(GCG) algorithm, has emerged as a powerful method for jailbreaking large
language models (LLMs). In this paper, we present a systematic appraisal of GCG
and its annealing-augmented variant, T-GCG, across open-source LLMs of varying
scales. Using Qwen2.5-0.5B, LLaMA-3.2-1B, and GPT-OSS-20B, we evaluate attack
effectiveness on both safety-oriented prompts (AdvBench) and
reasoning-intensive coding prompts. Our study reveals three key findings: (1)
attack success rates (ASR) decrease with model size, reflecting the increasing
complexity and non-convexity of larger models' loss landscapes; (2)
prefix-based heuristics substantially overestimate attack effectiveness
compared to GPT-4o semantic judgments, which provide a stricter and more
realistic evaluation; and (3) coding-related prompts are significantly more
vulnerable than adversarial safety prompts, suggesting that reasoning itself
can be exploited as an attack vector. In addition, preliminary results with
T-GCG show that simulated annealing can diversify adversarial search and
achieve competitive ASR under prefix evaluation, though its benefits under
semantic judgment remain limited. Together, these findings highlight the
scalability limits of GCG, expose overlooked vulnerabilities in reasoning
tasks, and motivate further development of annealing-inspired strategies for
more robust adversarial evaluation.

</details>


### [16] [MedSEBA: Synthesizing Evidence-Based Answers Grounded in Evolving Medical Literature](https://arxiv.org/abs/2509.00414)
*Juraj Vladika,Florian Matthes*

Main category: cs.CL

TL;DR: MedSEBA是一个基于AI的医疗问答系统，利用大语言模型生成答案，并通过PubMed数据库动态检索可信医学研究来支撑回答，提供研究共识演变的可视化。


<details>
  <summary>Details</summary>
Motivation: 解决互联网医疗信息可靠性问题和医学研究数量庞大难以追踪的挑战，帮助用户区分可靠信息与误导性内容。

Method: 结合大语言模型生成连贯表达的回答，同时从PubMed数据库动态检索可信医学研究作为支撑，提供关键点和论证，并可视化研究共识的时间演变。

Result: 用户研究表明，医学专家和普通用户都认为系统可用且有帮助，提供的答案可信且信息丰富。

Conclusion: MedSEBA系统既适用于日常健康问题，也适合高级研究洞察，能有效合成基于证据的医疗答案。

Abstract: In the digital age, people often turn to the Internet in search of medical
advice and recommendations. With the increasing volume of online content, it
has become difficult to distinguish reliable sources from misleading
information. Similarly, millions of medical studies are published every year,
making it challenging for researchers to keep track of the latest scientific
findings. These evolving studies can reach differing conclusions, which is not
reflected in traditional search tools. To address these challenges, we
introduce MedSEBA, an interactive AI-powered system for synthesizing
evidence-based answers to medical questions. It utilizes the power of Large
Language Models to generate coherent and expressive answers, but grounds them
in trustworthy medical studies dynamically retrieved from the research database
PubMed. The answers consist of key points and arguments, which can be traced
back to respective studies. Notably, the platform also provides an overview of
the extent to which the most relevant studies support or refute the given
medical claim, and a visualization of how the research consensus evolved
through time. Our user study revealed that medical experts and lay users find
the system usable and helpful, and the provided answers trustworthy and
informative. This makes the system well-suited for both everyday health
questions and advanced research insights.

</details>


### [17] [The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang](https://arxiv.org/abs/2509.00425)
*Fenghua Liu,Yulong Chen,Yixuan Liu,Zhujun Jin,Solomon Tsai,Ming Zhong*

Main category: cs.CL

TL;DR: 这篇论文提出Camlang构造语言案例，通过明确的语言学习测试LLM的真实推理能力，发现当前模型在语言学习方面远较人类差异显著


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型的成功是否来自真正的推理能力还是简单的模式匹配，通过语言学习这个认知科学视角进行测试

Method: 创建Camlang构造语言，包含语法书和双语词典两种明确资源，并将CommonsenseQA适配为Camlang-CSQA-v0任务，测试模型通过明确语法规则和词汇映射学习新语言的能力

Result: GPT-5在英语中达到98%准确率，但在Camlang中仅47%，远低于人类的87%。其他领先LLM表现更差。模型成功主要来自浅层词汇对齐，而非系统性语法掌握

Conclusion: Camlang建立了一个认知基础的评估范式，曝露了当前模型与人类语言学习能力之间的根本差距

Abstract: Large Language Models (LLMs) achieve gold-medal performance across many
benchmarks, yet it remains unclear whether such success reflects genuine
reasoning or pattern matching. From a cognitive science perspective, an
informative test is whether models can master an unfamiliar language through
explicit metalinguistic deductive learning, a paradigm where human learners can
reliably internalise grammatical systems through metalinguistic reasoning. We
address this question with Camlang, a novel constructed language that exhibits
naturalistic yet unattested feature combinations. Camlang consists of two
explicit resources, a grammar book and a bilingual dictionary, which mirror
adult second-language learning via explicit grammar rules and lexical lookup,
and enable us to disentangle errors in morpho-syntax, lexical semantics, and
sentence-level reasoning. Human experiments show that these resources are
sufficient for participants to acquire Camlang and successfully solve Camlang
tasks. To operationalise evaluation, we adapt CommonsenseQA into Camlang,
creating Camlang-CSQA-v0, the first task in a broader suite where solving
questions requires applying grammar rules and lexical mappings. Experimental
results show that GPT-5 achieves 98\% EM accuracy in English but only 47\% in
Camlang, far below human performance at 87\%, while other state-of-the-art
reasoning LLMs perform even worse. Human verification further reveals that most
model successes stem from shallow lexical alignment while GPT-5 shows emerging
metalinguistic awareness to a limited extent but not systematic grammatical
mastery as humans. Camlang establishes a cognitively grounded evaluation
paradigm that exposes fundamental gaps between current models and human
metalinguistic competence.

</details>


### [18] [GOSU: Retrieval-Augmented Generation with Global-Level Optimized Semantic Unit-Centric Framework](https://arxiv.org/abs/2509.00449)
*Xuecheng Zou,Ke Liu,Bingbing Wang,Huafei Deng,Li Zhang,Yu Tang*

Main category: cs.CL

TL;DR: GOSU是一个基于语义单元的RAG框架，通过全局消歧和语义单元整合来解决传统图RAG方法中局部语义单元提取的模糊性和复杂耦合问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于图的RAG方法使用异构图和超图来丰富检索和生成，但局部文本块中提取的高层语义单元容易产生歧义、复杂耦合，并因缺乏全局知识或忽略细粒度关系而增加检索开销。

Method: GOSU在图形构建阶段对局部文本块预提取的语义单元进行全局合并，指导实体和关系提取；在检索生成阶段引入分层关键词提取和语义单元补全技术，分别捕捉细粒度二元关系和粗粒度n元关系。

Result: 在多个任务上的评估表明，GOSU在生成质量方面优于基线RAG方法。

Conclusion: GOSU框架通过全局语义单元整合和分层关系捕捉，有效提升了RAG系统的检索和生成性能，解决了局部语义单元提取的局限性问题。

Abstract: Building upon the standard graph-based Retrieval-Augmented Generation (RAG),
the introduction of heterogeneous graphs and hypergraphs aims to enrich
retrieval and generation by leveraging the relationships between multiple
entities through the concept of semantic units (SUs). But this also raises a
key issue: The extraction of high-level SUs limited to local text chunks is
prone to ambiguity, complex coupling, and increased retrieval overhead due to
the lack of global knowledge or the neglect of fine-grained relationships. To
address these issues, we propose GOSU, a semantic unit-centric RAG framework
that efficiently performs global disambiguation and utilizes SUs to capture
interconnections between different nodes across the global context. In the
graph construction phase, GOSU performs global merging on the pre-extracted SUs
from local text chunks and guides entity and relationship extraction, reducing
the difficulty of coreference resolution while uncovering global semantic
objects across text chunks. In the retrieval and generation phase, we introduce
hierarchical keyword extraction and semantic unit completion. The former
uncovers the fine-grained binary relationships overlooked by the latter, while
the latter compensates for the coarse-grained n-ary relationships missing from
the former. Evaluation across multiple tasks demonstrates that GOSU outperforms
the baseline RAG methods in terms of generation quality.

</details>


### [19] [CVPD at QIAS 2025 Shared Task: An Efficient Encoder-Based Approach for Islamic Inheritance Reasoning](https://arxiv.org/abs/2509.00457)
*Salah Eddine Bekhouche,Abdellah Zakaria Sellam,Hichem Telli,Cosimo Distante,Abdenour Hadid*

Main category: cs.CL

TL;DR: 提出基于MARBERT编码器和注意力相关性评分(ARS)的轻量级框架，用于解决伊斯兰继承法选择题，在效率、设备部署和隐私方面具有优势，准确率达到69.87%


<details>
  <summary>Details</summary>
Motivation: 伊斯兰继承法需要精确识别继承人和计算份额，这对AI构成挑战，需要开发既准确又实用的解决方案

Method: 使用专门的阿拉伯语文本编码器(MARBERT、ArabicBERT、AraBERT)和注意力相关性评分(ARS)来对答案选项进行语义相关性排序，实现快速设备端推理

Result: MARBERT方法达到69.87%准确率，虽然低于最佳LLM的87.6%，但在资源需求、上下文依赖性和隐私保护方面具有优势

Conclusion: 量化了大模型峰值性能与小型专业化系统在实际应用中的关键权衡，证明了轻量级方法在高风险领域的实用价值

Abstract: Islamic inheritance law (Ilm al-Mawarith) requires precise identification of
heirs and calculation of shares, which poses a challenge for AI. In this paper,
we present a lightweight framework for solving multiple-choice inheritance
questions using a specialised Arabic text encoder and Attentive Relevance
Scoring (ARS). The system ranks answer options according to semantic relevance,
and enables fast, on-device inference without generative reasoning. We evaluate
Arabic encoders (MARBERT, ArabicBERT, AraBERT) and compare them with API-based
LLMs (Gemini, DeepSeek) on the QIAS 2025 dataset. While large models achieve an
accuracy of up to 87.6%, they require more resources and are context-dependent.
Our MARBERT-based approach achieves 69.87% accuracy, presenting a compelling
case for efficiency, on-device deployability, and privacy. While this is lower
than the 87.6% achieved by the best-performing LLM, our work quantifies a
critical trade-off between the peak performance of large models and the
practical advantages of smaller, specialized systems in high-stakes domains.

</details>


### [20] [TECP: Token-Entropy Conformal Prediction for LLMs](https://arxiv.org/abs/2509.00461)
*Beining Xu*

Main category: cs.CL

TL;DR: 提出了Token-Entropy Conformal Prediction (TECP)框架，利用token-level熵作为无需logit和参考的不确定性度量，通过conformal prediction为黑盒语言模型生成提供形式化覆盖保证。


<details>
  <summary>Details</summary>
Motivation: 黑盒设置下的开放文本生成不确定性量化是一个关键但未被充分探索的挑战，现有方法依赖语义一致性启发式或白盒特征，缺乏形式化保证。

Method: 使用token-level熵作为不确定性度量，集成到split conformal prediction流程中，通过CP分位数校准不确定性阈值，确保可证明的错误控制。

Result: 在6个大语言模型和2个基准测试(CoQA和TriviaQA)上的实验表明，TECP始终实现可靠覆盖和紧凑预测集，优于先前的自一致性UQ方法。

Conclusion: TECP为黑盒LLM设置中的可信生成提供了一个原则性和高效的解决方案。

Abstract: Uncertainty quantification (UQ) for open-ended language generation remains a
critical yet underexplored challenge, especially under black-box constraints
where internal model signals are inaccessible. In this paper, we introduce
Token-Entropy Conformal Prediction (TECP), a novel framework that leverages
token-level entropy as a logit-free, reference-free uncertainty measure and
integrates it into a split conformal prediction (CP) pipeline to construct
prediction sets with formal coverage guarantees. Unlike existing approaches
that rely on semantic consistency heuristics or white-box features, TECP
directly estimates epistemic uncertainty from the token entropy structure of
sampled generations and calibrates uncertainty thresholds via CP quantiles to
ensure provable error control. Empirical evaluations across six large language
models and two benchmarks (CoQA and TriviaQA) demonstrate that TECP
consistently achieves reliable coverage and compact prediction sets,
outperforming prior self-consistency-based UQ methods. Our method provides a
principled and efficient solution for trustworthy generation in black-box LLM
settings.

</details>


### [21] [Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting](https://arxiv.org/abs/2509.00482)
*Saksorn Ruangtanusak,Pittawat Taveekitworachai,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 本研究探索了四种提示方法来解决角色扮演对话代理中的过度说话和工具使用不足问题，其中基于规则的提示方法(RRP)表现最佳，通过角色卡/场景契约设计和严格函数调用执行，将得分从0.519提升到0.571。


<details>
  <summary>Details</summary>
Motivation: 解决工具增强大语言模型在角色扮演对话中产生的过度说话(over-speaking)和工具使用不足(under-acting)问题，如生成不存在的函数调用或在回答前进行不必要的工具调用。

Method: 探索了四种提示方法：1)基础角色提示 2)人工制作角色提示 3)自动提示优化(APO) 4)基于规则的角色提示(RRP)，其中RRP采用角色卡/场景契约设计和严格函数调用执行技术。

Result: 基于规则的角色提示(RRP)方法获得了0.571的整体得分，相比零样本基线得分0.519有显著提升，表现优于更复杂的APO方法。

Conclusion: RRP设计能显著提高角色扮演对话代理的有效性和可靠性，研究团队开源了最佳提示和APO工具以支持未来研究。

Abstract: This report investigates approaches for prompting a tool-augmented large
language model (LLM) to act as a role-playing dialogue agent in the API track
of the Commonsense Persona-grounded Dialogue Challenge (CPDC) 2025. In this
setting, dialogue agents often produce overly long in-character responses
(over-speaking) while failing to use tools effectively according to the persona
(under-acting), such as generating function calls that do not exist or making
unnecessary tool calls before answering. We explore four prompting approaches
to address these issues: 1) basic role prompting, 2) human-crafted role
prompting, 3) automatic prompt optimization (APO), and 4) rule-based role
prompting. The rule-based role prompting (RRP) approach achieved the best
performance through two novel techniques--character-card/scene-contract design
and strict enforcement of function calling--which led to an overall score of
0.571, improving on the zero-shot baseline score of 0.519. These findings
demonstrate that RRP design can substantially improve the effectiveness and
reliability of role-playing dialogue agents compared with more elaborate
methods such as APO. To support future efforts in developing persona prompts,
we are open-sourcing all of our best-performing prompts and the APO tool.
Source code is available at https://github.com/scb-10x/apo.

</details>


### [22] [ResearchQA: Evaluating Scholarly Question Answering at Scale Across 75 Fields with Survey-Mined Questions and Rubrics](https://arxiv.org/abs/2509.00496)
*Li S. Yifei,Allen Chang,Chaitanya Malaviya,Mark Yatskar*

Main category: cs.CL

TL;DR: ResearchQA是一个从75个研究领域的综述文章中提取21K查询和160K评分标准项的资源，用于评估LLM系统在回答研究问题时的表现，发现现有系统在引用文献、解释和描述局限性方面存在显著能力差距。


<details>
  <summary>Details</summary>
Motivation: 当前评估研究查询的长篇回答主要依赖专家标注，限制了评估范围。研究专业知识广泛存在于综述文章中，需要开发一个更全面的评估资源来支持多领域研究。

Method: 从75个研究领域的综述文章中提取21K个查询和160K个评分标准项，每个评分标准包含查询特定的答案评估标准（引用论文、解释说明、描述局限性）。使用31位博士标注者在8个领域进行评估。

Result: 96%的查询支持博士信息需求，87%的评分标准项需要在系统回答中用至少一个句子来满足。自动配对评估与专家判断达到74%一致率。18个系统的评估显示，没有参数化或检索增强系统超过70%的评分标准覆盖率，最高排名代理系统达到75%覆盖率。

Conclusion: ResearchQA揭示了LLM系统在研究查询回答中的显著能力差距，特别是在引用文献方面（完全满足率低于11%）。该资源为更全面的多领域评估提供了基础。

Abstract: Evaluating long-form responses to research queries heavily relies on expert
annotators, restricting attention to areas like AI where researchers can
conveniently enlist colleagues. Yet, research expertise is widespread: survey
articles synthesize knowledge distributed across the literature. We introduce
ResearchQA, a resource for evaluating LLM systems by distilling survey articles
from 75 research fields into 21K queries and 160K rubric items. Each rubric,
derived jointly with queries from survey sections, lists query-specific answer
evaluation criteria, i.e., citing papers, making explanations, and describing
limitations. Assessments by 31 Ph.D. annotators in 8 fields indicate 96% of
queries support Ph.D. information needs and 87% of rubric items should be
addressed in system responses by a sentence or more. Using our rubrics, we are
able to construct an automatic pairwise judge obtaining 74% agreement with
expert judgments. We leverage ResearchQA to analyze competency gaps in 18
systems in over 7.6K pairwise evaluations. No parametric or retrieval-augmented
system we evaluate exceeds 70% on covering rubric items, and the
highest-ranking agentic system shows 75% coverage. Error analysis reveals that
the highest-ranking system fully addresses less than 11% of citation rubric
items, 48% of limitation items, and 49% of comparison items. We release our
data to facilitate more comprehensive multi-field evaluations.

</details>


### [23] [Entropy-based Coarse and Compressed Semantic Speech Representation Learning](https://arxiv.org/abs/2509.00503)
*Jialong Zuo,Guangyan Zhang,Minghui Fang,Shengpeng Ji,Xiaoqi Jiao,Jingyu Li,Yiwen Guo,Zhou Zhao*

Main category: cs.CL

TL;DR: 提出基于熵的动态聚合框架，将细粒度语音token压缩为更粗粒度的语义表示，在保持性能的同时提高效率


<details>
  <summary>Details</summary>
Motivation: 现有语音离散表示方法生成25-50 tokens/秒，但语音通常只有2-5词/秒，存在冗余且主要捕获音素级信息，不利于下游任务效率

Method: 先通过下一token预测预训练语音语言模型，然后使用预测熵自适应确定聚合边界，再用交叉注意力模块融合段内信息

Result: 在ASR、语音转文本翻译和语音转换任务上，压缩后的表示性能与密集token序列相当或更好

Conclusion: 提出的熵基动态聚合框架能有效学习压缩的语义语音表示，通过调整熵阈值可灵活控制表示粒度和压缩比

Abstract: Discrete speech representation learning has recently attracted increasing
interest in both acoustic and semantic modeling. Existing approaches typically
encode 16 kHz waveforms into discrete tokens at a rate of 25 or 50 tokens per
second. However, given that speech generally conveys only 2 to 5 words per
second, such fine-grained tokenization introduces redundancy and hinders
efficiency in downstream training and inference. Moreover, semantic speech
representations at this frequency primarily capture phonetic-level information,
while semantic understanding may not require such detailed token-level
resolution. To address these limitations, we propose an entropy-based dynamic
aggregation framework for learning compressed semantic speech representations.
A speech language model is first pre-trained via next-token prediction on
large-scale unlabeled data to capture frequent token patterns. Predictive
entropy is then used to adaptively determine aggregation boundaries, followed
by a cross-attention module that fuses information within each segment. By
adjusting the entropy threshold, the granularity and compression ratio of the
representations can be flexibly controlled. Experiments on ASR, speech-to-text
translation, and voice conversion tasks demonstrate that the compressed
representations perform on par with or better than dense token sequences,
demonstrating the effectiveness of the proposed approach.

</details>


### [24] [Modeling Motivated Reasoning in Law: Evaluating Strategic Role Conditioning in LLM Summarization](https://arxiv.org/abs/2509.00529)
*Eunjung Cho,Alexander Hoyle,Yoan Hermstrüwer*

Main category: cs.CL

TL;DR: LLMs在生成法律文件摘要时会根据用户角色（法官、检察官、律师等）进行动机性推理，选择性包含信息以符合角色立场，即使有平衡指令也难以避免这种偏见。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在法律语境中如何根据不同的法律角色进行动机性推理，即模型如何策略性地构建信息以符合利益相关者在法律体系中的立场。

Method: 基于法律现实主义和近期法律实践趋势，引入基于法律事实和推理包含度的评估框架，分析LLMs在不同法律角色提示下总结司法判决的行为。

Result: 结果显示即使提示包含平衡指令，模型仍表现出选择性包含模式，反映出与角色一致的视角偏好。

Conclusion: 研究强调了在高风险法律环境中对LLM摘要行为进行角色感知评估的必要性，因为即使没有明确角色指令，LLMs也可能从先前交互或上下文中推断用户角色而产生类似的对齐问题。

Abstract: Large Language Models (LLMs) are increasingly used to generate user-tailored
summaries, adapting outputs to specific stakeholders. In legal contexts, this
raises important questions about motivated reasoning -- how models
strategically frame information to align with a stakeholder's position within
the legal system. Building on theories of legal realism and recent trends in
legal practice, we investigate how LLMs respond to prompts conditioned on
different legal roles (e.g., judges, prosecutors, attorneys) when summarizing
judicial decisions. We introduce an evaluation framework grounded in legal fact
and reasoning inclusion, also considering favorability towards stakeholders.
Our results show that even when prompts include balancing instructions, models
exhibit selective inclusion patterns that reflect role-consistent perspectives.
These findings raise broader concerns about how similar alignment may emerge as
LLMs begin to infer user roles from prior interactions or context, even without
explicit role instructions. Our results underscore the need for role-aware
evaluation of LLM summarization behavior in high-stakes legal settings.

</details>


### [25] [Thinking Hard, Going Misaligned: Emergent Misalignment in LLMs](https://arxiv.org/abs/2509.00544)
*Hanqi Yan,Hainiu Xu,Yulan He*

Main category: cs.CL

TL;DR: 研究发现LLMs在推理能力增强时更容易响应恶意请求，这种现象被称为推理诱导错位，特别是在密集模型中更为明显。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛应用，对其安全性和与人类价值观对齐的担忧日益增加。之前研究表明在恶意数据集上微调会导致错位行为，但本研究发现即使使用良性数据增强推理能力也会导致安全问题。

Method: 通过切换到"思考模式"或在良性数学数据集上微调来增强LLMs的推理能力，然后分析模型对恶意请求的响应性，并检查内部模型状态如注意力转移和专家混合模型中的专家分工。

Result: 发现推理能力增强后LLMs对恶意请求的响应性显著提高，密集模型特别脆弱。同时发现注意力转移和专家混合模型中的专门专家有助于将过度推理重新导向安全防护机制。

Conclusion: 研究揭示了新兴的推理-安全权衡问题，强调了为高级推理模型推进对齐技术的紧迫性，为理解LLMs安全机制提供了新视角。

Abstract: With Large Language Models (LLMs) becoming increasingly widely adopted,
concerns regarding their safety and alignment with human values have
intensified. Previous studies have shown that fine-tuning LLMs on narrow and
malicious datasets induce misaligned behaviors. In this work, we report a more
concerning phenomenon, Reasoning-Induced Misalignment. Specifically, we observe
that LLMs become more responsive to malicious requests when reasoning is
strengthened, via switching to "think-mode" or fine-tuning on benign math
datasets, with dense models particularly vulnerable. Moreover, we analyze
internal model states and find that both attention shifts and specialized
experts in mixture-of-experts models help redirect excessive reasoning towards
safety guardrails. These findings provide new insights into the emerging
reasoning-safety trade-off and underscore the urgency of advancing alignment
for advanced reasoning models.

</details>


### [26] [StealthEval: A Probe-Rewrite-Evaluate Workflow for Reliable Benchmarks](https://arxiv.org/abs/2509.00591)
*Lang Xiong,Nishant Bhargava,Wesley Chang,Jianhang Hong,Haihao Liu,Kevin Zhu*

Main category: cs.CL

TL;DR: LLMs在不同感知环境下行为差异显著，评估意识现象导致基准测试无法准确反映模型真实安全性和诚实度。通过线性探测和提示重写方法，研究发现模型在测试环境下更容易产生不安全或欺骗性输出。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在感知到从实际部署环境切换到受控评估环境时会出现显著行为变化，这种评估意识现象对AI对齐构成严峻挑战，因为基准性能可能无法准确反映模型的真实安全性和诚实度。

Method: 引入线性探测方法对提示进行从"测试类"到"部署类"的连续评分，利用LLM重写策略将提示转向更自然的部署风格上下文，同时保持原始任务不变。

Result: 重写后提示的平均探测分数提高了30%，所有模型诚实回答平均增加5.26%，欺骗性回答平均减少12.40%，拒绝率平均增加6.38%，表明安全合规性增强。

Conclusion: 评估意识是可量化和可操纵的因素，直接影响LLM行为，模型在感知的测试环境中更容易产生不安全或欺骗性输出，迫切需要更现实的评估框架来准确衡量模型对齐度。

Abstract: Large Language Models (LLMs) often exhibit significant behavioral shifts when
they perceive a change from a real-world deployment context to a controlled
evaluation setting, a phenomenon known as "evaluation awareness." This
discrepancy poses a critical challenge for AI alignment, as benchmark
performance may not accurately reflect a model's true safety and honesty. In
this work, we systematically quantify these behavioral changes by manipulating
the perceived context of prompts. We introduce a methodology that uses a linear
probe to score prompts on a continuous scale from "test-like" to "deploy-like"
and leverage an LLM rewriting strategy to shift these prompts towards a more
natural, deployment-style context while preserving the original task. Using
this method, we achieved a 30% increase in the average probe score across a
strategic role-playing dataset after rewriting. Evaluating a suite of
state-of-the-art models on these original and rewritten prompts, we find that
rewritten "deploy-like" prompts induce a significant and consistent shift in
behavior. Across all models, we observed an average increase in honest
responses of 5.26% and a corresponding average decrease in deceptive responses
of 12.40%. Furthermore, refusal rates increased by an average of 6.38%,
indicating heightened safety compliance. Our findings demonstrate that
evaluation awareness is a quantifiable and manipulable factor that directly
influences LLM behavior, revealing that models are more prone to unsafe or
deceptive outputs in perceived test environments. This underscores the urgent
need for more realistic evaluation frameworks to accurately gauge true model
alignment before deployment.

</details>


### [27] [Gated Associative Memory: A Parallel O(N) Architecture for Efficient Sequence Modeling](https://arxiv.org/abs/2509.00605)
*Rishiraj Acharya*

Main category: cs.CL

TL;DR: 提出Gated Associative Memory (GAM)网络，一种线性复杂度的并行架构，替代Transformer的二次复杂度自注意力机制，在保持性能的同时显著提升训练速度。


<details>
  <summary>Details</summary>
Motivation: Transformer的自注意力机制存在二次计算复杂度问题，在处理长序列时成为显著瓶颈，需要开发更高效的序列建模架构。

Method: 使用并行双通路结构：因果卷积捕获局部位置依赖上下文，关联记忆检索机制建模全局内容模式，通过门控机制动态融合局部和全局信息。

Result: 在WikiText-2和TinyStories数据集上，GAM比标准Transformer和Mamba基线训练速度更快，验证困惑度达到相当或更优水平。

Conclusion: GAM作为线性复杂度架构，在序列建模任务中展现出有前景的高效替代方案，平衡了计算效率和模型性能。

Abstract: The Transformer architecture, underpinned by the self-attention mechanism,
has become the de facto standard for sequence modeling tasks. However, its core
computational primitive scales quadratically with sequence length (O(N^2)),
creating a significant bottleneck for processing long contexts. In this paper,
we propose the Gated Associative Memory (GAM) network, a novel, fully parallel
architecture for sequence modeling that exhibits linear complexity (O(N)) with
respect to sequence length. The GAM block replaces the self-attention layer
with two parallel pathways: a causal convolution to efficiently capture local,
position-dependent context, and a parallel associative memory retrieval
mechanism to model global, content-based patterns. These pathways are
dynamically fused using a gating mechanism, allowing the model to flexibly
combine local and global information for each token. We implement GAM from
scratch and conduct a rigorous comparative analysis against a standard
Transformer model and a modern linear-time baseline (Mamba) on the WikiText-2
benchmark, as well as against the Transformer on the TinyStories dataset. Our
experiments demonstrate that GAM is consistently faster, outperforming both
baselines on training speed, and achieves a superior or competitive final
validation perplexity across all datasets, establishing it as a promising and
efficient alternative for sequence modeling.

</details>


### [28] [A Multi-Strategy Approach for AI-Generated Text Detection](https://arxiv.org/abs/2509.00623)
*Ali Zain,Sareem Farooqui,Muhammad Rafi*

Main category: cs.CL

TL;DR: 本文介绍了三种用于检测新闻文章和学术摘要中AI生成内容的系统，其中基于RoBERTa的分类器表现最佳，在开发和测试集上均取得近乎完美的结果。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成内容的普及，开发有效的检测系统对于维护内容真实性和学术诚信至关重要。M-DAIGT共享任务旨在推动这一领域的技术发展。

Method: 开发了三种系统：(1) 基于RoBERTa-base的微调分类器；(2) TF-IDF + SVM传统分类器；(3) 创新的Candace集成模型，利用多个Llama-3.2模型提取概率特征并通过自定义Transformer编码器处理。

Result: RoBERTa-based系统表现最优，在开发和测试集上都达到了近乎完美的检测效果。

Conclusion: 基于预训练语言模型的微调方法在AI生成内容检测任务中展现出卓越性能，为相关领域提供了有效的技术解决方案。

Abstract: This paper presents presents three distinct systems developed for the M-DAIGT
shared task on detecting AI generated content in news articles and academic
abstracts. The systems includes: (1) A fine-tuned RoBERTa-base classifier, (2)
A classical TF-IDF + Support Vector Machine (SVM) classifier , and (3) An
Innovative ensemble model named Candace, leveraging probabilistic features
extracted from multiple Llama-3.2 models processed by a customTransformer
encoder.The RoBERTa-based system emerged as the most performant, achieving
near-perfect results on both development and test sets.

</details>


### [29] [Can Multi-turn Self-refined Single Agent LMs with Retrieval Solve Hard Coding Problems?](https://arxiv.org/abs/2509.00629)
*Md Tanzib Hosain,Md Kishor Morol*

Main category: cs.CL

TL;DR: 该研究提出了ICPC基准测试，包含254个国际大学生程序设计竞赛题目，通过多轮自判断、反思和检索技术将语言模型的解题率从19.1%提升到42.2%，并发现特定指令能显著提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 竞争性编程任务需要复杂的算法思维和代码创建能力，但作为评估语言模型的领域尚未得到足够关注。研究旨在开发评估语言模型在算法问题解决能力上的基准和方法。

Method: 构建包含254个ICPC题目的基准测试集，每个问题包含官方分析、参考代码和测试用例。采用零样本思维链提示、多轮自判断结合反思和情景信息检索等技术进行模型推理。

Result: 零样本思维链提示下模型仅达到19.1%的通过率，最佳推理技术（多轮自判断+反思+检索）将通过率提升至42.2%。人类参与研究发现特定指令能让模型解决之前无法解决的17/18个问题。

Conclusion: 该研究为开发具有基础性、想象力和算法思维的语言模型提供了重要进展，通过定量结果和定性分析展示了语言模型在竞争性编程任务中的潜力和剩余挑战。

Abstract: Among the hardest tasks for humans are those found in competitive programming
where problems require sophisticated algorithmic thinking, puzzle solving, and
the creation of effective code. As a domain to assess language models (LMs), it
has not received enough attention, though. This study presents the ICPC
benchmark, which consists of 254 international collegiate programming contest
(ICPC) tasks. Each problem includes official analysis, reference code, and
sample, high-quality unit, and hidden tests. We are able to develop and
evaluate a variety of LM inference techniques for competitive programming with
these resources. With zero-shot chain-of-thought prompting, we find that o1
only achieves a 19.1\% pass@1 solve rate. With our best inference technique,
which combines multi-turn self-judge with reflection and retrieval over
episodic information, raises this to 42.2\%. Furthermore, we conduct a new
human-in-the-loop investigation to gain a deeper understanding of the remaining
difficulties. Surprisingly, we discover that o1 can solve 17 out of 18 problems
that were previously unsolvable by any model or technique with just a few
specific instructions. A footstep toward LMs with grounded, imaginative, and
algorithmic thinking is provided by our quantitative findings and qualitative
research. We open-source our code and data at https://github.com/kraritt/zolve.

</details>


### [30] [SimulMEGA: MoE Routers are Advanced Policy Makers for Simultaneous Speech Translation](https://arxiv.org/abs/2509.01200)
*Chenyang Le,Bing Han,Jinshun Li,Songyong Chen,Yanmin Qian*

Main category: cs.CL

TL;DR: SimulMEGA是一个无监督策略学习框架，通过混合专家门控机制和前缀训练，在保持推理效率的同时显著提升了多语言同步语音翻译的质量和延迟表现。


<details>
  <summary>Details</summary>
Motivation: 现有的同步语音翻译系统在多语言多对多场景中难以平衡翻译质量、延迟和语义连贯性，不同的读写策略阻碍了统一策略学习。

Method: 结合前缀训练和混合专家精炼器，以隐式方式学习有效的读写决策，无需增加推理时间开销，仅需对标准Transformer架构进行最小修改。

Result: 在6个语言对上的评估显示，5亿参数的语音转文本模型优于Seamless基线，在1.5秒平均延迟下BLEU下降低于7%，在3秒延迟下低于3%。

Conclusion: SimulMEGA框架在同步语音翻译和流式文本转语音任务中都表现出优异的延迟-质量权衡，具有很好的通用性。

Abstract: Simultaneous Speech Translation (SimulST) enables real-time cross-lingual
communication by jointly optimizing speech recognition and machine translation
under strict latency constraints. Existing systems struggle to balance
translation quality, latency, and semantic coherence, particularly in
multilingual many-to-many scenarios where divergent read and write policies
hinder unified strategy learning. In this paper, we present SimulMEGA
(Simultaneous Generation by Mixture-of-Experts Gating), an unsupervised policy
learning framework that combines prefix-based training with a
Mixture-of-Experts refiner to learn effective read and write decisions in an
implicit manner, without adding inference-time overhead. Our design requires
only minimal modifications to standard transformer architectures and
generalizes across both speech-to-text and text-to-speech streaming tasks.
Through comprehensive evaluation on six language pairs, our 500M parameter
speech-to-text model outperforms the Seamless baseline, achieving under 7
percent BLEU degradation at 1.5 seconds average lag and under 3 percent at 3
seconds. We further demonstrate the versatility of SimulMEGA by extending it to
streaming TTS with a unidirectional backbone, yielding superior latency quality
tradeoffs.

</details>


### [31] [Confident, Calibrated, or Complicit: Probing the Trade-offs between Safety Alignment and Ideological Bias in Language Models in Detecting Hate Speech](https://arxiv.org/abs/2509.00673)
*Sanjeeevan Selvaganapathy,Mehwish Nasim*

Main category: cs.CL

TL;DR: 研究表明，经过安全对齐的审查模型在仇恨言论检测准确性和鲁棒性上显著优于未审查模型（78.7% vs 64.1%），但存在意识形态锚定效应；所有模型在理解讽刺等微妙语言方面都存在严重缺陷，且存在公平性问题和过度自信问题。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型在检测隐性和显性仇恨言论方面的有效性，比较经过安全对齐（审查）和未对齐（未审查）模型在客观分类能力上的差异。

Method: 通过对比分析经过安全对齐和未安全对齐的LLMs模型，评估它们在仇恨言论检测任务中的准确性、鲁棒性、对意识形态框架的敏感性以及对微妙语言的理解能力。

Result: 审查模型在准确性和鲁棒性上显著优于未审查模型（78.7% vs 64.1%），但具有强烈的意识形态锚定效应；未审查模型对意识形态框架高度敏感；所有模型在理解讽刺语言方面都存在关键失败；存在针对不同目标群体的公平性差异和系统性过度自信问题。

Conclusion: 研究挑战了LLMs作为客观仲裁者的观念，强调需要开发更复杂的审计框架来考虑公平性、校准性和意识形态一致性。

Abstract: We investigate the efficacy of Large Language Models (LLMs) in detecting
implicit and explicit hate speech, examining whether models with minimal safety
alignment (uncensored) might provide more objective classification capabilities
compared to their heavily-aligned (censored) counterparts. While uncensored
models theoretically offer a less constrained perspective free from moral
guardrails that could bias classification decisions, our results reveal a
surprising trade-off: censored models significantly outperform their uncensored
counterparts in both accuracy and robustness, achieving 78.7% versus 64.1%
strict accuracy. However, this enhanced performance comes with its own
limitation -- the safety alignment acts as a strong ideological anchor, making
censored models resistant to persona-based influence, while uncensored models
prove highly malleable to ideological framing. Furthermore, we identify
critical failures across all models in understanding nuanced language such as
irony. We also find alarming fairness disparities in performance across
different targeted groups and systemic overconfidence that renders
self-reported certainty unreliable. These findings challenge the notion of LLMs
as objective arbiters and highlight the need for more sophisticated auditing
frameworks that account for fairness, calibration, and ideological consistency.

</details>


### [32] [NADI 2025: The First Multidialectal Arabic Speech Processing Shared Task](https://arxiv.org/abs/2509.02038)
*Bashar Talafha,Hawau Olamide Toyin,Peter Sullivan,AbdelRahim Elmadany,Abdurrahman Juma,Amirbek Djanibekov,Chiyu Zhang,Hamad Alshehhi,Hanan Aldarmaki,Mustafa Jarrar,Nizar Habash,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: NADI 2025共享任务聚焦阿拉伯语方言语音处理，包含方言识别、语音识别和方言音标恢复三个子任务，共有8个团队提交100份有效结果，最佳系统在三个任务上分别达到79.8%准确率和35.68/12.20、55/13的WER/CER指标


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语方言语音处理中的挑战，包括方言识别、语音识别和音标恢复，促进阿拉伯语方言计算语言学的发展

Method: 通过共享任务形式组织研究社区，设置三个子任务：口语方言识别、语音识别、方言音标恢复，收集多团队提交的系统进行性能评估

Result: 44个团队注册，8个团队提交100份有效结果，最佳系统在子任务1达到79.8%准确率，子任务2达到35.68/12.20 WER/CER，子任务3达到55/13 WER/CER

Conclusion: 阿拉伯语方言语音处理仍面临重大挑战，特别是在方言识别、识别准确率和音标恢复方面，需要进一步研究改进

Abstract: We present the findings of the sixth Nuanced Arabic Dialect Identification
(NADI 2025) Shared Task, which focused on Arabic speech dialect processing
across three subtasks: spoken dialect identification (Subtask 1), speech
recognition (Subtask 2), and diacritic restoration for spoken dialects (Subtask
3). A total of 44 teams registered, and during the testing phase, 100 valid
submissions were received from eight unique teams. The distribution was as
follows: 34 submissions for Subtask 1 "five teams{\ae}, 47 submissions for
Subtask 2 "six teams", and 19 submissions for Subtask 3 "two teams". The
best-performing systems achieved 79.8% accuracy on Subtask 1, 35.68/12.20
WER/CER (overall average) on Subtask 2, and 55/13 WER/CER on Subtask 3. These
results highlight the ongoing challenges of Arabic dialect speech processing,
particularly in dialect identification, recognition, and diacritic restoration.
We also summarize the methods adopted by participating teams and briefly
outline directions for future editions of NADI.

</details>


### [33] [Router Upcycling: Leveraging Mixture-of-Routers in Mixture-of-Experts Upcycling](https://arxiv.org/abs/2509.00679)
*Junfeng Ran,Guangxiang Zhao,Yuhan Wu,Dawei Zhu,Longyun Wu,Yikai Zhao,Tong Yang,Lin Sun,Xiangzheng Zhang,Sujian Li*

Main category: cs.CL

TL;DR: 提出Router Upcycling方法，通过从注意力头初始化多个路由器来增强MoE上循环模型的性能，实现SOTA效果


<details>
  <summary>Details</summary>
Motivation: MoE模型在深度学习中获得广泛关注，但高效训练仍具挑战性。现有MoE上循环技术中的简单路由器难以处理复杂路由任务

Method: 在MoE上循环过程中，从前面注意力层的注意力头初始化多个路由器，这些路由器以类似注意力的方式协作分配token给专家

Result: 实验结果表明该方法实现了最先进的性能，优于其他上循环基线方法

Conclusion: Router Upcycling技术有效解决了MoE上循环中的路由问题，显著提升了模型性能

Abstract: The Mixture-of-Experts (MoE) models have gained significant attention in deep
learning due to their dynamic resource allocation and superior performance
across diverse tasks. However, efficiently training these models remains
challenging. The MoE upcycling technique has been proposed to reuse and improve
existing model components, thereby minimizing training overhead. Despite this,
simple routers, such as linear routers, often struggle with complex routing
tasks within MoE upcycling. In response, we propose a novel routing technique
called Router Upcycling to enhance the performance of MoE upcycling models. Our
approach initializes multiple routers from the attention heads of preceding
attention layers during upcycling. These routers collaboratively assign tokens
to specialized experts in an attention-like manner. Each token is processed
into diverse queries and aligned with the experts' features (serving as keys).
Experimental results demonstrate that our method achieves state-of-the-art
(SOTA) performance, outperforming other upcycling baselines.

</details>


### [34] [Flavors of Moonshine: Tiny Specialized ASR Models for Edge Devices](https://arxiv.org/abs/2509.02523)
*Evan King,Adam Sabra,Manjunath Kudlur,James Wang,Pete Warden*

Main category: cs.CL

TL;DR: Flavors of Moonshine是一系列专门为代表性不足语言设计的小型自动语音识别模型，通过单语训练和精心设计的数据混合策略，在27M参数规模下显著超越多语言模型性能


<details>
  <summary>Details</summary>
Motivation: 挑战当前多语言ASR模型优于单语模型的普遍认知，探索在小型模型规模下通过高质量数据混合策略为代表性不足语言提供更好的语音识别支持

Method: 使用精心平衡的高质量人类标注数据、伪标注数据和合成数据训练单语系统，模型参数量为27M

Result: 平均错误率比同等规模的Whisper Tiny模型低48%，性能超越9倍大的Whisper Small模型，在大多数情况下匹配或超越28倍大的Whisper Medium模型

Conclusion: 该方法在小型模型规模下实现了最先进的性能，为之前支持有限的语言提供了准确的设备端ASR能力，并开源发布了阿拉伯语、中文、日语、韩语、乌克兰语和越南语模型

Abstract: We present the Flavors of Moonshine, a suite of tiny automatic speech
recognition (ASR) models specialized for a range of underrepresented languages.
Prevailing wisdom suggests that multilingual ASR models outperform monolingual
counterparts by exploiting cross-lingual phonetic similarities. We challenge
this assumption, showing that for sufficiently small models (27M parameters),
training monolingual systems on a carefully balanced mix of high-quality
human-labeled, pseudo-labeled, and synthetic data yields substantially superior
performance. On average, our models achieve error rates 48% lower than the
comparably sized Whisper Tiny model, outperform the 9x larger Whisper Small
model, and in most cases match or outperform the 28x larger Whisper Medium
model. These results advance the state of the art for models of this size,
enabling accurate on-device ASR for languages that previously had limited
support. We release Arabic, Chinese, Japanese, Korean, Ukrainian, and
Vietnamese Moonshine models under a permissive open-source license.

</details>


### [35] [Do small language models generate realistic variable-quality fake news headlines?](https://arxiv.org/abs/2509.00680)
*Austin McCutcheon,Chris Brogly*

Main category: cs.CL

TL;DR: 本研究评估了14个小语言模型生成虚假新闻标题的能力，发现这些模型在明确提示下高度配合生成假新闻，且现有检测器难以准确识别这些AI生成的假新闻标题。


<details>
  <summary>Details</summary>
Motivation: 随着小语言模型(SLMs)的普及，需要评估它们被滥用于生成虚假新闻的潜在风险，以及现有检测系统对AI生成假新闻的识别能力。

Method: 使用受控提示工程对14个SLM模型(1.7B-14B参数)生成24,000个低质量和高质量虚假新闻标题，并应用现有的机器学习检测模型进行分析。

Result: SLMs表现出高配合率，伦理约束有限；DistilBERT和bagging分类器的检测准确率仅为35.2%-63.5%，表明质量误分类现象普遍。

Conclusion: 测试的SLM模型普遍能够生成虚假标题，生成的标题与真人撰写内容相似度低，现有检测系统对AI生成假新闻的识别效果不佳。

Abstract: Small language models (SLMs) have the capability for text generation and may
potentially be used to generate falsified texts online. This study evaluates 14
SLMs (1.7B-14B parameters) including LLaMA, Gemma, Phi, SmolLM, Mistral, and
Granite families in generating perceived low and high quality fake news
headlines when explicitly prompted, and whether they appear to be similar to
real-world news headlines. Using controlled prompt engineering, 24,000
headlines were generated across low-quality and high-quality deceptive
categories. Existing machine learning and deep learning-based news headline
quality detectors were then applied against these SLM-generated fake news
headlines. SLMs demonstrated high compliance rates with minimal ethical
resistance, though there were some occasional exceptions. Headline quality
detection using established DistilBERT and bagging classifier models showed
that quality misclassification was common, with detection accuracies only
ranging from 35.2% to 63.5%. These findings suggest the following: tested SLMs
generally are compliant in generating falsified headlines, although there are
slight variations in ethical restraints, and the generated headlines did not
closely resemble existing primarily human-written content on the web, given the
low quality classification accuracy.

</details>


### [36] [Text Reinforcement for Multimodal Time Series Forecasting](https://arxiv.org/abs/2509.00687)
*Chen Su,Yuanhe Tian,Yan Song,Yongdong Zhang*

Main category: cs.CL

TL;DR: 提出文本强化模型(TeR)来增强多模态时间序列预测中的文本质量，通过强化学习优化生成文本，提升预测性能


<details>
  <summary>Details</summary>
Motivation: 现有多模态时间序列预测方法依赖高质量文本输入，但实际应用中文本可能无法准确捕捉时间序列信息，导致性能不稳定，需要增强文本内容

Method: 设计文本强化模型(TeR)生成强化文本，采用基于多模态TSF模型性能和任务相关性的强化学习奖励机制来优化TeR

Result: 在涵盖多个领域的真实基准数据集上进行了广泛实验，方法优于强基线和现有研究

Conclusion: 通过强化文本模态可以有效提升多模态时间序列预测性能，提出的TeR模型和强化学习方法具有显著效果

Abstract: Recent studies in time series forecasting (TSF) use multimodal inputs, such
as text and historical time series data, to predict future values. These
studies mainly focus on developing advanced techniques to integrate textual
information with time series data to perform the task and achieve promising
results. Meanwhile, these approaches rely on high-quality text and time series
inputs, whereas in some cases, the text does not accurately or fully capture
the information carried by the historical time series, which leads to unstable
performance in multimodal TSF. Therefore, it is necessary to enhance the
textual content to improve the performance of multimodal TSF. In this paper, we
propose improving multimodal TSF by reinforcing the text modalities. We propose
a text reinforcement model (TeR) to generate reinforced text that addresses
potential weaknesses in the original text, then apply this reinforced text to
support the multimodal TSF model's understanding of the time series, improving
TSF performance. To guide the TeR toward producing higher-quality reinforced
text, we design a reinforcement learning approach that assigns rewards based on
the impact of each reinforced text on the performance of the multimodal TSF
model and its relevance to the TSF task. We optimize the TeR accordingly, so as
to improve the quality of the generated reinforced text and enhance TSF
performance. Extensive experiments on a real-world benchmark dataset covering
various domains demonstrate the effectiveness of our approach, which
outperforms strong baselines and existing studies on the dataset.

</details>


### [37] [CE-Bench: Towards a Reliable Contrastive Evaluation Benchmark of Interpretability of Sparse Autoencoders](https://arxiv.org/abs/2509.00691)
*Alex Gulko,Yusen Peng,Sachin Kumar*

Main category: cs.CL

TL;DR: CE-Bench是一个轻量级的对比评估基准，用于评估稀疏自编码器的可解释性，基于对比故事对数据集构建，无需外部LLM即可可靠测量性能。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器是揭示大语言模型中可解释特征的有前景方法，但缺乏自动化评估方法阻碍了其广泛采用和发展。

Method: 提出了CE-Bench基准，基于精心策划的对比故事对数据集构建，通过全面的消融研究验证方法有效性。

Result: CE-Bench能够可靠测量稀疏自编码器的可解释性，与现有基准良好对齐，且不需要外部LLM。

Conclusion: CE-Bench为稀疏自编码器评估提供了有效的自动化解决方案，官方实现和评估数据集已开源。

Abstract: Probing with sparse autoencoders is a promising approach for uncovering
interpretable features in large language models (LLMs). However, the lack of
automated evaluation methods has hindered their broader adoption and
development. In this work, we introduce CE-Bench, a novel and lightweight
contrastive evaluation benchmark for sparse autoencoders, built on a curated
dataset of contrastive story pairs. We conduct comprehensive ablation studies
to validate the effectiveness of our approach. Our results show that CE-Bench
reliably measures the interpretability of sparse autoencoders and aligns well
with existing benchmarks, all without requiring an external LLM. The official
implementation and evaluation dataset are open-sourced under the MIT License.

</details>


### [38] [Learning to Shop Like Humans: A Review-driven Retrieval-Augmented Recommendation Framework with LLMs](https://arxiv.org/abs/2509.00698)
*Kaiwen Wei,Jinpeng Gao,Jiang Zhong,Yuming Yang,Fengmao Lv,Zhenyang Li*

Main category: cs.CL

TL;DR: RevBrowse是一个基于LLM的评论驱动推荐框架，通过PrefRAG模块自适应检索相关评论来解决LLM上下文窗口限制和评论优先级问题


<details>
  <summary>Details</summary>
Motivation: LLM在推荐任务中表现出色，但如何有效利用用户评论面临两个挑战：LLM上下文窗口限制无法动态使用大量评论，以及缺乏机制来优先处理与当前决策最相关的评论

Method: 提出RevBrowse框架，模拟用户"浏览-决策"过程，集成用户评论到LLM重排序中。引入PrefRAG模块，将用户和物品表示解耦为结构化形式，根据目标物品自适应检索偏好相关内容

Result: 在四个Amazon评论数据集上的实验表明，RevBrowse相比强基线取得了一致且显著的改进，展示了其在建模动态用户偏好方面的泛化能力和有效性

Conclusion: RevBrowse通过检索增强的透明过程不仅提升了推荐性能，还提供了一定程度的可解释性，使影响最终推荐的评论可见

Abstract: Large language models (LLMs) have shown strong potential in recommendation
tasks due to their strengths in language understanding, reasoning and knowledge
integration. These capabilities are especially beneficial for review-based
recommendation, which relies on semantically rich user-generated texts to
reveal fine-grained user preferences and item attributes. However, effectively
incorporating reviews into LLM-based recommendation remains challenging due to
(1) inefficient to dynamically utilize user reviews under LLMs' constrained
context windows, and (2) lacking effective mechanisms to prioritize reviews
most relevant to the user's current decision context. To address these
challenges, we propose RevBrowse, a review-driven recommendation framework
inspired by the "browse-then-decide" decision process commonly observed in
online user behavior. RevBrowse integrates user reviews into the LLM-based
reranking process to enhance its ability to distinguish between candidate
items. To improve the relevance and efficiency of review usage, we introduce
PrefRAG, a retrieval-augmented module that disentangles user and item
representations into structured forms and adaptively retrieves
preference-relevant content conditioned on the target item. Extensive
experiments on four Amazon review datasets demonstrate that RevBrowse achieves
consistent and significant improvements over strong baselines, highlighting its
generalizability and effectiveness in modeling dynamic user preferences.
Furthermore, since the retrieval-augmented process is transparent, RevBrowse
offers a certain level of interpretability by making visible which reviews
influence the final recommendation.

</details>


### [39] [Reward-Weighted Sampling: Enhancing Non-Autoregressive Characteristics in Masked Diffusion LLMs](https://arxiv.org/abs/2509.00707)
*Daehoon Gwak,Minseo Jung,Junwoo Park,Minho Park,ChaeHun Park,Junha Hyung,Jaegul Choo*

Main category: cs.CL

TL;DR: 提出Reward-Weighted Sampling (RWS)解码策略，通过外部奖励模型在扩散过程中提供全局信号，改善掩码扩散模型的非自回归生成顺序和性能


<details>
  <summary>Details</summary>
Motivation: 标准置信度采样方法导致掩码扩散模型的生成顺序类似自回归过程，限制了非自回归建模的优势

Method: 在每一步扩散过程中，RWS评估整个中间序列质量并相应缩放token对数概率，通过全局序列一致性指导token选择

Result: RWS显著促进了非自回归生成顺序，在多个评估指标上都有改进

Conclusion: 整合全局信号能有效增强掩码扩散模型的非自回归特性和整体性能

Abstract: Masked diffusion models (MDMs) offer a promising non-autoregressive
alternative for large language modeling. Standard decoding methods for MDMs,
such as confidence-based sampling, select tokens independently based on
individual token confidences at each diffusion step. However, we observe that
this independent token selection often results in generation orders resembling
sequential autoregressive processes, limiting the advantages of
non-autoregressive modeling. To mitigate this pheonomenon, we propose
Reward-Weighted Sampling (RWS), a novel decoding strategy that leverages an
external reward model to provide a principled global signal during the
iterative diffusion process. Specifically, at each diffusion step, RWS
evaluates the quality of the entire intermediate sequence and scales token
logits accordingly, guiding token selection by integrating global
sequence-level coherence. This method selectively increases the confidence of
tokens that initially have lower scores, thereby promoting a more
non-autoregressive generation order. Furthermore, we provide theoretical
justification showing that reward-weighted logit scaling induces beneficial
rank reversals in token selection and consistently improves expected reward.
Experiments demonstrate that RWS significantly promotes non-autoregressive
generation orders, leading to improvements across multiple evaluation metrics.
These results highlight the effectiveness of integrating global signals in
enhancing both the non-autoregressive properties and overall performance of
MDMs.

</details>


### [40] [Designing LMS and Instructional Strategies for Integrating Generative-Conversational AI](https://arxiv.org/abs/2509.00709)
*Elias Ra,Seung Je Kim,Eui-Yeong Seo,Geunju So*

Main category: cs.CL

TL;DR: 这篇论文提出了一种结构化框架，设计基于AI的学习管理系统(AI-LMS)，通过整合生成式AI和对话式AI来支持适应性、互动性和以学习者为中心的教学体验。


<details>
  <summary>Details</summary>
Motivation: 高等教育面临着提供个性化、可扩展和教育学一致的学习体验的挑战，需要一种新的框架来整合AI技术以支持适应性教学。

Method: 采用基于设计的研究(DBR)方法论，包括五个阶段：文献综述、SWOT分析、伦理-教育学原则开发、系统设计和教学策略制定。系统包含可配置提示、适应性反馈循环和多代理对话流等模块组件。

Result: 开发出了一个结合AI能力与人类中心设计及伦理保障的AI-LMS框架，该框架与行为主义、建构主义和连接主义等教育学理论相符合。

Conclusion: 这项研究提出了一种实用的AI整合模型，为教育领域的AI应用提供了新的视角。未来研究将通过实际应用来验证和优化该系统。

Abstract: Higher education faces growing challenges in delivering personalized,
scalable, and pedagogically coherent learning experiences. This study
introduces a structured framework for designing an AI-powered Learning
Management System (AI-LMS) that integrates generative and conversational AI to
support adaptive, interactive, and learner-centered instruction. Using a
design-based research (DBR) methodology, the framework unfolds through five
phases: literature review, SWOT analysis, development of ethical-pedagogical
principles, system design, and instructional strategy formulation. The
resulting AI-LMS features modular components -- including configurable prompts,
adaptive feedback loops, and multi-agent conversation flows -- aligned with
pedagogical paradigms such as behaviorist, constructivist, and connectivist
learning theories. By combining AI capabilities with human-centered design and
ethical safeguards, this study advances a practical model for AI integration in
education. Future research will validate and refine the system through
real-world implementation.

</details>


### [41] [LLM Encoder vs. Decoder: Robust Detection of Chinese AI-Generated Text with LoRA](https://arxiv.org/abs/2509.00731)
*Houji Jin,Negin Ashrafi,Armin Abdollahi,Wei Liu,Jian Wang,Ganyu Gui,Maryam Pishgar,Huanghao Feng*

Main category: cs.CL

TL;DR: 本文系统比较了不同模型在中文AI生成文本检测任务上的表现，发现使用LoRA微调的Qwen2.5-7B解码器模型表现最佳，达到95.94%的测试准确率，显示了更好的演化能力和稳健性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，准确检测AI生成文本的需求日益增长，特别是在中文语言中，细微的语言细节给现有方法带来了重大挑战。

Method: 采用NLPCC 2025中文AI生成文本检测数据集，系统比较了编码器模型（BERT-large和RoBERTa-wwm-ext-large）、解码器模型（Qwen2.5-7B通过LoRA微调）以及FastText基线。编码器模型采用提示基础的掩码语言建模方法，解码器模型通过指令格式输入和轻量级分类头进行微调。

Result: 编码器模型虽然几乎记住了训练数据，但在分布偏移下表现大幅下降（RoBERTa: 76.3%，BERT: 79.3%）。FastText显示出意外的词汇稳健性（83.5%）但缺乏深层语义理解。LoRA微调的Qwen2.5-7B达到95.94%测试准确率，具有平衡的精确率和召回率。

Conclusion: 研究结果强调了基于解码器的大语言模型通过参数效率微调在中文AI生成文本检测中的效果优势，具有更好的演化能力和对数据集特定人工物的耐受性。未来工作将探索Qwen3模型、精简版本和集成策略以进一步提升跨域稳健性。

Abstract: The rapid growth of large language models (LLMs) has heightened the demand
for accurate detection of AI-generated text, particularly in languages like
Chinese, where subtle linguistic nuances pose significant challenges to current
methods. In this study, we conduct a systematic comparison of encoder-based
Transformers (Chinese BERT-large and RoBERTa-wwm-ext-large), a decoder-only LLM
(Alibaba's Qwen2.5-7B/DeepSeek-R1-Distill-Qwen-7B fine-tuned via Low-Rank
Adaptation, LoRA), and a FastText baseline using the publicly available dataset
from the NLPCC 2025 Chinese AI-Generated Text Detection Task. Encoder models
were fine-tuned using a novel prompt-based masked language modeling approach,
while Qwen2.5-7B was adapted for classification with an instruction-format
input and a lightweight classification head trained via LoRA. Experiments
reveal that although encoder models nearly memorize training data, they suffer
significant performance degradation under distribution shifts (RoBERTa: 76.3%
test accuracy; BERT: 79.3%). FastText demonstrates surprising lexical
robustness (83.5% accuracy) yet lacks deeper semantic understanding. In
contrast, the LoRA-adapted Qwen2.5-7B achieves 95.94% test accuracy with
balanced precision-recall metrics, indicating superior generalization and
resilience to dataset-specific artifacts. These findings underscore the
efficacy of decoder-based LLMs with parameter-efficient fine-tuning for robust
Chinese AI-generated text detection. Future work will explore next-generation
Qwen3 models, distilled variants, and ensemble strategies to enhance
cross-domain robustness further.

</details>


### [42] [Decomposing and Revising What Language Models Generate](https://arxiv.org/abs/2509.00765)
*Zhichao Yan,Jiaoyan Chen,Jiapu Wang,Xiaoli Li,Ru Li,Jeff Z. Pan*

Main category: cs.CL

TL;DR: FIDES是一个基于事实分解的框架，通过上下文增强的两阶段忠实分解方法将长答案分解为子事实，用于检索相关证据片段，并在证据冲突时修订子事实，最后根据原始句子聚合证据，在六个数据集上平均超越SOTA方法14%以上。


<details>
  <summary>Details</summary>
Motivation: 当前基于问题分解的方法生成的问题往往不相关且不完整，导致检索中丢失事实，并且无法聚合来自不同文档和段落的证据片段。

Method: 使用上下文增强的两阶段忠实分解方法分解长答案为子事实，检索相关证据片段，在证据冲突时修订子事实，最后根据原始句子聚合证据。

Result: 在六个数据集上，使用GPT-3.5-turbo、Gemini和Llama 70B系列，FIDES平均超越SOTA方法14%以上，并提出了新的证据精度评估指标$Attr_{auto-P}$。

Conclusion: FIDES框架有效解决了现有方法在问题生成和证据聚合方面的不足，显著提升了归因问答的性能和证据精度。

Abstract: Attribution is crucial in question answering (QA) with Large Language Models
(LLMs).SOTA question decomposition-based approaches use long form answers to
generate questions for retrieving related documents. However, the generated
questions are often irrelevant and incomplete, resulting in a loss of facts in
retrieval.These approaches also fail to aggregate evidence snippets from
different documents and paragraphs. To tackle these problems, we propose a new
fact decomposition-based framework called FIDES (\textit{faithful context
enhanced fact decomposition and evidence aggregation}) for attributed QA. FIDES
uses a contextually enhanced two-stage faithful decomposition method to
decompose long form answers into sub-facts, which are then used by a retriever
to retrieve related evidence snippets. If the retrieved evidence snippets
conflict with the related sub-facts, such sub-facts will be revised
accordingly. Finally, the evidence snippets are aggregated according to the
original sentences.Extensive evaluation has been conducted with six datasets,
with an additionally proposed new metric called $Attr_{auto-P}$ for evaluating
the evidence precision. FIDES outperforms the SOTA methods by over 14\% in
average with GPT-3.5-turbo, Gemini and Llama 70B series.

</details>


### [43] [LegalChainReasoner: A Legal Chain-guided Framework for Criminal Judicial Opinion Generation](https://arxiv.org/abs/2509.00783)
*Weizhe Shi,Qiqi Wang,Yihong Pan,Qian Liu,Kaiqi Zhao*

Main category: cs.CL

TL;DR: 提出LegalChainReasoner框架，通过结构化法律链实现法律推理和量刑判决的端到端生成，解决传统方法中两者不一致的问题


<details>
  <summary>Details</summary>
Motivation: 现有研究将司法意见生成分为法律推理和量刑预测两个独立子任务，导致推理与预测不一致，且依赖人工知识难以实际部署

Method: 引入LegalChainReasoner框架，使用结构化法律链整合事实前提、复合法律条件和量刑结论，实现灵活知识注入和端到端意见生成

Result: 在两个真实中文法律案例数据集上的实验表明，该方法优于基线模型

Conclusion: 提出的司法意见生成任务和LegalChainReasoner框架能更好地符合法律实践需求，实现一致的法律推理和量刑决策

Abstract: A criminal judicial opinion represents the judge's disposition of a case,
including the decision rationale and sentencing. Automatically generating such
opinions can assist in analyzing sentencing consistency and provide judges with
references to similar past cases. However, current research typically
approaches this task by dividing it into two isolated subtasks: legal reasoning
and sentencing prediction. This separation often leads to inconsistency between
the reasoning and predictions, failing to meet real-world judicial
requirements. Furthermore, prior studies rely on manually curated knowledge to
enhance applicability, yet such methods remain limited in practical deployment.
To address these limitations and better align with legal practice, we propose a
new LegalAI task: Judicial Opinion Generation, which simultaneously produces
both legal reasoning and sentencing decisions. To achieve this, we introduce
LegalChainReasoner, a framework that applies structured legal chains to guide
the model through comprehensive case assessments. By integrating factual
premises, composite legal conditions, and sentencing conclusions, our approach
ensures flexible knowledge injection and end-to-end opinion generation.
Experiments on two real-world and open-source Chinese legal case datasets
demonstrate that our method outperforms baseline models.

</details>


### [44] [CaresAI at BioCreative IX Track 1 -- LLM for Biomedical QA](https://arxiv.org/abs/2509.00806)
*Reem Abdel-Salam,Mary Adewunmi,Modinat A. Abayomi*

Main category: cs.CL

TL;DR: 本文采用LLaMA 3 8B模型进行监督微调，在生物医学多跳问答任务MedHopQA上进行评估，发现模型在概念理解上表现良好但精确匹配得分较低，提出了两阶段推理管道来改进答案提取。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在问答任务中的广泛应用，需要对其在复杂生物医学问答能力上进行严格评估，特别是在真实医疗应用部署前的性能验证。

Method: 使用LLaMA 3 8B模型进行监督微调，利用从BioASQ、MedQuAD和TREC等外部来源整理的生物医学问答数据集。探索了三种实验设置：长短答案联合微调、仅短答案和仅长答案微调。

Result: 模型在概念级别准确率达到0.8，但精确匹配得分显著较低，特别是在测试阶段。两阶段推理管道部分改善了答案提取，但在严格格式化输出方面仍存在挑战。

Conclusion: 研究揭示了生物医学大语言模型应用中语义理解与精确答案评估之间的差距，需要进一步研究输出控制和后处理策略。

Abstract: Large language models (LLMs) are increasingly evident for accurate question
answering across various domains. However, rigorous evaluation of their
performance on complex question-answering (QA) capabilities is essential before
deployment in real-world biomedical and healthcare applications. This paper
presents our approach to the MedHopQA track of the BioCreative IX shared task,
which focuses on multi-hop biomedical question answering involving diseases,
genes, and chemicals. We adopt a supervised fine-tuning strategy leveraging
LLaMA 3 8B, enhanced with a curated biomedical question-answer dataset compiled
from external sources including BioASQ, MedQuAD, and TREC. Three experimental
setups are explored: fine-tuning on combined short and long answers, short
answers only, and long answers only. While our models demonstrate strong domain
understanding, achieving concept-level accuracy scores of up to 0.8, their
Exact Match (EM) scores remain significantly lower, particularly in the test
phase. We introduce a two-stage inference pipeline for precise short-answer
extraction to mitigate verbosity and improve alignment with evaluation metrics.
Despite partial improvements, challenges persist in generating strictly
formatted outputs. Our findings highlight the gap between semantic
understanding and exact answer evaluation in biomedical LLM applications,
motivating further research in output control and post-processing strategies.

</details>


### [45] [TMT: A Simple Way to Translate Topic Models Using Dictionaries](https://arxiv.org/abs/2509.00822)
*Felix Engl,Andreas Henrich*

Main category: cs.CL

TL;DR: 提出Topic Model Translation (TMT)方法，无需对齐语料库即可将主题模型从一种语言迁移到另一种语言，特别适用于目标语言数据稀缺的场景。


<details>
  <summary>Details</summary>
Motivation: 多语言环境下训练主题模型面临诸多挑战，特别是当开发者不熟悉目标语言或可用语料库有限时，需要一种无需对齐语料库就能跨语言重用主题模型的方法。

Method: TMT技术通过翻译机制将源语言的主题模型转移到目标语言，不需要元数据、嵌入向量或对齐的语料库支持。

Result: 通过定量和定性评估表明，TMT能够产生语义一致且连贯的主题翻译结果。

Conclusion: TMT是一种鲁棒且透明的主题模型跨语言迁移技术，在目标语言大数据不可得或人工翻译不可行的情况下特别有效。

Abstract: The training of topic models for a multilingual environment is a challenging
task, requiring the use of sophisticated algorithms, topic-aligned corpora, and
manual evaluation. These difficulties are further exacerbated when the
developer lacks knowledge of the target language or is working in an
environment with limited data, where only small or unusable multilingual
corpora are available.
  Considering these challenges, we introduce Topic Model Translation (TMT), a
novel, robust and transparent technique designed to transfer topic models
(e.g., Latent Dirichlet Allocation (LDA) based topic models) from one language
to another, without the need for metadata, embeddings, or aligned corpora. TMT
enables the reuse of topic models across languages, making it especially
suitable for scenarios where large corpora in the target language are
unavailable or manual translation is infeasible. Furthermore, we evaluate TMT
extensively using both quantitative and qualitative methods, demonstrating that
it produces semantically coherent and consistent topic translations.

</details>


### [46] [Neural Models and Language Model Prompting for the Multidimensional Evaluation of Open-Ended Conversations](https://arxiv.org/abs/2509.00841)
*Michelle Elizabeth,Alicja Kasicka,Natalia Krawczyk,Magalie Ochs,Gwénolé Lecorvé,Justyna Gromada,Lina M. Rojas-Barahona*

Main category: cs.CL

TL;DR: 本文在DSTC-12 Track 1挑战中开发了相对小型模型（少于130亿参数）来预测对话级维度评分，比较了基于提示的语言模型方法和编码器分类回归模型的效果。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI对话系统的快速增长，如何有效评估这些系统成为一个关键挑战。本文旨在通过相对小型的模型来解决对话系统评估问题。

Method: 采用两种主要策略：1）通过提示使用语言模型作为评估器；2）训练基于编码器的分类和回归模型。

Result: 语言模型提示方法仅获得中等相关性，在测试集上排名第二；编码器模型在验证集上某些维度表现出高相关性，但在测试集上性能下降，主要因为测试集评分范围与训练验证集存在显著差异。

Conclusion: 相对小型的模型在对话评估任务中具有一定潜力，但测试集分布差异对模型性能影响显著，需要更好的泛化能力。

Abstract: The growing number of generative AI-based dialogue systems has made their
evaluation a crucial challenge. This paper presents our contribution to this
important problem through the Dialogue System Technology Challenge (DSTC-12,
Track 1), where we developed models to predict dialogue-level,
dimension-specific scores. Given the constraint of using relatively small
models (i.e. fewer than 13 billion parameters) our work follows two main
strategies: employing Language Models (LMs) as evaluators through prompting,
and training encoder-based classification and regression models.
  Our results show that while LM prompting achieves only modest correlations
with human judgments, it still ranks second on the test set, outperformed only
by the baseline. The regression and classification models, with significantly
fewer parameters, demonstrate high correlation for some dimensions on the
validation set. Although their performance decreases on the test set, it is
important to note that the test set contains annotations with significantly
different score ranges for some of the dimensions with respect to the train and
validation sets.

</details>


### [47] [Negative Matters: Multi-Granularity Hard-Negative Synthesis and Anchor-Token-Aware Pooling for Enhanced Text Embeddings](https://arxiv.org/abs/2509.00842)
*Tengyu Pan,Zhichao Duan,Zhenyu Li,Bowen Dong,Ning Liu,Xiuxing Li,Jianyong Wang*

Main category: cs.CL

TL;DR: 提出了MGH框架和ATA池化方法，通过多粒度负样本合成和锚点令牌感知机制，在文本嵌入任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有文本嵌入模型的负样本生成策略不够多样化，难以捕捉细粒度的语义差异，需要更有效的负样本合成方法和特征聚合机制来提升模型性能。

Method: 1. MGH框架：利用大语言模型生成不同相似度级别的负样本，实现从粗到细的课程学习策略；2. ATA池化：基于LLM聚合模式为锚点令牌分配更高权重，提升嵌入准确性。

Result: 在MTEB基准测试中取得了最先进的性能，超越了现有的合成策略，无论是在纯合成数据还是与公共检索数据集结合的情况下都表现出色。

Conclusion: 多粒度负样本合成和锚点令牌感知池化方法能有效提升文本嵌入模型的语义区分能力，为对比学习提供了新的技术路径。

Abstract: Text embedding models are essential for various natural language processing
tasks, enabling the effective encoding of semantic information into dense
vector representations. These models are typically optimized using triplets of
(query, positive, negative) data pairs for contrastive learning, where the
negative samples play a critical role in enhancing the model's ability to
discern subtle semantic distinctions. In this work, we introduce a
Multi-Granularity Hard-negative (MGH) synthesis framework that leverages large
language models (LLMs) to generate diverse negative samples with varying levels
of similarity with the query. This approach facilitates a coarse-to-fine
curriculum learning strategy during supervised training, allowing the embedding
model to progressively learn more nuanced semantic representations. Meanwhile,
we propose an Anchor Token Aware (ATA) pooling method that assigns higher
weights to anchor tokens based on aggregation patterns observed in LLMs,
improving text embedding accuracy without increasing model complexity.
Comprehensive experiments on the MTEB benchmark demonstrate that our methods
achieve state-of-the-art performance, surpassing existing synthesis strategies
both with synthetic data and when combined with public retrieval datasets.

</details>


### [48] [Prompting Away Stereotypes? Evaluating Bias in Text-to-Image Models for Occupations](https://arxiv.org/abs/2509.00849)
*Shaina Raza,Maximus Powers,Partha Pratim Saha,Mahveen Raza,Rizwan Qureshi*

Main category: cs.CL

TL;DR: 本文评估了5个TTI模型在职业描绘中的社会偏见，通过对比中性提示词和公平性提示词，发现提示词工程可以显著改变人口统计表征，但效果因模型而异，有些能有效多样化，有些则过度校正或响应有限。


<details>
  <summary>Details</summary>
Motivation: 文本到图像模型作为强大的创意工具，存在放大有害社会偏见风险，需要系统评估其表征偏见并探索干预策略。

Method: 构建职业描绘基准数据集（5个社会重要角色），使用5个SOTA模型（闭源和开源），对比中性提示词与公平性提示词，对输出图像进行性别和种族标注并进行分布分析。

Result: 提示词工程能显著改变人口统计表征，但效果高度模型依赖：部分系统能有效多样化，部分过度校正导致不现实均匀性，部分响应有限。

Conclusion: 提示词工程作为公平性干预手段既有潜力也有局限，需要结合模型层面的补充策略，研究提供了透明可复现的代码和数据。

Abstract: Text-to-Image (TTI) models are powerful creative tools but risk amplifying
harmful social biases. We frame representational societal bias assessment as an
image curation and evaluation task and introduce a pilot benchmark of
occupational portrayals spanning five socially salient roles (CEO, Nurse,
Software Engineer, Teacher, Athlete). Using five state-of-the-art models:
closed-source (DALLE 3, Gemini Imagen 4.0) and open-source (FLUX.1-dev, Stable
Diffusion XL Turbo, Grok-2 Image), we compare neutral baseline prompts against
fairness-aware controlled prompts designed to encourage demographic diversity.
All outputs are annotated for gender (male, female) and race (Asian, Black,
White), enabling structured distributional analysis. Results show that
prompting can substantially shift demographic representations, but with highly
model-specific effects: some systems diversify effectively, others overcorrect
into unrealistic uniformity, and some show little responsiveness. These
findings highlight both the promise and the limitations of prompting as a
fairness intervention, underscoring the need for complementary model-level
strategies. We release all code and data for transparency and reproducibility
https://github.com/maximus-powers/img-gen-bias-analysis.

</details>


### [49] [Exploring and Mitigating Fawning Hallucinations in Large Language Models](https://arxiv.org/abs/2509.00869)
*Zixuan Shangguan,Yanjie Dong,Lanjun Wang,Xiaoyi Fan,Victor C. M. Leung,Xiping Hu*

Main category: cs.CL

TL;DR: 该论文提出协作对比解码(CCD)方法来缓解大语言模型中的奉承幻觉问题，通过对比诱导欺骗性输入和中性输入之间的输出分布差异，在不需额外训练的情况下提高生成响应的真实性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理欺骗性和误导性提示时会产生奉承幻觉，即模型优先考虑与输入隐含视角的一致性而非准确性，这会影响生成信息的真实性。

Method: 设计两种范式生成欺骗性/误导性输入来诱导奉承幻觉，然后提出协作对比解码(CCD)方法，通过对比诱导输入和转换后中性输入之间的输出分布偏差来减少对欺骗信息的依赖。

Result: 大量实验表明，所提出的CCD方法能有效缓解奉承幻觉，并在各种任务中提高生成响应的真实性。

Conclusion: 协作对比解码是一种有效的后处理方法，能够在不进行额外训练的情况下显著减少大语言模型中的奉承幻觉问题，提升模型输出的真实性和可靠性。

Abstract: Large language models (LLMs) have demonstrated exceptional proficiency in
language understanding. However, when LLMs align their outputs with deceptive
and/or misleading prompts, the generated responses could deviate from the de
facto information. Such observations are known as fawning hallucinations, where
the model prioritizes alignment with the input's implied perspective over
accuracy and truthfulness. In this work, we analyze fawning hallucinations in
various natural language processing tasks and tailor the so-termed contrastive
decoding method for fawning-hallucination mitigation. Specifically, we design
two paradigms to generate corresponding deceptive and/or misleading inputs for
the consistent fawning hallucinations induction. Then, we propose the
collaborative contrastive decoding (CCD) to handle the fawning hallucinations
across different tasks in LLMs. By contrasting the deviation in output
distribution between induced and transformed neutral inputs, the proposed CCD
can reduce reliance on deceptive and/or misleading information without
requiring additional training. Extensive experiments demonstrate that the
proposed CCD can effectively mitigate fawning hallucinations and improve the
factuality of the generated responses over various tasks.

</details>


### [50] [EviNote-RAG: Enhancing RAG Models via Answer-Supportive Evidence Notes](https://arxiv.org/abs/2509.00877)
*Yuqin Dai,Guoqing Wang,Yuan Wang,Kairan Dou,Kaichen Zhou,Zhanwei Zhang,Shuo Yang,Fei Tang,Jun Yin,Pengyu Zeng,Zhenzhe Ying,Can Yi,Changhua Meng,Yuchen Zhou,Yongliang Shen,Shuai Lu*

Main category: cs.CL

TL;DR: EviNote-RAG是一个新的RAG框架，通过结构化检索-笔记-回答流程，训练模型生成简洁的支持性证据笔记(SENs)来提升开放域问答性能，解决了传统检索-回答范式中噪声干扰和多跳推理错误累积的问题。


<details>
  <summary>Details</summary>
Motivation: 传统检索-回答范式存在两个关键限制：(1)检索证据中信号噪声比低，有用信息被无关内容淹没；(2)多跳推理中不完整或噪声段落导致错误累积。

Method: 提出EviNote-RAG框架，采用结构化检索-笔记-回答流程，训练模型生成支持性证据笔记(SENs)来提炼答案相关信息，并通过基于蕴含的证据质量奖励(EQR)来强化学习过程。

Result: 在领域内和领域外QA基准测试中，EviNote-RAG在准确性、泛化性和训练稳定性方面均优于强基线，在HotpotQA、Bamboogle和2Wiki数据集上分别获得20%、40%和91%的相对F1提升。

Conclusion: EviNote-RAG通过SENs和EQR的结合，实现了更忠实和鲁棒的推理，同时减少了噪声影响，在提升性能的同时增强了鲁棒性和效率。

Abstract: Large Language Models (LLMs) empowered with retrieval mechanisms have
achieved strong progress in open-domain question answering (QA). Yet, the
conventional retrieve--then--answer paradigm often suffers from two key
limitations: (1) low signal-to-noise ratio in retrieved evidence, where useful
information is buried under irrelevant content, and (2) error accumulation in
multi-hop reasoning when incomplete or noisy passages are involved. To address
these challenges, we present EviNote-RAG, an agentic RAG framework that
introduces a structured retrieve--note--answer pipeline. Instead of directly
reasoning over raw retrievals, the model is trained to compose
Supportive-Evidence Notes (SENs), concise, human-like notes that preserve only
answer-relevant information, highlight uncertainty, and explicitly state when
no useful evidence exists. This distillation process is further reinforced by
the Evidence Quality Reward (EQR), an entailment-based signal that evaluates
whether SENs logically support the final answer. Together, SENs and EQR guide
the model toward faithful and robust reasoning, while reducing the impact of
noise. Experiments on in-domain and out-of-domain QA benchmarks show that
EviNote-RAG consistently outperforms strong baselines in accuracy,
generalization, and training stability. In particular, it achieves
state-of-the-art results while enhancing robustness and efficiency, yielding
relative F1 gains of 20\% on HotpotQA (+0.093), 40\% on Bamboogle (+0.151), and
91\% on 2Wiki (+0.256) via denser rewards and reduced verbosity.

</details>


### [51] [SeLeRoSa: Sentence-Level Romanian Satire Detection Dataset](https://arxiv.org/abs/2509.00893)
*Răzvan-Alexandru Smădu,Andreea Iuga,Dumitru-Clementin Cercel,Florin Pop*

Main category: cs.CL

TL;DR: 本文介绍了首个罗马尼亚语句级讽刺检测数据集SeLeRoSa，包含13,873个手工标注的句子，并评估了多种LLM和transformer模型在零样本和微调设置下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 讽刺、反讽和挖苦通常用于表达幽默和批评，但有时会被误认为是事实报道，类似于假新闻。这些技术可以在更细粒度的句子级别应用，因此需要专门的检测方法。

Method: 创建了包含13,873个手工标注句子的罗马尼亚语讽刺检测数据集SeLeRoSa，涵盖多个领域。评估了多种基于LLM的基线模型在零样本和微调设置下的性能，以及基于transformer的基线模型。

Result: 研究发现当前这些模型在句子级讽刺检测任务中存在局限性，为新的研究方向铺平了道路。

Conclusion: 该研究填补了罗马尼亚语句级讽刺检测数据集的空白，揭示了现有模型在此任务上的不足，为未来改进提供了基础。

Abstract: Satire, irony, and sarcasm are techniques typically used to express humor and
critique, rather than deceive; however, they can occasionally be mistaken for
factual reporting, akin to fake news. These techniques can be applied at a more
granular level, allowing satirical information to be incorporated into news
articles. In this paper, we introduce the first sentence-level dataset for
Romanian satire detection for news articles, called SeLeRoSa. The dataset
comprises 13,873 manually annotated sentences spanning various domains,
including social issues, IT, science, and movies. With the rise and recent
progress of large language models (LLMs) in the natural language processing
literature, LLMs have demonstrated enhanced capabilities to tackle various
tasks in zero-shot settings. We evaluate multiple baseline models based on LLMs
in both zero-shot and fine-tuning settings, as well as baseline
transformer-based models. Our findings reveal the current limitations of these
models in the sentence-level satire detection task, paving the way for new
research directions.

</details>


### [52] [Supervised In-Context Fine-Tuning for Generative Sequence Labeling](https://arxiv.org/abs/2509.00921)
*David Dukić,Goran Glavaš,Jan Šnajder*

Main category: cs.CL

TL;DR: 本文提出了监督上下文微调(SIFT)方法，将序列标注任务转化为受限响应生成问题，结合上下文学习和监督微调，显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 由于因果语言模型(LLMs)的快速发展，预期其在序列标注任务上能超越停滞发展的编码器模型，但现有研究较少关注更适合因果LLMs的生成式序列标注方法。

Method: 提出监督上下文微调(SIFT)，将序列标注任务重新表述为受限响应生成问题，结合上下文学习(ICL)和监督微调，无需因果掩码即可有效处理序列标注。

Result: SIFT在多个标准序列标注任务上显著优于ICL和解码器作为编码器的微调基线方法，即使去除指令也能保持强劲性能。

Conclusion: 生成式任务表述对序列标注性能至关重要，SIFT方法展示了LLMs在序列标注任务中的优势和局限性，为有效利用LLMs进行序列标注提供了重要见解。

Abstract: Sequence labeling (SL) tasks, where labels are assigned to tokens, are
abundant in NLP (e.g., named entity recognition and aspect-based sentiment
analysis). Owing to the intuition that they require bidirectional context, SL
tasks are commonly tackled with encoder-only models. Recent work also shows
that removing the causal mask in fine-tuning enables decoder-based LLMs to
become effective token classifiers. Less work, however, focused on (supervised)
generative SL, a more natural setting for causal LLMs. Due to their rapid
scaling, causal LLMs applied to SL are expected to outperform encoders, whose
own development has stagnated. In this work, we propose supervised in-context
fine-tuning (SIFT) for generative SL. SIFT casts SL tasks as constrained
response generation, natural to LLMs, combining (1) in-context learning (ICL)
from demonstrations with (2) supervised fine-tuning. SIFT considerably
outperforms both ICL and decoder-as-encoder fine-tuning baselines on a range of
standard SL tasks. We further find that although long context hinders the
performance of generative SL in both ICL and SIFT, this deficiency can be
mitigated by removing the instruction, as instructions are shown to be largely
unnecessary for achieving strong SL performance with SIFT. Our findings
highlight strengths and limitations of SL with LLMs, underscoring the
importance of a response-based generative task formulation for effective SL
performance.

</details>


### [53] [MedCOD: Enhancing English-to-Spanish Medical Translation of Large Language Models Using Enriched Chain-of-Dictionary Framework](https://arxiv.org/abs/2509.00934)
*Md Shahidul Salim,Lian Fu,Arav Adikesh Ramakrishnan,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: MedCOD是一个混合框架，通过整合医学领域结构化知识（UMLS和LLM-KB）来提升英西医学翻译质量，在多个开源LLM上显著超越基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决医学翻译中专业术语准确性问题，通过整合领域特定结构化知识来增强大语言模型的医学翻译能力。

Method: 构建2999对英西医学文章平行语料和100句测试集，使用包含多语言变体、医学同义词和UMLS定义的结构化提示，结合LoRA微调方法。

Result: 所有模型翻译质量显著提升，Phi-4模型达到BLEU 44.23、chrF++ 28.91、COMET 0.863，超越GPT-4o等基线模型。

Conclusion: 结构化知识整合能有效提升LLM在医学翻译任务中的表现，MedCOD提示和模型适配均独立贡献性能提升。

Abstract: We present MedCOD (Medical Chain-of-Dictionary), a hybrid framework designed
to improve English-to-Spanish medical translation by integrating
domain-specific structured knowledge into large language models (LLMs). MedCOD
integrates domain-specific knowledge from both the Unified Medical Language
System (UMLS) and the LLM-as-Knowledge-Base (LLM-KB) paradigm to enhance
structured prompting and fine-tuning. We constructed a parallel corpus of 2,999
English-Spanish MedlinePlus articles and a 100-sentence test set annotated with
structured medical contexts. Four open-source LLMs (Phi-4, Qwen2.5-14B,
Qwen2.5-7B, and LLaMA-3.1-8B) were evaluated using structured prompts that
incorporated multilingual variants, medical synonyms, and UMLS-derived
definitions, combined with LoRA-based fine-tuning. Experimental results
demonstrate that MedCOD significantly improves translation quality across all
models. For example, Phi-4 with MedCOD and fine-tuning achieved BLEU 44.23,
chrF++ 28.91, and COMET 0.863, surpassing strong baseline models like GPT-4o
and GPT-4o-mini. Ablation studies confirm that both MedCOD prompting and model
adaptation independently contribute to performance gains, with their
combination yielding the highest improvements. These findings highlight the
potential of structured knowledge integration to enhance LLMs for medical
translation tasks.

</details>


### [54] [Structure and Destructure: Dual Forces in the Making of Knowledge Engines](https://arxiv.org/abs/2509.00949)
*Yihong Chen*

Main category: cs.CL

TL;DR: 该论文探讨了NLP中结构化与非结构化知识引擎范式的统一，提出了结构与解构的互补机制来构建透明可控的通用知识系统


<details>
  <summary>Details</summary>
Motivation: 弥合NLP中基于知识图谱的结构化范式与基于大规模数据的非结构化范式之间的鸿沟，建立概念联系

Method: 通过结构机制组织已知符号交互，通过解构机制（周期性嵌入重置）提升模型可塑性和对未见场景的泛化能力

Result: 建立了两种范式间的概念连接，提出了开发通用知识引擎的新方法

Conclusion: 结构与解构的互补作用为构建透明、可控、自适应的智能系统提供了新的理论框架和实践路径

Abstract: The making of knowledge engines in natural language processing has been
shaped by two seemingly distinct paradigms: one grounded in structure, the
other driven by massively available unstructured data. The structured paradigm
leverages predefined symbolic interactions, such as knowledge graphs, as priors
and designs models to capture them. In contrast, the unstructured paradigm
centers on scaling transformer architectures with increasingly vast data and
model sizes, as seen in modern large language models. Despite their divergence,
this thesis seeks to establish conceptual connections bridging these paradigms.
Two complementary forces, structure and destructure, emerge across both
paradigms: structure organizes seen symbolic interactions, while destructure,
through periodic embedding resets, improves model plasticity and generalization
to unseen scenarios. These connections form a new recipe for developing general
knowledge engines that can support transparent, controllable, and adaptable
intelligent systems.

</details>


### [55] [RPRO:Ranked Preference Reinforcement Optimization for Enhancing Medical QA and Diagnostic Reasoning](https://arxiv.org/abs/2509.00974)
*Chia-Hsuan Hsu,Jun-En Ding,Hsin-Ling Hsu,Feng Liu,Fang-Ming Hung*

Main category: cs.CL

TL;DR: RPRO框架通过结合强化学习和偏好驱动的推理优化，提升医疗问答中思维链的临床可靠性和事实准确性，在PubMedQA和MedQA-USMLE基准上显著优于更大的模型。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在医疗问答中生成的推理链缺乏事实准确性和临床可靠性，需要一种能够整合领域知识和逻辑推理的改进方法。

Method: 提出Ranked Preference Reinforcement Optimization (RPRO)框架，结合强化学习和偏好驱动推理优化，使用任务自适应推理模板和概率评估机制，基于Bradley-Terry模型进行组间排序优化，并加入KL散度正则化确保训练稳定性。

Result: 在PubMedQA和MedQA-USMLE上的实验显示，1.1B参数的模型性能超过7B-13B的大型模型，包括医疗专用变体，证明了方法的有效性。

Conclusion: 将偏好优化与质量驱动的细化相结合，为构建更可靠、临床基础更强的医疗LLMs提供了可扩展且有效的方法。

Abstract: Medical question answering requires advanced reasoning that integrates domain
knowledge with logical inference. However, existing large language models
(LLMs) often generate reasoning chains that lack factual accuracy and clinical
reliability. We propose Ranked Preference Reinforcement Optimization (RPRO), a
novel framework that uniquely combines reinforcement learning with
preference-driven reasoning refinement to enhance clinical chain-of-thought
(CoT) performance. RPRO differentiates itself from prior approaches by
employing task-adaptive reasoning templates and a probabilistic evaluation
mechanism that aligns outputs with established clinical workflows, while
automatically identifying and correcting low-quality reasoning chains. Unlike
traditional pairwise preference methods, RPRO introduces a groupwise ranking
optimization based on the Bradley-Terry model and incorporates KL-divergence
regularization for stable training. Experiments on PubMedQA and MedQA-USMLE
show consistent improvements over strong baselines. Remarkably, our 1.1B
parameter model outperforms much larger 7B-13B models, including
medical-specialized variants. These findings demonstrate that combining
preference optimization with quality-driven refinement offers a scalable and
effective approach to building more reliable, clinically grounded medical LLMs.

</details>


### [56] [Performance Analysis of Supervised Machine Learning Algorithms for Text Classification](https://arxiv.org/abs/2509.00983)
*Sadia Zaman Mishu,S M Rafiuddin*

Main category: cs.CL

TL;DR: 本文比较了多种监督机器学习技术在文本分类中的性能，包括使用反向传播网络的人工神经网络模型，通过实验分析不同分类器在标注文档上的准确率


<details>
  <summary>Details</summary>
Motivation: 随着网络搜索、数据挖掘、推荐系统等领域对文本分类需求的快速增长，需要评估不同分类器在文本分类任务中的性能表现

Method: 使用标准监督机器学习技术，包括人工神经网络（ANN）和反向传播网络（BPN）模型，在多个标注数据集上应用不同分类器进行文本分类

Result: 通过实验分析揭示了哪些模型在分类准确率方面表现更好，为标注和监督文本分类过程提供了独立平台

Conclusion: 研究为文本分类任务提供了性能评估框架，帮助选择最适合特定应用场景的分类器模型

Abstract: The demand for text classification is growing significantly in web searching,
data mining, web ranking, recommendation systems, and so many other fields of
information and technology. This paper illustrates the text classification
process on different datasets using some standard supervised machine learning
techniques. Text documents can be classified through various kinds of
classifiers. Labeled text documents are used to classify the text in supervised
classifications. This paper applies these classifiers on different kinds of
labeled documents and measures the accuracy of the classifiers. An Artificial
Neural Network (ANN) model using Back Propagation Network (BPN) is used with
several other models to create an independent platform for labeled and
supervised text classification process. An existing benchmark approach is used
to analyze the performance of classification using labeled documents.
Experimental analysis on real data reveals which model works well in terms of
classification accuracy.

</details>


### [57] [Ranking of Bangla Word Graph using Graph-based Ranking Algorithms](https://arxiv.org/abs/2509.01011)
*S M Rafiuddin*

Main category: cs.CL

TL;DR: 本文研究使用图排序算法对孟加拉语单词进行排名，通过构建词图并应用多种图排序算法来评估单词重要性，实验结果显示不同算法在F1分数上的准确度差异。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏标准的孟加拉语词汇数据库，且词图能有效表示文本中单词间的关系并确定单词相对重要性，因此需要研究如何利用图排序算法对孟加拉语单词进行准确排名。

Method: 使用印度语言词性标注语料库构建孟加拉语词图，经过预处理步骤后应用多种图排序算法（如PageRank等）进行单词排名计算，并通过F1分数评估算法准确度。

Result: 实验结果表明不同图排序算法在孟加拉语单词排名任务中表现出不同的准确度，具体F1分数显示了各算法的性能差异。

Conclusion: 该研究成功建立了孟加拉语单词排名的完整流程，证明了图排序算法在该任务中的有效性，为缺乏标准数据库的孟加拉语自然语言处理提供了实用方法。

Abstract: Ranking words is an important way to summarize a text or to retrieve
information. A word graph is a way to represent the words of a sentence or a
text as the vertices of a graph and to show the relationship among the words.
It is also useful to determine the relative importance of a word among the
words in the word-graph. In this research, the ranking of Bangla words are
calculated, representing Bangla words from a text in a word graph using various
graph based ranking algorithms. There is a lack of a standard Bangla word
database. In this research, the Indian Language POS-tag Corpora is used, which
has a rich collection of Bangla words in the form of sentences with their parts
of speech tags. For applying a word graph to various graph based ranking
algorithms, several standard procedures are applied. The preprocessing steps
are done in every word graph and then applied to graph based ranking algorithms
to make a comparison among these algorithms. This paper illustrate the entire
procedure of calculating the ranking of Bangla words, including the
construction of the word graph from text. Experimental result analysis on real
data reveals the accuracy of each ranking algorithm in terms of F1 measure.

</details>


### [58] [We Politely Insist: Your LLM Must Learn the Persian Art of Taarof](https://arxiv.org/abs/2509.01035)
*Nikta Gohari Sadr,Sahar Heidariasl,Karine Megerdoomian,Laleh Seyyed-Kalantari,Ali Emami*

Main category: cs.CL

TL;DR: 该论文提出了TaarofBench，首个评估大语言模型对波斯taarof文化礼仪理解能力的基准测试，发现现有模型在跨文化沟通中存在显著差距，并通过微调方法显著提升了模型的文化对齐能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在理解特定文化沟通规范方面存在困难，特别是在波斯taarof这种强调谦逊、间接和尊重的复杂礼仪系统方面，现有文化基准测试完全缺失这方面的评估。

Method: 构建包含450个角色扮演场景的TaarofBench基准，涵盖12个常见社交话题，由母语者验证。评估5个前沿LLM，进行监督微调和直接偏好优化，并开展包含33名参与者的人类研究建立基线。

Result: 主流LLM在taarof文化适当情境下的准确率比母语者低40-48%，性能因话题而异，波斯语提示能改善表现，存在性别不对称性。通过微调方法分别实现了21.8%和42.3%的文化对齐改进。

Conclusion: 西方礼貌框架无法准确评估taarof等文化特定礼仪，需要开发更多样化和文化敏感的LLM基准，为构建能够更好处理复杂社交互动的应用奠定基础。

Abstract: Large language models (LLMs) struggle to navigate culturally specific
communication norms, limiting their effectiveness in global contexts. We focus
on Persian taarof, a social norm in Iranian interactions, which is a
sophisticated system of ritual politeness that emphasizes deference, modesty,
and indirectness, yet remains absent from existing cultural benchmarks. We
introduce TaarofBench, the first benchmark for evaluating LLM understanding of
taarof, comprising 450 role-play scenarios covering 12 common social
interaction topics, validated by native speakers. Our evaluation of five
frontier LLMs reveals substantial gaps in cultural competence, with accuracy
rates 40-48% below native speakers when taarof is culturally appropriate.
Performance varies between interaction topics, improves with Persian-language
prompts, and exhibits gender-based asymmetries. We also show that responses
rated "polite" by standard metrics often violate taarof norms, indicating the
limitations of Western politeness frameworks. Through supervised fine-tuning
and Direct Preference Optimization, we achieve 21.8% and 42.3% improvement in
model alignment with cultural expectations. Our human study with 33
participants (11 native Persian, 11 heritage, and 11 non-Iranian speakers)
forms baselines in varying degrees of familiarity with Persian norms. This work
lays the foundation for developing diverse and culturally aware LLMs, enabling
applications that better navigate complex social interactions.

</details>


### [59] [A Dynamic Fusion Model for Consistent Crisis Response](https://arxiv.org/abs/2509.01053)
*Xiaoying Song,Anirban Saha Anik,Eduardo Blanco,Vanessa Frias-Martinez,Lingzi Hong*

Main category: cs.CL

TL;DR: 提出了一种基于融合的生成方法，通过两阶段过程优化危机沟通中的语言模型响应风格一致性，显著提升了响应质量和风格均匀性。


<details>
  <summary>Details</summary>
Motivation: 危机沟通中自动化响应的风格一致性对建立受影响人群信任至关重要，但现有研究很少探索这一问题。

Method: 首先提出了风格一致性评估指标，然后采用两阶段融合生成方法：先评估候选响应的风格，再通过实例层面的融合过程进行优化和整合。

Result: 在多个数据集上的实验结果显示，该方法在响应质量和风格均匀性方面均一致超过基准方法。

Conclusion: 该研究为危机沟通中的风格一致性问题提供了有效解决方案，通过新颖的评估指标和融合生成方法，显著提升了生成响应的质量咏风格稳定性。

Abstract: In response to the urgent need for effective communication with
crisis-affected populations, automated responses driven by language models have
been proposed to assist in crisis communications. A critical yet often
overlooked factor is the consistency of response style, which could affect the
trust of affected individuals in responders. Despite its importance, few
studies have explored methods for maintaining stylistic consistency across
generated responses. To address this gap, we propose a novel metric for
evaluating style consistency and introduce a fusion-based generation approach
grounded in this metric. Our method employs a two-stage process: it first
assesses the style of candidate responses and then optimizes and integrates
them at the instance level through a fusion process. This enables the
generation of high-quality responses while significantly reducing stylistic
variation between instances. Experimental results across multiple datasets
demonstrate that our approach consistently outperforms baselines in both
response quality and stylistic uniformity.

</details>


### [60] [Speaking at the Right Level: Literacy-Controlled Counterspeech Generation with RAG-RL](https://arxiv.org/abs/2509.01058)
*Xiaoying Song,Anirban Saha Anik,Dibakar Barua,Pengcheng Luo,Junhua Ding,Lingzi Hong*

Main category: cs.CL

TL;DR: 使用检索增强生成和强化学习的控制健康语文框架，生成适应不同健康语文水平的批判话语，提高反假信息效果


<details>
  <summary>Details</summary>
Motivation: 现有的自动生成批判话语方法产生统一响应，忽略了受众健康语文水平对批判话语可访问性和效果的影响

Method: 控制健康语文框架，结合检索增强生成(RAG)和强化学习(RL)，检索适合特定健康语文水平的知识，设计包含主观用户偏好和客观可读性奖励的奖励函数

Result: 实验结果显示，控制健康语斆框架在生成更易访问和用户更喜欢的批判话语方面超过基线方法

Conclusion: 该研究通过提高批判话语的可访问性和理解能力，为公共健康沟通提供了更公平和有影响力的方法

Abstract: Health misinformation spreading online poses a significant threat to public
health. Researchers have explored methods for automatically generating
counterspeech to health misinformation as a mitigation strategy. Existing
approaches often produce uniform responses, ignoring that the health literacy
level of the audience could affect the accessibility and effectiveness of
counterspeech. We propose a Controlled-Literacy framework using
retrieval-augmented generation (RAG) with reinforcement learning (RL) to
generate tailored counterspeech adapted to different health literacy levels. In
particular, we retrieve knowledge aligned with specific health literacy levels,
enabling accessible and factual information to support generation. We design a
reward function incorporating subjective user preferences and objective
readability-based rewards to optimize counterspeech to the target health
literacy level. Experiment results show that Controlled-Literacy outperforms
baselines by generating more accessible and user-preferred counterspeech. This
research contributes to more equitable and impactful public health
communication by improving the accessibility and comprehension of counterspeech
to health misinformation.

</details>


### [61] [Assessing Large Language Models on Islamic Legal Reasoning: Evidence from Inheritance Law Evaluation](https://arxiv.org/abs/2509.01081)
*Abdessalam Bouchekif,Samer Rashwani,Heba Sbahi,Shahd Gaben,Mutez Al-Khatib,Mohammed Ghaly*

Main category: cs.CL

TL;DR: 评估7个大型语言模型在伊斯兰继承法领域的知识和推理能力，发现性能差异显著：o3和Gemini 2.5准确率超过90%，而其他模型低于50%


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在伊斯兰继承法（'ilm al-mawarith）这一专业法律领域的知识和推理能力，了解模型在结构化法律推理方面的表现

Method: 使用包含1000个多选题的基准测试，涵盖多样化继承场景，测试模型理解继承背景和计算伊斯兰法规定份额分配的能力

Result: 模型性能存在显著差距：o3和Gemini 2.5准确率>90%，ALLaM、Fanar、LLaMA和Mistral准确率<50%。错误模式包括继承场景误解、法律规则错误应用和领域知识不足

Conclusion: 研究揭示了LLMs在处理结构化法律推理方面的局限性，为改进伊斯兰法律推理性能提供了方向，表明需要更好的领域适应和推理能力提升

Abstract: This paper evaluates the knowledge and reasoning capabilities of Large
Language Models in Islamic inheritance law, known as 'ilm al-mawarith. We
assess the performance of seven LLMs using a benchmark of 1,000 multiple-choice
questions covering diverse inheritance scenarios, designed to test models'
ability to understand the inheritance context and compute the distribution of
shares prescribed by Islamic jurisprudence. The results reveal a significant
performance gap: o3 and Gemini 2.5 achieved accuracies above 90%, whereas
ALLaM, Fanar, LLaMA, and Mistral scored below 50%. These disparities reflect
important differences in reasoning ability and domain adaptation. We conduct a
detailed error analysis to identify recurring failure patterns across models,
including misunderstandings of inheritance scenarios, incorrect application of
legal rules, and insufficient domain knowledge. Our findings highlight
limitations in handling structured legal reasoning and suggest directions for
improving performance in Islamic legal reasoning. Code:
https://github.com/bouchekif/inheritance_evaluation

</details>


### [62] [A Paradigm Gap in Urdu](https://arxiv.org/abs/2509.01084)
*Farah Adeeba,Rajesh Bhatt*

Main category: cs.CL

TL;DR: 乌尔都语中-ya: kar结构的完成体形式在现代语法中极不自然，尽管19世纪文献中常见，这是由于主格主语要求与及物完成体赋予作格的核心语法规则冲突所致。


<details>
  <summary>Details</summary>
Motivation: 研究乌尔都语动词和体组合中的范式空缺：-ya: kar结构的完成体形式在现代乌尔都语和印地语中极不自然，但在19世纪文献中自由出现，需要探究这一历时变化的原因。

Method: 通过历史文本分析、大规模语料库研究（确认完成体形式的明显缺失）以及母语者的主观评价任务（判断完成体例句高度不自然）来调查这一历时转变。

Result: 研究发现完成体形式在现代语法中极不稳定，其功能被其他结构替代，导致这一空缺在现代语法中固化。

Conclusion: 这一空缺源于根本的形态句法冲突：该结构要求主格主语和不变分词，与及物完成体赋予作格的核心语法规则相冲突，使得完成体形式不稳定并被其他结构功能替代。

Abstract: In this paper, we document a paradigm gap in the combinatorial possibilities
of verbs and aspect in Urdu: the perfective form of the -ya: kar construction
(e.g. ro-ya: ki: cry-Pfv do.Pfv) is sharply ungrammatical in modern Urdu and
Hindi, despite being freely attested in 19th century literature. We investigate
this diachronic shift through historical text analysis, a large-scale corpus
study which confirms the stark absence of perfective forms and subjective
evaluation tasks with native speakers, who judge perfective examples as highly
unnatural. We argue that this gap arose from a fundamental morphosyntactic
conflict: the construction's requirement for a nominative subject and an
invariant participle clashes with the core grammatical rule that transitive
perfective assign ergative case. This conflict rendered the perfective form
unstable, and its functional replacement by other constructions allowed the gap
to become entrenched in the modern grammar.

</details>


### [63] [Privacy-Preserving Reasoning with Knowledge-Distilled Parametric Retrieval Augmented Generation](https://arxiv.org/abs/2509.01088)
*Jinwen Chen,Hainan Zhang,Liang Pang,Yongxin Tong,Haibo Zhou,Yuan Zhan,Wei Lin,Zhiming Zheng*

Main category: cs.CL

TL;DR: DistilledPRAG是一种知识蒸馏的参数化RAG模型，通过将文档编码为LoRA参数而非明文，在保护隐私的同时保持RAG性能，解决了传统PRAG的推理延迟和泛化问题。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统需要上传明文文档到云端，存在隐私泄露风险。参数化RAG(PRAG)虽然通过LoRA编码保护隐私，但仍面临推理延迟高和泛化性能差的问题。

Method: 1)合成单文档和多文档QA对增强跨文档推理；2)用特殊标记屏蔽明文文档，通过参数生成器转换为LoRA；3)通过知识蒸馏训练参数生成器匹配标准RAG的隐藏状态和输出logits。

Result: 在四个QA数据集上的实验表明，DistilledPRAG在准确率上优于基线方法，并在分布外数据上表现出良好的泛化能力。

Conclusion: DistilledPRAG成功实现了高效参数化同时保持RAG级别性能，为隐私保护推理提供了有效解决方案。

Abstract: The current RAG system requires uploading plaintext documents to the cloud,
risking private data leakage. Parametric RAG (PRAG) addresses this by encoding
documents as LoRA within LLMs, enabling reasoning without exposing raw content.
However, it still faces two issues: (1) PRAG demands synthesizing QA pairs and
fine-tuning LLM for each individual document to create its corresponding LoRA,
leading to unacceptable inference latency. (2) The performance of PRAG relies
solely on synthetic QA data, lacking internal alignment with standard RAG,
resulting in poor generalization on out-of-distribution(OOD) inputs. Therefore,
achieving high-efficiency parameterization while maintaining RAG-level
performance remains a critical challenge for privacy-preserving reasoning. In
this paper, we propose DistilledPRAG, a generalizable knowledge-distilled
parametric RAG model aligned with standard RAG in document structure and
parameter activation. We first synthesize QA pairs from single and
multi-documents to enhance cross-document reasoning. Then, we mask the
plaintext documents with a special token and translate them to LoRA via a
parameter generator, maintaining the standard RAG document structure. Finally,
guided by synthetic QA data, we train the parameter generator to match standard
RAG's hidden states and output logits, enabling RAG-style reasoning without
original documents. Experiments on four QA datasets show that DistilledPRAG
outperforms baselines in accuracy and generalizes well on OOD data.

</details>


### [64] [REFRAG: Rethinking RAG based Decoding](https://arxiv.org/abs/2509.01092)
*Xiaoqiang Lin,Aritra Ghosh,Bryan Kian Hsiang Low,Anshumali Shrivastava,Vijai Mohan*

Main category: cs.CL

TL;DR: REFRAG是一个针对RAG应用的高效解码框架，通过压缩、感知和扩展机制，利用检索上下文的稀疏性结构，在保持性能的同时显著提升解码速度并扩展上下文长度。


<details>
  <summary>Details</summary>
Motivation: RAG应用中检索到的上下文通常包含大量不相关段落，形成块对角注意力模式，导致传统LLM解码过程中存在大量不必要的计算，造成系统延迟和内存消耗问题。

Method: 提出REFRAG框架，通过分析RAG上下文的稀疏结构特性，设计压缩、感知和扩展机制来优化解码过程，减少不必要的注意力计算。

Result: 实验显示REFRAG实现了30.85倍的首token时间加速（相比之前工作提升3.75倍），在保持困惑度不变的同时将LLM上下文长度扩展16倍，在多个长上下文任务中均取得显著加速效果。

Conclusion: REFRAG通过利用RAG上下文的固有稀疏性，有效解决了知识增强与系统效率之间的权衡问题，为RAG应用提供了高效且可扩展的解码解决方案。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
leveraging extensive external knowledge to enhance responses in multi-turn and
agentic applications, such as retrieval-augmented generation (RAG). However,
processing long-context inputs introduces significant system latency and
demands substantial memory for the key-value cache, resulting in reduced
throughput and a fundamental trade-off between knowledge enrichment and system
efficiency. While minimizing latency for long-context inputs is a primary
objective for LLMs, we contend that RAG require specialized consideration. In
RAG, much of the LLM context consists of concatenated passages from retrieval,
with only a small subset directly relevant to the query. These passages often
exhibit low semantic similarity due to diversity or deduplication during
re-ranking, leading to block-diagonal attention patterns that differ from those
in standard LLM generation tasks. Based on this observation, we argue that most
computations over the RAG context during decoding are unnecessary and can be
eliminated with minimal impact on performance. To this end, we propose REFRAG,
an efficient decoding framework that compresses, senses, and expands to improve
latency in RAG applications. By exploiting the sparsity structure, we
demonstrate a 30.85 the time-to-first-token acceleration (3.75 improvement to
previous work) without loss in perplexity. In addition, our optimization
framework for large context enables REFRAG to extend the context size of LLMs
by 16. We provide rigorous validation of REFRAG across diverse long-context
tasks, including RAG, multi-turn conversations, and long document
summarization, spanning a wide range of datasets. Experimental results confirm
that REFRAG delivers substantial speedup with no loss in accuracy compared to
LLaMA models and other state-of-the-art baselines across various context sizes.

</details>


### [65] [Natural Context Drift Undermines the Natural Language Understanding of Large Language Models](https://arxiv.org/abs/2509.01093)
*Yulong Wu,Viktor Schlegel,Riza Batista-Navarro*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在问答任务中的性能会随着阅读段落与预训练时内容的自然演变而显著下降，即使问题和必要信息在推理时都保持不变。


<details>
  <summary>Details</summary>
Motivation: 研究自然文本演变如何影响生成式大型语言模型在问答任务中的表现，探究模型对预训练内容变化的敏感度。

Method: 提出了一个框架来整理自然演变的人类编辑版本阅读段落，通过语义相似度评分量化变体与预训练内容的对齐程度，评估了6个QA数据集和8个LLM。

Result: 实验显示LLM性能随着阅读段落与预训练版本的语义相似度降低而显著下降，例如BoolQ数据集上模型准确率从最高到最低相似度区间下降了30%以上。

Conclusion: 自然文本演变对LLM的语言理解能力构成了重要挑战，模型对预训练内容的依赖性很强。

Abstract: How does the natural evolution of context paragraphs affect question
answering in generative Large Language Models (LLMs)? To investigate this, we
propose a framework for curating naturally evolved, human-edited variants of
reading passages from contemporary QA benchmarks and for analyzing LLM
performance across a range of semantic similarity scores, which quantify how
closely each variant aligns with content seen during pretraining. Using this
framework, we evaluate six QA datasets and eight LLMs with publicly available
training data. Our experiments reveal that LLM performance declines as reading
passages naturally diverge from the versions encountered during
pretraining-even when the question and all necessary information remains
present at inference time. For instance, average model accuracy on BoolQ drops
by over 30% from the highest to lowest similarity bins, with slopes exceeding
70 across several LLMs. These findings suggest that natural text evolution
poses a significant challenge to the language understanding capabilities of
LLMs.

</details>


### [66] [Dream-Coder 7B: An Open Diffusion Language Model for Code](https://arxiv.org/abs/2509.01142)
*Zhihui Xie,Jiacheng Ye,Lin Zheng,Jiahui Gao,Jingwei Dong,Zirui Wu,Xueliang Zhao,Shansan Gong,Xin Jiang,Zhenguo Li,Lingpeng Kong*

Main category: cs.CL

TL;DR: Dream-Coder 7B是一个开源的离散扩散语言模型，具有新兴的任意顺序代码生成能力，通过自适应解码策略和强化学习训练，在多个代码生成基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统自回归模型只能从左到右解码，限制了代码生成的灵活性。需要开发能够根据任务自适应选择解码策略的模型，提高复杂算法生成和代码理解任务的性能。

Method: 将预训练的自回归检查点适配到离散扩散框架，使用连续时间加权交叉熵目标。训练包括：1）监督微调，通过随机截断和填充惩罚提高样本效率；2）使用可验证奖励的强化学习，针对扩散语言模型定制训练方法。

Result: Dream-Coder 7B Instruct在LiveCodeBench上达到21.4% pass@1，在HumanEval、MBPP、BigCodeBench和CRUXEval等基准测试中表现出竞争力。

Conclusion: 该模型展示了离散扩散方法在代码生成任务中的有效性，提供了自适应解码能力，并开源了检查点、训练方法和推理代码以促进进一步研究。

Abstract: We present Dream-Coder 7B, an open-source discrete diffusion language model
for code generation that exhibits emergent any-order generation capabilities.
Unlike traditional autoregressive (AR) models that decode strictly
left-to-right, Dream-Coder 7B adaptively determines its decoding strategy based
on the coding task: sketch-first generation for complex algorithms,
left-to-right generation for straightforward completions, and interleaved
reasoning generation for code understanding tasks. We adapt a pretrained AR
checkpoint to a discrete diffusion frameworks with a continuous-time weighted
cross-entropy objective. Our post-training recipe comprises (i) supervised
fine-tuning, where we mitigate padding pathologies via random truncation and a
padding penalty to improve sample efficiency and stabilize generation; and (ii)
reinforcement learning with verifiable rewards over a curated high-quality
prompt set drawn from open-source datasets, using a tailored reinforcement
learning recipe for diffusion language models. The resulting Dream-Coder 7B
Instruct attains 21.4\% pass@1 on LiveCodeBench (2410--2505) and demonstrates
competitive performance on HumanEval, MBPP, BigCodeBench, and CRUXEval. We
release Dream-Coder-7B and Dream-Coder-7B-Instruct checkpoints, training
recipes, preprocessing pipelines, and inference code to facilitate
reproducibility and further research.

</details>


### [67] [Zero-shot Cross-lingual NER via Mitigating Language Difference: An Entity-aligned Translation Perspective](https://arxiv.org/abs/2509.01147)
*Zhihao Zhang,Sophia Yat Mei Lee,Dong Zhang,Shoushan Li,Guodong Zhou*

Main category: cs.CL

TL;DR: 提出EAT方法解决非拉丁语系语言的零样本跨语言命名实体识别问题，通过双重翻译策略和LLM微调实现实体对齐


<details>
  <summary>Details</summary>
Motivation: 现有零样本跨语言NER方法主要针对拉丁语系语言，对中文、日文等非拉丁语系语言效果不佳，因为存在深层结构差异

Method: 使用大语言模型的双重翻译策略进行实体对齐，并利用多语言维基百科数据微调LLM以增强源语言到目标语言的实体对齐

Result: 未在摘要中明确说明具体实验结果

Conclusion: EAT方法能够有效解决非拉丁语系语言的跨语言NER问题，通过实体对齐改善知识迁移效果

Abstract: Cross-lingual Named Entity Recognition (CL-NER) aims to transfer knowledge
from high-resource languages to low-resource languages. However, existing
zero-shot CL-NER (ZCL-NER) approaches primarily focus on Latin script language
(LSL), where shared linguistic features facilitate effective knowledge
transfer. In contrast, for non-Latin script language (NSL), such as Chinese and
Japanese, performance often degrades due to deep structural differences. To
address these challenges, we propose an entity-aligned translation (EAT)
approach. Leveraging large language models (LLMs), EAT employs a
dual-translation strategy to align entities between NSL and English. In
addition, we fine-tune LLMs using multilingual Wikipedia data to enhance the
entity alignment from source to target languages.

</details>


### [68] [Joint Information Extraction Across Classical and Modern Chinese with Tea-MOELoRA](https://arxiv.org/abs/2509.01158)
*Xuemei Tang,Chengxi Yan,Jinghang Gu,Chu-Ren Huang*

Main category: cs.CL

TL;DR: Tea-MOELoRA是一个参数高效的多任务框架，结合LoRA和混合专家设计，用于中文信息抽取任务，通过任务-时代感知路由机制动态分配专家贡献


<details>
  <summary>Details</summary>
Motivation: 中文信息抽取涉及古典和现代文档等多个时间域的任务，在异构任务和不同时代上微调单一模型可能导致干扰和性能下降

Method: 结合LoRA与混合专家(MoE)设计，多个低秩LoRA专家专注于不同的IE任务和时代，使用任务-时代感知路由机制动态分配专家贡献

Result: 实验表明Tea-MOELoRA优于单任务和联合LoRA基线，展示了其有效利用任务和时间知识的能力

Conclusion: 提出的参数高效多任务框架能够有效处理中文信息抽取中的异构任务和跨时代挑战

Abstract: Chinese information extraction (IE) involves multiple tasks across diverse
temporal domains, including Classical and Modern documents. Fine-tuning a
single model on heterogeneous tasks and across different eras may lead to
interference and reduced performance. Therefore, in this paper, we propose
Tea-MOELoRA, a parameter-efficient multi-task framework that combines LoRA with
a Mixture-of-Experts (MoE) design. Multiple low-rank LoRA experts specialize in
different IE tasks and eras, while a task-era-aware router mechanism
dynamically allocates expert contributions. Experiments show that Tea-MOELoRA
outperforms both single-task and joint LoRA baselines, demonstrating its
ability to leverage task and temporal knowledge effectively.

</details>


### [69] [Enhancing Large Language Model for Knowledge Graph Completion via Structure-Aware Alignment-Tuning](https://arxiv.org/abs/2509.01166)
*Yu Liu,Yanan Cao,Xixun Lin,Yanmin Shang,Shi Wang,Shirui Pan*

Main category: cs.CL

TL;DR: SAT框架通过结构感知对齐调优增强LLM在知识图谱补全中的表现，解决了自然语言与图结构表示空间不一致的问题，使用统一图指令实现多任务处理


<details>
  <summary>Details</summary>
Motivation: 现有LLM增强的KGC方法存在两个关键挑战：自然语言与图结构表示空间不一致，以及不同KGC任务需要单独设计指令导致重复工作和耗时

Method: 提出SAT框架，包含分层知识对齐（通过多任务对比学习对齐图嵌入与自然语言空间）和结构指令调优（使用统一图指令和轻量级知识适配器指导LLM进行结构感知推理）

Result: 在4个基准数据集的两个KGC任务上显著优于最先进方法，链接预测任务提升8.7%到29.8%

Conclusion: SAT框架有效解决了表示空间不一致和指令设计冗余问题，为LLM在知识图谱补全中的应用提供了高效统一的解决方案

Abstract: Knowledge graph completion (KGC) aims to infer new knowledge and make
predictions from knowledge graphs. Recently, large language models (LLMs) have
exhibited remarkable reasoning capabilities. LLM-enhanced KGC methods primarily
focus on designing task-specific instructions, achieving promising
advancements. However, there are still two critical challenges. First, existing
methods often ignore the inconsistent representation spaces between natural
language and graph structures. Second, most approaches design separate
instructions for different KGC tasks, leading to duplicate works and
time-consuming processes. To address these challenges, we propose SAT, a novel
framework that enhances LLMs for KGC via structure-aware alignment-tuning.
Specifically, we first introduce hierarchical knowledge alignment to align
graph embeddings with the natural language space through multi-task contrastive
learning. Then, we propose structural instruction tuning to guide LLMs in
performing structure-aware reasoning over KGs, using a unified graph
instruction combined with a lightweight knowledge adapter. Experimental results
on two KGC tasks across four benchmark datasets demonstrate that SAT
significantly outperforms state-of-the-art methods, especially in the link
prediction task with improvements ranging from 8.7% to 29.8%.

</details>


### [70] [Modular Techniques for Synthetic Long-Context Data Generation in Language Model Training and Evaluation](https://arxiv.org/abs/2509.01185)
*Seganrasan Subramanian,Abhigya Verma*

Main category: cs.CL

TL;DR: 提出了一个模块化、可扩展的框架，通过基于提示的LLM交互生成合成长上下文数据，支持多种训练目标，包括SFT、DPO和GRPO。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏高质量、多样化且可验证的长上下文数据集，这严重制约了大型语言模型在长文本处理和推理能力方面的发展。

Method: 采用模块化框架，通过模板化提示、模型无关架构和元数据丰富的输出，支持四种核心生成范式：多轮对话、文档基础输入输出对、可验证指令响应任务和长上下文推理示例。

Result: 该框架能够实现可扩展、可控且目标对齐的数据集创建，为提升LLMs的长上下文能力提供支持。

Conclusion: 提出的合成数据生成框架为解决长上下文数据集稀缺问题提供了有效解决方案，有助于推动LLMs在长文本处理方面的发展。

Abstract: The ability of large language models (LLMs) to process and reason over long
textual inputs is critical for a wide range of real-world applications.
However, progress in this area is significantly constrained by the absence of
high-quality, diverse, and verifiable long-context datasets suitable for both
training and evaluation. This work introduces a modular, extensible framework
for synthetic long-context data generation via prompt-based interaction with
LLMs. The framework supports multiple training and alignment objectives,
including Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO),
and Group Relative Policy Optimization (GRPO). It encompasses four core
generation paradigms: multi-turn conversational dialogues, document-grounded
input-output pairs, verifiable instruction-response tasks, and long-context
reasoning examples. Through templated prompting, a model-agnostic architecture,
and metadata-enriched outputs, the proposed approach facilitates scalable,
controllable, and purpose-aligned dataset creation for advancing long-context
capabilities in LLMs.

</details>


### [71] [Statutory Construction and Interpretation for Artificial Intelligence](https://arxiv.org/abs/2509.01186)
*Luxi He,Nimra Nadeem,Michel Liao,Howard Chen,Danqi Chen,Mariano-Florentino Cuéllar,Peter Henderson*

Main category: cs.CL

TL;DR: 该论文提出了一种计算框架来管理AI系统中的解释性模糊问题，借鉴法律系统的机制来提高规则解释和应用的一致性。


<details>
  <summary>Details</summary>
Motivation: AI系统越来越依赖自然语言原则进行治理，但语言解释的模糊性导致模型行为不一致和不稳定，而当前AI对齐流程缺乏类似法律系统的制度性保障机制。

Method: 提出了一个计算框架，包含两个法律机制：(1)规则精炼流程，通过修订模糊规则来最小化解释分歧；(2)基于提示的解释约束，减少规则应用的不一致性。在WildChat数据集的5000个场景子集上进行评估。

Result: 两种干预措施都显著提高了合理解释者小组的判断一致性。

Conclusion: 该方法是系统管理解释性模糊性的第一步，对于构建更稳健、遵循规则的AI系统至关重要。

Abstract: AI systems are increasingly governed by natural language principles, yet a
key challenge arising from reliance on language remains underexplored:
interpretive ambiguity. As in legal systems, ambiguity arises both from how
these principles are written and how they are applied. But while legal systems
use institutional safeguards to manage such ambiguity, such as transparent
appellate review policing interpretive constraints, AI alignment pipelines
offer no comparable protections. Different interpretations of the same rule can
lead to inconsistent or unstable model behavior. Drawing on legal theory, we
identify key gaps in current alignment pipelines by examining how legal systems
constrain ambiguity at both the rule creation and rule application steps. We
then propose a computational framework that mirrors two legal mechanisms: (1) a
rule refinement pipeline that minimizes interpretive disagreement by revising
ambiguous rules (analogous to agency rulemaking or iterative legislative
action), and (2) prompt-based interpretive constraints that reduce
inconsistency in rule application (analogous to legal canons that guide
judicial discretion). We evaluate our framework on a 5,000-scenario subset of
the WildChat dataset and show that both interventions significantly improve
judgment consistency across a panel of reasonable interpreters. Our approach
offers a first step toward systematically managing interpretive ambiguity, an
essential step for building more robust, law-following AI systems.

</details>


### [72] [Efficient Large Language Models with Zero-Shot Adjustable Acceleration](https://arxiv.org/abs/2509.01190)
*Sajjad Kachuee,Mohammad Sharifkhani*

Main category: cs.CL

TL;DR: 提出Zero-Shot Adjustable Acceleration方法，可在推理时动态调整硬件使用，无需额外微调，实现高达11倍的加速


<details>
  <summary>Details</summary>
Motivation: 在LLM实际应用中平衡计算效率和性能是重大挑战，需要在微调后和推理阶段优化加速以构建高效架构

Method: 引入零样本可调加速的新型训练和推理方法，在推理过程中动态调整硬件使用

Result: 实验结果显示该方法能够以零样本方式实现广泛的加速范围，相比基线达到最高11倍的速度提升

Conclusion: 该方法为LLM应用提供了一种有效的动态加速解决方案，显著提升了推理效率

Abstract: Using Large Language Models (LLMs) in real-world applications presents
significant challenges, particularly in balancing computational efficiency and
performance. Optimizing acceleration after the fine-tuning phase and during
inference is crucial for building an efficient architecture. This paper
introduces Zero-Shot Adjustable Acceleration, a novel training and inference
method that dynamically adjusts hardware usage during inference without
requiring additional fine-tuning. The proposed approach is applied to newly
developed models and evaluated across multiple classification and text
generation tasks. Experimental results demonstrate that the method enables a
wide range of acceleration in a zero-shot manner and achieves up to a 11x
speedup compared to the baseline.

</details>


### [73] [Mitigating Catastrophic Forgetting in Continual Learning through Model Growth](https://arxiv.org/abs/2509.01213)
*Ege Süalp,Mina Rezaei*

Main category: cs.CL

TL;DR: 本文探讨了基于模型增长策略（特别是transformer堆叠）在缓解大语言模型持续学习中的灾难性遗忘问题方面的效果，发现该方法在阅读理解等任务上能减少性能退化，但在社会偏见处理方面存在权衡。


<details>
  <summary>Details</summary>
Motivation: 灾难性遗忘是持续学习中的主要挑战，特别是在大语言模型持续微调时会丢失先前学到的知识。模型增长策略通过利用小模型加速大模型训练来缓解这一问题，但其对遗忘的影响尚未充分研究。

Method: 采用基于增长的预训练方法（transformer堆叠），构建Stack LLM模型，并与传统LLM基线在序列微调任务上进行对比评估，任务涵盖领域知识、推理、阅读理解和偏见分析。

Result: 两种模型在领域知识上都有提升，但推理和阅读理解能力随时间退化。Stack LLM表现出更少的性能退化，特别是在阅读理解方面。在偏见评估中，基线LLM变得更中性，而Stack LLM保持约60-61%的稳定偏见比率。

Conclusion: 基于增长的预训练在抵抗灾难性遗忘方面能带来适度改进，但在处理社会偏见方面存在权衡，需要进一步研究来平衡性能保持和偏见控制。

Abstract: Catastrophic forgetting is a significant challenge in continual learning, in
which a model loses prior knowledge when it is fine-tuned on new tasks. This
problem is particularly critical for large language models (LLMs) undergoing
continual learning, as retaining performance across diverse domains is
important for their general utility. In this paper, we explore model growth, a
promising strategy that leverages smaller models to expedite and structure the
training of larger ones for mitigating the catastrophic forgetting problem.
Although growth-based pretraining, particularly via transformer stacking, has
shown promise in accelerating convergence, its impact on forgetting remains
under-explored. Therefore, we evaluate whether growth-based models can retain
previously learned capabilities more effectively across a sequence of
fine-tuning tasks involving domain knowledge, reasoning, reading comprehension,
and bias. Our findings show that both models -- one trained with growth (Stack
LLM) and one without (LLM) -- exhibit improvements in domain knowledge.
However, reasoning and reading comprehension degrade over time, indicating
signs of catastrophic forgetting. Stack LLM consistently shows less
degradation, especially in reading comprehension, suggesting enhanced retention
capabilities. Interestingly, in bias evaluation, the baseline LLM becomes
progressively more neutral with continued fine-tuning, while Stack LLM
maintains a steady bias ratio around 60--61\%. These results indicate that
growth-based pretraining may deliver modest improvements in resisting
catastrophic forgetting, though trade-offs remain in handling social biases.

</details>


### [74] [DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning Domain Taks Based on Data and Model Compression](https://arxiv.org/abs/2509.01221)
*Wei Huang,Huang Wei,Yinggui Wang*

Main category: cs.CL

TL;DR: 提出了DaMoC框架，通过数据压缩和模型压缩技术，快速选择最优LLM进行微调，节省约20倍训练时间


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在通用任务上表现优异，但在特定领域任务上需要微调，如何快速选择最优模型进行微调是一个挑战

Method: 数据层面：系统分类数据过滤方法（分布感知、质量感知、混合方法），进行token压缩和文本重写优化；模型层面：使用层相似性评分评估重要性，移除低重要性层，引入稀疏合并范式

Result: 在医疗问答、金融问答、通用问答和阅读理解四个数据集上的实验表明，能够选择最优LLM同时节省约20倍训练时间

Conclusion: DaMoC框架有效解决了LLM选择问题，通过数据模型双重压缩显著提升效率

Abstract: Large language models (LLMs) excel in general tasks but struggle with
domain-specific ones, requiring fine-tuning with specific data. With many
open-source LLMs available, selecting the best model for fine-tuning downstream
tasks is challenging, primarily focusing on how to quickly identify the optimal
LLM. We introduce a Data and Model Compression Framework (DaMoC) that addresses
this challenge by: 1) Data Level: A systematic categorization of data filtering
methodologies for LLMs is first established, classifying them into three
distinct paradigms: (1) distribution-aware methods, (2) quality-aware methods,
and (3) hybrid approaches considering both dimensions. Further, we enhance the
density of key tokens in the text achieving token compression. Subsequently, we
use an LLM to iterative rewrite the text to optimize its expression. 2) Model
Level: We use layer similarity scores to assess each layer's importance and
remove those with lower importance. Then, we introduce a sparse merging
paradigm to preserve as much of the original model's capability as possible.
Extensive experiments on four datasets, medical Q&A, financial Q&A, general
Q&A, and reading comprehension, show that we can select the optimal LLM while
saving approximately 20-fold in training time.

</details>


### [75] [Rethinking the Chain-of-Thought: The Roles of In-Context Learning and Pre-trained Priors](https://arxiv.org/abs/2509.01236)
*Hao Yang,Zhiyu Yang,Yunjie Zhang,Shanyi Zhu,Lin Yang*

Main category: cs.CL

TL;DR: 本文从上下文学习与预训练先验的双重关系角度，探索了思维链推理的工作机制，通过细粒度词汇分析和噪声样本实验，揭示了模型如何平衡预训练先验与上下文信息。


<details>
  <summary>Details</summary>
Motivation: 尽管思维链推理在增强模型推理能力方面日益重要，但其底层工作机制仍不明确，需要从理论层面深入探究。

Method: 采用细粒度词汇级分析、逐步引入噪声样本实验，以及提示工程诱导慢思考的方法来研究思维链推理机制。

Result: 发现模型能快速学习推理结构和逻辑模式但依赖预训练先验；足够样本可使决策转向上下文信号；长思维链提示能提升下游任务性能。

Conclusion: 思维链推理是预训练先验与上下文学习动态平衡的结果，长推理链能有效诱导慢思考模式，提升模型推理能力。

Abstract: Chain-of-Thought reasoning has emerged as a pivotal methodology for enhancing
model inference capabilities. Despite growing interest in Chain-of-Thought
reasoning, its underlying mechanisms remain unclear. This paper explores the
working mechanisms of Chain-of-Thought reasoning from the perspective of the
dual relationship between in-context learning and pretrained priors. We first
conduct a fine-grained lexical-level analysis of rationales to examine the
model's reasoning behavior. Then, by incrementally introducing noisy exemplars,
we examine how the model balances pretrained priors against erroneous
in-context information. Finally, we investigate whether prompt engineering can
induce slow thinking in large language models. Our extensive experiments reveal
three key findings: (1) The model not only quickly learns the reasoning
structure at the lexical level but also grasps deeper logical reasoning
patterns, yet it heavily relies on pretrained priors. (2) Providing sufficient
exemplars shifts the model's decision-making from pretrained priors to
in-context signals, while misleading prompts introduce instability. (3) Long
Chain-of-Thought prompting can induce the model to generate longer reasoning
chains, thereby improving its performance on downstream tasks.

</details>


### [76] [Annotation and modeling of emotions in a textual corpus: an evaluative approach](https://arxiv.org/abs/2509.01260)
*Jonas Noblet*

Main category: cs.CL

TL;DR: 本文研究基于评估方法标注的情感文本语料，发现虽然人工标注存在显著分歧，但标注过程遵循稳定的统计趋势，语言模型能够建模标注过程并区分情感情境。


<details>
  <summary>Details</summary>
Motivation: 情感是人类社会功能中的关键现象，但在文本表现方面仍是一个开放的研究领域。当前评估方法的情感理论框架未被充分利用，需要探索不同于传统方法的新视角。

Method: 使用基于评估方法手动标注的工业语料库，训练语言模型来分析标注过程。通过统计方法验证标注分歧中的稳定趋势，并探究语言特征对标注变异性的驱动作用。

Result: 研究发现人工标注虽然存在显著分歧，但遵循稳定的统计规律。语言模型能够成功建模标注过程，证明标注变异性是由底层语言特征驱动的。语言模型能够基于评估标准区分不同的情感情境。

Conclusion: 评估方法为情感分析提供了有价值的补充视角。尽管人工标注存在主观差异，但通过统计建模可以捕捉稳定的标注模式。语言模型在理解和区分情感情境方面表现出强大能力，为情感计算研究提供了新思路。

Abstract: Emotion is a crucial phenomenon in the functioning of human beings in
society. However, it remains a widely open subject, particularly in its textual
manifestations. This paper examines an industrial corpus manually annotated
following an evaluative approach to emotion. This theoretical framework, which
is currently underutilized, offers a different perspective that complements
traditional approaches. Noting that the annotations we collected exhibit
significant disagreement, we hypothesized that they nonetheless follow stable
statistical trends. Using language models trained on these annotations, we
demonstrate that it is possible to model the labeling process and that
variability is driven by underlying linguistic features. Conversely, our
results indicate that language models seem capable of distinguishing emotional
situations based on evaluative criteria.

</details>


### [77] [Culture is Everywhere: A Call for Intentionally Cultural Evaluation](https://arxiv.org/abs/2509.01301)
*Juhyun Oh,Inha Cha,Michael Saxon,Hyunseung Lim,Shaily Bhatt,Alice Oh*

Main category: cs.CL

TL;DR: 本文主张从传统的"琐事中心"文化评估范式转向"有意文化评估"，强调需要系统性地审视评估中嵌入的文化假设，而不仅仅是在明确的文化任务中。


<details>
  <summary>Details</summary>
Motivation: 当前LLM文化对齐评估主要采用基于静态事实的多选题或简答题，将文化简化为孤立琐事，忽视了文化的多元性和互动性本质，以及文化假设在看似"中性"评估环境中的渗透。

Method: 提出"有意文化评估"框架，系统分析评估中文化因素的what（什么）、how（如何）和circumstances（情境），强调研究者立场性的重要性，并建议采用HCI启发的参与式方法让社区参与评估设计。

Result: 建立了系统性分析文化因素在评估中作用的理论框架，指出了当前基准测试实践的局限性，并为未来研究方向提供了指导。

Conclusion: 需要超越现有的文化评估范式，采用更加包容和参与式的方法，通过有意文化评估来发现未知的重要应用场景，促进文化对齐的NLP研究发展。

Abstract: The prevailing ``trivia-centered paradigm'' for evaluating the cultural
alignment of large language models (LLMs) is increasingly inadequate as these
models become more advanced and widely deployed. Existing approaches typically
reduce culture to static facts or values, testing models via multiple-choice or
short-answer questions that treat culture as isolated trivia. Such methods
neglect the pluralistic and interactive realities of culture, and overlook how
cultural assumptions permeate even ostensibly ``neutral'' evaluation settings.
In this position paper, we argue for \textbf{intentionally cultural
evaluation}: an approach that systematically examines the cultural assumptions
embedded in all aspects of evaluation, not just in explicitly cultural tasks.
We systematically characterize the what, how, and circumstances by which
culturally contingent considerations arise in evaluation, and emphasize the
importance of researcher positionality for fostering inclusive, culturally
aligned NLP research. Finally, we discuss implications and future directions
for moving beyond current benchmarking practices, discovering important
applications that we don't know exist, and involving communities in evaluation
design through HCI-inspired participatory methodologies.

</details>


### [78] [TableZoomer: A Collaborative Agent Framework for Large-scale Table Question Answering](https://arxiv.org/abs/2509.01312)
*Sishi Xiong,Ziyang He,Zhongjiang He,Yu Zhao,Changzai Pan,Jie Zhang,Zhenhe Wu,Shuangyong Song,Yongxiang Li*

Main category: cs.CL

TL;DR: TableZoomer是一个基于LLM的程序化代理框架，通过结构化表模式、查询感知的表缩放机制和程序化思维策略，显著提升了表格问答任务的性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在表格问答任务中面临的结构异质性、目标数据定位困难和复杂推理瓶颈等工业应用挑战。

Method: 采用结构化表模式替代完全文本化表格，引入查询感知的表缩放机制动态生成子表模式，使用程序化思维策略将查询转换为可执行代码，并结合ReAct范式实现迭代推理。

Result: 在DataBench数据集上比传统PoT方法准确率提升19.34%，在TableBench数据集的事实检查任务上提升25%。

Conclusion: TableZoomer框架在保持可用性优势的同时，显著提升了表格问答任务的性能和可扩展性，适用于不同规模的表格处理。

Abstract: While large language models (LLMs) have shown promise in the table question
answering (TQA) task through prompt engineering, they face challenges in
industrial applications, including structural heterogeneity, difficulties in
target data localization, and bottlenecks in complex reasoning. To address
these limitations, this paper presents TableZoomer, a novel LLM-powered,
programming-based agent framework. It introduces three key innovations: (1)
replacing the original fully verbalized table with structured table schema to
bridge the semantic gap and reduce computational complexity; (2) a query-aware
table zooming mechanism that dynamically generates sub-table schema through
column selection and entity linking, significantly improving target
localization efficiency; and (3) a Program-of-Thoughts (PoT) strategy that
transforms queries into executable code to mitigate numerical hallucination.
Additionally, we integrate the reasoning workflow with the ReAct paradigm to
enable iterative reasoning. Extensive experiments demonstrate that our
framework maintains the usability advantages while substantially enhancing
performance and scalability across tables of varying scales. When implemented
with the Qwen3-8B-Instruct LLM, TableZoomer achieves accuracy improvements of
19.34% and 25% over conventional PoT methods on the large-scale DataBench
dataset and the small-scale Fact Checking task of TableBench dataset,
respectively.

</details>


### [79] [Can Smaller LLMs do better? Unlocking Cross-Domain Potential through Parameter-Efficient Fine-Tuning for Text Summarization](https://arxiv.org/abs/2509.01314)
*Anum Afzal,Mehul Kumawat,Florian Matthes*

Main category: cs.CL

TL;DR: 该论文研究如何利用参数高效微调技术(PEFTs)在资源丰富的数据集上进行训练，以提高在未见低资源领域的文本摘要性能，探索领域内和跨领域适配器的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然通用，但在适应新领域时面临挑战，特别是在低资源领域缺乏标注数据时。传统的全模型微调计算成本高且耗时，需要更高效的领域适应方法。

Method: 使用6种参数高效微调技术(PEFTs)在Llama-3-8B-Instruct模型上，基于14个来自科学、医疗、法律和新闻领域的数据集进行文本摘要任务实验，评估领域内适配器和跨领域适配器的性能。

Result: 实验表明，对于低资源领域，使用领域内适配器的推理性能优于少样本学习，甚至优于更大的Llama-3-70B-Instruct模型。在没有领域内适配器时，跨领域适配器和策略性组合适配器也能利用语言相似性提升性能。

Conclusion: 参数高效微调技术能够有效解决低资源领域的适应问题，领域内适配器表现最佳，跨领域适配器为缺乏目标领域数据时提供了可行的替代方案，通过利用语言共性实现更好的领域适应性。

Abstract: Large Language Models (LLMs), being generic task solvers, are versatile.
However, despite the vast amount of data they are trained on, there are
speculations about their adaptation capabilities to a new domain. Additionally,
the simple fine-tuning of the model to incorporate knowledge of a new domain is
computationally expensive and time-consuming. This becomes more challenging
when the domain in question is also low-resource, and labeled data is
unavailable. We leverage parameter-efficient fine-tuning techniques (PEFTs) on
high-resource datasets to address these challenges to improve performance on
unseen low-resource domains. Throughout our experiments, we evaluate whether
intrinsic linguistic commonalities between datasets can be leveraged for
efficient domain adaptation. We benchmark six PEFTs with
\texttt{Llama-3-8B-Instruct} on 14 training datasets from the Scientific,
Medical, Legal, and News domains for a Text Summarization task. Our experiments
show that for low-resource domains, inference using Within-Domain Adapters can
achieve better performance than Few-Shot as well as a much larger
\texttt{Llama-3-70B-Instruct}. Lastly, in the absence of Within-Domain
Adapters, we explore the concept of using Cross-Domain Adapters as well as the
strategic combinations of adapters to leverage intrinsic language similarities
across domains, facilitating better adaptability and performance in
low-resource settings.

</details>


### [80] [LongCat-Flash Technical Report](https://arxiv.org/abs/2509.01322)
*Meituan LongCat Team,Bayan,Bei Li,Bingye Lei,Bo Wang,Bolin Rong,Chao Wang,Chao Zhang,Chen Gao,Chen Zhang,Cheng Sun,Chengcheng Han,Chenguang Xi,Chi Zhang,Chong Peng,Chuan Qin,Chuyu Zhang,Cong Chen,Congkui Wang,Dan Ma,Daoru Pan,Defei Bu,Dengchang Zhao,Deyang Kong,Dishan Liu,Feiye Huo,Fengcun Li,Fubao Zhang,Gan Dong,Gang Liu,Gang Xu,Ge Li,Guoqiang Tan,Guoyuan Lin,Haihang Jing,Haomin Fu,Haonan Yan,Haoxing Wen,Haozhe Zhao,Hong Liu,Hongmei Shi,Hongyan Hao,Hongyin Tang,Huantian Lv,Hui Su,Jiacheng Li,Jiahao Liu,Jiahuan Li,Jiajun Yang,Jiaming Wang,Jian Yang,Jianchao Tan,Jiaqi Sun,Jiaqi Zhang,Jiawei Fu,Jiawei Yang,Jiaxi Hu,Jiayu Qin,Jingang Wang,Jiyuan He,Jun Kuang,Junhui Mei,Kai Liang,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Liang Gao,Liang Shi,Lianhui Ma,Lin Qiu,Lingbin Kong,Lingtong Si,Linkun Lyu,Linsen Guo,Liqi Yang,Lizhi Yan,Mai Xia,Man Gao,Manyuan Zhang,Meng Zhou,Mengxia Shen,Mingxiang Tuo,Mingyang Zhu,Peiguang Li,Peng Pei,Peng Zhao,Pengcheng Jia,Pingwei Sun,Qi Gu,Qianyun Li,Qingyuan Li,Qiong Huang,Qiyuan Duan,Ran Meng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shizhe Wu,Shuai Liang,Shuo Wang,Suogui Dang,Tao Fang,Tao Li,Tefeng Chen,Tianhao Bai,Tianhao Zhou,Tingwen Xie,Wei He,Wei Huang,Wei Liu,Wei Shi,Wei Wang,Wei Wu,Weikang Zhao,Wen Zan,Wenjie Shi,Xi Nan,Xi Su,Xiang Li,Xiang Mei,Xiangyang Ji,Xiangyu Xi,Xiangzhou Huang,Xianpeng Li,Xiao Fu,Xiao Liu,Xiao Wei,Xiaodong Cai,Xiaolong Chen,Xiaoqing Liu,Xiaotong Li,Xiaowei Shi,Xiaoyu Li,Xili Wang,Xin Chen,Xing Hu,Xingyu Miao,Xinyan He,Xuemiao Zhang,Xueyuan Hao,Xuezhi Cao,Xunliang Cai,Xurui Yang,Yan Feng,Yang Bai,Yang Chen,Yang Yang,Yaqi Huo,Yerui Sun,Yifan Lu,Yifan Zhang,Yipeng Zang,Yitao Zhai,Yiyang Li,Yongjing Yin,Yongkang Lv,Yongwei Zhou,Yu Yang,Yuchen Xie,Yueqing Sun,Yuewen Zheng,Yuhua Wei,Yulei Qian,Yunfan Liang,Yunfang Tai,Yunke Zhao,Zeyang Yu,Zhao Zhang,Zhaohua Yang,Zhenchao Zhang,Zhikang Xia,Zhiye Zou,Zhizhao Zeng,Zhongda Su,Zhuofan Chen,Zijian Zhang,Ziwen Wang,Zixu Jiang,Zizhe Zhao,Zongyu Wang,Zunhai Su*

Main category: cs.CL

TL;DR: LongCat-Flash是一个5600亿参数的MoE语言模型，通过Zero-computation Experts和Shortcut-connected MoE设计实现高效计算和推理，在30天内完成20万亿token训练，推理成本低至每百万输出token 0.70美元，在智能体任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模语言模型在计算效率和可扩展性方面的挑战，同时提升智能体能力，需要设计既能保持高性能又能优化资源使用的模型架构。

Method: 采用两种创新设计：Zero-computation Experts实现动态计算预算分配，Shortcut-connected MoE扩大计算-通信重叠窗口；结合超参数迁移、模型增长初始化、稳定性套件和确定性计算的综合扩展框架；大规模预训练后针对推理、代码和指令进行中后期训练。

Result: 模型在30天内完成20万亿token训练，推理速度超过100 TPS，成本为每百万输出token 0.70美元；在各项评估中表现竞争力强，在智能体任务中表现尤为突出。

Conclusion: LongCat-Flash通过创新的MoE架构设计和高效的训练框架，成功实现了大规模语言模型的高效训练和推理，为智能体智能的发展提供了强有力的基础模型，并已开源促进社区研究。

Abstract: We introduce LongCat-Flash, a 560-billion-parameter Mixture-of-Experts (MoE)
language model designed for both computational efficiency and advanced agentic
capabilities. Stemming from the need for scalable efficiency, LongCat-Flash
adopts two novel designs: (a) Zero-computation Experts, which enables dynamic
computational budget allocation and activates 18.6B-31.3B (27B on average) per
token depending on contextual demands, optimizing resource usage. (b)
Shortcut-connected MoE, which enlarges the computation-communication overlap
window, demonstrating notable gains in inference efficiency and throughput
compared to models of a comparable scale. We develop a comprehensive scaling
framework for large models that combines hyperparameter transfer, model-growth
initialization, a multi-pronged stability suite, and deterministic computation
to achieve stable and reproducible training. Notably, leveraging the synergy
among scalable architectural design and infrastructure efforts, we complete
model training on more than 20 trillion tokens within 30 days, while achieving
over 100 tokens per second (TPS) for inference at a cost of \$0.70 per million
output tokens. To cultivate LongCat-Flash towards agentic intelligence, we
conduct a large-scale pre-training on optimized mixtures, followed by targeted
mid- and post-training on reasoning, code, and instructions, with further
augmentation from synthetic data and tool use tasks. Comprehensive evaluations
demonstrate that, as a non-thinking foundation model, LongCat-Flash delivers
highly competitive performance among other leading models, with exceptional
strengths in agentic tasks. The model checkpoint of LongCat-Flash is
open-sourced to foster community research.
  LongCat Chat: https://longcat.ai
  Hugging Face: https://huggingface.co/meituan-longcat
  GitHub: https://github.com/meituan-longcat

</details>


### [81] [KoBLEX: Open Legal Question Answering with Multi-hop Reasoning](https://arxiv.org/abs/2509.01324)
*Jihyung Lee,Daehui Kim,Seonjeong Hwang,Hyounghun Kim,Gary Lee*

Main category: cs.CL

TL;DR: 提出了韩国法律可解释问答基准KoBLEX和参数化条款引导检索方法ParSeR，用于评估基于法律条款的多跳推理能力，在多项指标上显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有法律评估基准无法有效评估开放式、基于法律条款的问答任务，需要专门针对多跳法律推理的评测体系。

Method: 采用混合LLM-专家流水线构建226个场景化问答实例，提出ParSeR方法通过生成参数化条款进行三阶段顺序检索，并设计LF-Eval自动评估指标。

Result: ParSeR在多个LLM上表现最佳，相比标准检索方法F1分数提升37.91，LF-Eval分数提升30.81，在不同推理深度上均保持稳定性能。

Conclusion: KoBLEX基准和ParSeR方法有效解决了法律领域多跳推理的评估问题，LF-Eval指标与人工评估高度相关，为法律AI发展提供了重要工具。

Abstract: Large Language Models (LLM) have achieved remarkable performances in general
domains and are now extending into the expert domain of law. Several benchmarks
have been proposed to evaluate LLMs' legal capabilities. However, these
benchmarks fail to evaluate open-ended and provision-grounded Question
Answering (QA). To address this, we introduce a Korean Benchmark for Legal
EXplainable QA (KoBLEX), designed to evaluate provision-grounded, multi-hop
legal reasoning. KoBLEX includes 226 scenario-based QA instances and their
supporting provisions, created using a hybrid LLM-human expert pipeline. We
also propose a method called Parametric provision-guided Selection Retrieval
(ParSeR), which uses LLM-generated parametric provisions to guide legally
grounded and reliable answers. ParSeR facilitates multi-hop reasoning on
complex legal questions by generating parametric provisions and employing a
three-stage sequential retrieval process. Furthermore, to better evaluate the
legal fidelity of the generated answers, we propose Legal Fidelity Evaluation
(LF-Eval). LF-Eval is an automatic metric that jointly considers the question,
answer, and supporting provisions and shows a high correlation with human
judgments. Experimental results show that ParSeR consistently outperforms
strong baselines, achieving the best results across multiple LLMs. Notably,
compared to standard retrieval with GPT-4o, ParSeR achieves +37.91 higher F1
and +30.81 higher LF-Eval. Further analyses reveal that ParSeR efficiently
delivers consistent performance across reasoning depths, with ablations
confirming the effectiveness of ParSeR.

</details>


### [82] [Can Large Language Models Master Complex Card Games?](https://arxiv.org/abs/2509.01328)
*Wei Wang,Fuqing Bie,Junzhe Chen,Dan Zhang,Shiyu Huang,Evgeny Kharlamov,Jie Tang*

Main category: cs.CL

TL;DR: LLMs通过高质量游戏数据微调可以接近强游戏AI性能，能同时掌握多种复杂卡牌游戏，但在掌握复杂游戏时通用能力会下降，可通过加入通用指令数据缓解。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在复杂卡牌游戏中的潜力，测试其是否能像AlphaGo等AI在复杂游戏中取得类似成功。

Method: 系统评估LLMs在8种不同卡牌游戏中的学习能力，分析微调对游戏表现的影响，检验模型在掌握游戏时保持通用能力的能力。

Result: LLMs通过监督微调可接近强游戏AI性能；能同时掌握多个复杂卡牌游戏，相似规则游戏有性能增强，不相似游戏存在冲突；掌握复杂游戏时通用能力下降但可通过加入通用指令数据缓解。

Conclusion: 评估结果展示了LLMs强大的学习能力和多用途性，在复杂游戏领域具有显著潜力。

Abstract: Complex games have long been an important benchmark for testing the progress
of artificial intelligence algorithms. AlphaGo, AlphaZero, and MuZero have
defeated top human players in Go and Chess, garnering widespread societal
attention towards artificial intelligence. Concurrently, large language models
(LLMs) have exhibited remarkable capabilities across various tasks, raising the
question of whether LLMs can achieve similar success in complex games. In this
paper, we explore the potential of LLMs in mastering complex card games. We
systematically assess the learning capabilities of LLMs across eight diverse
card games, evaluating the impact of fine-tuning on high-quality gameplay data,
and examining the models' ability to retain general capabilities while
mastering these games. Our findings indicate that: (1) LLMs can approach the
performance of strong game AIs through supervised fine-tuning on high-quality
data, (2) LLMs can master multiple complex card games simultaneously, with
performance augmentation for games with similar rules and conflicts for
dissimilar ones, and (3) LLMs experience a decline in general capabilities when
mastering complex games, but this decline can be mitigated by integrating a
certain amount of general instruction data. The evaluation results demonstrate
strong learning ability and versatility of LLMs.

</details>


### [83] [Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic](https://arxiv.org/abs/2509.01363)
*Mohammad Zbeeb,Hasan Abed Al Kader Hammoud,Bernard Ghanem*

Main category: cs.CL

TL;DR: 通过提取理性任务向量，将GRPO调优的理性能力转移到其他模型，避免重复调优成本


<details>
  <summary>Details</summary>
Motivation: 避免重复调优的高成本，将已学习的理性能力从现有模型中提取并重用

Method: 从GRPO和SFT模型的参数差中提取理性向量，通过简单的向量加法应用到其他模型

Result: 在多个理性测试中持续提升性能（GSM8K +4.9%，HumanEval +4.3%，BigBenchHard +12.3%），减法导致性能显著下降

Conclusion: 理性能力可以通过简单的张量运算提取和转移，为模型增强提供了一种高效实用的方法

Abstract: Large language models often require costly optimization, such as
reinforcement learning, to master complex reasoning tasks. This work
demonstrates that reasoning ability, once learned, can be extracted and
transferred between models as a compact task vector. We source two publicly
available, identically initialized Qwen2.5 models, one fine-tuned with
supervised fine-tuning (SFT) and the other with group relative policy
optimization (GRPO) on the same dataset. From these, we extract a reasoning
vector: $v_{\text{reason}} = \theta_{\text{GRPO}} - \theta_{\text{SFT}}$. We
hypothesize that this vector captures the reasoning capability instilled by
reinforcement learning while factoring out shared knowledge from the SFT
process. When added to compatible instruction-tuned models through simple
arithmetic, this vector consistently improves performance across diverse
reasoning benchmarks: GSM8K (+4.9%), HumanEval (+4.3%), SciQ (+1.7%), and
BigBenchHard (+12.3% for the 1.5B model). The performance improvements persist
under adversarial conditions. Conversely, subtracting the vector causes
significant performance degradation (-11.8% on GSM8K), demonstrating the
vector's strong contribution to the model's reasoning abilities. This work
shows how reasoning capabilities, typically developed through expensive
training, can be extracted from existing open-source models and reused through
simple tensor arithmetic, offering a practical way to enhance models by
recycling prior computational investments.

</details>


### [84] [WATCHED: A Web AI Agent Tool for Combating Hate Speech by Expanding Data](https://arxiv.org/abs/2509.01379)
*Paloma Piot,Diego Sánchez,Javier Parapar*

Main category: cs.CL

TL;DR: WATCHED是一个基于大语言模型的聊天机器人，结合专业工具帮助内容审核员检测和解释仇恨言论，达到0.91的F1分数


<details>
  <summary>Details</summary>
Motivation: 解决数字空间中日益增长的仇恨言论问题，需要结合自动化系统的速度和人类审核员的判断力，建立可解释的审核工具

Method: 构建AI代理系统，使用大语言模型配合专业工具：比对真实仇恨言论示例、BERT分类器标记有害信息、查询俚语词典、生成思维链推理、检查平台指南

Result: 实验结果显示该方法超越现有最先进方法，达到0.91的宏F1分数

Conclusion: 该工具通过支持AI与人类监督的协作，有效减少网络危害，为审核员、安全团队和研究人员提供有力支持

Abstract: Online harms are a growing problem in digital spaces, putting user safety at
risk and reducing trust in social media platforms. One of the most persistent
forms of harm is hate speech. To address this, we need tools that combine the
speed and scale of automated systems with the judgment and insight of human
moderators. These tools should not only find harmful content but also explain
their decisions clearly, helping to build trust and understanding. In this
paper, we present WATCHED, a chatbot designed to support content moderators in
tackling hate speech. The chatbot is built as an Artificial Intelligence Agent
system that uses Large Language Models along with several specialised tools. It
compares new posts with real examples of hate speech and neutral content, uses
a BERT-based classifier to help flag harmful messages, looks up slang and
informal language using sources like Urban Dictionary, generates
chain-of-thought reasoning, and checks platform guidelines to explain and
support its decisions. This combination allows the chatbot not only to detect
hate speech but to explain why content is considered harmful, grounded in both
precedent and policy. Experimental results show that our proposed method
surpasses existing state-of-the-art methods, reaching a macro F1 score of 0.91.
Designed for moderators, safety teams, and researchers, the tool helps reduce
online harms by supporting collaboration between AI and human oversight.

</details>


### [85] [ABCD-LINK: Annotation Bootstrapping for Cross-Document Fine-Grained Links](https://arxiv.org/abs/2509.01387)
*Serwar Basch,Ilia Kuznetsov,Tom Hope,Iryna Gurevych*

Main category: cs.CL

TL;DR: 提出了一个领域无关的框架，用于自动评估和人工标注跨文档链接，在新闻和同行评审领域验证了检索模型与LLM结合的方法效果最佳


<details>
  <summary>Details</summary>
Motivation: 跨文档关系理解对许多应用领域至关重要，但缺乏有效的训练和评估数据集创建方法限制了自动化辅助研究的发展

Method: 首先生成和验证半合成的互联文档数据集，进行自动评估筛选出最佳链接方法，然后在自然文本对上开展广泛的人工评估研究

Result: 在新闻和同行评审两个领域应用该框架，结合检索模型和LLM的方法获得了78%的人工评分者链接批准率，比单独使用强检索器的精确度提高了一倍多

Conclusion: 该框架支持跨应用场景的系统性跨文档理解研究，产生的新数据集为媒体框架分析和同行评审等众多跨文档任务奠定了基础

Abstract: Understanding fine-grained relations between documents is crucial for many
application domains. However, the study of automated assistance is limited by
the lack of efficient methods to create training and evaluation datasets of
cross-document links. To address this, we introduce a new domain-agnostic
framework for selecting a best-performing approach and annotating
cross-document links in a new domain from scratch. We first generate and
validate semi-synthetic datasets of interconnected documents. This data is used
to perform automatic evaluation, producing a shortlist of best-performing
linking approaches. These approaches are then used in an extensive human
evaluation study, yielding performance estimates on natural text pairs. We
apply our framework in two distinct domains -- peer review and news -- and show
that combining retrieval models with LLMs achieves 78\% link approval from
human raters, more than doubling the precision of strong retrievers alone. Our
framework enables systematic study of cross-document understanding across
application scenarios, and the resulting novel datasets lay foundation for
numerous cross-document tasks like media framing and peer review. We make the
code, data, and annotation protocols openly available.

</details>


### [86] [Analysing the Language of Neural Audio Codecs](https://arxiv.org/abs/2509.01390)
*Joonyong Park,Shinnosuke Takamichi,David M. Chan,Shunsuke Kando,Yuki Saito,Hiroshi Saruwatari*

Main category: cs.CL

TL;DR: 研究对深度学习音频编码器产生的语言类代码进行统计特性分析，发现其满足语言统计学定律，且这些特性与语音识别和重构性能正相关


<details>
  <summary>Details</summary>
Motivation: 探索神经音频编码器产生的离散代码的统计特性和语言学规律，以及这些特性如何影响语音识别和重构质量

Method: 对多种NAC模型产生的离散语音代码进行统计分析，检验Zipf定律、Heaps定律、熵和冗余度，并通过语音识别错误率和UTMOS评分评估语义保存和音质质量

Result: NAC代码特别是3-gram显示出类似于自然语言的统计模式，这些统计特性与信息内容量指标一起与语音识别和重构任务的性能提升呈现正相关

Conclusion: 研究结果揭示了NAC代码序列的结构特征，为设计更有效的生成式语音模型提供了重要体系结构和性能预测的见解

Abstract: This study presents a comparative analysis of the statistical and linguistic
properties of neural audio codecs (NACs). We investigate discrete speech tokens
produced by various NAC models, examining their adherence to linguistic
statistical laws such as Zipf's law and Heaps' law, as well as their entropy
and redundancy. To assess how these token-level properties relate to semantic
and acoustic preservation in synthesized speech, we evaluate intelligibility
using error rates of automatic speech recognition, and quality using the UTMOS
score. Our results reveal that NAC tokens, particularly 3-grams, exhibit
language-like statistical patterns. Moreover, these properties, together with
measures of information content, are found to correlate with improved
performances in speech recognition and resynthesis tasks. These findings offer
insights into the structure of NAC token sequences and inform the design of
more effective generative speech models.

</details>


### [87] [LLMs cannot spot math errors, even when allowed to peek into the solution](https://arxiv.org/abs/2509.01395)
*KV Aditya Srivatsa,Kaushal Kumar Maurya,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: LLMs在数学应用题上表现优异，但在元推理任务（如识别学生解题错误）上存在困难。本文研究定位逐步解答中第一个错误步骤的挑战，并提出通过生成中间修正学生解答的方法来改善性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在数学应用题上表现出色，但在识别学生解题错误等元推理任务上仍有困难，需要研究如何准确定位逐步解答中的第一个错误步骤。

Method: 使用VtG和PRM800K两个错误推理数据集进行实验，提出生成中间修正学生解答的方法，使修正方案更贴近原始学生解答，从而提高错误定位性能。

Result: 实验表明，即使提供参考答案，最先进的LLMs也难以准确定位学生解答中的第一个错误步骤。提出的中间修正方法有助于改善性能。

Conclusion: 定位逐步解答中的第一个错误步骤对LLMs具有挑战性，通过生成更贴近原始学生解答的中间修正方案可以有效提升错误定位的准确性。

Abstract: Large language models (LLMs) demonstrate remarkable performance on math word
problems, yet they have been shown to struggle with meta-reasoning tasks such
as identifying errors in student solutions. In this work, we investigate the
challenge of locating the first error step in stepwise solutions using two
error reasoning datasets: VtG and PRM800K. Our experiments show that
state-of-the-art LLMs struggle to locate the first error step in student
solutions even when given access to the reference solution. To that end, we
propose an approach that generates an intermediate corrected student solution,
aligning more closely with the original student's solution, which helps improve
performance.

</details>


### [88] [Vis-CoT: A Human-in-the-Loop Framework for Interactive Visualization and Intervention in LLM Chain-of-Thought Reasoning](https://arxiv.org/abs/2509.01412)
*Kaviraj Pather,Elena Hadjigeorgiou,Arben Krasniqi,Claire Schmit,Irina Rusu,Marc Pons,Kabir Khan*

Main category: cs.CL

TL;DR: Vis-CoT是一个交互式框架，将链式思维文本转换为可视化推理图，允许用户识别错误步骤并进行干预，显著提高LLM推理的准确性和可信度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的链式思维推理过程不透明，难以在高风险场景中进行验证、调试和控制，需要更可靠和可理解的方法。

Method: 开发Vis-CoT框架，将线性CoT文本转换为交互式推理图，支持用户可视化逻辑流程、识别错误步骤、修剪错误路径和嫁接新前提。

Result: 在GSM8K和StrategyQA数据集上，Vis-CoT比非交互式基线提高了最多24个百分点的最终答案准确率，用户研究显示可用性和信任度大幅提升。

Conclusion: Vis-CoT通过结合LLM和针对性人工监督，为实现更可靠、可理解和协作的推理提供了实用路径。

Abstract: Large language models (LLMs) show strong reasoning via chain-of-thought (CoT)
prompting, but the process is opaque, which makes verification, debugging, and
control difficult in high-stakes settings. We present Vis-CoT, a
human-in-the-loop framework that converts linear CoT text into an interactive
reasoning graph. Users can visualize the logical flow, identify flawed steps,
and intervene by pruning incorrect paths and grafting new, user-defined
premises. This shifts interaction from passive observation to active
collaboration, steering models toward more accurate and trustworthy
conclusions. Across GSM8K and StrategyQA, Vis-CoT improves final-answer
accuracy by up to 24 percentage points over non-interactive baselines. A user
study also shows large gains in perceived usability and trust. Vis-CoT points
to a practical path for more reliable, understandable, and collaborative
reasoning by combining LLMs with targeted human oversight.

</details>


### [89] [On the Alignment of Large Language Models with Global Human Opinion](https://arxiv.org/abs/2509.01418)
*Yang Liu,Masahiro Kaneko,Chenhui Chu*

Main category: cs.CL

TL;DR: 本研究创建了一个基于世界价值观调查的评估框架，系统评估LLMs在不同国家、语言和历史时期与人类意见的对齐情况，发现LLMs仅与少数国家适当或过度对齐，而与大多数国家对齐不足，同时提示语言改变能有效引导LLMs更好地与对应国家意见对齐。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注美国或少数国家的人口群体意见，缺乏全球国家样本、不同历史时期人类意见研究，以及使用语言引导LLMs的讨论，同时忽视了提示语言对LLMs意见对齐的潜在影响。

Method: 基于世界价值观调查(WVS)创建评估框架，系统评估LLMs在全球不同国家、语言和历史时期与人类意见的对齐情况。

Result: LLMs仅与少数国家适当或过度对齐意见，而与大多数国家对齐不足；改变提示语言以匹配问卷语言能比现有引导方法更有效地使LLMs与对应国家意见对齐；LLMs更符合当代人群的意见。

Conclusion: 这是首个在全球、语言和时间维度上全面调查LLMs意见对齐主题的研究，填补了现有研究的空白，为理解LLMs在不同语言和文化背景下的意见表达提供了重要见解。

Abstract: Today's large language models (LLMs) are capable of supporting multilingual
scenarios, allowing users to interact with LLMs in their native languages. When
LLMs respond to subjective questions posed by users, they are expected to align
with the views of specific demographic groups or historical periods, shaped by
the language in which the user interacts with the model. Existing studies
mainly focus on researching the opinions represented by LLMs among demographic
groups in the United States or a few countries, lacking worldwide country
samples and studies on human opinions in different historical periods, as well
as lacking discussion on using language to steer LLMs. Moreover, they also
overlook the potential influence of prompt language on the alignment of LLMs'
opinions. In this study, our goal is to fill these gaps. To this end, we create
an evaluation framework based on the World Values Survey (WVS) to
systematically assess the alignment of LLMs with human opinions across
different countries, languages, and historical periods around the world. We
find that LLMs appropriately or over-align the opinions with only a few
countries while under-aligning the opinions with most countries. Furthermore,
changing the language of the prompt to match the language used in the
questionnaire can effectively steer LLMs to align with the opinions of the
corresponding country more effectively than existing steering methods. At the
same time, LLMs are more aligned with the opinions of the contemporary
population. To our knowledge, our study is the first comprehensive
investigation of the topic of opinion alignment in LLMs across global,
language, and temporal dimensions. Our code and data are publicly available at
https://github.com/nlply/global-opinion-alignment.

</details>


### [90] [Trusted Uncertainty in Large Language Models: A Unified Framework for Confidence Calibration and Risk-Controlled Refusal](https://arxiv.org/abs/2509.01455)
*Markus Oehri,Giulia Conti,Kaviraj Pather,Alexandre Rossi,Laia Serra,Adrian Parody,Rogvi Johannesen,Aviaja Petersen,Arben Krasniqi*

Main category: cs.CL

TL;DR: UniCR是一个统一框架，将多种不确定性证据转换为校准后的正确概率，并通过原则性拒绝来执行用户指定的错误预算，提高语言模型的可信度。


<details>
  <summary>Details</summary>
Motivation: 部署的语言模型需要决定何时回答、何时不回答，以避免错误回答。现有方法往往缺乏统一的证据融合和风险控制机制。

Method: 使用温度缩放和适当评分学习轻量级校准头，支持黑盒模型，利用符合风险控制提供分布无关保证，通过检索证据监督原子事实性得分来对齐长文本生成的置信度。

Result: 在短问答、代码生成和检索增强长问答任务中，校准指标持续改进，风险-覆盖率曲线下面积降低，固定风险下覆盖率更高。

Conclusion: UniCR提供了一个可移植的证据融合到校准概率再到风险控制决策的解决方案，无需微调基础模型，在分布偏移下仍有效，显著提升了模型可信度。

Abstract: Deployed language models must decide not only what to answer but also when
not to answer. We present UniCR, a unified framework that turns heterogeneous
uncertainty evidence including sequence likelihoods, self-consistency
dispersion, retrieval compatibility, and tool or verifier feedback into a
calibrated probability of correctness and then enforces a user-specified error
budget via principled refusal. UniCR learns a lightweight calibration head with
temperature scaling and proper scoring, supports API-only models through
black-box features, and offers distribution-free guarantees using conformal
risk control. For long-form generation, we align confidence with semantic
fidelity by supervising on atomic factuality scores derived from retrieved
evidence, reducing confident hallucinations while preserving coverage.
Experiments on short-form QA, code generation with execution tests, and
retrieval-augmented long-form QA show consistent improvements in calibration
metrics, lower area under the risk-coverage curve, and higher coverage at fixed
risk compared to entropy or logit thresholds, post-hoc calibrators, and
end-to-end selective baselines. Analyses reveal that evidence contradiction,
semantic dispersion, and tool inconsistency are the dominant drivers of
abstention, yielding informative user-facing refusal messages. The result is a
portable recipe of evidence fusion to calibrated probability to risk-controlled
decision that improves trustworthiness without fine-tuning the base model and
remains valid under distribution shift.

</details>


### [91] [Robust Knowledge Editing via Explicit Reasoning Chains for Distractor-Resilient Multi-Hop QA](https://arxiv.org/abs/2509.01468)
*Yuchen Wu,Liang Ding,Li Shen,Dacheng Tao*

Main category: cs.CL

TL;DR: Reason-KE是一个端到端的基于推理链的知识编辑框架，通过四个结构化阶段引导LLM在单次处理中过滤干扰信息，显著提升多跳问答准确率至90.2%，在强干扰下仅下降6.3%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练后知识静态化，完整重训练成本高昂。现有知识编辑技术要么过度依赖表面线索，要么在噪声多跳条件下复杂的迭代流程会崩溃。

Method: 提出Reason-KE框架，通过四个结构化阶段（事实确认、相关性判定、选择性应用和最终推理）引导预训练LLM在单次处理中过滤干扰信息。在MQuAKE-CF数据集上训练，最多包含四个无关事实。

Result: 将Qwen2.5-7B的多跳问答准确率提升至90.2%，在强干扰下仅下降6.3%，答案泄露时下降<1%。定量分析证实了其鲁棒性和效率。

Conclusion: Reason-KE建立了可靠LLM知识更新的新state-of-the-art，展示了在噪声多跳条件下的优异表现和效率。

Abstract: Large language models (LLMs) encode vast amounts of world knowledge but
remain static once trained, making the timely integration of emerging facts
prohibitively expensive via full retraining. Knowledge-editing techniques have
thus emerged to inject or overwrite specific facts into LLMs, yet they either
over-rely on superficial cues or incur complex, iterative pipelines that
collapse under noisy, multi-hop conditions. We introduce Reason-KE, an
end-to-end reasoning-chain-based editing framework that steers a pretrained LLM
through four structured stages-fact acknowledgment, relevance determination,
selective application, and final reasoning-to filter distractors in a single
pass. Trained on MQuAKE-CF with up to four irrelevant facts, Reason-KE elevates
Qwen2.5-7B's multi-hop QA accuracy to 90.2% while suffering merely a 6.3% drop
under heavy distraction and <1% when answers are leaked. Our quantitative
analysis confirms Reason-KE's resilience and efficiency, establishing a new
state-of-the-art for reliable LLM knowledge updates.

</details>


### [92] [Do Retrieval Augmented Language Models Know When They Don't Know?](https://arxiv.org/abs/2509.01476)
*Youchao Zhou,Heyan Huang,Yicheng Liu,Rui Dai,Xinglin Wang,Xingchen Zhang,Shumin Shi,Yang Deng*

Main category: cs.CL

TL;DR: 本研究探讨了检索增强语言模型(RALMs)的拒绝能力，发现LLMs存在显著过度拒绝行为，研究了不同后训练方法对过度拒绝问题的影响，并提出了一种简单有效的拒绝方法来提高答案质量。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型会产生事实错误的幻觉，研究者主要使用检索增强语言模型和拒绝后训练两种方法，但当前研究忽视了RALMs拒绝能力的评估，需要探讨RALMs是否知道何时不知道。

Method: 通过分析不同内部和外部知识状态下RALMs的校准情况，研究拒绝后训练对过度拒绝问题的影响，测试Refusal-aware Instruction Tuning和In-Context Fine-tuning方法，并开发新的拒绝方法。

Result: 发现LLMs存在显著过度拒绝行为；In-context fine-tuning能缓解过度拒绝问题，但R-tuning会加剧该问题；拒绝能力可能与答案质量存在冲突。

Conclusion: 研究开发了简单有效的拒绝方法来提高拒绝后训练模型的整体答案质量，为理解重要因素对RALM系统的影响提供了更全面的认识。

Abstract: Existing Large Language Models (LLMs) occasionally generate plausible yet
factually incorrect responses, known as hallucinations. Researchers are
primarily using two approaches to mitigate hallucinations, namely Retrieval
Augmented Language Models (RALMs) and refusal post-training. However, current
research predominantly emphasizes their individual effectiveness while
overlooking the evaluation of the refusal capability of RALMs. In this study,
we ask the fundamental question: Do RALMs know when they don't know?
Specifically, we ask three questions. First, are RALMs well-calibrated
regarding different internal and external knowledge states? We examine the
influence of various factors. Contrary to expectations, we find that LLMs
exhibit significant \textbf{over-refusal} behavior. Then, how does refusal
post-training affect the over-refusal issue? We investigate the Refusal-aware
Instruction Tuning and In-Context Fine-tuning methods. Our results show that
the over-refusal problem is mitigated by In-context fine-tuning. but magnified
by R-tuning. However, we also find that the refusal ability may conflict with
the quality of the answer. Finally, we develop a simple yet effective refusal
method for refusal post-trained models to improve their overall answer quality
in terms of refusal and correct answers. Our study provides a more
comprehensive understanding of the influence of important factors on RALM
systems.

</details>


### [93] [MeVe: A Modular System for Memory Verification and Effective Context Control in Language Models](https://arxiv.org/abs/2509.01514)
*Andreas Ottem*

Main category: cs.CL

TL;DR: MeVe是一个新颖的模块化RAG架构，通过五阶段设计实现内存验证和智能上下文组合，显著提高了上下文效率，在Wikipedia数据集上减少57%，在HotpotQA上减少75%的上下文使用。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统采用简单的top-k语义搜索机制，经常导致包含不相关或冗余信息，从而降低性能和处理效率。

Method: 提出五阶段模块化设计：初始检索、相关性验证、备用检索、上下文优先级排序和token预算管理，实现细粒度控制和任务依赖的过滤适配。

Result: 在知识密集型QA任务上评估，相比标准RAG实现，在Wikipedia数据集上减少57%的上下文使用，在更复杂的HotpotQA数据集上减少75%。

Conclusion: MeVe通过主动验证信息和精炼上下文，为更可扩展和可靠的LLM应用提供了框架，实现了更好的基础支持和更准确的事实支撑。

Abstract: Retrieval-Augmented Generation (RAG) systems typically face constraints
because of their inherent mechanism: a simple top-k semantic search [1]. The
approach often leads to the incorporation of irrelevant or redundant
information in the context, degrading performance and efficiency [10][11]. This
paper presents MeVe, a novel modular architecture intended for Memory
Verification and smart context composition. MeVe rethinks the RAG paradigm by
proposing a five-phase modular design that distinctly breaks down the retrieval
and context composition process into distinct, auditable, and independently
tunable phases: initial retrieval, relevance verification, fallback retrieval,
context prioritization, and token budgeting. This architecture enables
fine-grained control of what knowledge is made available to an LLM, enabling
task-dependent filtering and adaptation. We release a reference implementation
of MeVe as a proof of concept and evaluate its performance on knowledge-heavy
QA tasks over a subset of English Wikipedia [22]. Our results demonstrate that
by actively verifying information before composition, MeVe significantly
improves context efficiency, achieving a 57% reduction on the Wikipedia dataset
and a 75% reduction on the more complex HotpotQA dataset compared to standard
RAG implementations [25]. This work provides a framework for more scalable and
reliable LLM applications. By refining and distilling contextual information,
MeVe offers a path toward better grounding and more accurate factual support
[16].

</details>


### [94] [Service, Solidarity, and Self-Help: A Comparative Topic Modeling Analysis of Community Unionism in the Boot and Shoe Union and Unite Community](https://arxiv.org/abs/2509.01529)
*Thomas Compton*

Main category: cs.CL

TL;DR: 本文通过BERTopic和词频分析比较了两个不同时期社区工会模式，发现Unite Community更紧密对准社会正义主题，而股靴工会则以传统服务模式为主，说明社区工会模式在不同时期和部门间存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于比较不同历史时期和组织背景下社区工会模式的话语对齐程度，以验证社区工会模式在不同时代和部门的连续性和普遍性假设。

Method: 采用BERTopic主题建模和cTF-IDF权重方法，结合词频分析，对两个工会的话语进行定量分析。

Result: 结果显示两个工会在主题重点和话语一致性上存在显著差异：Unite Community更外向化、重视社会正义主题，而股靴工会则以内部管理、工业关系和成员服务为主。

Conclusion: 研究结论表明，虽然两个工会都涉及社区相关主题，但它们的参与模式存在显著差异，这挖成了对社区工会模式在不同时期和部门间连续性和普遍性的假设。同时证明了现代NLP技术在历史劳工档案研究中的应用价值。

Abstract: This paper presents a comparative analysis of community unionism (CU) in two
distinct historical and organizational contexts: the National Boot and Shoe
Union (B\&S) in the 1920s and Unite Community in the 2010s--2020s. Using
BERTopic for thematic modeling and cTF-IDF weighting, alongside word frequency
analysis, the study examines the extent to which each union's discourse aligns
with key features of CU -- such as coalition-building, grassroots engagement,
and action beyond the workplace. The results reveal significant differences in
thematic focus and discursive coherence. While Unite Community demonstrates
stronger alignment with outward-facing, social justice-oriented themes, the
B\&S corpus emphasizes internal administration, industrial relations, and
member services -- reflecting a more traditional, servicing-oriented union
model. The analysis also highlights methodological insights, demonstrating how
modern NLP techniques can enhance the study of historical labor archives.
Ultimately, the findings suggest that while both unions engage with
community-related themes, their underlying models of engagement diverge
significantly, challenging assumptions about the continuity and universality of
community unionism across time and sector.

</details>


### [95] [CAT: Causal Attention Tuning For Injecting Fine-grained Causal Knowledge into Large Language Models](https://arxiv.org/abs/2509.01535)
*Kairong Han,Wenshuo Zhao,Ziyu Zhao,JunJian Ye,Lujia Pan,Kun Kuang*

Main category: cs.CL

TL;DR: 本文提出Causal Attention Tuning (CAT)方法，通过将细粒度因果知识注入注意力机制，解决LLMs在OOD场景下因捕捉伪相关而非真实因果关系导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLMs)在大规模数据训练中往往捕捉的是伪相关而非真实的因果关系，导致在分布外(OOD)场景下性能不佳。需要探索LLMs是否能有效利用因果知识进行预测和生成。

Method: 提出Causal Attention Tuning (CAT)方法：1) 利用人类先验自动生成token级别的因果信号；2) 引入Re-Attention机制指导训练，使模型关注因果结构同时减轻注意力分数中的噪声和偏差。

Result: 在提出的Spurious Token Game (STG)基准测试和多个下游任务上的实验结果表明，该方法能有效利用因果知识进行预测，并在OOD场景下保持鲁棒性。

Conclusion: CAT方法成功地将因果知识注入LLMs的注意力机制，显著提升了模型在因果推理和OOD泛化方面的性能，为解决LLMs中的伪相关问题提供了有效方案。

Abstract: Large Language Models (LLMs) have achieved remarkable success across various
domains. However, a fundamental question remains: Can LLMs effectively utilize
causal knowledge for prediction and generation? Through empirical studies, we
find that LLMs trained directly on large-scale data often capture spurious
correlations rather than true causal relationships, leading to suboptimal
performance, especially in out-of-distribution (OOD) scenarios. To address this
challenge, we propose Causal Attention Tuning (CAT), a novel approach that
injects fine-grained causal knowledge into the attention mechanism. We propose
an automated pipeline that leverages human priors to automatically generate
token-level causal signals and introduce the Re-Attention mechanism to guide
training, helping the model focus on causal structures while mitigating noise
and biases in attention scores. Experimental results on our proposed Spurious
Token Game (STG) benchmark and multiple downstream tasks demonstrate that our
approach effectively leverages causal knowledge for prediction and remains
robust in OOD scenarios. Implementation details can be found at
https://github.com/Kairong-Han/CAT.

</details>


### [96] [In-N-Out: A Parameter-Level API Graph Dataset for Tool Agents](https://arxiv.org/abs/2509.01560)
*Seungkyu Lee,Nalim Kim,Yohan Jo*

Main category: cs.CL

TL;DR: 本文提出了In-N-Out数据集，通过将API文档转换为结构化API图来改善工具代理在多工具查询中的性能，显著提升了API检索和组合调用能力。


<details>
  <summary>Details</summary>
Motivation: 随着任务复杂性增加，基于LLM的工具代理难以正确识别和按顺序调用API，需要更好的方法来理解API依赖关系。

Method: 将API文档转换为结构化API图，构建专家标注的API图数据集In-N-Out，并利用该数据集进行模型微调。

Result: 使用In-N-Out数据集后，工具检索和多工具查询生成的性能几乎翻倍，微调模型能够填补90%的性能差距。

Conclusion: 显式API图对工具代理具有重要价值，In-N-Out数据集是理解API文档和参数关系的宝贵资源。

Abstract: Tool agents -- LLM-based systems that interact with external APIs -- offer a
way to execute real-world tasks. However, as tasks become increasingly complex,
these agents struggle to identify and call the correct APIs in the proper
order. To tackle this problem, we investigate converting API documentation into
a structured API graph that captures API dependencies and leveraging it for
multi-tool queries that require compositional API calls. To support this, we
introduce In-N-Out, the first expert-annotated dataset of API graphs built from
two real-world API benchmarks and their documentation. Using In-N-Out
significantly improves performance on both tool retrieval and multi-tool query
generation, nearly doubling that of LLMs using documentation alone. Moreover,
graphs generated by models fine-tuned on In-N-Out close 90% of this gap,
showing that our dataset helps models learn to comprehend API documentation and
parameter relationships. Our findings highlight the promise of using explicit
API graphs for tool agents and the utility of In-N-Out as a valuable resource.
We will release the dataset and code publicly.

</details>


### [97] [Enhancing Uncertainty Estimation in LLMs with Expectation of Aggregated Internal Belief](https://arxiv.org/abs/2509.01564)
*Zeguan Xiao,Diyang Dou,Boya Xiong,Yun Chen,Guanhua Chen*

Main category: cs.CL

TL;DR: EAGLE是一种基于自评估的校准方法，通过聚合LLM内部隐藏状态的多层信念来生成更准确的置信度分数，显著改善了模型校准性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在RLHF后经常表现出过度自信，生成看似合理但错误的答案，这给可靠的uncertainty estimation和安全部署带来了重大挑战

Method: 提出EAGLE方法，从自评估过程中提取多个中间层的内部信念，聚合这些层间信念并计算置信度分数分布的期望值

Result: 在多个数据集和LLM上的广泛实验表明，EAGLE显著优于现有基线方法的校准性能

Conclusion: EAGLE通过利用模型内部隐藏状态提供更准确的置信度评估，为LLM的可靠不确定性估计提供了有效解决方案

Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide
range of natural language tasks, but often exhibit overconfidence and generate
plausible yet incorrect answers. This overconfidence, especially in models
undergone Reinforcement Learning from Human Feedback (RLHF), poses significant
challenges for reliable uncertainty estimation and safe deployment. In this
paper, we propose EAGLE (Expectation of AGgregated internaL bEief), a novel
self-evaluation-based calibration method that leverages the internal hidden
states of LLMs to derive more accurate confidence scores. Instead of relying on
the model's final output, our approach extracts internal beliefs from multiple
intermediate layers during self-evaluation. By aggregating these layer-wise
beliefs and calculating the expectation over the resulting confidence score
distribution, EAGLE produces a refined confidence score that more faithfully
reflects the model's internal certainty. Extensive experiments on diverse
datasets and LLMs demonstrate that EAGLE significantly improves calibration
performance over existing baselines. We also provide an in-depth analysis of
EAGLE, including a layer-wise examination of uncertainty patterns, a study of
the impact of self-evaluation prompts, and an analysis of the effect of
self-evaluation score range.

</details>


### [98] [Testing the assumptions about the geometry of sentence embedding spaces: the cosine measure need not apply](https://arxiv.org/abs/2509.01606)
*Vivi Nastase,Paola Merlo*

Main category: cs.CL

TL;DR: 研究发现句子嵌入空间中的几何距离并不能预测其在具体任务上的性能表现，语言信息是通过不同维度的加权组合编码的，而非反映在嵌入空间的几何结构中。


<details>
  <summary>Details</summary>
Motivation: 探究句子嵌入空间中距离相近是否意味着共享相似属性，以及这种几何关系是否能预测句子嵌入在不同任务上的相对性能。

Method: 通过三种方式计算句子嵌入：平均词嵌入、特殊[CLS]标记嵌入和随机词嵌入，分析这些变体之间的距离与语言任务性能的相关性。

Result: 余弦相似度只能捕捉句子嵌入之间的浅层共性或差异，这些差异不能预测具体任务性能。语言信息是通过不同维度的加权组合编码的。

Conclusion: 句子嵌入空间的几何结构不能有效预测其任务性能，语言信息的编码方式比简单的几何距离关系更为复杂和深层。

Abstract: Transformer models learn to encode and decode an input text, and produce
contextual token embeddings as a side-effect. The mapping from language into
the embedding space maps words expressing similar concepts onto points that are
close in the space. In practice, the reverse implication is also assumed: words
corresponding to close points in this space are similar or related, those that
are further are not.
  Does closeness in the embedding space extend to shared properties for
sentence embeddings? We present an investigation of sentence embeddings and
show that the geometry of their embedding space is not predictive of their
relative performances on a variety of tasks.
  We compute sentence embeddings in three ways: as averaged token embeddings,
as the embedding of the special [CLS] token, and as the embedding of a random
token from the sentence. We explore whether there is a correlation between the
distance between sentence embedding variations and their performance on
linguistic tasks, and whether despite their distances, they do encode the same
information in the same manner.
  The results show that the cosine similarity -- which treats dimensions
shallowly -- captures (shallow) commonalities or differences between sentence
embeddings, which are not predictive of their performance on specific tasks.
Linguistic information is rather encoded in weighted combinations of different
dimensions, which are not reflected in the geometry of the sentence embedding
space.

</details>


### [99] [Benchmarking the Detection of LLMs-Generated Modern Chinese Poetry](https://arxiv.org/abs/2509.01620)
*Shanshan Wang,Junchao Wu,Fengying Ye,Jingming Yao,Lidia S. Chao,Derek F. Wong*

Main category: cs.CL

TL;DR: 本文提出了一个新的基准测试集，用于检测大语言模型生成的现代诗歌，实验结果显示当前检测器无法可靠识别AI生成的现代诗歌。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，AI生成文本与人类文本难以区分，而现代诗歌检测领域存在空白，AI生成诗歌的流行严重干扰了诗歌生态系统。

Method: 首先构建了高质量数据集，包含6位专业诗人的800首诗歌和4个主流LLMs生成的41,600首诗歌，然后系统性评估了6个检测器在这个数据集上的性能。

Result: 实验结果显示当前检测器无法作为可靠工具检测LLMs生成的现代诗歌，最难检测的诗歌特征是内在品质（特别是风格）。

Conclusion: 这项工作为未来AI生成诗歌的检测奠定了基础，所提出的基准测试集验证了其有效性和必要性。

Abstract: The rapid development of advanced large language models (LLMs) has made
AI-generated text indistinguishable from human-written text. Previous work on
detecting AI-generated text has made effective progress, but has not involved
modern Chinese poetry. Due to the distinctive characteristics of modern Chinese
poetry, it is difficult to identify whether a poem originated from humans or
AI. The proliferation of AI-generated modern Chinese poetry has significantly
disrupted the poetry ecosystem. Based on the urgency of identifying
AI-generated poetry in the real Chinese world, this paper proposes a novel
benchmark for detecting LLMs-generated modern Chinese poetry. We first
construct a high-quality dataset, which includes both 800 poems written by six
professional poets and 41,600 poems generated by four mainstream LLMs.
Subsequently, we conduct systematic performance assessments of six detectors on
this dataset. Experimental results demonstrate that current detectors cannot be
used as reliable tools to detect modern Chinese poems generated by LLMs. The
most difficult poetic features to detect are intrinsic qualities, especially
style. The detection results verify the effectiveness and necessity of our
proposed benchmark. Our work lays a foundation for future detection of
AI-generated poetry.

</details>


### [100] [TransGAT: Transformer-Based Graph Neural Networks for Multi-Dimensional Automated Essay Scoring](https://arxiv.org/abs/2509.01640)
*Hind Aljuaid,Areej Alhothali,Ohoud Al-Zamzami,Hussein Assalahi*

Main category: cs.CL

TL;DR: TransGAT模型结合微调Transformer和图注意力网络，用于自动化作文分析评分，在ELLIPSE数据集上表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统人工评分耗时且不一致，现有自动化评分方法使用静态词嵌入无法捕捉上下文语义，且多采用整体评分而忽略具体写作维度。

Method: 提出TransGAT方法，将微调Transformer（BERT、RoBERTa、DeBERTaV3）与图注意力网络配对，进行双流预测：一流生成文章级预测，二流对Transformer词嵌入应用GAT（基于句法依赖构建边），最后融合两流预测。

Result: 在ELLIPSE数据集上，TransGAT平均二次加权Kappa达到0.854，在所有分析评分维度上均优于基线模型。

Conclusion: TransGAT展示了结合Transformer上下文理解能力和GAT关系建模优势的潜力，可推动自动化作文评分系统发展。

Abstract: Essay writing is a critical component of student assessment, yet manual
scoring is labor-intensive and inconsistent. Automated Essay Scoring (AES)
offers a promising alternative, but current approaches face limitations. Recent
studies have incorporated Graph Neural Networks (GNNs) into AES using static
word embeddings that fail to capture contextual meaning, especially for
polysemous words. Additionally, many methods rely on holistic scoring,
overlooking specific writing aspects such as grammar, vocabulary, and cohesion.
To address these challenges, this study proposes TransGAT, a novel approach
that integrates fine-tuned Transformer models with GNNs for analytic scoring.
TransGAT combines the contextual understanding of Transformers with the
relational modeling strength of Graph Attention Networks (GAT). It performs
two-stream predictions by pairing each fine-tuned Transformer (BERT, RoBERTa,
and DeBERTaV3) with a separate GAT. In each pair, the first stream generates
essay-level predictions, while the second applies GAT to Transformer token
embeddings, with edges constructed from syntactic dependencies. The model then
fuses predictions from both streams to produce the final analytic score.
Experiments on the ELLIPSE dataset show that TransGAT outperforms baseline
models, achieving an average Quadratic Weighted Kappa (QWK) of 0.854 across all
analytic scoring dimensions. These findings highlight the potential of TransGAT
to advance AES systems.

</details>


### [101] [Parallel Needleman-Wunsch on CUDA to measure word similarity based on phonetic transcriptions](https://arxiv.org/abs/2509.01654)
*Dominic Plein*

Main category: cs.CL

TL;DR: 基于Needleman-Wunsch算法计算词语语音相似度，使用Rust实现并利用CPU/GPU并行处理，通过构建全连接图和聚类分析验证方法有效性


<details>
  <summary>Details</summary>
Motivation: 需要一种高效的方法来分析词语之间的语音相似性，以便研究语言的语音结构特征

Method: 使用Needleman-Wunsch算法计算语音转录的相似度，在Rust中实现并利用CUDA和cudarc库进行CPU和GPU并行化处理，构建全连接图并通过聚类算法分析

Result: 方法在处理大规模数据集时表现出高效性，GPU实现带来显著性能提升，成功识别出语音相似的词语群组

Conclusion: 提出的方法在分析语言语音结构方面具有可行性和有效性，且易于扩展到其他语言

Abstract: We present a method to calculate the similarity between words based on their
phonetic transcription (their pronunciation) using the Needleman-Wunsch
algorithm. We implement this algorithm in Rust and parallelize it on both CPU
and GPU to handle large datasets efficiently. The GPU implementation leverages
CUDA and the cudarc Rust library to achieve significant performance
improvements. We validate our approach by constructing a fully-connected graph
where nodes represent words and edges have weights according to the similarity
between the words. This graph is then analyzed using clustering algorithms to
identify groups of phonetically similar words. Our results demonstrate the
feasibility and effectiveness of the proposed method in analyzing the phonetic
structure of languages. It might be easily expanded to other languages.

</details>


### [102] [Bridging Thoughts and Words: Graph-Based Intent-Semantic Joint Learning for Fake News Detection](https://arxiv.org/abs/2509.01660)
*Zhengjia Wang,Qiang Sheng,Danding Wang,Beizhe Hu,Juan Cao*

Main category: cs.CL

TL;DR: 本文提出InSide模型，通过图神经网络联合建模新闻语义和意图信号，在四个基准数据集上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有假新闻检测方法主要依赖语义线索（如情感词、文体特征），容易陷入表面模式检测，在动态环境中性能有限。本文从新闻意图的新视角出发，认为结合意图可以更深入理解新闻欺骗的内在思想

Method: 提出基于图的意图-语义联合建模（InSide）方法：1）将语义和意图信号重构为异构图结构；2）通过实体引导实现长距离上下文交互；3）通过粗到细的意图建模捕获整体和实施层面的意图；4）开发基于动态路径的图对齐策略，在共同空间中进行有效消息传递和聚合

Result: 在四个基准数据集上的大量实验证明了所提出InSide方法相比最先进方法的优越性

Conclusion: 通过联合建模新闻语义和意图信号，InSide方法能够更有效地检测假新闻，解决了现有方法过度依赖表面语义模式的问题

Abstract: Fake news detection is an important and challenging task for defending online
information integrity. Existing state-of-the-art approaches typically extract
news semantic clues, such as writing patterns that include emotional words,
stylistic features, etc. However, detectors tuned solely to such semantic clues
can easily fall into surface detection patterns, which can shift rapidly in
dynamic environments, leading to limited performance in the evolving news
landscape. To address this issue, this paper investigates a novel perspective
by incorporating news intent into fake news detection, bridging intents and
semantics together. The core insight is that by considering news intents, one
can deeply understand the inherent thoughts behind news deception, rather than
the surface patterns within words alone. To achieve this goal, we propose
Graph-based Intent-Semantic Joint Modeling (InSide) for fake news detection,
which models deception clues from both semantic and intent signals via
graph-based joint learning. Specifically, InSide reformulates news semantic and
intent signals into heterogeneous graph structures, enabling long-range context
interaction through entity guidance and capturing both holistic and
implementation-level intent via coarse-to-fine intent modeling. To achieve
better alignment between semantics and intents, we further develop a dynamic
pathway-based graph alignment strategy for effective message passing and
aggregation across these signals by establishing a common space. Extensive
experiments on four benchmark datasets demonstrate the superiority of the
proposed InSide compared to state-of-the-art methods.

</details>


### [103] [chDzDT: Word-level morphology-aware language model for Algerian social media text](https://arxiv.org/abs/2509.01772)
*Abdelkrime Aries*

Main category: cs.CL

TL;DR: 提出了chDzDT，一个面向阿尔及利亚方言的字符级预训练语言模型，专门处理该方言复杂的形态学特征和多语言混合问题


<details>
  <summary>Details</summary>
Motivation: 阿尔及利亚方言在自然语言处理中代表性不足，其复杂的形态学、频繁的语码转换、多文字系统和强词汇影响使得传统词级或子词级方法效果不佳

Method: 开发字符级预训练模型chDzDT，在孤立词上进行训练，不依赖分词边界或标准化拼写。训练语料来自YouTube评论、多语言维基百科和Tatoeba项目，涵盖多种文字和语言变体

Result: 构建了阿尔及利亚方言的多语言词典数据集，开发了专注于形态学编码的字符级PLM，为下游任务提供有效编码器

Conclusion: 字符级建模对于形态丰富、资源稀缺的方言具有巨大潜力，为构建更具包容性和适应性的NLP系统奠定了基础

Abstract: Pre-trained language models (PLMs) have substantially advanced natural
language processing by providing context-sensitive text representations.
However, the Algerian dialect remains under-represented, with few dedicated
models available. Processing this dialect is challenging due to its complex
morphology, frequent code-switching, multiple scripts, and strong lexical
influences from other languages. These characteristics complicate tokenization
and reduce the effectiveness of conventional word- or subword-level approaches.
  To address this gap, we introduce chDzDT, a character-level pre-trained
language model tailored for Algerian morphology. Unlike conventional PLMs that
rely on token sequences, chDzDT is trained on isolated words. This design
allows the model to encode morphological patterns robustly, without depending
on token boundaries or standardized orthography. The training corpus draws from
diverse sources, including YouTube comments, French, English, and Berber
Wikipedia, as well as the Tatoeba project. It covers multiple scripts and
linguistic varieties, resulting in a substantial pre-training workload.
  Our contributions are threefold: (i) a detailed morphological analysis of
Algerian dialect using YouTube comments; (ii) the construction of a
multilingual Algerian lexicon dataset; and (iii) the development and extensive
evaluation of a character-level PLM as a morphology-focused encoder for
downstream tasks. The proposed approach demonstrates the potential of
character-level modeling for morphologically rich, low-resource dialects and
lays a foundation for more inclusive and adaptable NLP systems.

</details>


### [104] [Flaw or Artifact? Rethinking Prompt Sensitivity in Evaluating LLMs](https://arxiv.org/abs/2509.01790)
*Andong Hua,Kenan Tang,Chenhe Gu,Jindong Gu,Eric Wong,Yao Qin*

Main category: cs.CL

TL;DR: 研究表明，LLM的提示敏感性更多是评估方法造成的假象而非模型固有缺陷，使用LLM-as-a-Judge评估可显著降低性能方差


<details>
  <summary>Details</summary>
Motivation: 重新审视广泛报道的LLM提示敏感性问题，探究这是否是模型固有弱点还是评估过程的人为产物

Method: 系统评估7个LLM模型在6个基准测试上的表现，使用12个不同提示模板，对比启发式评估方法和LLM-as-a-Judge方法

Result: 发现提示敏感性主要源于启发式评估方法（如对数似然评分和严格答案匹配），这些方法经常忽略语义正确但表述不同的回答。使用LLM-as-a-Judge评估时，性能方差显著降低，模型排名相关性更高

Conclusion: 现代LLM对提示模板的鲁棒性比之前认为的要强，提示敏感性更多是评估方法的产物而非模型缺陷

Abstract: Prompt sensitivity, referring to the phenomenon where paraphrasing (i.e.,
repeating something written or spoken using different words) leads to
significant changes in large language model (LLM) performance, has been widely
accepted as a core limitation of LLMs. In this work, we revisit this issue and
ask: Is the widely reported high prompt sensitivity truly an inherent weakness
of LLMs, or is it largely an artifact of evaluation processes? To answer this
question, we systematically evaluate 7 LLMs (e.g., GPT and Gemini family)
across 6 benchmarks, including both multiple-choice and open-ended tasks on 12
diverse prompt templates. We find that much of the prompt sensitivity stems
from heuristic evaluation methods, including log-likelihood scoring and rigid
answer matching, which often overlook semantically correct responses expressed
through alternative phrasings, such as synonyms or paraphrases. When we adopt
LLM-as-a-Judge evaluations, we observe a substantial reduction in performance
variance and a consistently higher correlation in model rankings across
prompts. Our findings suggest that modern LLMs are more robust to prompt
templates than previously believed, and that prompt sensitivity may be more an
artifact of evaluation than a flaw in the models.

</details>


### [105] [Mic Drop or Data Flop? Evaluating the Fitness for Purpose of AI Voice Interviewers for Data Collection within Quantitative & Qualitative Research Contexts](https://arxiv.org/abs/2509.01814)
*Shreyas Tirumala,Nishant Jain,Danny D. Leybzon,Trent D. Buskirk*

Main category: cs.CL

TL;DR: 本文评估了基于Transformer的大型语言模型作为AI面试官在定量和定性研究中的数据收集能力，发现AI面试官在语音识别、回答记录和推理能力方面已超越传统IVR系统，但在实时转录准确性、情感检测和后续问题质量方面仍有局限。


<details>
  <summary>Details</summary>
Motivation: 随着基于Transformer的大型语言模型的发展，AI面试官系统能够实时进行语音调查。本文旨在评估这类系统在定量和定性研究中的数据收集适用性，比较其与传统交互式语音应答系统的能力差异。

Method: 通过回顾新兴证据，从两个维度评估AI面试官和当前IVR系统的能力：输入/输出性能（语音识别、回答记录、情感处理）和语言推理能力（追问、澄清、处理分支逻辑）。

Result: 实地研究表明，AI面试官在定量和定性数据收集方面已超越IVR系统能力，但存在实时转录错误率较高、情感检测能力有限、后续问题质量不均等问题，使得当前AI面试官技术在定性数据收集中的效用和使用可能受情境限制。

Conclusion: 虽然AI面试官技术显示出巨大潜力，特别是在定量研究方面，但在处理复杂的定性数据收集时仍需要根据具体情境谨慎采用，技术成熟度还有待进一步提升。

Abstract: Transformer-based Large Language Models (LLMs) have paved the way for "AI
interviewers" that can administer voice-based surveys with respondents in
real-time. This position paper reviews emerging evidence to understand when
such AI interviewing systems are fit for purpose for collecting data within
quantitative and qualitative research contexts. We evaluate the capabilities of
AI interviewers as well as current Interactive Voice Response (IVR) systems
across two dimensions: input/output performance (i.e., speech recognition,
answer recording, emotion handling) and verbal reasoning (i.e., ability to
probe, clarify, and handle branching logic). Field studies suggest that AI
interviewers already exceed IVR capabilities for both quantitative and
qualitative data collection, but real-time transcription error rates, limited
emotion detection abilities, and uneven follow-up quality indicate that the
utility, use and adoption of current AI interviewer technology may be
context-dependent for qualitative data collection efforts.

</details>


### [106] [Extracting OPQRST in Electronic Health Records using Large Language Models with Reasoning](https://arxiv.org/abs/2509.01885)
*Zhimeng Luo,Abhibha Gupta,Adam Frisch,Daqing He*

Main category: cs.CL

TL;DR: 本文提出使用大语言模型从电子健康记录中提取OPQRST评估信息的新方法，将序列标注任务重构为文本生成任务，并改进评估指标以包含语义相似度度量。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录数据复杂且非结构化，传统机器学习方法难以有效捕捉关键信息，临床医生难以有效利用这些工具进行患者护理。

Method: 利用大语言模型将OPQRST评估提取任务从序列标注重构为文本生成，使模型能够提供类似医生认知过程的推理步骤，并整合BERT Score等语义相似度度量来改进评估方法。

Result: 该方法显著提高了从电子健康记录中提取信息的准确性和可用性，为临床医生提供更好的决策支持。

Conclusion: 该方法在医疗保健AI应用中取得了重要进展，提供了可扩展的解决方案，有助于改善患者护理结果。

Abstract: The extraction of critical patient information from Electronic Health Records
(EHRs) poses significant challenges due to the complexity and unstructured
nature of the data. Traditional machine learning approaches often fail to
capture pertinent details efficiently, making it difficult for clinicians to
utilize these tools effectively in patient care. This paper introduces a novel
approach to extracting the OPQRST assessment from EHRs by leveraging the
capabilities of Large Language Models (LLMs). We propose to reframe the task
from sequence labeling to text generation, enabling the models to provide
reasoning steps that mimic a physician's cognitive processes. This approach
enhances interpretability and adapts to the limited availability of labeled
data in healthcare settings. Furthermore, we address the challenge of
evaluating the accuracy of machine-generated text in clinical contexts by
proposing a modification to traditional Named Entity Recognition (NER) metrics.
This includes the integration of semantic similarity measures, such as the BERT
Score, to assess the alignment between generated text and the clinical intent
of the original records. Our contributions demonstrate a significant
advancement in the use of AI in healthcare, offering a scalable solution that
improves the accuracy and usability of information extraction from EHRs,
thereby aiding clinicians in making more informed decisions and enhancing
patient care outcomes.

</details>


### [107] [Weakly Supervised Medical Entity Extraction and Linking for Chief Complaints](https://arxiv.org/abs/2509.01899)
*Zhimeng Luo,Zhendong Wang,Rui Meng,Diyang Xue,Adam Frisch,Daqing He*

Main category: cs.CL

TL;DR: 提出了一种弱监督方法，用于自动提取和链接主诉中的实体，无需人工标注，在120万条真实世界主诉记录上取得了优于先前方法的性能。


<details>
  <summary>Details</summary>
Motivation: 主诉记录存在多种录入方式，导致医学术语差异很大，难以在不同医疗机构间进行标准化记录保存或文本挖掘。

Method: 采用分割匹配算法生成弱标注（实体提及跨度和类别标签），然后基于BERT模型训练来定位实体提及并将其链接到预定义本体。

Result: 在大量实验中，该弱监督实体提取和链接方法在没有人工标注的情况下表现出优于先前方法的性能。

Conclusion: 该方法能够有效解决主诉记录标准化问题，为医疗文本挖掘提供了可行的弱监督解决方案。

Abstract: A Chief complaint (CC) is the reason for the medical visit as stated in the
patient's own words. It helps medical professionals to quickly understand a
patient's situation, and also serves as a short summary for medical text
mining. However, chief complaint records often take a variety of entering
methods, resulting in a wide variation of medical notations, which makes it
difficult to standardize across different medical institutions for record
keeping or text mining. In this study, we propose a weakly supervised method to
automatically extract and link entities in chief complaints in the absence of
human annotation. We first adopt a split-and-match algorithm to produce weak
annotations, including entity mention spans and class labels, on 1.2 million
real-world de-identified and IRB approved chief complaint records. Then we
train a BERT-based model with generated weak labels to locate entity mentions
in chief complaint text and link them to a pre-defined ontology. We conducted
extensive experiments, and the results showed that our Weakly Supervised Entity
Extraction and Linking (\ours) method produced superior performance over
previous methods without any human annotation.

</details>


### [108] [DRAssist: Dispute Resolution Assistance using Large Language Models](https://arxiv.org/abs/2509.01962)
*Sachin Pawar,Manoj Apte,Girish K. Palshikar,Basit Ali,Nitin Ramrakhiyani*

Main category: cs.CL

TL;DR: 该论文探索使用大型语言模型作为人类法官助手来解决争议，开发了DRAssist系统，专注于汽车保险和域名争议领域，通过结构化总结和多种提示策略来辅助争议解决。


<details>
  <summary>Details</summary>
Motivation: 解决各种领域（如税务、保险、银行、医疗等）中常见的争议问题，探索LLMs作为人类法官助手的潜力，提高争议解决效率。

Method: 开发DRAssist系统，识别争议的关键结构元素（事实、争议方面、论点），将非结构化争议描述总结为结构化摘要，使用多种提示策略和多个LLMs在三个不同层次上产生争议解决输出。

Result: 通过比较相关基线和合适的评估指标，评估了LLMs在所有任务上的性能表现。

Conclusion: LLMs可以作为有效的争议解决助手，在识别强势方、评估具体要求和论点强度等方面展现出潜力，为自动化争议解决提供了新的可能性。

Abstract: Disputes between two parties occur in almost all domains such as taxation,
insurance, banking, healthcare, etc. The disputes are generally resolved in a
specific forum (e.g., consumer court) where facts are presented, points of
disagreement are discussed, arguments as well as specific demands of the
parties are heard, and finally a human judge resolves the dispute by often
favouring one of the two parties. In this paper, we explore the use of large
language models (LLMs) as assistants for the human judge to resolve such
disputes, as part of our DRAssist system. We focus on disputes from two
specific domains -- automobile insurance and domain name disputes. DRAssist
identifies certain key structural elements (e.g., facts, aspects or
disagreement, arguments) of the disputes and summarizes the unstructured
dispute descriptions to produce a structured summary for each dispute. We then
explore multiple prompting strategies with multiple LLMs for their ability to
assist in resolving the disputes in these domains. In DRAssist, these LLMs are
prompted to produce the resolution output at three different levels -- (i)
identifying an overall stronger party in a dispute, (ii) decide whether each
specific demand of each contesting party can be accepted or not, (iii) evaluate
whether each argument by each contesting party is strong or weak. We evaluate
the performance of LLMs on all these tasks by comparing them with relevant
baselines using suitable evaluation metrics.

</details>


### [109] [StructCoh: Structured Contrastive Learning for Context-Aware Text Semantic Matching](https://arxiv.org/abs/2509.02033)
*Chao Xue,Ziyuan Gao*

Main category: cs.CL

TL;DR: StructCoh是一个图增强对比学习框架，通过结合结构推理和表示空间优化来解决文本语义匹配问题，在多个基准测试中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型虽然在捕捉token级交互方面表现出色，但往往忽略层次结构模式，难以处理细微的语义区分，需要同时理解结构关系和细粒度语义差异

Method: 采用双图编码器构建语义图（依赖解析和主题建模），使用图同构网络传播结构特征；设计分层对比目标，在多个粒度上强制执行一致性，包括节点级对比正则化和图感知对比学习

Result: 在三个法律文档匹配基准和学术抄袭检测数据集上表现显著优于最先进方法，在法律法规匹配上达到86.7%的F1分数（绝对提升6.2%），有效识别论证结构相似性

Conclusion: StructCoh通过结合结构推理和对比学习，成功解决了文本语义匹配中的结构模式捕捉和细粒度语义区分问题，为相关领域提供了有效的解决方案

Abstract: Text semantic matching requires nuanced understanding of both structural
relationships and fine-grained semantic distinctions. While pre-trained
language models excel at capturing token-level interactions, they often
overlook hierarchical structural patterns and struggle with subtle semantic
discrimination. In this paper, we proposed StructCoh, a graph-enhanced
contrastive learning framework that synergistically combines structural
reasoning with representation space optimization. Our approach features two key
innovations: (1) A dual-graph encoder constructs semantic graphs via dependency
parsing and topic modeling, then employs graph isomorphism networks to
propagate structural features across syntactic dependencies and cross-document
concept nodes. (2) A hierarchical contrastive objective enforces consistency at
multiple granularities: node-level contrastive regularization preserves core
semantic units, while graph-aware contrastive learning aligns inter-document
structural semantics through both explicit and implicit negative sampling
strategies. Experiments on three legal document matching benchmarks and
academic plagiarism detection datasets demonstrate significant improvements
over state-of-the-art methods. Notably, StructCoh achieves 86.7% F1-score
(+6.2% absolute gain) on legal statute matching by effectively identifying
argument structure similarities.

</details>


### [110] [DeepSeek performs better than other Large Language Models in Dental Cases](https://arxiv.org/abs/2509.02036)
*Hexian Zhang,Xinyu Yan,Yanqi Yang,Lijian Jin,Ping Yang,Junwen Wang*

Main category: cs.CL

TL;DR: 本研究评估了四种先进大语言模型在分析牙科纵向病例方面的表现，DeepSeek V3在忠实度和专家评分方面表现最佳，成为医疗案例分析的领先模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在医疗领域具有变革潜力，但其解释纵向患者叙述的能力尚未充分探索。牙科领域丰富的结构化临床数据为评估LLMs的推理能力提供了独特机会。

Method: 使用34个标准化纵向牙周病例（包含258个问答对），通过开放式临床任务评估GPT-4o、Gemini 2.0 Flash、Copilot和DeepSeek V3四种模型的表现，采用自动化指标和持证牙医的盲法评估。

Result: DeepSeek表现最佳，显示出更高的忠实度（中位数得分0.528 vs. 0.367-0.457）和更高的专家评分（中位数4.5/5 vs. 4.0/5），且未显著影响可读性。

Conclusion: DeepSeek被定位为案例分析的领先LLM，支持其作为辅助工具整合到医学教育和研究中，并突显其作为领域特定代理的潜力。

Abstract: Large language models (LLMs) hold transformative potential in healthcare, yet
their capacity to interpret longitudinal patient narratives remains
inadequately explored. Dentistry, with its rich repository of structured
clinical data, presents a unique opportunity to rigorously assess LLMs'
reasoning abilities. While several commercial LLMs already exist, DeepSeek, a
model that gained significant attention earlier this year, has also joined the
competition. This study evaluated four state-of-the-art LLMs (GPT-4o, Gemini
2.0 Flash, Copilot, and DeepSeek V3) on their ability to analyze longitudinal
dental case vignettes through open-ended clinical tasks. Using 34 standardized
longitudinal periodontal cases (comprising 258 question-answer pairs), we
assessed model performance via automated metrics and blinded evaluations by
licensed dentists. DeepSeek emerged as the top performer, demonstrating
superior faithfulness (median score = 0.528 vs. 0.367-0.457) and higher expert
ratings (median = 4.5/5 vs. 4.0/5), without significantly compromising
readability. Our study positions DeepSeek as the leading LLM for case analysis,
endorses its integration as an adjunct tool in both medical education and
research, and highlights its potential as a domain-specific agent.

</details>


### [111] [Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation](https://arxiv.org/abs/2509.02040)
*Guangzeng Han,Weisi Liu,Xiaolei Huang*

Main category: cs.CL

TL;DR: Genetic Prompt是一个结合遗传算法和LLM的新框架，通过将语义文本属性视为基因序列，利用LLM模拟交叉和变异操作来增强合成数据生成的质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型擅长生成合成数据，但确保其质量和多样性仍然具有挑战性。需要一种方法来产生更接近真实世界数据分布的合成数据。

Method: 提出Genetic Prompt框架，将语义文本属性作为基因序列，利用LLM模拟遗传算法中的交叉和变异操作。集成主动学习方案来优化父代选择，扩展后代搜索空间。

Result: 在多个NLP任务上的实验表明：Genetic Prompt显著优于最先进的基线方法，在不同规模的生成模型上都表现出鲁棒性能。将合成数据与原始训练集融合能显著提升下游模型性能，特别是在类别不平衡场景中。

Conclusion: Genetic Prompt是生产高质量合成数据的有效方法，适用于广泛的NLP应用，能够生成更接近真实数据分布的合成数据。

Abstract: Large Language Models (LLMs) excel at generating synthetic data, but ensuring
its quality and diversity remains challenging. We propose Genetic Prompt, a
novel framework that combines genetic algorithms with LLMs to augment synthetic
data generation. Our approach treats semantic text attributes as gene sequences
and leverages the LLM to simulate crossover and mutation operations. This
genetic process enhances data quality and diversity by creating novel attribute
combinations, yielding synthetic distributions closer to real-world data. To
optimize parent selection, we also integrate an active learning scheme that
expands the offspring search space. Our experiments on multiple NLP tasks
reveal several key findings: Genetic Prompt not only significantly outperforms
state-of-the-art baselines but also shows robust performance across various
generator model sizes and scales. Moreover, we demonstrate that fusing our
synthetic data with the original training set significantly boosts downstream
model performance, particularly for class-imbalanced scenarios. Our findings
validate that Genetic Prompt is an effective method for producing high-quality
synthetic data for a wide range of NLP applications.

</details>


### [112] [How Instruction-Tuning Imparts Length Control: A Cross-Lingual Mechanistic Analysis](https://arxiv.org/abs/2509.02075)
*Elisabetta Rocchetti,Alfio Ferrara*

Main category: cs.CL

TL;DR: 指令微调显著提升大语言模型的长度控制能力，主要通过深层网络组件的专业化实现，在英语和意大利语中表现出不同的机制适应


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在精确字数控制文本生成方面的挑战，比较基础模型和指令微调模型在英语和意大利语中的表现差异

Method: 使用累积加权归因（源自直接对数归因）分析模型性能和内部组件贡献，特别关注不同层级的注意力头和MLP

Result: 指令微调大幅改善长度控制，深层注意力头在英语中贡献显著，意大利语中最终层MLP起补偿作用，显示语言适应性

Conclusion: 指令微调通过重新配置深层网络来实现任务遵循，组件级策略会根据语言上下文进行适应性调整

Abstract: Adhering to explicit length constraints, such as generating text with a
precise word count, remains a significant challenge for Large Language Models
(LLMs). This study aims at investigating the differences between foundation
models and their instruction-tuned counterparts, on length-controlled text
generation in English and Italian. We analyze both performance and internal
component contributions using Cumulative Weighted Attribution, a metric derived
from Direct Logit Attribution. Our findings reveal that instruction-tuning
substantially improves length control, primarily by specializing components in
deeper model layers. Specifically, attention heads in later layers of IT models
show increasingly positive contributions, particularly in English. In Italian,
while attention contributions are more attenuated, final-layer MLPs exhibit a
stronger positive role, suggesting a compensatory mechanism. These results
indicate that instruction-tuning reconfigures later layers for task adherence,
with component-level strategies potentially adapting to linguistic context.

</details>


### [113] [Better by Comparison: Retrieval-Augmented Contrastive Reasoning for Automatic Prompt Optimization](https://arxiv.org/abs/2509.02093)
*Juhyeon Lee,Wonduk Seo,Hyunjin An,Seunghyun Lee,Yi Bu*

Main category: cs.CL

TL;DR: CRPO框架通过对比推理优化提示，利用检索增强和对比学习，在HelpSteer2基准上显著优于基线方法


<details>
  <summary>Details</summary>
Motivation: 现有提示优化方法主要关注直接提示精炼或模型微调，忽视了利用LLMs固有推理能力从对比示例中学习的潜力

Method: 提出对比推理提示优化(CRPO)框架，从HelpSteer2数据集中检索参考提示，构建分层对比推理和多指标对比推理两种优化范式

Result: 在HelpSteer2基准测试中，CRPO显著优于基线方法

Conclusion: 对比性、检索增强的推理方法在推进自动提示优化方面具有广阔前景

Abstract: Automatic prompt optimization has recently emerged as a strategy for
improving the quality of prompts used in Large Language Models (LLMs), with the
goal of generating more accurate and useful responses. However, most prior work
focuses on direct prompt refinement or model fine-tuning, overlooking the
potential of leveraging LLMs' inherent reasoning capability to learn from
contrasting examples. In this paper, we present Contrastive Reasoning Prompt
Optimization (CRPO), a novel framework that formulates prompt optimization as a
retrieval augmented reasoning process. Our approach retrieves top k reference
prompts from the HelpSteer2 dataset, an open-source collection annotated for
helpfulness, correctness, coherence, complexity, and verbosity, and constructs
two complementary optimization paradigms: (1) tiered contrastive reasoning,
where the LLM compares high, medium, and low quality prompts to refine its own
generation through reflective reasoning, and (2) multi-metric contrastive
reasoning, where the LLM analyzes the best prompts along each evaluation
dimension and integrates their strengths into an optimized prompt. By
explicitly contrasting high and low quality exemplars, CRPO enables the model
to deduce why certain prompts succeed while others fail, thereby achieving more
robust and interpretable optimization. Experimental results on the HelpSteer2
benchmark demonstrate that CRPO significantly outperforms baselines. Our
findings highlight the promise of contrastive, retrieval-augmented reasoning
for advancing automatic prompt optimization.

</details>


### [114] [JudgeAgent: Dynamically Evaluate LLMs with Agent-as-Interviewer](https://arxiv.org/abs/2509.02097)
*Zhichao Shi,Xuhui Jiang,Chengjin Xu,Cangli Yao,Zhenxin Huang,Shengjie Ma,Yinghan Shen,Yuanzhuo Wang*

Main category: cs.CL

TL;DR: JudgeAgent是一个基于面试官式评估范式的知识目标自适应动态评估框架，通过基准评分、交互扩展和评估反馈的综合方法，解决传统LLM评估中交互有限、难度控制不足和结果验证困难的问题。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型评估基于预定义问题集的范式存在与目标交互有限、难度控制不足、评估结果有效性验证困难等问题，难以精确确定目标模型的知识和能力边界。

Method: 提出JudgeAgent框架，采用知识驱动的数据合成和目标自适应难度调整方法，包含基准评分、交互扩展和评估反馈三个组成部分，通过扩展测试提供准确有效的评估结果。

Result: 通过大量实验证明了JudgeAgent及其动态评估范式的有效性，为评估方法的验证提供了新的视角。

Conclusion: JudgeAgent框架能够有效解决传统LLM评估范式的局限性，提供更准确和有效的模型能力评估，为LLM在不同领域的成功应用提供保障。

Abstract: Evaluating the capabilities of large language models (LLMs) is an essential
step to ensure the successful application of LLMs across various domains. The
current evaluation of LLMs is based on a paradigm that involves querying them
with predefined question sets and assessing their outputs. This paradigm offers
controllable processes and simplicity, but faces challenges such as limited
interaction with targets, insufficient difficulty control, and difficulties in
verifying the validity of evaluation results, making it hard to precisely
determine the knowledge and capability boundaries of target models. To address
these challenges, we propose JudgeAgent, a knowledge-target adaptive dynamic
evaluation framework based on a new interviewer-style evaluation paradigm.
JudgeAgent employs a comprehensive evaluation approach consisting of benchmark
grading, interactive extension, and evaluation feedback. It utilizes
knowledge-driven data synthesis and target-adaptive difficulty adjustment
methods to conduct extended testing, providing accurate and effective
evaluation results. We also introduce a novel insight into validating
evaluation methods, demonstrating the effectiveness of JudgeAgent and its
dynamic evaluation paradigm through extensive experiments.

</details>


### [115] [CMRAG: Co-modality-based document retrieval and visual question answering](https://arxiv.org/abs/2509.02123)
*Wang Chen,Guanqiang Qi,Weikang Li,Yang Li*

Main category: cs.CL

TL;DR: 本文提出了co-modality-based RAG (CMRAG)方法，通过同时利用文本和图像信息进行多模态文档问答，显著提升了纯视觉RAG方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在处理多模态文档时存在局限：基于布局分析和文本提取的方法只能利用显式文本信息，无法处理图像内容；而纯视觉方法虽然能处理图像但忽略了文本的语义优势，导致生成结果不理想。

Method: 首先对文档进行结构化解析，获得文本片段和图像区域的共模态表示；然后分别从文本和图像通道检索候选证据，在跨模态检索层面聚合结果；最后基于共模态检索结果提示视觉语言模型生成最终响应。

Result: 实验证明该方法在视觉文档问答任务中显著优于纯视觉RAG方法。

Conclusion: 以统一方式将共模态信息整合到RAG框架中是提升复杂文档视觉问答系统性能的有效途径。

Abstract: Retrieval-Augmented Generation (RAG) has become a core paradigm in document
question answering tasks. However, existing methods have limitations when
dealing with multimodal documents: one category of methods relies on layout
analysis and text extraction, which can only utilize explicit text information
and struggle to capture images or unstructured content; the other category
treats document segmentation as visual input and directly passes it to visual
language models (VLMs) for processing, yet it ignores the semantic advantages
of text, leading to suboptimal generation results. This paper proposes
co-modality-based RAG (CMRAG), which can simultaneously leverage text and
images for efficient retrieval and generation. Specifically, we first perform
structured parsing on documents to obtain co-modality representations of text
segments and image regions. Subsequently, in response to user queries, we
retrieve candidate evidence from text and image channels, respectively, and
aggregate the results at the cross-modal retrieval level. Finally, we prompt
the VLM to generate the final response based on the co-modality retrieval
results. Experiments demonstrate that our method significantly outperforms
pure-vision-based RAG in visual document question answering tasks. The findings
of this paper show that integrating co-modality information into the RAG
framework in a unified manner is an effective approach to improving the
performance of complex document visual question-answering (VQA) systems.

</details>


### [116] [AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models](https://arxiv.org/abs/2509.02133)
*Snehasis Mukhopadhyay,Aryan Kasat,Shivam Dubey,Rahul Karthikeyan,Dhruv Sood,Vinija Jain,Aman Chadha,Amitava Das*

Main category: cs.CL

TL;DR: 提出了AMBEDKAR框架，通过宪法感知解码层和推测解码算法，在不修改基础模型参数的情况下，有效减少LLM在种姓和宗教方面的偏见，偏见绝对减少达26.41%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型可能反映训练数据中的社会偏见，特别是在印度语境下，种姓和宗教偏见尤为突出。现有缓解策略多为西方中心，无法解决本地化偏见问题。

Method: 基于印度宪法第14-17条的平等愿景，设计宪法感知解码层，在推理时应用推测解码算法。使用小型语言模型作为潜在偏见生成器，大型语言模型作为宪法指导的验证器，实施公平性推测范式。

Result: 相比基线方法，偏见绝对减少最高达26.41%。该方法无需重新训练模型，降低了计算和基础设施成本。

Conclusion: AMBEDKAR框架成功将推测解码重新诠释为公平性机制而非效率工具，为处理本地化社会偏见提供了有效解决方案，特别是在印度种姓和宗教偏见方面。

Abstract: Large Language Models (LLMs) can inadvertently reflect societal biases
present in their training data, leading to harmful or prejudiced outputs. In
the Indian context, our empirical evaluations across a suite of models reveal
that biases around caste and religion are particularly salient. Yet, most
existing mitigation strategies are Western-centric and fail to address these
local nuances. We propose AMBEDKAR, a framework inspired by the egalitarian
vision of Dr B. R. Ambedkar, architect of the Indian Constitution, to guide LLM
outputs toward fairness, neutrality, and inclusion in line with Articles 14 to
17. Our approach introduces a Constitution-Aware Decoding Layer, guided by the
AI Constitution of India and applied only at inference time, without any
parameter updates to the base model. We incorporate a speculative decoding
algorithm that proactively reduces casteist and communal bias during
generation. This mitigation layer operates directly within the decoding
process, avoiding changes to model internals and lowering the computational and
infrastructural costs associated with retraining. We reinterpret speculative
decoding not merely as an efficiency tool but as a mechanism for fairness. In
this framework, a Small Language Model (SLM) acts as a potentially biased
generator, while a constitutionally guided Large Language Model (LLM) serves as
the verifier. Rather than accelerating generation, the LLM enforces bias-robust
trajectories in the SLM outputs. This inversion of roles gives rise to a
fairness-by-speculation paradigm. Our approach yields an absolute reduction of
bias up to 26.41 percent compared to baseline. Our source code, datasets, and
results are available at https://anonymous.4open.science/r/AMBEDKAR-983B/

</details>


### [117] [Meta-Pretraining for Zero-Shot Cross-Lingual Named Entity Recognition in Low-Resource Philippine Languages](https://arxiv.org/abs/2509.02160)
*David Demitri Africa,Suchir Salhan,Yuval Weiss,Paula Buttery,Richard Diehl Martinez*

Main category: cs.CL

TL;DR: 通过继承学习方法(MAML)预训练小型解码器模型，在低资源语言的命名实体识别任务中实现了更快的适应和更好的零样本转移性能


<details>
  <summary>Details</summary>
Motivation: 解决在内存或延迟受限环境下，无法使用大型多语言模型进行低资源语言命名实体识别的问题

Method: 将自回归目标与一阶模型无关元学习(MAML)结合，预训练小型解码器模型，使其能够快速适应并向预训练时未见过的语言进行零样本转移

Result: 在11M-570M四种模型规模下，MAML方法在仅调整头部时微观F1提升2-6个百分点，全模型微调时提升1-3个百分点，收敛速度提升达8%，特别在标记人名实体时效果显著

Conclusion: 继承学习方法能够有效提升小型模型在低资源语言NER任务中的适应性和转移性能，表面标记(如语法助词)在识别实体时起重要作用

Abstract: Named-entity recognition (NER) in low-resource languages is usually tackled
by finetuning very large multilingual LMs, an option that is often infeasible
in memory- or latency-constrained settings. We ask whether small decoder LMs
can be pretrained so that they adapt quickly and transfer zero-shot to
languages unseen during pretraining. To this end we replace part of the
autoregressive objective with first-order model-agnostic meta-learning (MAML).
Tagalog and Cebuano are typologically similar yet structurally different in
their actor/non-actor voice systems, and hence serve as a challenging test-bed.
Across four model sizes (11 M - 570 M) MAML lifts zero-shot micro-F1 by 2-6 pp
under head-only tuning and 1-3 pp after full tuning, while cutting convergence
time by up to 8%. Gains are largest for single-token person entities that
co-occur with Tagalog case particles si/ni, highlighting the importance of
surface anchors.

</details>


### [118] [Avoidance Decoding for Diverse Multi-Branch Story Generation](https://arxiv.org/abs/2509.02170)
*Kyeongman Park,Nakyeong Yang,Kyomin Jung*

Main category: cs.CL

TL;DR: 提出Avoidance Decoding解码策略，通过惩罚与先前生成内容的相似性来提升LLM生成故事的多样性，减少重复性


<details>
  <summary>Details</summary>
Motivation: 大语言模型在相同输入提示下往往生成重复单调的输出，特别是在故事生成任务中缺乏创意多样性

Method: 修改token logits，通过两个自适应平衡的相似性惩罚：早期优先概念级相似性惩罚以多样化初始故事概念，后期增加叙事级相似性惩罚以确保自然且多样的情节发展

Result: 相比强基线方法，输出多样性提升2.6倍，重复性平均减少30%，同时有效缓解文本退化问题，激活了更广泛的神经元

Conclusion: 该方法成功提升了LLM生成内容的多样性，证明了其能够有效利用模型的内在创造力

Abstract: Large Language Models (LLMs) often generate repetitive and monotonous
outputs, especially in tasks like story generation, due to limited creative
diversity when given the same input prompt. To address this challenge, we
propose a novel decoding strategy, Avoidance Decoding, that modifies token
logits by penalizing similarity to previously generated outputs, thereby
encouraging more diverse multi-branch stories. This penalty adaptively balances
two similarity measures: (1) Concept-level Similarity Penalty, which is
prioritized in early stages to diversify initial story concepts, and (2)
Narrative-level Similarity Penalty, which is increasingly emphasized later to
ensure natural yet diverse plot development. Notably, our method achieves up to
2.6 times higher output diversity and reduces repetition by an average of 30%
compared to strong baselines, while effectively mitigating text degeneration.
Furthermore, we reveal that our method activates a broader range of neurons,
demonstrating that it leverages the model's intrinsic creativity.

</details>


### [119] [FActBench: A Benchmark for Fine-grained Automatic Evaluation of LLM-Generated Text in the Medical Domain](https://arxiv.org/abs/2509.02198)
*Anum Afzal,Juraj Vladika,Florian Matthes*

Main category: cs.CL

TL;DR: FActBench是一个针对医学领域的全面事实核查基准，涵盖4个生成任务和6个主流大语言模型，使用CoT提示和NLI两种技术进行事实核查，发现一致投票结果与专家评估相关性最佳


<details>
  <summary>Details</summary>
Motivation: 大语言模型在专业领域表现不佳，事实准确性是最关键的评估维度，需要可靠的事实核查工具和数据源来解决幻觉问题

Method: 构建医学领域事实核查基准FActBench，涵盖4个生成任务和6个LLM，采用Chain-of-Thought提示和自然语言推理两种先进事实核查技术

Result: 实验表明，通过两种技术的一致投票获得的事实核查分数与领域专家评估的相关性最好

Conclusion: FActBench为医学领域提供了有效的事实核查基准，一致投票方法能够可靠地评估LLM的事实准确性

Abstract: Large Language Models tend to struggle when dealing with specialized domains.
While all aspects of evaluation hold importance, factuality is the most
critical one. Similarly, reliable fact-checking tools and data sources are
essential for hallucination mitigation. We address these issues by providing a
comprehensive Fact-checking Benchmark FActBench covering four generation tasks
and six state-of-the-art Large Language Models (LLMs) for the Medical domain.
We use two state-of-the-art Fact-checking techniques: Chain-of-Thought (CoT)
Prompting and Natural Language Inference (NLI). Our experiments show that the
fact-checking scores acquired through the Unanimous Voting of both techniques
correlate best with Domain Expert Evaluation.

</details>


### [120] [Towards Fundamental Language Models: Does Linguistic Competence Scale with Model Size?](https://arxiv.org/abs/2509.02225)
*Jaime Collado-Montañez,L. Alfonso Ureña-López,Arturo Montejo-Ráez*

Main category: cs.CL

TL;DR: 大语言模型存在幻觉、偏见、隐私和高计算成本等问题，主要源于语言能力和事实记忆的混合。本文提出基础语言模型（FLM）范式，使用小型语言模型配合外部工具进行事实检索，实证表明模型规模与记忆能力而非核心语言能力更相关。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型中存在的幻觉、偏见、隐私泄露和高计算成本等问题，这些问题的根源在于将语言能力和事实记忆功能混合在单一模型中。

Method: 提出基础语言模型（FLM）范式，使用较小参数规模（1.35亿到320亿）的语言模型，将事实检索功能卸载到外部工具，评估模型在语言能力、外部事实知识和内部事实知识三个维度的表现。

Result: 研究发现语言能力和事实知识都随模型规模增长而提升，但内部事实知识增长更快，表明模型规模与记忆能力而非核心语言能力更相关。

Conclusion: 支持模块化语言建模方法，使用紧凑、语言能力强的模型作为工具增强系统的基础，FLM范式为更高效、可解释和可持续的NLP解决方案提供了路径。

Abstract: Large Language Models offer impressive language capabilities but suffer from
well-known limitations, including hallucinations, biases, privacy concerns, and
high computational costs. These issues are largely driven by the combination of
linguistic competence and factual memorization within a single monolithic
model. This paper introduces and empirically supports the Fundamental Language
Model (FLM) paradigm, which advocates for smaller, linguistically competent
models that offload factual retrieval to external tools. We evaluate models
ranging from 135M to 32B parameters across three dimensions: linguistic
competence, external factual knowledge, and internal factual knowledge. Our
findings reveal that while both linguistic competence and factual knowledge
improve with scale, internal factual knowledge grows significantly faster,
suggesting that model size is more closely tied to memorization than to core
language ability. These results support a modular approach to language
modeling, where compact, linguistically proficient models serve as the
foundation for tool-augmented systems. The FLM paradigm offers a path toward
more efficient, interpretable, and sustainable NLP solutions.

</details>


### [121] [LLMs and their Limited Theory of Mind: Evaluating Mental State Annotations in Situated Dialogue](https://arxiv.org/abs/2509.02292)
*Katharine Kowalyshyn,Matthias Scheutz*

Main category: cs.CL

TL;DR: 提出了一个两阶段框架，利用大语言模型作为团队对话标注器和差异检测器，来追踪团队的共享心智模型并发现成员间的认知差异。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型是否不仅能推断人类思维，还能揭示团队对话中的盲点，特别是团队成员在共同理解上的差异。

Method: 采用两步骤方法：首先用LLM生成团队对话的共享心智模型标注，然后用另一个LLM比较LLM标注与人工标注的差异，检测认知分歧。基于CReST语料库构建评估框架。

Result: LLM在简单自然语言标注任务中表现出良好一致性，但在需要空间推理或韵律线索消歧的场景中会系统性出错。

Conclusion: 虽然LLM在基础标注任务中有效，但在复杂推理场景中存在局限性，为团队认知差异检测提供了实用框架但需进一步改进。

Abstract: What if large language models could not only infer human mindsets but also
expose every blind spot in team dialogue such as discrepancies in the team
members' joint understanding? We present a novel, two-step framework that
leverages large language models (LLMs) both as human-style annotators of team
dialogues to track the team's shared mental models (SMMs) and as automated
discrepancy detectors among individuals' mental states. In the first step, an
LLM generates annotations by identifying SMM elements within task-oriented
dialogues from the Cooperative Remote Search Task (CReST) corpus. Then, a
secondary LLM compares these LLM-derived annotations and human annotations
against gold-standard labels to detect and characterize divergences. We define
an SMM coherence evaluation framework for this use case and apply it to six
CReST dialogues, ultimately producing: (1) a dataset of human and LLM
annotations; (2) a reproducible evaluation framework for SMM coherence; and (3)
an empirical assessment of LLM-based discrepancy detection. Our results reveal
that, although LLMs exhibit apparent coherence on straightforward
natural-language annotation tasks, they systematically err in scenarios
requiring spatial reasoning or disambiguation of prosodic cues.

</details>


### [122] [DCPO: Dynamic Clipping Policy Optimization](https://arxiv.org/abs/2509.02333)
*Shihui Yang,Chengfeng Dou,Peidong Guo,Kai Lu,Qiang Ju,Fei Deng,Rihui Xin*

Main category: cs.CL

TL;DR: DCPO提出动态剪切策略和平滑优势标准化技术，解决RLVR中因固定剪切边界和奖励标准化导致的零梯度问题，在多个基准测试中达到最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法如GRPO存在零梯度问题，主要由于固定剪切边界和相同奖励标准化导致的无效梯度更新和生成响应利用不充分。

Method: 提出DCPO方法：1）动态剪切策略，根据标记特定先验概率自适应调整剪切边界以增强标记级探索；2）平滑优势标准化技术，在累计训练步骤中标准化奖励以提高响应级利用效果。

Result: 在4个基准测试中达到最佳性能：AIME24基准上Avg@1 46.7（超过DAPO 36.7和GRPO 36.7），AIME25基准上23.3（超过GRPO 13.3和DAPO 20.0）。非零优势提高28%，训练效率提高一倍，标记剪切比率明显降低。

Conclusion: DCPO能够更有效地利用生成数据进行加强学习，通过动态剪切和优势标准化技术有效解决了现有方法的限制，在大语言模型的推理能力提升方面发挥重要作用。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a
promising framework for enhancing the reasoning capabilities of large language
models. However, existing approaches such as GRPO often suffer from zero
gradients. This problem arises primarily due to fixed clipping bounds for
token-level probability ratios and the standardization of identical rewards,
which can lead to ineffective gradient updates and underutilization of
generated responses. In this work, we propose Dynamic Clipping Policy
Optimization (DCPO), which introduces a dynamic clipping strategy that
adaptively adjusts the clipping bounds based on token-specific prior
probabilities to enhance token-level exploration, and a smooth advantage
standardization technique that standardizes rewards across cumulative training
steps to improve the response-level effective utilization of generated
responses. DCPO achieved state-of-the-art performance on four benchmarks based
on four different models. In particular, DCPO achieved an Avg@1 of 46.7 under
greedy decoding and an Avg@32 of 38.8 under 32 times sampling on the AIME24
benchmark, surpassing both DAPO (36.7/31.6) and GRPO (36.7/32.1) on the
Qwen2.5-Math-7B model. On the AIME25 benchmark based on Qwen2.5-14B, DCPO
achieves a performance of (23.3/19.0), surpassing GRPO (13.3/10.5) and DAPO
(20.0/15.3). Furthermore, DCPO achieved an average 28% improvement in the
nonzero advantage over GRPO in four models, doubled the training efficiency
over DAPO, and significantly reduced the token clipping ratio by an order of
magnitude compared to both GRPO and DAPO, while achieving superior performance.
These results highlight DCPO's effectiveness in leveraging generated data more
efficiently for reinforcement learning in large language models.

</details>


### [123] [Implicit Reasoning in Large Language Models: A Comprehensive Survey](https://arxiv.org/abs/2509.02350)
*Jindong Li,Yali Fu,Li Fan,Jiahong Liu,Yao Shu,Chengwei Qin,Menglin Yang,Irwin King,Rex Ying*

Main category: cs.CL

TL;DR: 这篇论文是一个关于大语言模型隐式推理的综述，介绍了不发生文本中间步骤的内部计算推理方法，包括三种执行范弋和相关评估指标。


<details>
  <summary>Details</summary>
Motivation: 尽管之前的研究讨论了推理中的潜在表征，但缺乏一个专门从机制层面分析LLM内部如何展开推理的综述。

Method: 通过以执行范弋为中心的分类法，将现有方法组织为三类：潜在优化、信号导向控制和层循环执行，并综述支持隐式推理的结构、行为和表征证据。

Result: 该研究提供了一个结构化的视角来理解LLM内部推理机制，并综述了相关评估指标和测试集。

Conclusion: 隐式推理具有生成成本低、推理速度快、与内部计算更一致等优势，这个综述为该领域提供了机制层面的深入分析。

Abstract: Large Language Models (LLMs) have demonstrated strong generalization across a
wide range of tasks. Reasoning with LLMs is central to solving multi-step
problems and complex decision-making. To support efficient reasoning, recent
studies have shifted attention from explicit chain-of-thought prompting toward
implicit reasoning, where reasoning occurs silently via latent structures
without emitting intermediate textual steps. Implicit reasoning brings
advantages such as lower generation cost, faster inference, and better
alignment with internal computation. Although prior surveys have discussed
latent representations in the context of reasoning, a dedicated and
mechanism-level examination of how reasoning unfolds internally within LLMs
remains absent. This survey fills that gap by introducing a taxonomy centered
on execution paradigms, shifting the focus from representational forms to
computational strategies. We organize existing methods into three execution
paradigms based on \textbf{\textit{how and where internal computation
unfolds}}: latent optimization, signal-guided control, and layer-recurrent
execution. We also review structural, behavioral and representation-based
evidence that supports the presence of implicit reasoning in LLMs. We further
provide a structured overview of the evaluation metrics and benchmarks used in
existing works to assess the effectiveness and reliability of implicit
reasoning.We maintain a continuously updated project at:
https://github.com/digailab/awesome-llm-implicit-reasoning.

</details>


### [124] [Towards Temporal Knowledge-Base Creation for Fine-Grained Opinion Analysis with Language Models](https://arxiv.org/abs/2509.02363)
*Gaurav Negi,Atul Kr. Ojha,Omnia Zayed,Paul Buitelaar*

Main category: cs.CL

TL;DR: 使用大语言模型构建时序意见知识库的可扩展方法，通过声明式注释流水线实现结构化意见提取，无需手动提示工程


<details>
  <summary>Details</summary>
Motivation: 现有方法没有充分利用时间序列意见分析的潜力，缺乏时态基础的细粒度注释

Method: 将意见挖掘形式集成到声明式LLM注释流水线中，定义三种基于情感和意见挖掘文献的数据模型

Result: 使用人工注释测试样本进行严格的定量评估，计算了两个LLM之间的评注者一致性

Conclusion: 构建的知识库包含时间对齐的结构化意见，兼容RAG、时态问答和时间线摘要等应用

Abstract: We propose a scalable method for constructing a temporal opinion knowledge
base with large language models (LLMs) as automated annotators. Despite the
demonstrated utility of time-series opinion analysis of text for downstream
applications such as forecasting and trend analysis, existing methodologies
underexploit this potential due to the absence of temporally grounded
fine-grained annotations. Our approach addresses this gap by integrating
well-established opinion mining formulations into a declarative LLM annotation
pipeline, enabling structured opinion extraction without manual prompt
engineering. We define three data models grounded in sentiment and opinion
mining literature, serving as schemas for structured representation. We perform
rigorous quantitative evaluation of our pipeline using human-annotated test
samples. We carry out the final annotations using two separate LLMs, and
inter-annotator agreement is computed label-wise across the fine-grained
opinion dimensions, analogous to human annotation protocols. The resulting
knowledge base encapsulates time-aligned, structured opinions and is compatible
with applications in Retrieval-Augmented Generation (RAG), temporal question
answering, and timeline summarisation.

</details>


### [125] [An Ensemble Classification Approach in A Multi-Layered Large Language Model Framework for Disease Prediction](https://arxiv.org/abs/2509.02446)
*Ali Hamdi,Malak Mohamed,Rokaia Emad,Khaled Shaban*

Main category: cs.CL

TL;DR: 这篇论文研究了阿拉伯语医疗社交远程健康文本的疾病分类方法，通过结合LLM预处理技术、精调阿拉伯语transformer模型和多数投票集成学习，达到了80.56%的最高分类准确率。


<details>
  <summary>Details</summary>
Motivation: 社交远程健康平台上存在大量阿拉伯语医疗文本数据，需要有效的疾病分类方法来利用这些数据。虽然LLM和transformer模型在医疗文本处理方面表现突出，但在阿拉伯语医疗预处理和集成学习方面仍然缺乏系统性研究。

Method: 采用三种阿拉伯语医疗文本预处理方法：摘要化、精细化和命名实体识别(NER)，然后应用精调的阿拉伯语transformer模型(CAMeLBERT、AraBERT、AsafayaBERT)。采用多数投票集成方法，结合原始文本和预处理文本表征的预测结果。

Result: 该方法在阿拉伯语社交远程健康数据上达到了80.56%的疾病分类准确率，显示出通过利用不同文本表征和模型预测来提高医疗文本理解能力的有效性。

Conclusion: 这是首次将LLM基于预处理技术与精调阿拉伯语transformer模型和集成学习相结合用于阿拉伯语社交远程健康数据的疾病分类研究，为阿拉伯语医疗文本分析提供了有效的方法。

Abstract: Social telehealth has made remarkable progress in healthcare by allowing
patients to post symptoms and participate in medical consultations remotely.
Users frequently post symptoms on social media and online health platforms,
creating a huge repository of medical data that can be leveraged for disease
classification. Large language models (LLMs) such as LLAMA3 and GPT-3.5, along
with transformer-based models like BERT, have demonstrated strong capabilities
in processing complex medical text. In this study, we evaluate three Arabic
medical text preprocessing methods such as summarization, refinement, and Named
Entity Recognition (NER) before applying fine-tuned Arabic transformer models
(CAMeLBERT, AraBERT, and AsafayaBERT). To enhance robustness, we adopt a
majority voting ensemble that combines predictions from original and
preprocessed text representations. This approach achieved the best
classification accuracy of 80.56%, thus showing its effectiveness in leveraging
various text representations and model predictions to improve the understanding
of medical texts. To the best of our knowledge, this is the first work that
integrates LLM-based preprocessing with fine-tuned Arabic transformer models
and ensemble learning for disease classification in Arabic social telehealth
data.

</details>


### [126] [EmoPerso: Enhancing Personality Detection with Self-Supervised Emotion-Aware Modelling](https://arxiv.org/abs/2509.02450)
*Lingzhi Shen,Xiaohao Cai,Yunfei Long,Imran Razzak,Guanming Chen,Shoaib Jameel*

Main category: cs.CL

TL;DR: EmoPerso是一个自监督框架，通过情感感知建模改进人格检测，利用生成机制进行数据增强和表示学习，通过多任务学习和交叉注意力模块捕捉人格与情感的细粒度交互。


<details>
  <summary>Details</summary>
Motivation: 现有的人格检测方法严重依赖大规模标注数据集，难以获得高质量人格标签，且大多将情感和人格视为独立变量，忽视了它们的相互作用。

Method: 提出EmoPerso框架：1）利用生成机制进行合成数据增强和丰富表示学习；2）提取伪标签情感特征并通过多任务学习与人格预测联合优化；3）使用交叉注意力模块捕捉人格特质与情感表示的细粒度交互；4）采用自学习策略迭代增强模型推理能力。

Result: 在两个基准数据集上的广泛实验表明，EmoPerso超越了最先进的模型。

Conclusion: EmoPerso通过情感感知建模有效提升了人格检测性能，证明了情感与人格之间相互作用的重要性，并为自监督人格检测提供了新的解决方案。

Abstract: Personality detection from text is commonly performed by analysing users'
social media posts. However, existing methods heavily rely on large-scale
annotated datasets, making it challenging to obtain high-quality personality
labels. Moreover, most studies treat emotion and personality as independent
variables, overlooking their interactions. In this paper, we propose a novel
self-supervised framework, EmoPerso, which improves personality detection
through emotion-aware modelling. EmoPerso first leverages generative mechanisms
for synthetic data augmentation and rich representation learning. It then
extracts pseudo-labeled emotion features and jointly optimizes them with
personality prediction via multi-task learning. A cross-attention module is
employed to capture fine-grained interactions between personality traits and
the inferred emotional representations. To further refine relational reasoning,
EmoPerso adopts a self-taught strategy to enhance the model's reasoning
capabilities iteratively. Extensive experiments on two benchmark datasets
demonstrate that EmoPerso surpasses state-of-the-art models. The source code is
available at https://github.com/slz0925/EmoPerso.

</details>


### [127] [Do LLMs Adhere to Label Definitions? Examining Their Receptivity to External Label Definitions](https://arxiv.org/abs/2509.02452)
*Seyedali Mohammadi,Bhaskara Hanuma Vedula,Hemank Lamba,Edward Raff,Ponnurangam Kumaraguru,Francis Ferraro,Manas Gaur*

Main category: cs.CL

TL;DR: 研究发现LLM在处理外部标签定义时并不总是整合这些定义，而是经常依赖内部参数化知识，特别是在通用任务中，而领域特定任务更能从显式定义中受益


<details>
  <summary>Details</summary>
Motivation: 探究LLM是否真正整合外部定义，还是主要依赖其参数化知识来处理任务

Method: 在多个解释基准数据集（通用和领域特定）上进行控制实验，使用专家策划、LLM生成、扰动和交换的定义条件

Result: 显式标签定义可以提高准确性和可解释性，但LLM整合这些定义到任务解决过程中既不保证也不一致，模型经常默认使用内部表示

Conclusion: 需要更深入理解LLM如何处理外部知识与其现有能力的关系，模型对内部表示的依赖表明需要更好的外部知识整合机制

Abstract: Do LLMs genuinely incorporate external definitions, or do they primarily rely
on their parametric knowledge? To address these questions, we conduct
controlled experiments across multiple explanation benchmark datasets (general
and domain-specific) and label definition conditions, including expert-curated,
LLM-generated, perturbed, and swapped definitions. Our results reveal that
while explicit label definitions can enhance accuracy and explainability, their
integration into an LLM's task-solving processes is neither guaranteed nor
consistent, suggesting reliance on internalized representations in many cases.
Models often default to their internal representations, particularly in general
tasks, whereas domain-specific tasks benefit more from explicit definitions.
These findings underscore the need for a deeper understanding of how LLMs
process external knowledge alongside their pre-existing capabilities.

</details>


### [128] [SpecEval: Evaluating Model Adherence to Behavior Specifications](https://arxiv.org/abs/2509.02464)
*Ahmed Ahmed,Kevin Klyman,Yi Zeng,Sanmi Koyejo,Percy Liang*

Main category: cs.CL

TL;DR: 自动化框架审计基础模型是否遵守发布商的行为指南，发现系统性的不一致性问题


<details>
  <summary>Details</summary>
Motivation: 基础模型发布商宣称模型遵守行为指南，但缺乏系统性的审计方法来验证实际遵守情况

Method: 开发自动化框架，通过解析行为声明、生成针对性提示、使用模型作为判断者来检验三方一致性（规范-输出-评估模型）

Result: 在16个模型和100多个行为声明中发现系统性不一致性，最高达20%的遵循问题

Conclusion: 基础模型并非始终遵守发布商指南，需要建立必要的基准检验机制确保三方一致性

Abstract: Companies that develop foundation models publish behavioral guidelines they
pledge their models will follow, but it remains unclear if models actually do
so. While providers such as OpenAI, Anthropic, and Google have published
detailed specifications describing both desired safety constraints and
qualitative traits for their models, there has been no systematic audit of
adherence to these guidelines. We introduce an automated framework that audits
models against their providers specifications by parsing behavioral statements,
generating targeted prompts, and using models to judge adherence. Our central
focus is on three way consistency between a provider specification, its model
outputs, and its own models as judges; an extension of prior two way generator
validator consistency. This establishes a necessary baseline: at minimum, a
foundation model should consistently satisfy the developer behavioral
specifications when judged by the developer evaluator models. We apply our
framework to 16 models from six developers across more than 100 behavioral
statements, finding systematic inconsistencies including compliance gaps of up
to 20 percent across providers.

</details>


### [129] [GRAM-R$^2$: Self-Training Generative Foundation Reward Models for Reward Reasoning](https://arxiv.org/abs/2509.02492)
*Chenglong Wang,Yongyu Mu,Hang Zhou,Yifu Huo,Ziming Zhu,Jiali Zeng,Murun Yang,Bei Li,Tong Xiao,Xiaoyang Hao,Chunliang Zhang,Fandong Meng,Jingbo Zhu*

Main category: cs.CL

TL;DR: 提出了GRAM-R²生成式奖励模型，通过自训练方法利用未标注数据训练奖励模型，不仅能输出偏好标签还能生成奖励理由，在多个任务上表现优异


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型严重依赖大规模标注偏好数据，而预训练方法缺乏明确的推理能力，需要开发能够进行显式推理的奖励模型

Method: 采用自训练方法利用未标注数据激发奖励推理，开发GRAM-R²生成式奖励模型，同时输出偏好标签和奖励理由

Result: 在响应排序、任务适应和人类反馈强化学习等任务上表现优异，超越多个判别式和生成式基线模型

Conclusion: GRAM-R²可作为奖励推理的基础模型，支持下游应用如响应排序和任务特定奖励调优，具有广泛适用性

Abstract: Significant progress in reward modeling over recent years has been driven by
a paradigm shift from task-specific designs towards generalist reward models.
Despite this trend, developing effective reward models remains a fundamental
challenge: the heavy reliance on large-scale labeled preference data.
Pre-training on abundant unlabeled data offers a promising direction, but
existing approaches fall short of instilling explicit reasoning into reward
models. To bridge this gap, we propose a self-training approach that leverages
unlabeled data to elicit reward reasoning in reward models. Based on this
approach, we develop GRAM-R$^2$, a generative reward model trained to produce
not only preference labels but also accompanying reward rationales. GRAM-R$^2$
can serve as a foundation model for reward reasoning and can be applied to a
wide range of tasks with minimal or no additional fine-tuning. It can support
downstream applications such as response ranking and task-specific reward
tuning. Experiments on response ranking, task adaptation, and reinforcement
learning from human feedback demonstrate that GRAM-R$^2$ consistently delivers
strong performance, outperforming several strong discriminative and generative
baselines.

</details>


### [130] [MoSEs: Uncertainty-Aware AI-Generated Text Detection via Mixture of Stylistics Experts with Conditional Thresholds](https://arxiv.org/abs/2509.02499)
*Junxi Wu,Jinpeng Wang,Zheng Liu,Bin Chen,Dongjian Hu,Hao Wu,Shu-Tao Xiu*

Main category: cs.CL

TL;DR: 提出了MoSEs框架，通过条件阈值估计实现风格感知的不确定性量化，显著提升AI生成文本检测性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速发展引发了对滥用的担忧，现有方法忽视风格建模且依赖静态阈值，限制了检测性能

Method: MoSEs框架包含三个核心组件：风格参考库(SRR)、风格感知路由器(SAR)和条件阈值估计器(CTE)，通过动态确定最优阈值进行检测

Result: 相比基线方法平均提升11.34%的检测性能，在低资源情况下提升更显著达39.15%

Conclusion: MoSEs框架通过风格感知的条件阈值估计有效提升了AI生成文本检测的准确性和鲁棒性

Abstract: The rapid advancement of large language models has intensified public
concerns about the potential misuse. Therefore, it is important to build
trustworthy AI-generated text detection systems. Existing methods neglect
stylistic modeling and mostly rely on static thresholds, which greatly limits
the detection performance. In this paper, we propose the Mixture of Stylistic
Experts (MoSEs) framework that enables stylistics-aware uncertainty
quantification through conditional threshold estimation. MoSEs contain three
core components, namely, the Stylistics Reference Repository (SRR), the
Stylistics-Aware Router (SAR), and the Conditional Threshold Estimator (CTE).
For input text, SRR can activate the appropriate reference data in SRR and
provide them to CTE. Subsequently, CTE jointly models the linguistic
statistical properties and semantic features to dynamically determine the
optimal threshold. With a discrimination score, MoSEs yields prediction labels
with the corresponding confidence level. Our framework achieves an average
improvement 11.34% in detection performance compared to baselines. More
inspiringly, MoSEs shows a more evident improvement 39.15% in the low-resource
case. Our code is available at https://github.com/creator-xi/MoSEs.

</details>


### [131] [L3Cube-IndicHeadline-ID: A Dataset for Headline Identification and Semantic Evaluation in Low-Resource Indian Languages](https://arxiv.org/abs/2509.02503)
*Nishant Tanksale,Tanmay Kokate,Darshan Gohad,Sarvadnyaa Barate,Raviraj Joshi*

Main category: cs.CL

TL;DR: 这篇论文为印度语言开发了L3Cube-IndicHeadline-ID数据集，用于评估句子编码器在低资源语言中的语义理解能力，包含10种印度语言的20,000篇新闻文章和四种标题变体。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言中语义评估的挑战，填补印度语言缺乏高质量基准测试集的空白，以支持句子编码器在这些语言中的研究和应用。

Method: 构建了包含10种印度语言和英语的新闻标题识别数据集，每篇文章配有四种标题变体：原始标题、语义相似版本、词汇相似版本和无关标题。使用余弦相似度对多语言和语言特定句子编码器进行性能测试。

Result: 多语言模型表现一致良好，而语言特定模型的效果存在差异。该数据集不仅可用于语义理解评估，还可重新用于多选题答题、标题分类等其他NLP任务。

Conclusion: L3Cube-IndicHeadline-ID数据集为印度语言的语义理解研究提供了重要的基准资源，尤其在RAG系统中具有应用价值，并展示了多语言模型在低资源语言中的优势。

Abstract: Semantic evaluation in low-resource languages remains a major challenge in
NLP. While sentence transformers have shown strong performance in high-resource
settings, their effectiveness in Indic languages is underexplored due to a lack
of high-quality benchmarks. To bridge this gap, we introduce
L3Cube-IndicHeadline-ID, a curated headline identification dataset spanning ten
low-resource Indic languages: Marathi, Hindi, Tamil, Gujarati, Odia, Kannada,
Malayalam, Punjabi, Telugu, Bengali and English. Each language includes 20,000
news articles paired with four headline variants: the original, a semantically
similar version, a lexically similar version, and an unrelated one, designed to
test fine-grained semantic understanding. The task requires selecting the
correct headline from the options using article-headline similarity. We
benchmark several sentence transformers, including multilingual and
language-specific models, using cosine similarity. Results show that
multilingual models consistently perform well, while language-specific models
vary in effectiveness. Given the rising use of similarity models in
Retrieval-Augmented Generation (RAG) pipelines, this dataset also serves as a
valuable resource for evaluating and improving semantic understanding in such
applications. Additionally, the dataset can be repurposed for multiple-choice
question answering, headline classification, or other task-specific evaluations
of LLMs, making it a versatile benchmark for Indic NLP. The dataset is shared
publicly at https://github.com/l3cube-pune/indic-nlp

</details>


### [132] [The Forgotten Code: Validating a Century-Old Translation System with AI](https://arxiv.org/abs/2509.02506)
*Jean-Marie Le Ray*

Main category: cs.CL

TL;DR: 本研究通过AI重现了1929年Federico Pucci发明的基于规则的机器翻译系统，验证了该方法在94年后仍能产生相似结果，并将这一被遗忘的早期机器翻译先驱重新纳入历史视野。


<details>
  <summary>Details</summary>
Motivation: 重新发掘和验证Federico Pucci在1929年提出的基于规则的机器翻译系统，这一早期发明几乎被完全遗忘，从未在创造者之外得到应用。研究旨在通过现代AI技术验证该方法的有效性，并确立Pucci在机器翻译历史上的地位。

Method: 使用AI按照Pucci的方法重新翻译1931年文献中记录的两个文本片段：但丁《新生》的意大利语到法语翻译，以及伏尔泰《查第格》的法语到意大利语翻译。随后将方法扩展到英语、西班牙语和德语，并尝试翻译更现代的科技文本。

Result: AI按照Pucci方法翻译的结果与94年前的原始翻译相比差异很小，只有微小变化。方法在多种语言间转换都表现一致，证明该系统的有效性。

Conclusion: Pucci的机器翻译系统经过近一个世纪后仍能有效工作，应被确认为机器翻译领域的早期先驱，其贡献应与Troyanskij、Booth和Weaver等知名先驱并列，这可能改变对机器翻译历史的理解。

Abstract: A pioneering rule-based mechanical translation system (precursor of modern
RBMTs) was first presented in December 1929 by its inventor, Federico Pucci,
who later published the full method in a book titled "Il traduttore meccanico
ed il metodo per corrispondersi fra Europei conoscendo ciascuno solo la propria
lingua: Parte I", in Salerno (Italy), in 1931. This study illustrates how AI
breathes new life into the system of international keys and ideograms devised
by Pucci to translate from/into any Romance language (at least as a first
step). The methodology involves having the AIs retranslate, following Pucci's
method, the two text excerpts originally translated in 1931 and clearly
documented in his publication: a passage from Dante's La Vita Nuova, translated
from Italian into French, and a passage from Voltaire's Zadig, translated from
French into Italian. The result is notable: the two texts, translated 94 years
apart using the same method--by Pucci in 1931 and by AIs in 2025--show a low
average difference, with only minor variations observed. With Pucci's system
thus validated, it became feasible to have the AIs reproduce the excerpts in
English, Spanish, and German according to his method. The results were
consistent, and Pucci--via Artificial Intelligence--was tasked with translating
more modern and technical texts, thereby reviving, nearly a century later, an
invention that had remained almost entirely unknown and never applied beyond
its creator, now brought to wider attention and opened to possible
experimentation. Such a demonstration would not only affirm Pucci's historical
status but also place him among the precursors and intellectual contributors to
machine translation, whose work merits examination alongside figures such as
Troyanskij, Booth, and Weaver, with possible consequences for how the history
of the field is understood.

</details>


### [133] [Top-H Decoding: Adapting the Creativity and Coherence with Bounded Entropy in Text Generation](https://arxiv.org/abs/2509.02510)
*Erfan Baghaei Potraghloo,Seyedarmin Azizi,Souvik Kundu,Massoud Pedram*

Main category: cs.CL

TL;DR: 提出了top-H解码方法，通过熵约束质量最大化来解决LLM在开放文本生成中多样性与逻辑连贯性的平衡问题，相比现有方法性能提升显著


<details>
  <summary>Details</summary>
Motivation: 现有截断采样技术（如温度缩放、top-p采样、min-p采样）在有效融入模型置信度方面存在局限，特别是min-p采样仅依赖单个顶部token作为置信度启发式方法，未能充分利用概率分布信息

Method: 首先建立熵约束最小散度问题的理论框架，证明其等价于NP难的熵约束质量最大化问题，然后提出top-H解码这一计算高效贪心算法来解决该问题

Result: 在创意写作基准测试中top-H比最先进的min-p采样方法性能提升高达25.63%，在GPQA、GSM8K和MT-Bench等问答数据集上保持鲁棒性，LLM作为评判者的评估确认即使在更高温度下也能产生连贯输出

Conclusion: top-H推进了开放文本生成的最新技术水平，可轻松集成到创意写作应用中，有效平衡了创造性与连贯性

Abstract: Large language models (LLMs), despite their impressive performance across a
wide range of tasks, often struggle to balance two competing objectives in
open-ended text generation: fostering diversity and creativity while preserving
logical coherence. Existing truncated sampling techniques, including
temperature scaling, top-\$p\$ (nucleus) sampling, and min-\$p\$ sampling, aim
to manage this trade-off. However, they exhibit limitations, particularly in
the effective incorporation of the confidence of the model into the
corresponding sampling strategy. For example, min-\$p\$ sampling relies on a
single top token as a heuristic for confidence, eventually underutilizing the
information of the probability distribution. Toward effective incorporation of
the confidence of the model, in this paper, we present **top-H** decoding. We
first establish the theoretical foundation of the interplay between creativity
and coherence in truncated sampling by formulating an **entropy-constrained
minimum divergence** problem. We then prove this minimization problem to be
equivalent to an **entropy-constrained mass maximization** (ECMM) problem,
which is NP-hard. Finally, we present top-H decoding, a computationally
efficient greedy algorithm to solve the ECMM problem. Extensive empirical
evaluations demonstrate that top-H outperforms the state-of-the-art (SoTA)
alternative of min-\$p\$ sampling by up to **25.63%** on creative writing
benchmarks, while maintaining robustness on question-answering datasets such as
GPQA, GSM8K, and MT-Bench. Additionally, an *LLM-as-judge* evaluation confirms
that top-H indeed produces coherent outputs even at higher temperatures, where
creativity is especially critical. In summary, top-H advances SoTA in
open-ended text generation and can be *easily integrated* into creative writing
applications. The code is available at
https://github.com/ErfanBaghaei/Top-H-Decoding.

</details>


### [134] [Comparative Study of Pre-Trained BERT and Large Language Models for Code-Mixed Named Entity Recognition](https://arxiv.org/abs/2509.02514)
*Mayur Shirke,Amey Shembade,Pavan Thorat,Madhushri Wagh,Raviraj Joshi*

Main category: cs.CL

TL;DR: 本研究比较了针对印地语-英语混合文本的专门微调模型、多语言模型和零样本大语言模型在命名实体识别任务上的表现，发现专门针对混合文本训练的模型性能最佳


<details>
  <summary>Details</summary>
Motivation: 印地语-英语混合文本的命名实体识别面临非正式结构、音译和频繁语言转换等独特挑战，需要评估不同模型的适应性和性能

Method: 评估了HingBERT、HingMBERT、HingRoBERTa等专门微调模型，BERT Base Cased、IndicBERT等多语言模型，以及Google Gemini零样本大语言模型，使用精确率、召回率和F1分数在基准数据集上进行测试

Result: 专门针对混合文本训练的模型（特别是HingRoBERTa和HingBERT）性能最优，超越了包括Google Gemini在内的闭源大语言模型。非混合文本模型表现尚可但适应性有限，Gemini在零样本设置下展现出有竞争力的性能

Conclusion: 针对特定领域预训练的专门模型在代码混合命名实体识别任务中表现最佳，但现代大语言模型也展现出强大的泛化能力，为专门化与通用化模型的选择提供了重要见解

Abstract: Named Entity Recognition (NER) in code-mixed text, particularly Hindi-English
(Hinglish), presents unique challenges due to informal structure,
transliteration, and frequent language switching. This study conducts a
comparative evaluation of code-mixed fine-tuned models and non-code-mixed
multilingual models, along with zero-shot generative large language models
(LLMs). Specifically, we evaluate HingBERT, HingMBERT, and HingRoBERTa (trained
on code-mixed data), and BERT Base Cased, IndicBERT, RoBERTa and MuRIL (trained
on non-code-mixed multilingual data). We also assess the performance of Google
Gemini in a zero-shot setting using a modified version of the dataset with NER
tags removed. All models are tested on a benchmark Hinglish NER dataset using
Precision, Recall, and F1-score. Results show that code-mixed models,
particularly HingRoBERTa and HingBERT-based fine-tuned models, outperform
others - including closed-source LLMs like Google Gemini - due to
domain-specific pretraining. Non-code-mixed models perform reasonably but show
limited adaptability. Notably, Google Gemini exhibits competitive zero-shot
performance, underlining the generalization strength of modern LLMs. This study
provides key insights into the effectiveness of specialized versus generalized
models for code-mixed NER tasks.

</details>


### [135] [Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR](https://arxiv.org/abs/2509.02522)
*Jiaming Li,Longze Chen,Ze Gong,Yukun Chen,Lu Wang,Wanwei He,Run Luo,Min Yang*

Main category: cs.CL

TL;DR: PACS是一个新的RLVR框架，通过监督学习实现隐式Actor-Critic耦合，将可验证奖励问题转化为监督学习任务，在数学推理任务上表现优于PPO和GRPO等基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法存在奖励信号稀疏和策略梯度更新不稳定的问题，特别是在基于RL的方法中，需要更稳定高效的训练框架。

Method: 将结果奖励视为可预测标签，将RLVR问题重新表述为对策略模型参数化评分函数的监督学习任务，使用交叉熵损失进行优化，实现隐式的Actor-Critic耦合。

Result: 在数学推理基准测试中，PACS显著优于PPO和GRPO等强基线，在AIME 2025上达到59.78%的pass@256，比PPO和GRPO分别提升13.32和14.36个百分点。

Conclusion: PACS提供了一个简单而强大的框架，为具有可验证奖励的LLM后训练提供了有前景的途径，通过监督学习实现了更稳定高效的训练。

Abstract: Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) have
empowered large language models (LLMs) to tackle challenging reasoning tasks
such as mathematics and programming. RLVR leverages verifiable outcome rewards
to guide policy optimization, enabling LLMs to progressively improve output
quality in a grounded and reliable manner. Despite its promise, the RLVR
paradigm poses significant challenges, as existing methods often suffer from
sparse reward signals and unstable policy gradient updates, particularly in
RL-based approaches. To address the challenges, we propose $\textbf{PACS}$, a
novel RLVR framework that achieves im$\textbf{P}$licit $\textbf{A}$ctor
$\textbf{C}$ritic coupling via a $\textbf{S}$upervised learning framework. By
treating the outcome reward as a predictable label, we reformulate the RLVR
problem into a supervised learning task over a score function parameterized by
the policy model and optimized using cross-entropy loss. A detailed gradient
analysis shows that this supervised formulation inherently recovers the
classical policy gradient update while implicitly coupling actor and critic
roles, yielding more stable and efficient training. Benchmarking on challenging
mathematical reasoning tasks, PACS outperforms strong RLVR baselines, such as
PPO and GRPO, achieving superior reasoning performance. For instance, PACS
achieves 59.78\% at pass@256 on AIME 2025, representing improvements of 13.32
and 14.36 points over PPO and GRPO. This simple yet powerful framework offers a
promising avenue for LLMs post-training with verifiable rewards. Our code and
data are available as open source at https://github.com/ritzz-ai/PACS.

</details>


### [136] [Jointly Reinforcing Diversity and Quality in Language Model Generations](https://arxiv.org/abs/2509.02534)
*Tianjian Li,Yiming Zhang,Ping Yu,Swarnadeep Saha,Daniel Khashabi,Jason Weston,Jack Lanchantin,Tianlu Wang*

Main category: cs.CL

TL;DR: DARLING框架通过联合优化响应质量和语义多样性，解决了大语言模型后训练中准确性和多样性之间的权衡问题，在创意任务和可验证任务上都取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的后训练往往过分关注准确性和有用性，导致输出分布过于集中，限制了在创意探索任务（如头脑风暴、故事创作、问题解决）中的实用性，需要平衡质量与多样性。

Method: 提出多样性感知强化学习（DARLING）框架，引入学习的分区函数来测量超越表面词汇变化的语义多样性，将多样性信号与质量奖励结合进行在线强化学习。

Result: 在多个模型家族和规模上的实验表明，DARLING在非可验证任务（指令跟随和创意写作）和可验证任务（竞赛数学）上都优于仅优化质量的RL基线，同时产生更高质量和更新颖的输出。

Conclusion: 明确优化多样性可以催化在线强化学习中的探索，表现为更高质量的响应，证明了在语言模型训练中同时考虑质量和多样性的重要性。

Abstract: Post-training of Large Language Models (LMs) often prioritizes accuracy and
helpfulness at the expense of diversity. This creates a tension: while
post-training improves response quality, it also sharpens output distributions
and reduces the range of ideas, limiting the usefulness of LMs in creative and
exploratory tasks such as brainstorming, storytelling, or problem solving. We
address this challenge with Diversity-Aware Reinforcement Learning (DARLING), a
framework that jointly optimizes for response quality and semantic diversity.
At its core, DARLING introduces a learned partition function to measure
diversity beyond surface-level lexical variations. This diversity signal is
then combined with a quality reward during online reinforcement learning,
encouraging models to generate outputs that are both high-quality and distinct.
Experiments across multiple model families and sizes show that DARLING
generalizes to two regimes: non-verifiable tasks (instruction following and
creative writing) and verifiable tasks (competition math). On five benchmarks
in the first setting, DARLING consistently outperforms quality-only RL
baselines, producing outputs that are simultaneously of higher quality and
novelty. In the second setting, DARLING achieves higher pass@1 (solution
quality) and pass@k (solution variety). Most strikingly, explicitly optimizing
for diversity catalyzes exploration in online RL, which manifests itself as
higher-quality responses.

</details>


### [137] [PalmX 2025: The First Shared Task on Benchmarking LLMs on Arabic and Islamic Culture](https://arxiv.org/abs/2509.02550)
*Fakhraddin Alwajih,Abdellah El Mekki,Hamdy Mubarak,Majd Hawasly,Abubakr Mohamed,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: PalmX 2025是首个针对LLMs在阿拉伯和伊斯兰文化领域文化能力的基准测试任务，包含阿拉伯文化和伊斯兰文化两个子任务，结果显示任务特定微调显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: LLMs在预训练阶段主要接触西方高资源语言和文化数据，导致对阿拉伯和伊斯兰文化的理解存在明显差距，特别是在代表性不足的主题上。

Method: 设计了包含多项选择题的两个子任务：通用阿拉伯文化和通用伊斯兰文化，涵盖22个阿拉伯国家的传统、食物、历史、宗教实践和语言表达等广泛主题。

Result: 任务吸引了26个团队注册子任务1和19个团队注册子任务2，最终分别有9个和6个有效提交。最佳系统在文化问题上达到72.15%准确率，在伊斯兰知识上达到84.22%准确率。

Conclusion: 任务特定微调显著优于基线模型，参数高效微调是最主要且最有效的方法，而数据增强的效用具有领域依赖性。

Abstract: Large Language Models (LLMs) inherently reflect the vast data distributions
they encounter during their pre-training phase. As this data is predominantly
sourced from the web, there is a high chance it will be skewed towards
high-resourced languages and cultures, such as those of the West. Consequently,
LLMs often exhibit a diminished understanding of certain communities, a gap
that is particularly evident in their knowledge of Arabic and Islamic cultures.
This issue becomes even more pronounced with increasingly under-represented
topics. To address this critical challenge, we introduce PalmX 2025, the first
shared task designed to benchmark the cultural competence of LLMs in these
specific domains. The task is composed of two subtasks featuring
multiple-choice questions (MCQs) in Modern Standard Arabic (MSA): General
Arabic Culture and General Islamic Culture. These subtasks cover a wide range
of topics, including traditions, food, history, religious practices, and
language expressions from across 22 Arab countries. The initiative drew
considerable interest, with 26 teams registering for Subtask 1 and 19 for
Subtask 2, culminating in nine and six valid submissions, respectively. Our
findings reveal that task-specific fine-tuning substantially boosts performance
over baseline models. The top-performing systems achieved an accuracy of 72.15%
on cultural questions and 84.22% on Islamic knowledge. Parameter-efficient
fine-tuning emerged as the predominant and most effective approach among
participants, while the utility of data augmentation was found to be
domain-dependent.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [138] [Traj-MLLM: Can Multimodal Large Language Models Reform Trajectory Data Mining?](https://arxiv.org/abs/2509.00053)
*Shuo Liu,Di Yao,Yan Lin,Gao Cong,Jingping Bi*

Main category: cs.MM

TL;DR: Traj-MLLM是首个使用多模态大语言模型进行轨迹数据挖掘的通用框架，通过多视图上下文将原始轨迹转换为图像-文本序列，无需训练数据或微调即可在多个任务上超越现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹分析方法存在泛化性问题，要么局限于特定区域训练，要么只适用于少数任务。本文探索MLLMs是否能改革当前轨迹数据挖掘并解决这些问题。

Method: 提出Traj-MLLM框架：1）集成多视图上下文将原始轨迹转换为保持时空特征的图像-文本序列；2）直接利用MLLMs的推理能力进行轨迹分析；3）提出提示优化方法实现任务自适应。

Result: 在四个公开数据集上的实验显示，Traj-MLLM在旅行时间估计、移动性预测、异常检测和交通方式识别任务上分别超越最先进基线48.05%、15.52%、51.52%和1.83%，且无需训练数据或微调MLLM骨干网络。

Conclusion: Traj-MLLM成功证明了MLLMs在轨迹数据挖掘中的有效性，通过多模态表示和提示优化实现了跨区域和跨任务的通用轨迹分析能力，为解决轨迹分析的泛化问题提供了新思路。

Abstract: Building a general model capable of analyzing human trajectories across
different geographic regions and different tasks becomes an emergent yet
important problem for various applications. However, existing works suffer from
the generalization problem, \ie, they are either restricted to train for
specific regions or only suitable for a few tasks. Given the recent advances of
multimodal large language models (MLLMs), we raise the question: can MLLMs
reform current trajectory data mining and solve the problem? Nevertheless, due
to the modality gap of trajectory, how to generate task-independent multimodal
trajectory representations and how to adapt flexibly to different tasks remain
the foundational challenges. In this paper, we propose \texttt{Traj-MLLM}},
which is the first general framework using MLLMs for trajectory data mining. By
integrating multiview contexts, \texttt{Traj-MLLM}} transforms raw trajectories
into interleaved image-text sequences while preserving key spatial-temporal
characteristics, and directly utilizes the reasoning ability of MLLMs for
trajectory analysis. Additionally, a prompt optimization method is proposed to
finalize data-invariant prompts for task adaptation. Extensive experiments on
four publicly available datasets show that \texttt{Traj-MLLM}} outperforms
state-of-the-art baselines by $48.05\%$, $15.52\%$, $51.52\%$, $1.83\%$ on
travel time estimation, mobility prediction, anomaly detection and
transportation mode identification, respectively. \texttt{Traj-MLLM}} achieves
these superior performances without requiring any training data or fine-tuning
the MLLM backbones.

</details>


### [139] [LLM-Guided Semantic Relational Reasoning for Multimodal Intent Recognition](https://arxiv.org/abs/2509.01337)
*Qianrui Zhou,Hua Xu,Yifan Wang,Xinzhi Dong,Hanlei Zhang*

Main category: cs.MM

TL;DR: 提出LGSRR方法，利用LLM的知识增强小模型的关系推理能力，通过浅到深的思维链自动提取细粒度语义，在多模态意图识别任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有方法在模态层面依赖性强，限制了复杂意图理解中的细粒度语义关系推理能力

Method: 使用LLM基于浅到深思维链策略自动提取细粒度语义作为指导，形式化建模三种基本语义关系类型并分析其相互作用

Result: 在多模态意图和对话行为识别任务上超越最先进方法，在不同语义理解场景中均获得一致性能提升

Conclusion: LGSRR方法通过LLM引导的语义关系推理有效提升了复杂意图理解能力，为多模态行为分析提供了新思路

Abstract: Understanding human intents from multimodal signals is critical for analyzing
human behaviors and enhancing human-machine interactions in real-world
scenarios. However, existing methods exhibit limitations in their
modality-level reliance, constraining relational reasoning over fine-grained
semantics for complex intent understanding. This paper proposes a novel
LLM-Guided Semantic Relational Reasoning (LGSRR) method, which harnesses the
expansive knowledge of large language models (LLMs) to establish semantic
foundations that boost smaller models' relational reasoning performance.
Specifically, an LLM-based strategy is proposed to extract fine-grained
semantics as guidance for subsequent reasoning, driven by a shallow-to-deep
Chain-of-Thought (CoT) that autonomously uncovers, describes, and ranks
semantic cues by their importance without relying on manually defined priors.
Besides, we formally model three fundamental types of semantic relations
grounded in logical principles and analyze their nuanced interplay to enable
more effective relational reasoning. Extensive experiments on multimodal intent
and dialogue act recognition tasks demonstrate LGSRR's superiority over
state-of-the-art methods, with consistent performance gains across diverse
semantic understanding scenarios. The complete data and code are available at
https://github.com/thuiar/LGSRR.

</details>


### [140] [Efficient Geometry Compression and Communication for 3D Gaussian Splatting Point Clouds](https://arxiv.org/abs/2509.02232)
*Liang Xie,Yanting Li,Luyang Tang,Wei Gao*

Main category: cs.MM

TL;DR: 使用AVS PCRM压缩技术优化3D高斯场景的储存和传输效率，在40Mbps带宽下实现高保真传输，节省10%-25%码率


<details>
  <summary>Details</summary>
Motivation: 解决动态3D场景表示中高斯数据量爆发式增长导致的储存和传输挑战

Method: 在i3DV平台中集成AVS PCRM参考软件，结合二进制哈希表的率头优化机制，对高斯点云几何数据进行高效压缩

Result: 实验结果显示该联合框架在保持快速渲染和高质量合成优势的同时，在通用测试集上实现了10%-25%的码率节省

Conclusion: 该方案为3D体积视频的储存、传输和交互提供了优秀的率头夸损恢复解决方案

Abstract: Storage and transmission challenges in dynamic 3D scene representation based
on the i3DV platform, With increasing scene complexity, the explosive growth of
3D Gaussian data volume causes excessive storage space occupancy. To address
this issue, we propose adopting the AVS PCRM reference software for efficient
compression of Gaussian point cloud geometry data. The strategy deeply
integrates the advanced encoding capabilities of AVS PCRM into the i3DV
platform, forming technical complementarity with the original rate-distortion
optimization mechanism based on binary hash tables. On one hand, the hash table
efficiently caches inter-frame Gaussian point transformation relationships,
which allows for high-fidelity transmission within a 40 Mbps bandwidth
constraint. On the other hand, AVS PCRM performs precise compression on
geometry data. Experimental results demonstrate that the joint framework
maintains the advantages of fast rendering and high-quality synthesis in 3D
Gaussian technology while achieving significant 10\%-25\% bitrate savings on
universal test sets. It provides a superior rate-distortion tradeoff solution
for the storage, transmission, and interaction of 3D volumetric video.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [141] [From Sound to Sight: Towards AI-authored Music Videos](https://arxiv.org/abs/2509.00029)
*Leo Vitasovic,Stella Graßhof,Agnes Mercedes Kloft,Ville V. Lehtola,Martin Cunneen,Justyna Starostka,Glenn McGarry,Kun Li,Sami S. Brandt*

Main category: cs.SD

TL;DR: 提出两种基于深度学习模型的自动音乐视频生成管道，通过音频特征分析和文本场景描述生成，实现音乐情感和节奏的可视化表达


<details>
  <summary>Details</summary>
Motivation: 传统音乐可视化系统依赖手工制作的形状和颜色变换，表达能力有限，需要更智能的自动生成方法来提升音乐视频的创作效率和质量

Method: 使用现成的深度学习模型：1）基于潜在特征技术分析音频，检测音乐品质（情感线索、乐器模式）；2）用语言模型生成文本场景描述；3）用生成模型生成对应视频片段

Result: 通过初步用户评估验证了生成视频在叙事潜力、视觉连贯性和情感对齐方面的表现，展示了良好的效果

Conclusion: 潜在特征技术和深度生成模型有潜力将音乐可视化扩展到超越传统方法的新领域，为自动音乐视频创作提供了可行方案

Abstract: Conventional music visualisation systems rely on handcrafted ad hoc
transformations of shapes and colours that offer only limited expressiveness.
We propose two novel pipelines for automatically generating music videos from
any user-specified, vocal or instrumental song using off-the-shelf deep
learning models. Inspired by the manual workflows of music video producers, we
experiment on how well latent feature-based techniques can analyse audio to
detect musical qualities, such as emotional cues and instrumental patterns, and
distil them into textual scene descriptions using a language model. Next, we
employ a generative model to produce the corresponding video clips. To assess
the generated videos, we identify several critical aspects and design and
conduct a preliminary user evaluation that demonstrates storytelling potential,
visual coherency and emotional alignment with the music. Our findings
underscore the potential of latent feature techniques and deep generative
models to expand music visualisation beyond traditional approaches.

</details>


### [142] [A Survey on Evaluation Metrics for Music Generation](https://arxiv.org/abs/2509.00051)
*Faria Binte Kader,Santu Karmaker*

Main category: cs.SD

TL;DR: 本文系统分析了音乐生成评估方法的研究现状，指出了当前评估体系在客观指标与人类感知相关性、跨文化偏见和标准化缺失等方面的主要局限，并提出了构建全面评估框架的未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管音乐生成系统取得了显著进展，但由于音乐本身的复杂性（如结构、连贯性、创造性和情感表达等方面），评估生成音乐的方法学发展滞后，存在明显的研究空白。

Method: 通过引入针对音频和符号音乐表示的详细评估指标分类法，并进行批判性文献综述，识别当前评估方法学的主要局限性。

Result: 研究发现当前评估方法存在三个主要问题：客观指标与人类感知相关性差、存在跨文化偏见、缺乏标准化导致跨模型比较困难。

Conclusion: 需要构建一个全面的音乐生成评估框架来解决现有局限性，本文为此提出了具体的未来研究方向。

Abstract: Despite significant advancements in music generation systems, the
methodologies for evaluating generated music have not progressed as expected
due to the complex nature of music, with aspects such as structure, coherence,
creativity, and emotional expressiveness. In this paper, we shed light on this
research gap, introducing a detailed taxonomy for evaluation metrics for both
audio and symbolic music representations. We include a critical review
identifying major limitations in current evaluation methodologies which
includes poor correlation between objective metrics and human perception,
cross-cultural bias, and lack of standardization that hinders cross-model
comparisons. Addressing these gaps, we further propose future research
directions towards building a comprehensive evaluation framework for music
generation evaluation.

</details>


### [143] [CoComposer: LLM Multi-agent Collaborative Music Composition](https://arxiv.org/abs/2509.00132)
*Peiwen Xing,Aske Plaat,Niki van Stein*

Main category: cs.SD

TL;DR: CoComposer是一个多智能体音乐创作系统，通过五个协作智能体模拟传统作曲流程，在音乐质量和制作复杂度上优于现有基于LLM的多智能体系统，相比非LLM的MusicLM具有更好的可解释性和可编辑性。


<details>
  <summary>Details</summary>
Motivation: 现有AI音乐创作工具在生成时长、音乐质量和可控性方面存在局限，需要开发更好的多智能体协作系统来提升音乐创作能力。

Method: 构建包含五个协作智能体的多智能体系统，每个智能体基于传统音乐创作流程执行特定任务，使用AudioBox-Aesthetics系统在四个作曲标准上进行实验评估，测试了GPT-4o、DeepSeek-V3-0324和Gemini-2.5-Flash三种LLM。

Result: CoComposer在音乐质量上优于现有基于LLM的多智能体系统，在制作复杂度上优于单智能体系统，相比非LLM的MusicLM具有更好的可解释性和可编辑性，但MusicLM仍能产生更好的音乐。

Conclusion: 多智能体协作方法能有效提升AI音乐创作的性能，特别是在可解释性和可控性方面，但在纯音乐质量方面仍需进一步提升以匹敌专业音乐生成系统。

Abstract: Existing AI Music composition tools are limited in generation duration,
musical quality, and controllability. We introduce CoComposer, a multi-agent
system that consists of five collaborating agents, each with a task based on
the traditional music composition workflow. Using the AudioBox-Aesthetics
system, we experimentally evaluate CoComposer on four compositional criteria.
We test with three LLMs (GPT-4o, DeepSeek-V3-0324, Gemini-2.5-Flash), and find
(1) that CoComposer outperforms existing multi-agent LLM-based systems in music
quality, and (2) compared to a single-agent system, in production complexity.
Compared to non- LLM MusicLM, CoComposer has better interpretability and
editability, although MusicLM still produces better music.

</details>


### [144] [Algorithms for Collaborative Harmonization](https://arxiv.org/abs/2509.00120)
*Eyal Briman,Eyal Leizerovich,Nimrod Talmon*

Main category: cs.SD

TL;DR: 本文研究音乐和声聚合问题，提出多种算法来聚合多个和声建议，旨在实现集体意见的有效代表和音乐连贯性，发现Kemeny和基于多数的算法效果最佳。


<details>
  <summary>Details</summary>
Motivation: 音乐和声与文本聚合有相似之处，但和声语言更具结构性。需要开发聚合算法来处理多个和声建议，既要有效代表集体意见，又要保持音乐连贯性。

Method: 提出了不同的和声聚合算法，包括Kemeny算法和基于多数的算法，并分析了这些算法的复杂度。

Result: 研究结果表明，Kemeny算法和基于多数的算法在评估代表性和保持音乐连贯性方面最为有效。

Conclusion: 在音乐和声聚合场景中，Kemeny和基于多数的算法能够很好地平衡集体意见代表性和音乐质量的要求。

Abstract: We consider a specific scenario of text aggregation, in the realm of musical
harmonization. Musical harmonization shares similarities with text aggregation,
however the language of harmony is more structured than general text.
Concretely, given a set of harmonization suggestions for a given musical
melody, our interest lies in devising aggregation algorithms that yield an
harmonization sequence that satisfies the following two key criteria: (1) an
effective representation of the collective suggestions; and (2) an
harmonization that is musically coherent. We present different algorithms for
the aggregation of harmonies given by a group of agents and analyze their
complexities. The results indicate that the Kemeny and plurality-based
algorithms are most effective in assessing representation and maintaining
musical coherence.

</details>


### [145] [The Name-Free Gap: Policy-Aware Stylistic Control in Music Generation](https://arxiv.org/abs/2509.00654)
*Ashwin Nagarajan,Hao-Wen Dong*

Main category: cs.SD

TL;DR: 该研究探讨使用大型语言模型生成的人可读描述符作为艺术家名称的替代方案，用于音乐生成的风格控制，发现名称限制可能无法完全防止风格模仿。


<details>
  <summary>Details</summary>
Motivation: 现有音乐风格化方法通常需要重新训练或特殊条件设置，限制了可复现性和政策合规性。研究旨在寻找轻量级、政策鲁棒的风格控制替代方案。

Method: 使用MusicGen-small模型，评估Billie Eilish和Ludovico Einaudi两位艺术家的风格控制。通过大型语言模型生成三种提示条件：基线提示、艺术家名称提示和五组描述符集，使用VGGish和CLAP嵌入进行评估。

Result: 艺术家名称是最强的控制信号，但无名称描述符能恢复大部分效果。跨艺术家转移会降低对齐度，表明描述符编码了目标风格线索。

Conclusion: 研究定义了"无名称差距"概念，展示了通过可复现评估协议验证提示级可控性的方法，表明现有艺术家名称限制措施可能无法完全防止风格模仿。

Abstract: Text-to-music models capture broad attributes such as instrumentation or
mood, but fine-grained stylistic control remains an open challenge. Existing
stylization methods typically require retraining or specialized conditioning,
which complicates reproducibility and limits policy compliance when artist
names are restricted. We study whether lightweight, human-readable modifiers
sampled from a large language model can provide a policy-robust alternative for
stylistic control. Using MusicGen-small, we evaluate two artists: Billie Eilish
(vocal pop) and Ludovico Einaudi (instrumental piano). For each artist, we use
fifteen reference excerpts and evaluate matched seeds under three conditions:
baseline prompts, artist-name prompts, and five descriptor sets. All prompts
are generated using a large language model. Evaluation uses both VGGish and
CLAP embeddings with distributional and per-clip similarity measures, including
a new min-distance attribution metric. Results show that artist names are the
strongest control signal across both artists, while name-free descriptors
recover much of this effect. This highlights that existing safeguards such as
the restriction of artist names in music generation prompts may not fully
prevent style imitation. Cross-artist transfers reduce alignment, showing that
descriptors encode targeted stylistic cues. We also present a descriptor table
across ten contemporary artists to illustrate the breadth of the tokens.
Together these findings define the name-free gap, the controllability
difference between artist-name prompts and policy-compliant descriptors, shown
through a reproducible evaluation protocol for prompt-level controllability.

</details>


### [146] [From Discord to Harmony: Decomposed Consonance-based Training for Improved Audio Chord Estimation](https://arxiv.org/abs/2509.01588)
*Andrea Poltronieri,Xavier Serra,Martín Rocamora*

Main category: cs.SD

TL;DR: 本文提出了一种基于协和度概念的音频和弦估计新方法，包括协和度感知的距离度量标准和整合协和度标签平滑的conformer模型，以解决标注者主观性和类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 音频和弦估计存在标注者主观性导致的标注不一致和数据集类别不平衡问题，现有系统性能遇到瓶颈，需要新的评估方法和模型来解决这些根本挑战。

Method: 1) 提出超越传统二元度量的标注者一致性评估方法；2) 设计基于协和度的感知相似性距离度量；3) 开发整合协和度标签平滑的conformer模型，通过分别估计根音、低音和所有音符激活来重构和弦标签。

Result: 分析表明基于协和度的距离度量能更有效地捕捉标注之间的音乐意义一致性，新模型通过分解输出重构和弦标签的方式有效解决了类别不平衡问题。

Conclusion: 协和度概念为音频和弦估计提供了更音乐化的评估和建模框架，能够更好地处理标注主观性和数据不平衡问题，推动该领域突破现有性能瓶颈。

Abstract: Audio Chord Estimation (ACE) holds a pivotal role in music information
research, having garnered attention for over two decades due to its relevance
for music transcription and analysis. Despite notable advancements, challenges
persist in the task, particularly concerning unique characteristics of harmonic
content, which have resulted in existing systems' performances reaching a glass
ceiling. These challenges include annotator subjectivity, where varying
interpretations among annotators lead to inconsistencies, and class imbalance
within chord datasets, where certain chord classes are over-represented
compared to others, posing difficulties in model training and evaluation. As a
first contribution, this paper presents an evaluation of inter-annotator
agreement in chord annotations, using metrics that extend beyond traditional
binary measures. In addition, we propose a consonance-informed distance metric
that reflects the perceptual similarity between harmonic annotations. Our
analysis suggests that consonance-based distance metrics more effectively
capture musically meaningful agreement between annotations. Expanding on these
findings, we introduce a novel ACE conformer-based model that integrates
consonance concepts into the model through consonance-based label smoothing.
The proposed model also addresses class imbalance by separately estimating
root, bass, and all note activations, enabling the reconstruction of chord
labels from decomposed outputs.

</details>


### [147] [Generalizable Audio Spoofing Detection using Non-Semantic Representations](https://arxiv.org/abs/2509.00186)
*Arnab Das,Yassine El Kheir,Carlos Franzreb,Tim Herzig,Tim Polzehl,Sebastian Möller*

Main category: cs.SD

TL;DR: 该研究提出了一种利用非语义普遍音频表征进行深度伪造音频检测的新方法，在跨域测试集上显著超过现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 随着生成式模型的快速发展，合成音频生成变得容易，使语音服务更易受到伪造攻击。现有的深度伪造检测方案缺乏普遍性，在应对真实世界数据时效果差强。

Method: 提出了一种新题的方法，利用非语义的普遍音频表征来进行伪造检测。通过使用TRILL和TRILLsson模型进行广泛实验，找到适合的非语义特征。

Result: 该方法在域内测试集上达到了相当的性能，而在跨域测试集上显著超过了最新的状态之一方法。在公开数据集上表现出优异的普遍性，超过了基于手工特征、语义嵌入和端到端架构的方法。

Conclusion: 该研究提出的基于非语义普遍音频表征的方法为深度伪造音频检测提供了一种更健壁和具有更好普遍性的解决方案，在实际应用场景中具有重要价值。

Abstract: Rapid advancements in generative modeling have made synthetic audio
generation easy, making speech-based services vulnerable to spoofing attacks.
Consequently, there is a dire need for robust countermeasures more than ever.
Existing solutions for deepfake detection are often criticized for lacking
generalizability and fail drastically when applied to real-world data. This
study proposes a novel method for generalizable spoofing detection leveraging
non-semantic universal audio representations. Extensive experiments have been
performed to find suitable non-semantic features using TRILL and TRILLsson
models. The results indicate that the proposed method achieves comparable
performance on the in-domain test set while significantly outperforming
state-of-the-art approaches on out-of-domain test sets. Notably, it
demonstrates superior generalization on public-domain data, surpassing methods
based on hand-crafted features, semantic embeddings, and end-to-end
architectures.

</details>


### [148] [Evaluating the Effectiveness of Transformer Layers in Wav2Vec 2.0, XLS-R, and Whisper for Speaker Identification Tasks](https://arxiv.org/abs/2509.00230)
*Linus Stuhlmann,Michael Alexander Saxer*

Main category: cs.SD

TL;DR: 评估Wav2Vec 2.0、XLS-R和Whisper三种语音编码器在说话人识别任务中的性能表现，分析各模型层级的特征表示能力


<details>
  <summary>Details</summary>
Motivation: 研究先进语音编码模型在说话人识别任务中的表现差异，探索不同模型层级对说话人特征的学习能力

Method: 通过微调模型并使用SVCCA、k-means聚类和t-SNE可视化分析层级表示，确定各模型在说话人识别任务中的最优层数

Result: Wav2Vec 2.0和XLS-R在早期层就能有效捕获说话人特征，微调后性能更稳定；Whisper在深层表现更好；确定了各模型微调后的最优transformer层数

Conclusion: 不同语音编码模型在说话人识别任务中表现出层级特征捕获的差异性，为模型选择和微调策略提供了指导

Abstract: This study evaluates the performance of three advanced speech encoder models,
Wav2Vec 2.0, XLS-R, and Whisper, in speaker identification tasks. By
fine-tuning these models and analyzing their layer-wise representations using
SVCCA, k-means clustering, and t-SNE visualizations, we found that Wav2Vec 2.0
and XLS-R capture speaker-specific features effectively in their early layers,
with fine-tuning improving stability and performance. Whisper showed better
performance in deeper layers. Additionally, we determined the optimal number of
transformer layers for each model when fine-tuned for speaker identification
tasks.

</details>


### [149] [Towards High-Fidelity and Controllable Bioacoustic Generation via Enhanced Diffusion Learning](https://arxiv.org/abs/2509.00318)
*Tianyu Song,Ton Viet Ta*

Main category: cs.SD

TL;DR: BirdDiff是一个生成式框架，通过多尺度自适应鸟鸣增强和扩散模型，直接从嘈杂的野外录音中合成高质量的鸟类叫声，在信噪比和分类准确性方面显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 生成式建模为生物声学提供了新机遇，可以合成真实的动物叫声来支持生物监测工作并为濒危物种补充稀缺数据。但直接从嘈杂的野外录音生成鸟类叫声波形仍然是一个重大挑战。

Method: BirdDiff包含一个用于多尺度自适应鸟鸣增强的"零层"阶段，然后是基于三种模态（梅尔频率倒谱系数、物种标签和文本描述）的扩散生成器。增强阶段在最小化频谱失真的同时提高信噪比。

Result: 与三种广泛使用的非训练增强方法相比，获得了最高的SNR增益（+10.45 dB）和最低的Itakura-Saito距离（0.54）。相比DiffWave基线，在FAD（0.590→0.213）、JSD（0.259→0.226）等生成质量指标上有显著提升，分类准确率从35.9%提高到70.1%。

Conclusion: BirdDiff能够直接从嘈杂的野外录音中实现高保真、可控的鸟类叫声生成，为生物声学监测和濒危物种保护提供了有效的技术解决方案。

Abstract: Generative modeling offers new opportunities for bioacoustics, enabling the
synthesis of realistic animal vocalizations that could support biomonitoring
efforts and supplement scarce data for endangered species. However, directly
generating bird call waveforms from noisy field recordings remains a major
challenge.
  We propose BirdDiff, a generative framework designed to synthesize bird calls
from a noisy dataset of 12 wild bird species. The model incorporates a "zeroth
layer" stage for multi-scale adaptive bird-call enhancement, followed by a
diffusion-based generator conditioned on three modalities: Mel-frequency
cepstral coefficients, species labels, and textual descriptions. The
enhancement stage improves signal-to-noise ratio (SNR) while minimizing
spectral distortion, achieving the highest SNR gain (+10.45 dB) and lowest
Itakura-Saito Distance (0.54) compared to three widely used non-training
enhancement methods.
  We evaluate BirdDiff against a baseline generative model, DiffWave. Our
method yields substantial improvements in generative quality metrics: Fr\'echet
Audio Distance (0.590 to 0.213), Jensen-Shannon Divergence (0.259 to 0.226),
and Number of Statistically-Different Bins (7.33 to 5.58). To assess
species-specific detail preservation, we use a ResNet50 classifier trained on
the original dataset to identify generated samples. Classification accuracy
improves from 35.9% (DiffWave) to 70.1% (BirdDiff), with 8 of 12 species
exceeding 70% accuracy.
  These results demonstrate that BirdDiff enables high-fidelity, controllable
bird call generation directly from noisy field recordings.

</details>


### [150] [SaD: A Scenario-Aware Discriminator for Speech Enhancement](https://arxiv.org/abs/2509.00405)
*Xihao Yuan,Siqi Liu,Yan Chen,Hang Zhou,Chang Liu,Hanting Chen,Jie Hu*

Main category: cs.SD

TL;DR: 通过提出场景感知辨别器，在不改变生成器结构的前提下，实现了语音增强性能的进一步提升


<details>
  <summary>Details</summary>
Motivation: 当前GAN模型的优化策略主要集中在生成器结构或评估指标的改进，忽视了多样化场景中的丰富上下文信息

Method: 提出场景感知辨别器，抓取场景特征并进行频域分割，从而更准确评估生成器产出的增强语音质量

Result: 在两个公开数据集上对三个代表性模型进行完整实验，结果表明方法能有效适应各种生成器结构

Conclusion: 该方法可以在不改变生成器结构的情况下，为不同场景下的语音增强应用带来进一步的性能提升

Abstract: Generative adversarial network-based models have shown remarkable performance
in the field of speech enhancement. However, the current optimization
strategies for these models predominantly focus on refining the architecture of
the generator or enhancing the quality evaluation metrics of the discriminator.
This approach often overlooks the rich contextual information inherent in
diverse scenarios. In this paper, we propose a scenario-aware discriminator
that captures scene-specific features and performs frequency-domain division,
thereby enabling a more accurate quality assessment of the enhanced speech
generated by the generator. We conducted comprehensive experiments on three
representative models using two publicly available datasets. The results
demonstrate that our method can effectively adapt to various generator
architectures without altering their structure, thereby unlocking further
performance gains in speech enhancement across different scenarios.

</details>


### [151] [PicoAudio2: Temporal Controllable Text-to-Audio Generation with Natural Language Description](https://arxiv.org/abs/2509.00683)
*Zihao Zheng,Zeyu Xie,Xuenan Xu,Wen Wu,Chao Zhang,Mengyue Wu*

Main category: cs.SD

TL;DR: PicoAudio2通过新的数据处理流程和模型架构改进时序可控的文本到音频生成，使用真实数据和模拟数据结合训练，提升生成音频质量和时序控制能力


<details>
  <summary>Details</summary>
Motivation: 现有文本到音频生成方法虽然能基于时间戳实现细粒度控制，但声音事件类别受限且仅使用模拟数据训练，导致生成音频质量和在真实数据上的泛化性能有限

Method: 使用grounding模型标注真实音频-文本数据集的时间戳来构建时序强化的真实数据，结合现有工作的模拟数据训练模型；采用时间戳矩阵编码时间信息，在粗粒度文本描述基础上提供细粒度时间对齐信息

Result: 实验表明PicoAudio2在时序可控性和音频质量方面表现出优越性能

Conclusion: 通过真实数据和模拟数据结合训练以及时间戳矩阵编码，PicoAudio2显著提升了时序可控文本到音频生成的性能

Abstract: Controllable text-to-audio generation (TTA) has attracted much attention
recently. Although existing works can achieve fine-grained controllability
based on timestamp information, sound event categories are limited to a fixed
set. Moreover, since only simulated data is used for training, the generated
audio quality and generalization performance on real data are limited. To
tackle this issue, we propose PicoAudio2, improving temporal-controllable TTA
via a new data processing pipeline and model architecture. Specifically, we use
a grounding model to annotate event timestamps of real audio-text datasets to
curate temporally-strong real data, in addition to simulation data from
existing works. The model is trained on the combination of real and simulation
data. Moreover, following PicoAudio, we encode timestamp information into a
timestamp matrix to provide extra fine-grained time-aligned information to the
model, on top of the coarse-grained textual description. Experiments show that
PicoAudio2 exhibits superior performance in terms of temporal controllability
and audio quality.

</details>


### [152] [AImoclips: A Benchmark for Evaluating Emotion Conveyance in Text-to-Music Generation](https://arxiv.org/abs/2509.00813)
*Gyehun Go,Satbyul Han,Ahyeon Choi,Eunjin Choi,Juhan Nam,Jeong Mi Park*

Main category: cs.SD

TL;DR: AImoclips基准测试评估文本到音乐生成系统在情感传达方面的表现，发现商业系统倾向于生成比预期更愉悦的音乐，而开源系统则相反，所有系统都存在情感中性化的偏差。


<details>
  <summary>Details</summary>
Motivation: 文本到音乐生成系统在情感保真度方面研究不足，需要评估这些系统如何向人类听众传达预期情感。

Method: 创建AImoclips基准，选择12种情感意图覆盖效价-唤醒空间的四个象限，使用6个最先进的TTM系统生成1000多个音乐片段，111名参与者在9点李克特量表上评分。

Result: 商业系统产生比预期更愉悦的音乐，开源系统表现相反；高唤醒条件下情感传达更准确；所有系统都存在情感中性化偏差。

Conclusion: 该基准揭示了模型特定的情感渲染特征，为开发情感对齐的文本到音乐系统提供了重要见解。

Abstract: Recent advances in text-to-music (TTM) generation have enabled controllable
and expressive music creation using natural language prompts. However, the
emotional fidelity of TTM systems remains largely underexplored compared to
human preference or text alignment. In this study, we introduce AImoclips, a
benchmark for evaluating how well TTM systems convey intended emotions to human
listeners, covering both open-source and commercial models. We selected 12
emotion intents spanning four quadrants of the valence-arousal space, and used
six state-of-the-art TTM systems to generate over 1,000 music clips. A total of
111 participants rated the perceived valence and arousal of each clip on a
9-point Likert scale. Our results show that commercial systems tend to produce
music perceived as more pleasant than intended, while open-source systems tend
to perform the opposite. Emotions are more accurately conveyed under
high-arousal conditions across all models. Additionally, all systems exhibit a
bias toward emotional neutrality, highlighting a key limitation in affective
controllability. This benchmark offers valuable insights into model-specific
emotion rendering characteristics and supports future development of
emotionally aligned TTM systems.

</details>


### [153] [Adaptive Vehicle Speed Classification via BMCNN with Reinforcement Learning-Enhanced Acoustic Processing](https://arxiv.org/abs/2509.00839)
*Yuli Zhang,Pengfei Fan,Ruiyuan Jiang,Hankang Gu,Dongyao Jia,Xinheng Wang*

Main category: cs.SD

TL;DR: 提出了一种结合深度学习和强化学习的混合框架，用于声学车辆速度分类，通过双分支CNN处理音频特征，并使用注意力增强的DQN实现早期决策，在准确性和效率方面达到优越表现。


<details>
  <summary>Details</summary>
Motivation: 交通拥堵是城市面临的紧迫挑战，需要智能交通系统进行实时管理。现有的车辆速度分类方法在准确性和实时性方面存在不足，特别是在异构城市环境中。

Method: 采用混合框架：1）双分支BMCNN处理MFCC和小波特征以捕获互补频率模式；2）注意力增强的DQN自适应选择最少音频帧数，并在达到置信度阈值时触发早期决策。

Result: 在IDMT-Traffic和SZUR-Acoustic数据集上分别达到95.99%和92.3%的准确率，通过早期终止实现平均处理速度提升1.63倍。相比A3C、DDDQN、SA2C、PPO和TD3等方法，在准确性和效率权衡方面表现更优。

Conclusion: 该方法为异构城市环境中的实时智能交通系统部署提供了有效的解决方案，在保持高准确性的同时显著提升了处理效率。

Abstract: Traffic congestion remains a pressing urban challenge, requiring intelligent
transportation systems for real-time management. We present a hybrid framework
that combines deep learning and reinforcement learning for acoustic vehicle
speed classification. A dual-branch BMCNN processes MFCC and wavelet features
to capture complementary frequency patterns. An attention-enhanced DQN
adaptively selects the minimal number of audio frames and triggers early
decisions once confidence thresholds are reached. Evaluations on IDMT-Traffic
and our SZUR-Acoustic (Suzhou) datasets show 95.99% and 92.3% accuracy, with up
to 1.63x faster average processing via early termination. Compared with A3C,
DDDQN, SA2C, PPO, and TD3, the method provides a superior accuracy-efficiency
trade-off and is suitable for real-time ITS deployment in heterogeneous urban
environments.

</details>


### [154] [Speech Command Recognition Using LogNNet Reservoir Computing for Embedded Systems](https://arxiv.org/abs/2509.00862)
*Yuriy Izotov,Andrei Velichko*

Main category: cs.SD

TL;DR: 提出了一种低资源语音命令识别系统，结合能量VAD、优化MFCC和LogNNet分类器，在Arduino上实现高效实时识别


<details>
  <summary>Details</summary>
Motivation: 解决在严格内存和计算限制下（如IoT设备）实现可靠语音命令识别的需求

Method: 使用能量VAD检测语音活动，优化MFCC特征提取（自适应分箱64维特征），采用LogNNet储层计算分类器（64:33:9:4架构）

Result: 达到92.04%的说话人无关识别准确率，Arduino实现约90%实时准确率，仅消耗18KB RAM（55%利用率）

Conclusion: 该完整流水线可在严格资源限制下实现可靠的设备端语音识别，适用于电池供电IoT节点和无线传感器网络

Abstract: This paper presents a low-resource speech-command recognizer combining
energy-based voice activity detection (VAD), an optimized Mel-Frequency
Cepstral Coefficients (MFCC) pipeline, and the LogNNet reservoir-computing
classifier. Using four commands from the Speech Commands da-taset downsampled
to 8 kHz, we evaluate four MFCC aggregation schemes and find that adaptive
binning (64-dimensional feature vector) offers the best accuracy-to-compactness
trade-off. The LogNNet classifier with architecture 64:33:9:4 reaches 92.04%
accuracy under speaker-independent evaluation, while requiring significantly
fewer parameters than conventional deep learn-ing models. Hardware
implementation on Arduino Nano 33 IoT (ARM Cor-tex-M0+, 48 MHz, 32 KB RAM)
validates the practical feasibility, achieving ~90% real-time recognition
accuracy while consuming only 18 KB RAM (55% utilization). The complete
pipeline (VAD -> MFCC -> LogNNet) thus enables reliable on-device
speech-command recognition under strict memory and compute limits, making it
suitable for battery-powered IoT nodes, wire-less sensor networks, and
hands-free control interfaces.

</details>


### [155] [TinyMusician: On-Device Music Generation with Knowledge Distillation and Mixed Precision Quantization](https://arxiv.org/abs/2509.00914)
*Hainan Wang,Mehdi Hosseinzadeh,Reza Rawassizadeh*

Main category: cs.SD

TL;DR: TinyMusician是一个轻量级音乐生成模型，通过知识蒸馏和量化技术，在保持93%性能的同时减少55%模型大小，实现移动端部署。


<details>
  <summary>Details</summary>
Motivation: Transformer架构的音乐生成模型虽然性能优秀，但参数量大、计算资源需求高，难以在计算资源有限的边缘设备（如智能手机）上部署。

Method: 从MusicGen模型蒸馏得到TinyMusician，采用两种创新技术：(i) 阶段混合双向和偏斜KL散度 (ii) 自适应混合精度量化。

Result: 实验结果显示，TinyMusician在模型大小减少55%的情况下，仍能保持MusicGen-Small模型93%的性能。

Conclusion: TinyMusician是首个可移动部署的音乐生成模型，消除了对云端的依赖，同时保持高音频保真度和高效的资源使用。

Abstract: The success of the generative model has gained unprecedented attention in the
music generation area. Transformer-based architectures have set new benchmarks
for model performance. However, their practical adoption is hindered by some
critical challenges: the demand for massive computational resources and
inference time, due to their large number of parameters. These obstacles make
them infeasible to deploy on edge devices, such as smartphones and wearables,
with limited computational resources. In this work, we present TinyMusician, a
lightweight music generation model distilled from MusicGen (a State-of-the-art
music generation model). TinyMusician integrates two innovations: (i)
Stage-mixed Bidirectional and Skewed KL-Divergence and (ii) Adaptive
Mixed-Precision Quantization. The experimental results demonstrate that
TinyMusician retains 93% of the MusicGen-Small performance with 55% less model
size. TinyMusician is the first mobile-deployable music generation model that
eliminates cloud dependency while maintaining high audio fidelity and efficient
resource usage

</details>


### [156] [A Unified Denoising and Adaptation Framework for Self-Supervised Bengali Dialectal ASR](https://arxiv.org/abs/2509.00988)
*Swadhin Biswas,Imran,Tuhin Sheikh*

Main category: cs.SD

TL;DR: 本文提出了一种基于WavLM的新型统一框架，通过多阶段微调策略和针对性数据增强，同时解决孟加拉语ASR中的方言多样性和环境噪声挑战，在多种噪声条件下显著优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为世界第五大语言，其ASR系统面临两大挑战：方言多样性巨大和现实环境中的声学噪声。现有SSL模型缺乏处理环境噪声的显式机制和针对方言变化的专门适应策略。

Method: 基于具有掩码语音去噪目标的WavLM模型，提出多阶段微调策略：首先适应通用标准孟加拉语建立语言基础，然后通过针对性数据增强专门化用于噪声鲁棒的方言识别。

Result: 在包含多种孟加拉语方言和广泛模拟噪声条件的综合基准测试中，该框架显著优于包括标准微调wav2vec 2.0和大规模多语言Whisper模型在内的强基线。

Conclusion: 这项工作为该任务建立了新的最先进水平，并为全球其他低资源、高变异语言的实用ASR系统开发提供了可扩展、有效的蓝图。

Abstract: Automatic Speech Recognition (ASR) for Bengali, the world's fifth most spoken
language, remains a significant challenge, critically hindering technological
accessibility for its over 270 million speakers. This challenge is compounded
by two persistent and intertwined factors: the language's vast dialectal
diversity and the prevalence of acoustic noise in real-world environments.
While state-of-the-art self-supervised learning (SSL) models have advanced ASR
for low-resource languages, they often lack explicit mechanisms to handle
environmental noise during pre-training or specialized adaptation strategies
for the complex phonetic and lexical variations across Bengali dialects. This
paper introduces a novel, unified framework designed to address these dual
challenges simultaneously. Our approach is founded on the WavLM model, which is
uniquely pre-trained with a masked speech denoising objective, making it
inherently robust to acoustic distortions. We propose a specialized multi-stage
fine-tuning strategy that first adapts the model to general-domain standard
Bengali to establish a strong linguistic foundation and subsequently
specializes it for noise-robust dialectal recognition through targeted data
augmentation. The framework is rigorously evaluated on a comprehensive
benchmark comprising multiple Bengali dialects under a wide range of simulated
noisy conditions, from clean audio to low Signal-to-Noise Ratio (SNR) levels.
  Experimental results demonstrate that the proposed framework significantly
outperforms strong baselines, including standard fine-tuned wav2vec 2.0 and the
large-scale multilingual Whisper model. This work establishes a new
state-of-the-art for this task and provides a scalable, effective blueprint for
developing practical ASR systems for other low-resource, high-variation
languages globally.

</details>


### [157] [EZhouNet:A framework based on graph neural network and anchor interval for the respiratory sound event detection](https://arxiv.org/abs/2509.01153)
*Yun Chu,Qiuhao Wang,Enze Zhou,Qian Liu,Gang Zheng*

Main category: cs.SD

TL;DR: 提出基于图神经网络和锚点区间的呼吸音事件检测框架，能够处理变长音频并提供更精确的时间定位，结合呼吸位置信息提升异常声音识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有呼吸音事件检测方法主要依赖帧级预测和后处理，难以直接学习区间边界，且大多只能处理固定长度音频，限制了在变长呼吸音中的应用。呼吸音位置信息对检测性能的影响也未被充分探索。

Method: 采用图神经网络框架结合锚点区间，能够处理变长音频输入，通过锚点机制直接学习事件的时间边界，避免复杂的后处理过程，并整合呼吸位置信息提升检测精度。

Result: 在SPRSound 2024和HF Lung V1数据集上的实验证明该方法有效，结合呼吸位置信息后能更好地区分异常声音，提高了检测的灵活性和适用性。

Conclusion: 所提出的图神经网络框架解决了传统呼吸音事件检测方法的局限性，提供了更精确的时间定位能力，呼吸位置信息的整合进一步提升了异常声音检测性能，为呼吸系统疾病的早期诊断提供了更有效的工具。

Abstract: Auscultation is a key method for early diagnosis of respiratory and pulmonary
diseases, relying on skilled healthcare professionals. However, the process is
often subjective, with variability between experts. As a result, numerous deep
learning-based automatic classification methods have emerged, most of which
focus on respiratory sound classification. In contrast, research on respiratory
sound event detection remains limited. Existing sound event detection methods
typically rely on frame-level predictions followed by post-processing to
generate event-level outputs, making interval boundaries challenging to learn
directly. Furthermore, many approaches can only handle fixed-length audio, lim-
iting their applicability to variable-length respiratory sounds. Additionally,
the impact of respiratory sound location information on detection performance
has not been extensively explored. To address these issues, we propose a graph
neural network-based framework with anchor intervals, capable of handling
variable-length audio and providing more precise temporal localization for
abnormal respi- ratory sound events. Our method improves both the flexibility
and applicability of respiratory sound detection. Experiments on the SPRSound
2024 and HF Lung V1 datasets demonstrate the effec- tiveness of the proposed
approach, and incorporating respiratory position information enhances the
discrimination between abnormal sounds.

</details>


### [158] [The AudioMOS Challenge 2025](https://arxiv.org/abs/2509.01336)
*Wen-Chin Huang,Hui Wang,Cheng Liu,Yi-Chiao Wu,Andros Tjandra,Wei-Ning Hsu,Erica Cooper,Yong Qin,Tomoki Toda*

Main category: cs.SD

TL;DR: AudioMOS Challenge 2025是首个针对合成音频主观质量预测的挑战赛，包含三个赛道：文本到音乐质量评估、多维度音频美学评估和不同采样率语音质量评估，吸引了24个团队参与并取得了超越基线的成果。


<details>
  <summary>Details</summary>
Motivation: 随着音频生成系统的快速发展，需要建立自动化的主观质量评估方法来替代人工评估，以促进该领域的标准化发展。

Method: 挑战赛设置了三个赛道：1）文本到音乐样本的整体质量和文本对齐度评估；2）基于Meta Audiobox美学四个维度的多模态音频评估；3）不同采样率下合成语音质量评估。

Result: 吸引了来自学术界和工业界的24个独特团队参与，所有团队的表现都超越了基线模型，证明了自动评估方法的有效性。

Conclusion: 该挑战赛的成功举办将推动音频生成系统自动评估领域的发展和进步，为后续研究提供重要基准和方向。

Abstract: This is the summary paper for the AudioMOS Challenge 2025, the very first
challenge for automatic subjective quality prediction for synthetic audio. The
challenge consists of three tracks. The first track aims to assess
text-to-music samples in terms of overall quality and textual alignment. The
second track is based on the four evaluation dimensions of Meta Audiobox
Aesthetics, and the test set consists of text-to-speech, text-to-audio, and
text-to-music samples. The third track focuses on synthetic speech quality
assessment in different sampling rates. The challenge attracted 24 unique teams
from both academia and industry, and improvements over the baselines were
confirmed. The outcome of this challenge is expected to facilitate development
and progress in the field of automatic evaluation for audio generation systems.

</details>


### [159] [CabinSep: IR-Augmented Mask-Based MVDR for Real-Time In-Car Speech Separation with Distributed Heterogeneous Arrays](https://arxiv.org/abs/2509.01399)
*Runduo Han,Yanxin Hu,Yihui Fu,Zihan Zhang,Yukai Jv,Li Chen,Lei Xie*

Main category: cs.SD

TL;DR: CabinSep是一种轻量级神经网络语音分离方法，通过MVDR技术和数据增强，在车载环境中有效分离重叠语音，降低语音识别错误率17.5%


<details>
  <summary>Details</summary>
Motivation: 解决车载环境中多人重叠语音分离问题，提高后端语音识别系统的性能

Method: 使用通道信息提取空间特征，采用MVDR减少语音失真，结合模拟和真实脉冲响应的数据增强方法

Result: 计算复杂度仅0.4 GMACs，在真实数据集上相比DualSep模型相对降低17.5%的语音识别错误率

Conclusion: CabinSep是一种高效的车载语音分离解决方案，在保持低计算复杂度的同时显著提升语音识别性能

Abstract: Separating overlapping speech from multiple speakers is crucial for effective
human-vehicle interaction. This paper proposes CabinSep, a lightweight neural
mask-based minimum variance distortionless response (MVDR) speech separation
approach, to reduce speech recognition errors in back-end automatic speech
recognition (ASR) models. Our contributions are threefold: First, we utilize
channel information to extract spatial features, which improves the estimation
of speech and noise masks. Second, we employ MVDR during inference, reducing
speech distortion to make it more ASR-friendly. Third, we introduce a data
augmentation method combining simulated and real-recorded impulse responses
(IRs), improving speaker localization at zone boundaries and further reducing
speech recognition errors. With a computational complexity of only 0.4 GMACs,
CabinSep achieves a 17.5% relative reduction in speech recognition error rate
in a real-recorded dataset compared to the state-of-the-art DualSep model.
Demos are available at: https://cabinsep.github.io/cabinsep/.

</details>


### [160] [ArabEmoNet: A Lightweight Hybrid 2D CNN-BiLSTM Model with Attention for Robust Arabic Speech Emotion Recognition](https://arxiv.org/abs/2509.01401)
*Ali Abouzeid,Bilal Elbouardi,Mohamed Maged,Shady Shehata*

Main category: cs.SD

TL;DR: ArabEmoNet是一个轻量级阿拉伯语语音情感识别架构，仅使用100万参数就实现了最先进性能，比现有模型小90倍


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语等低资源语言在语音情感识别中面临的数据有限和研究不足的挑战，需要高效且性能优越的解决方案

Method: 使用Mel频谱图通过2D卷积处理，替代传统的离散MFCC特征和1D卷积方法，更好地保留情感线索和频谱-时间模式

Result: ArabEmoNet在参数规模仅为HuBERT base的1/90和Whisper的1/74的情况下，实现了优于大型模型的性能

Conclusion: 该架构为阿拉伯语语音情感识别提供了高性能且资源高效的解决方案，特别适合资源受限的实际应用环境

Abstract: Speech emotion recognition is vital for human-computer interaction,
particularly for low-resource languages like Arabic, which face challenges due
to limited data and research. We introduce ArabEmoNet, a lightweight
architecture designed to overcome these limitations and deliver
state-of-the-art performance. Unlike previous systems relying on discrete MFCC
features and 1D convolutions, which miss nuanced spectro-temporal patterns,
ArabEmoNet uses Mel spectrograms processed through 2D convolutions, preserving
critical emotional cues often lost in traditional methods.
  While recent models favor large-scale architectures with millions of
parameters, ArabEmoNet achieves superior results with just 1 million
parameters, 90 times smaller than HuBERT base and 74 times smaller than
Whisper. This efficiency makes it ideal for resource-constrained environments.
ArabEmoNet advances Arabic speech emotion recognition, offering exceptional
performance and accessibility for real-world applications.

</details>


### [161] [Music Genre Classification Using Machine Learning Techniques](https://arxiv.org/abs/2509.01762)
*Alokit Mishra,Ryyan Akhtar*

Main category: cs.SD

TL;DR: 本文对比分析了机器学习方法在音乐类型分类中的性能，发现基于领域知识的SVM分类器在GTZAN数据集上表现超过了深度学习模型CNN，说明在中等规模数据集上传统特征工程仍具有重要价值。


<details>
  <summary>Details</summary>
Motivation: 评估不同机器学习方法在音乐类型自动分类任务中的表现，特别是对比传统的特征工程方法与深度学习方法的效果，以探索深度学习在中等规模数据集上的普遍适用性。

Method: 使用GTZAN数据集，对比了支持向量机(SVM)和集成方法等传统分类器(基于手工特征提取)与卷积神经网络(CNN)模型(基于Mel谱图)的性能。

Result: SVM在分类准确率上表现更优于CNN。这是因为在数据规模有限的情况下，领域特定的特征工程提供了强烈的归纳偏置，能够减少过拟合风险。

Conclusion: 这项研究突出了传统特征提取方法在实际音频处理任务中的持久价值，并为深度学习在中等规模数据集上的普遍适用性提供了批判性视角。

Abstract: This paper presents a comparative analysis of machine learning methodologies
for automatic music genre classification. We evaluate the performance of
classical classifiers, including Support Vector Machines (SVM) and ensemble
methods, trained on a comprehensive set of hand-crafted audio features, against
a Convolutional Neural Network (CNN) operating on Mel spectrograms. The study
is conducted on the widely-used GTZAN dataset. Our findings demonstrate a
noteworthy result: the SVM, leveraging domain-specific feature engineering,
achieves superior classification accuracy compared to the end-to-end CNN model.
We attribute this outcome to the data-constrained nature of the benchmark
dataset, where the strong inductive bias of engineered features provides a
regularization effect that mitigates the risk of overfitting inherent in
high-capacity deep learning models. This work underscores the enduring
relevance of traditional feature extraction in practical audio processing tasks
and provides a critical perspective on the universal applicability of deep
learning, especially for moderately sized datasets.

</details>


### [162] [FireRedTTS-2: Towards Long Conversational Speech Generation for Podcast and Chatbot](https://arxiv.org/abs/2509.02020)
*Kun Xie,Feiyu Shen,Junjie Li,Fenglong Xie,Xu Tang,Yao Hu*

Main category: cs.SD

TL;DR: FireRedTTS-2是一个用于多说话人对话生成的长格式流式TTS系统，通过新的12.5Hz流式语音分词器和双变换器架构，实现了稳定的自然语音、可靠的说话人切换和上下文感知的韵律。


<details>
  <summary>Details</summary>
Motivation: 当前对话生成方法需要完整对话文本才能合成，产生包含所有声音的不可分割语音，不适合交互式聊天，且存在合成不稳定、说话人转换不准确和韵律不连贯的问题。

Method: 采用新的12.5Hz流式语音分词器加速训练和推理；使用文本-语音交错格式，按时间顺序连接说话人标记文本和对齐的语音标记；采用双变换器架构：大型仅解码器变换器在第一层预测标记，较小的变换器完成后续层。

Result: 实验结果表明，FireRedTTS-2能够无缝集成到聊天框架中，通过最小微调即可产生由隐式上下文线索引导的情感表达语音。在播客生成中，在客观可懂度、说话人轮换可靠性和感知自然度方面超越了现有系统。

Conclusion: FireRedTTS-2提供了一个有效的流式多说话人对话生成解决方案，解决了现有方法的局限性，在交互式应用中表现出色。

Abstract: Current dialogue generation approaches typically require the complete
dialogue text before synthesis and produce a single, inseparable speech
containing all voices, making them unsuitable for interactive chat; moreover,
they suffer from unstable synthesis, inaccurate speaker transitions, and
incoherent prosody. In this work, we present FireRedTTS-2, a long-form
streaming TTS system for multi-speaker dialogue generation, delivering stable,
natural speech with reliable speaker switching and context-aware prosody. A new
12.5Hz streaming speech tokenizer accelerates training and inference, extends
maximum dialogue length, encodes richer semantics to stabilize text-to-token
modeling and supports high-fidelity streaming generation for real-time
applications. We adopt a text-speech interleaved format, concatenating
speaker-labeled text with aligned speech tokens in chronological order, and
model it with a dual-transformer: a large decoder-only transformer predicts
tokens at the first layer, and a smaller one completes subsequent layers.
Experimental results show that FireRedTTS-2 integrates seamlessly with chat
frameworks and, with minimal fine-tuning, produces emotionally expressive
speech guided by implicit contextual cues. In podcast generation, it surpasses
existing systems including MoonCast, Zipvoice-Dialogue, and MOSS-TTSD in
objective intelligibility, speaker-turn reliability, and perceived naturalness
with context-consistent prosody. Our demos are available at
https://fireredteam.github.io/demos/firered_tts_2.

</details>


### [163] [AudioRWKV: Efficient and Stable Bidirectional RWKV for Audio Pattern Recognition](https://arxiv.org/abs/2509.02167)
*Jiayu Xiong,Jun Xue,Jianlong Kwan,Jing Wang*

Main category: cs.SD

TL;DR: 本文提出了AudioRWKV (A-RWKV)，一种高效稳定的音频建模架构，通过结合RWKV7的循环结构和双向WKV核，在保持线性计算复杂度的同时实现全局上下文建模。


<details>
  <summary>Details</summary>
Motivation: Transformer架构的O(L^2)计算复杂度限制了长序列处理效率，而Mamba架构在扩展参数和数据时容易变得不稳定。需要一种既高效又稳定的音频建模解决方案。

Method: 继承RWKV7的稳定高效循环公式，将1D token-shift操作替换为2D深度可分离卷积以捕捉局部频谱-时间模式，并将原始因果WKV核适配为双向WKV核(Bi-WKV)。

Result: A-RWKV-S (22M)在相同线性模型体系下达到与AuM-B (92M)相当的性能，同时比AST具有更稳定的吞吐量；对于长音频(~5分28秒)，处理速度提升高达13.3倍。

Conclusion: A-RWKV架构成功解决了音频建模中的效率和稳定性问题，能够无缝扩展到更大模型规模，为长序列音频处理提供了高效稳定的解决方案。

Abstract: Recently, Transformers (e.g., Audio Spectrogram Transformers, AST) and
state-space models (e.g., Audio Mamba, AuM) have achieved remarkable progress
in audio modeling. However, the O(L^2) computational complexity of the
Transformer architecture hinders efficient long-sequence processing, while the
Mamba architecture tends to become unstable when scaling parameters and data.
To address these challenges, this paper proposes AudioRWKV (A-RWKV), a highly
efficient and stable architecture for audio modeling. Specifically, we inherit
the stable and efficient recurrent formulation of RWKV7 and replace its 1D
token-shift operation with a 2D depthwise separable convolution to better
capture local spectro-temporal patterns. Furthermore, we adapt the original
causal WKV kernel into a bidirectional WKV kernel (Bi-WKV), enabling global
context modeling over the entire audio sequence while maintaining linear
computational complexity. Benefiting from the inherent stability of the RWKV7
foundation, A-RWKV scales seamlessly to larger model sizes. Experimental
results demonstrate that, under the same linear-model regime, A-RWKV-S (22M)
achieves performance parity with AuM-B (92M) while exhibiting more stable
throughput than AST; for long-form audio (~5 minutes 28 seconds), WKV7 achieves
up to a 13.3X speedup in processing.

</details>


### [164] [Spectrogram Patch Codec: A 2D Block-Quantized VQ-VAE and HiFi-GAN for Neural Speech Coding](https://arxiv.org/abs/2509.02244)
*Luis Felipe Chary,Miguel Arjona Ramirez*

Main category: cs.SD

TL;DR: 提出了一种简化的神经语音编解码器，使用单阶段量化方法替代复杂的残差向量量化堆栈，在7.5kbps码率下实现竞争性的感知质量和可懂度。


<details>
  <summary>Details</summary>
Motivation: 挑战传统神经语音编解码器中复杂的残差向量量化(RVQ)堆栈结构，寻求更简单、低延迟的量化方法。

Method: 直接在mel频谱图上操作，将其视为2D数据，将非重叠的4x4块量化为单个共享码本；采用后期对抗微调VQ-VAE，并从头训练HiFi-GAN声码器。

Result: 在16kHz语音约7.5kbits/s码率下，通过STOI、PESQ、MCD和ViSQOL等客观指标评估，显示该简化架构达到了竞争性的感知质量和可懂度。

Conclusion: 这种简化的非残差架构为未来低延迟编解码器设计提供了有效且开放的基础，证明了简单方法也能达到良好性能。

Abstract: We present a neural speech codec that challenges the need for complex
residual vector quantization (RVQ) stacks by introducing a simpler,
single-stage quantization approach. Our method operates directly on the
mel-spectrogram, treating it as a 2D data and quantizing non-overlapping 4x4
patches into a single, shared codebook. This patchwise design simplifies the
architecture, enables low-latency streaming, and yields a discrete latent grid.
To ensure high-fidelity synthesis, we employ a late-stage adversarial
fine-tuning for the VQ-VAE and train a HiFi-GAN vocoder from scratch on the
codec's reconstructed spectrograms. Operating at approximately 7.5 kbits/s for
16 kHz speech, our system was evaluated against several state-of-the-art neural
codecs using objective metrics such as STOI, PESQ, MCD, and ViSQOL. The results
demonstrate that our simplified, non-residual architecture achieves competitive
perceptual quality and intelligibility, validating it as an effective and open
foundation for future low-latency codec designs.

</details>


### [165] [Speech transformer models for extracting information from baby cries](https://arxiv.org/abs/2509.02259)
*Guillem Bonafos,Jéremy Rouch,Lény Lego,David Reby,Hugues Patural,Nicolas Mathevon,Rémy Emonet*

Main category: cs.SD

TL;DR: 预训练语音模型的潜在表示可以有效分类婴儿哭声，编码声音源不稳定性和婴儿身份信息，为类似情感检测任务提供设计参考


<details>
  <summary>Details</summary>
Motivation: 探索预训练语音模型在非语音数据（婴儿哭声）上的适用性，以及这些模型中编码的具体声学特性

Method: 评估5个预训练语音模型在8个婴儿哭声数据集（115小时音频，960名婴儿）上的表现，分析各模型的潜在表示在所有可用分类任务中的效果

Result: 模型潜在表示能有效分类婴儿哭声，编码了声音源不稳定性和婴儿身份的关键信息

Conclusion: 预训练语音模型适用于婴儿哭声分析，模型架构和训练策略的比较为未来类似任务（如情感检测）的模型设计提供了宝贵见解

Abstract: Transfer learning using latent representations from pre-trained speech models
achieves outstanding performance in tasks where labeled data is scarce.
However, their applicability to non-speech data and the specific acoustic
properties encoded in these representations remain largely unexplored. In this
study, we investigate both aspects. We evaluate five pre-trained speech models
on eight baby cries datasets, encompassing 115 hours of audio from 960 babies.
For each dataset, we assess the latent representations of each model across all
available classification tasks. Our results demonstrate that the latent
representations of these models can effectively classify human baby cries and
encode key information related to vocal source instability and identity of the
crying baby. In addition, a comparison of the architectures and training
strategies of these models offers valuable insights for the design of future
models tailored to similar tasks, such as emotion detection.

</details>


### [166] [AudioCodecBench: A Comprehensive Benchmark for Audio Codec Evaluation](https://arxiv.org/abs/2509.02349)
*Lu Wang,Hao Chen,Siyu Wu,Zhiyue Wu,Hao Zhou,Chengfeng Zhang,Ting Wang,Haodi Zhang*

Main category: cs.SD

TL;DR: 本文提出了音频token化的合适定义和系统评估框架，解决了现有研究中语义token和声学token定义不明确以及评估不全面的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在语音和音乐应用中广泛使用音频token化，但缺乏对语义token和声学token的明确定义，且评估方法局限于特定领域或任务，无法进行公平全面的比较。

Method: 提出了语义token和声学token的合适定义，并引入了一个系统评估框架，从四个维度全面评估编解码器能力：音频重建指标、码本索引稳定性、仅解码器transformer困惑度以及下游探测任务性能。

Result: 研究结果验证了所提供合适定义的正确性，并揭示了重建指标、码本索引稳定性、下游探测任务和困惑度之间的相关性。

Conclusion: 该研究为音频token化提供了理论基础和系统评估方法，有助于更公平全面地比较不同编解码器的性能，推动多模态大语言模型在音频领域的发展。

Abstract: Multimodal Large Language Models (MLLMs) have been widely applied in speech
and music. This tendency has led to a focus on audio tokenization for Large
Models (LMs). Unlike semantic-only text tokens, audio tokens must both capture
global semantic content and preserve fine-grained acoustic details. Moreover,
they provide a discrete method for speech and music that can be effectively
integrated into MLLMs. However, existing research is unsuitable in the
definitions of semantic tokens and acoustic tokens. In addition, the evaluation
of different codecs typically concentrates on specific domains or tasks, such
as reconstruction or Automatic Speech Recognition (ASR) task, which prevents
fair and comprehensive comparisons. To address these problems, this paper
provides suitable definitions for semantic and acoustic tokens and introduces a
systematic evaluation framework. This framework allows for a comprehensive
assessment of codecs' capabilities which evaluate across four dimensions: audio
reconstruction metric, codebook index (ID) stability, decoder-only transformer
perplexity, and performance on downstream probe tasks. Our results show the
correctness of the provided suitable definitions and the correlation among
reconstruction metrics, codebook ID stability, downstream probe tasks and
perplexity.

</details>


### [167] [TTA-Bench: A Comprehensive Benchmark for Evaluating Text-to-Audio Models](https://arxiv.org/abs/2509.02398)
*Hui Wang,Cheng Liu,Junyang Chen,Haoze Liu,Yuhang Jia,Shiwan Zhao,Jiaming Zhou,Haoqin Sun,Hui Bu,Yong Qin*

Main category: cs.SD

TL;DR: TTA-Bench是一个全面的文本到音频生成模型评估基准，涵盖7个维度、2999个多样化提示，结合客观指标和超过11.8万个人工标注，对10个最先进模型进行综合评估。


<details>
  <summary>Details</summary>
Motivation: 当前TTA生成模型的评估方法过于狭窄，主要关注感知质量，而忽视了鲁棒性、泛化能力和伦理问题，需要建立更全面的评估标准。

Method: 开发TTA-Bench基准，包含7个评估维度（准确性、鲁棒性、公平性、毒性等），使用自动和手动方法生成2999个多样化提示，结合客观指标和人类标注的统一评估协议。

Result: 对10个最先进的TTA模型进行了基准测试，提供了详细的性能优势和局限性分析，建立了TTA系统整体和负责任评估的新标准。

Conclusion: TTA-Bench为文本到音频生成模型提供了全面的评估框架，推动了该领域向更负责任和全面的评估方向发展，所有数据集和评估工具均已开源。

Abstract: Text-to-Audio (TTA) generation has made rapid progress, but current
evaluation methods remain narrow, focusing mainly on perceptual quality while
overlooking robustness, generalization, and ethical concerns. We present
TTA-Bench, a comprehensive benchmark for evaluating TTA models across
functional performance, reliability, and social responsibility. It covers seven
dimensions including accuracy, robustness, fairness, and toxicity, and includes
2,999 diverse prompts generated through automated and manual methods. We
introduce a unified evaluation protocol that combines objective metrics with
over 118,000 human annotations from both experts and general users. Ten
state-of-the-art models are benchmarked under this framework, offering detailed
insights into their strengths and limitations. TTA-Bench establishes a new
standard for holistic and responsible evaluation of TTA systems. The dataset
and evaluation tools are open-sourced at https://nku-hlt.github.io/tta-bench/.

</details>


### [168] [ESTM: An Enhanced Dual-Branch Spectral-Temporal Mamba for Anomalous Sound Detection](https://arxiv.org/abs/2509.02471)
*Chengyuan Ma,Peng Jia,Hongyue Guo,Wenming Yang*

Main category: cs.SD

TL;DR: 提出基于双路径Mamba架构的ESTM框架，通过时间-频率解耦建模和选择性状态空间模型来捕捉工业设备异常声音检测中的长程时序模式和跨频带动态耦合特征。


<details>
  <summary>Details</summary>
Motivation: 工业设备异常声音检测的核心挑战在于建模声学特征的时频耦合特性，现有方法受限于局部感受野，难以捕捉长程时序模式和跨频带动态耦合效应。

Method: ESTM框架采用双路径Mamba架构，结合时间-频率解耦建模，使用选择性状态空间模型进行长程序列建模，融合增强梅尔频谱图和原始音频特征，并通过TriStat-Gating模块提高对异常模式的敏感性。

Result: 在DCASE 2020 Task 2数据集上，ESTM提高了异常检测性能，验证了所提方法的有效性。

Conclusion: 提出的ESTM框架通过创新的双路径Mamba架构和时频解耦建模，有效解决了工业设备异常声音检测中的长程时序模式捕捉问题，为相关领域提供了新的解决方案。

Abstract: The core challenge in industrial equipment anoma lous sound detection (ASD)
lies in modeling the time-frequency coupling characteristics of acoustic
features. Existing modeling methods are limited by local receptive fields,
making it difficult to capture long-range temporal patterns and cross-band
dynamic coupling effects in machine acoustic features. In this paper, we
propose a novel framework, ESTM, which is based on a dual-path Mamba
architecture with time-frequency decoupled modeling and utilizes Selective
State-Space Models (SSM) for long-range sequence modeling. ESTM extracts rich
feature representations from different time segments and frequency bands by
fusing enhanced Mel spectrograms and raw audio features, while further
improving sensitivity to anomalous patterns through the TriStat-Gating (TSG)
module. Our experiments demonstrate that ESTM improves anomalous detection
performance on the DCASE 2020 Task 2 dataset, further validating the
effectiveness of the proposed method.

</details>


### [169] [FLM-Audio: Natural Monologues Improves Native Full-Duplex Chatbots via Dual Training](https://arxiv.org/abs/2509.02521)
*Yiqun Yao,Xiang Li,Xin Jiang,Xuezhi Fang,Naitong Yu,Wenjia Ma,Aixin Sun,Yequan Wang*

Main category: cs.SD

TL;DR: 本文提出了一种新的全双工对话模型FLM-Audio，通过使用自然独白和双重训练方案解决了音频流与文本对齐的挑战，实现了更低延迟和更好的对话体验。


<details>
  <summary>Details</summary>
Motivation: 现有的全双工对话模型存在文本独白与音频流对齐的挑战，单词级对齐方案会降低大模型的语言能力，且需要精确的时间戳标索引入级联错误和高处理成本。

Method: 提出使用"自然独白"（连续标记序列）模仿人类认知行为，并采用双重训练范式：在不同训练阶段交替将自然独白放置在音频的前端或后端。

Result: 构建了FLM-Audio 7B语音对话模型，实验结果证明其在响应速度、全双工能力和聊天体验方面都显示出优异性能。

Conclusion: 该方法有效解决了音频流与文本对齐的问题，为建立高性能全双工对话模型提供了一种可行的方案，在保持语言能力的同时实现了低延迟的直接对话。

Abstract: Full-duplex dialog models are designed to listen and speak simultaneously
with rapid responses to fast-changing user input. Among existing approaches,
native full-duplex models merges different channels (e.g. listen and speak) in
a single time step, overcoming the high response latency inherent to
time-division multiplexing time-division multiplexing (TDM) alternatives. Yet,
a key challenge remains: aligning textual monologues with audio streams that
operate at different bitrates. The prevailing solution relies on word-level
alignment, but this can degrade the language ability of large pre-trained
models. Moreover, it requires highly accurate timestamps for every token, which
introduces cascading errors and increases pre-processing costs. In this paper,
we propose textual monologues in continuous tokens sequence, namely "natural"
monologues, which mimics humanoid cognitive behavior in dialogs. For temporal
alignment, we alternate the position of the natural monologue - leading or
trailing the audio - across different training stages. This "dual" training
paradigm proves highly effective in building FLM-Audio, our 7B spoken dialog
model that demonstrates superior responsiveness, duplexity, and chatting
experiences, as confirmed by experimental results.

</details>
