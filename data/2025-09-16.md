<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 86]
- [cs.SD](#cs.SD) [Total: 13]
- [cs.MM](#cs.MM) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Uncovering the Vulnerability of Large Language Models in the Financial Domain via Risk Concealment](https://arxiv.org/abs/2509.10546)
*Gang Cheng,Haibo Jin,Wenbin Zhang,Haohan Wang,Jun Zhuang*

Main category: cs.CL

TL;DR: 本文提出了风险隐藏攻击(RCA)框架，通过多轮对话隐藏监管风险，成功绕过主流金融LLMs的安全防护，平均攻击成功率93.18%，揭示了金融领域LLM对齐技术的严重漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有红队测试主要针对有害内容，忽视了金融领域的监管风险。随着LLMs在金融应用中的广泛集成，需要专门评估其在金融监管合规方面的脆弱性。

Method: 提出了风险隐藏攻击(RCA)多轮框架，迭代式隐藏监管风险；构建了FIN-Bench金融领域基准测试集，用于系统评估LLMs在金融场景下的安全性。

Result: 在9个主流LLMs上测试，RCA攻击平均成功率93.18%，其中GPT-4.1达到98.28%，OpenAI o1达到97.56%，证明现有对齐技术存在严重缺陷。

Conclusion: 当前LLM对齐技术在金融领域存在重大安全漏洞，迫切需要开发更强的领域感知审核机制，为构建稳健的领域特定LLM对齐提供实践洞见。

Abstract: Large Language Models (LLMs) are increasingly integrated into financial
applications, yet existing red-teaming research primarily targets harmful
content, largely neglecting regulatory risks. In this work, we aim to
investigate the vulnerability of financial LLMs through red-teaming approaches.
We introduce Risk-Concealment Attacks (RCA), a novel multi-turn framework that
iteratively conceals regulatory risks to provoke seemingly compliant yet
regulatory-violating responses from LLMs. To enable systematic evaluation, we
construct FIN-Bench, a domain-specific benchmark for assessing LLM safety in
financial contexts. Extensive experiments on FIN-Bench demonstrate that RCA
effectively bypasses nine mainstream LLMs, achieving an average attack success
rate (ASR) of 93.18%, including 98.28% on GPT-4.1 and 97.56% on OpenAI o1.
These findings reveal a critical gap in current alignment techniques and
underscore the urgent need for stronger moderation mechanisms in financial
domains. We hope this work offers practical insights for advancing robust and
domain-aware LLM alignment.

</details>


### [2] [No Answer Needed: Predicting LLM Answer Accuracy from Question-Only Linear Probes](https://arxiv.org/abs/2509.10625)
*Iván Vicente Moreno Cencerrado,Arnau Padrés Masdemont,Anton Gonzalvez Hawthorne,David Demitri Africa,Lorenzo Pacchiardi*

Main category: cs.CL

TL;DR: 该研究通过提取LLM在回答问题前的激活状态，训练线性探针来预测模型即将给出的答案是否正确，发现这种"提前正确性方向"在不同规模模型和数据集上都具有良好的预测能力，且在中间层达到最佳效果。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型是否能够提前预知自己回答的正确性，探索模型内部自我评估机制的存在和特性。

Method: 在三个开源模型家族（7B-70B参数）上，提取问题读取后但未生成答案前的激活状态，训练线性探针来预测后续回答的正确性，并在分布内和分布外知识数据集上进行测试。

Result: 提前正确性方向在通用知识问题上表现出色，预测能力在中间层饱和，数学推理问题上泛化能力较差，模型说"我不知道"时与探针得分高度相关。

Conclusion: LLM在中间计算层就形成了自我评估能力，相同的内部方向既捕获正确性也捕获置信度，为理解LLM内部机制提供了重要发现。

Abstract: Do large language models (LLMs) anticipate when they will answer correctly?
To study this, we extract activations after a question is read but before any
tokens are generated, and train linear probes to predict whether the model's
forthcoming answer will be correct. Across three open-source model families
ranging from 7 to 70 billion parameters, projections on this "in-advance
correctness direction" trained on generic trivia questions predict success in
distribution and on diverse out-of-distribution knowledge datasets,
outperforming black-box baselines and verbalised predicted confidence.
Predictive power saturates in intermediate layers, suggesting that
self-assessment emerges mid-computation. Notably, generalisation falters on
questions requiring mathematical reasoning. Moreover, for models responding "I
don't know", doing so strongly correlates with the probe score, indicating that
the same direction also captures confidence. By complementing previous results
on truthfulness and other behaviours obtained with probes and sparse
auto-encoders, our work contributes essential findings to elucidate LLM
internals.

</details>


### [3] [Interdisciplinary Research in Conversation: A Case Study in Computational Morphology for Language Documentation](https://arxiv.org/abs/2509.10644)
*Enora Rice,Katharina von der Wense,Alexis Palmer*

Main category: cs.CL

TL;DR: 本文认为计算形态学与语言文档实践之间存在脱节，主张通过用户中心设计来重新调整研究方向，并通过GlossLM案例研究展示了尽管模型性能指标优秀，但实际可用性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 计算形态学的研究成果在现实语言文档工作中应用有限，存在理论研究与实践需求之间的脱节风险，需要通过用户中心设计来使研究更加贴近实际应用场景。

Method: 采用立场论文的形式，结合GlossLM多语言IGT生成模型的案例研究，通过小规模用户研究（三位文档语言学家）来评估系统在实际文档环境中的可用性。

Result: 研究发现尽管GlossLM模型在性能指标上表现优异，但在真实文档情境中无法满足核心可用性需求，揭示了模型约束、标签标准化、分词和个性化等方面的新研究问题。

Conclusion: 以用户为中心不仅能产生更有效的工具，还能发掘出更丰富、更相关的研究方向，建议系统性地整合用户中心设计来重塑计算形态学的研究议程。

Abstract: Computational morphology has the potential to support language documentation
through tasks like morphological segmentation and the generation of Interlinear
Glossed Text (IGT). However, our research outputs have seen limited use in
real-world language documentation settings. This position paper situates the
disconnect between computational morphology and language documentation within a
broader misalignment between research and practice in NLP and argues that the
field risks becoming decontextualized and ineffectual without systematic
integration of User-Centered Design (UCD). To demonstrate how principles from
UCD can reshape the research agenda, we present a case study of GlossLM, a
state-of-the-art multilingual IGT generation model. Through a small-scale user
study with three documentary linguists, we find that despite strong metric
based performance, the system fails to meet core usability needs in real
documentation contexts. These insights raise new research questions around
model constraints, label standardization, segmentation, and personalization. We
argue that centering users not only produces more effective tools, but surfaces
richer, more relevant research directions

</details>


### [4] [Context Copying Modulation: The Role of Entropy Neurons in Managing Parametric and Contextual Knowledge Conflicts](https://arxiv.org/abs/2509.10663)
*Zineddine Tighidet,Andrea Mogini,Hedi Ben-younes,Jiali Mei,Patrick Gallinari,Benjamin Piwowarski*

Main category: cs.CL

TL;DR: 本文研究了LLM中熵神经元在抑制上下文复制行为中的作用，特别是在处理上下文信息与参数知识冲突时的机制。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在面对与内部参数知识冲突的上下文信息时行为不一致，缺乏对预期结果分布的普遍解释。最近研究发现了一类熵神经元，它们对模型输出熵有显著影响但对预测标记排序影响适中，需要进一步研究这些神经元在抑制上下文复制行为中的作用。

Method: 通过研究熵神经元在解决上下文信息与参数信息冲突中的作用，分析这些神经元在不同LLM中抑制上下文复制行为的功能，并采用神经元消融技术观察生成过程的变化。

Result: 研究发现熵神经元确实负责抑制上下文复制行为，消融这些神经元会导致生成过程发生显著变化，证实了它们在处理冲突信息中的关键作用。

Conclusion: 这些结果增强了我们对LLM在处理冲突信息时内部动态机制的理解，为解释模型在上下文与参数知识冲突时的行为提供了新的见解。

Abstract: The behavior of Large Language Models (LLMs) when facing contextual
information that conflicts with their internal parametric knowledge is
inconsistent, with no generally accepted explanation for the expected outcome
distribution. Recent work has identified in autoregressive transformer models a
class of neurons -- called entropy neurons -- that produce a significant effect
on the model output entropy while having an overall moderate impact on the
ranking of the predicted tokens. In this paper, we investigate the preliminary
claim that these neurons are involved in inhibiting context copying behavior in
transformers by looking at their role in resolving conflicts between contextual
and parametric information. We show that entropy neurons are responsible for
suppressing context copying across a range of LLMs, and that ablating them
leads to a significant change in the generation process. These results enhance
our understanding of the internal dynamics of LLMs when handling conflicting
information.

</details>


### [5] [Text2Sign Diffusion: A Generative Approach for Gloss-Free Sign Language Production](https://arxiv.org/abs/2509.10845)
*Liqian Feng,Lintao Wang,Kun Hu,Dehui Kong,Zhiyong Wang*

Main category: cs.CL

TL;DR: 提出Text2SignDiff，一种基于扩散模型的免gloss手语生成方法，通过跨模态对齐和潜在扩散过程直接从文本生成手语序列，在PHOENIX14T和How2Sign数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有手语生成方法依赖gloss作为中间表示，但gloss标注稀缺且语言特定，限制了方法的灵活性和泛化能力，需要开发免gloss的直接生成方法

Method: 提出gloss-free潜在扩散模型，从噪声潜在手语编码和口语文本联合生成手语序列；设计跨模态手语对齐器学习共享潜在空间；采用非自回归迭代去噪过程减少误差累积

Result: 在PHOENIX14T和How2Sign数据集上的大量实验证明了方法的有效性，取得了最先进的性能

Conclusion: Text2SignDiff成功实现了免gloss的手语生成，通过扩散模型和跨模态对齐技术有效提升了手语生成的准确性和上下文相关性

Abstract: Sign language production (SLP) aims to translate spoken language sentences
into a sequence of pose frames in a sign language, bridging the communication
gap and promoting digital inclusion for deaf and hard-of-hearing communities.
Existing methods typically rely on gloss, a symbolic representation of sign
language words or phrases that serves as an intermediate step in SLP. This
limits the flexibility and generalization of SLP, as gloss annotations are
often unavailable and language-specific. Therefore, we present a novel
diffusion-based generative approach - Text2Sign Diffusion (Text2SignDiff) for
gloss-free SLP. Specifically, a gloss-free latent diffusion model is proposed
to generate sign language sequences from noisy latent sign codes and spoken
text jointly, reducing the potential error accumulation through a
non-autoregressive iterative denoising process. We also design a cross-modal
signing aligner that learns a shared latent space to bridge visual and textual
content in sign and spoken languages. This alignment supports the conditioned
diffusion-based process, enabling more accurate and contextually relevant sign
language generation without gloss. Extensive experiments on the commonly used
PHOENIX14T and How2Sign datasets demonstrate the effectiveness of our method,
achieving the state-of-the-art performance.

</details>


### [6] [Pluralistic Alignment for Healthcare: A Role-Driven Framework](https://arxiv.org/abs/2509.10685)
*Jiayou Zhong,Anudeex Shetty,Chao Jia,Xuanrui Lin,Usman Naseem*

Main category: cs.CL

TL;DR: EthosAgents：一种轻量级、可泛化的多元对齐方法，用于在医疗等敏感领域模拟多样化价值观和视角，提升大语言模型的多元对齐效果


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法（包括模块化多元主义）在医疗领域存在不足，医疗领域的多元主义受到个人、文化和情境因素影响，需要更适应性的方法

Method: 提出EthosAgents方法，通过模拟多样化视角和价值观来实现多元对齐，该方法轻量且可泛化

Result: 在7个不同规模的开源和闭源模型上实证显示，EthosAgents在所有三种模式下都提升了多元对齐效果

Conclusion: 医疗相关多元主义需要适应性强且具有规范意识的方法，这一发现为其他高风险领域如何更好尊重多样性提供了见解

Abstract: As large language models are increasingly deployed in sensitive domains such
as healthcare, ensuring their outputs reflect the diverse values and
perspectives held across populations is critical. However, existing alignment
approaches, including pluralistic paradigms like Modular Pluralism, often fall
short in the health domain, where personal, cultural, and situational factors
shape pluralism. Motivated by the aforementioned healthcare challenges, we
propose a first lightweight, generalizable, pluralistic alignment approach,
EthosAgents, designed to simulate diverse perspectives and values. We
empirically show that it advances the pluralistic alignment for all three modes
across seven varying-sized open and closed models. Our findings reveal that
health-related pluralism demands adaptable and normatively aware approaches,
offering insights into how these models can better respect diversity in other
high-stakes domains.

</details>


### [7] [Struct-Bench: A Benchmark for Differentially Private Structured Text Generation](https://arxiv.org/abs/2509.10696)
*Shuaiqi Wang,Vikas Raunak,Arturs Backurs,Victor Reis,Pei Zhou,Sihao Chen,Longqi Yang,Zinan Lin,Sergey Yekhanin,Giulia Fanti*

Main category: cs.CL

TL;DR: 提出了Struct-Bench框架和基准测试，用于评估包含自然语言的结构化数据的差分隐私合成数据生成方法，通过上下文无关文法表示数据结构，包含5个真实和2个合成数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的合成数据评估技术（如FID）难以捕捉结构化数据集的属性和相关性，特别是在企业环境中常见的包含自然语言字段的结构化数据。

Method: 开发Struct-Bench框架，要求用户使用上下文无关文法（CFG）表示数据集结构，包含7个标注CFG的数据集，提供标准化评估平台和指标实现。

Result: 这些数据集对最先进的DP合成数据生成方法构成重大挑战，框架提供了案例研究展示如何改进私有进化（PE）方法在结构化数据上的合成质量。

Conclusion: Struct-Bench为研究人员提供了标准化的评估平台，可用于基准测试和调查隐私保护合成数据生成方法，框架和排行榜已公开提供。

Abstract: Differentially private (DP) synthetic data generation is a promising
technique for utilizing private datasets that otherwise cannot be exposed for
model training or other analytics. While much research literature has focused
on generating private unstructured text and image data, in enterprise settings,
structured data (e.g., tabular) is more common, often including natural
language fields or components. Existing synthetic data evaluation techniques
(e.g., FID) struggle to capture the structural properties and correlations of
such datasets. In this work, we propose Struct-Bench, a framework and benchmark
for evaluating synthetic datasets derived from structured datasets that contain
natural language data. The Struct-Bench framework requires users to provide a
representation of their dataset structure as a Context-Free Grammar (CFG). Our
benchmark comprises 5 real-world and 2 synthetically generated datasets, each
annotated with CFGs. We show that these datasets demonstrably present a great
challenge even for state-of-the-art DP synthetic data generation methods.
Struct-Bench also includes reference implementations of different metrics and a
leaderboard, thereby providing researchers a standardized evaluation platform
to benchmark and investigate privacy-preserving synthetic data generation
methods. Further, we also present a case study showing how to use Struct-Bench
to improve the synthetic data quality of Private Evolution (PE) on structured
data. The benchmark and the leaderboard have been publicly made available at
https://struct-bench.github.io.

</details>


### [8] [A Survey on Retrieval And Structuring Augmented Generation with Large Language Models](https://arxiv.org/abs/2509.10697)
*Pengcheng Jiang,Siru Ouyang,Yizhu Jiao,Ming Zhong,Runchu Tian,Jiawei Han*

Main category: cs.CL

TL;DR: 这篇综述论文探讨了检索与结构化增强生成(RAS)方法，通过整合动态信息检索和结构化知识表示来解决LLMs在现实应用中的幻觉生成、知识过时和领域专业知识有限等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在现实世界应用中面临幻觉生成、知识过时和领域专业知识有限等关键挑战，需要新的方法来增强其能力。

Method: 论文系统性地研究了：(1)检索机制包括稀疏、密集和混合方法；(2)文本结构化技术如分类法构建、层次分类和信息提取；(3)结构化表示与LLMs的集成方法包括提示方法、推理框架和知识嵌入技术。

Result: 论文提供了RAS方法的全面概述，识别了检索效率、结构质量和知识集成等技术挑战，并突出了多模态检索、跨语言结构和交互系统等研究方向。

Conclusion: RAS增强生成通过整合动态检索和结构化知识表示，为解决LLMs的现实应用挑战提供了有效途径，为研究者和实践者提供了方法、应用和未来方向的深入见解。

Abstract: Large Language Models (LLMs) have revolutionized natural language processing
with their remarkable capabilities in text generation and reasoning. However,
these models face critical challenges when deployed in real-world applications,
including hallucination generation, outdated knowledge, and limited domain
expertise. Retrieval And Structuring (RAS) Augmented Generation addresses these
limitations by integrating dynamic information retrieval with structured
knowledge representations. This survey (1) examines retrieval mechanisms
including sparse, dense, and hybrid approaches for accessing external
knowledge; (2) explore text structuring techniques such as taxonomy
construction, hierarchical classification, and information extraction that
transform unstructured text into organized representations; and (3) investigate
how these structured representations integrate with LLMs through prompt-based
methods, reasoning frameworks, and knowledge embedding techniques. It also
identifies technical challenges in retrieval efficiency, structure quality, and
knowledge integration, while highlighting research opportunities in multimodal
retrieval, cross-lingual structures, and interactive systems. This
comprehensive overview provides researchers and practitioners with insights
into RAS methods, applications, and future directions.

</details>


### [9] [SearchInstruct: Enhancing Domain Adaptation via Retrieval-Based Instruction Dataset Creation](https://arxiv.org/abs/2509.10708)
*Iman Barati,Mostafa Amiri,Heshaam Faili*

Main category: cs.CL

TL;DR: SearchInstruct是一个创新的方法，用于构建高质量的指令数据集来增强监督微调(SFT)，通过有限的人工生成问题扩展和动态检索领域相关资源来生成答案。


<details>
  <summary>Details</summary>
Motivation: 特定领域监督微调数据集的创建面临领域约束和数据稀缺的挑战，需要高质量指令数据集来提升大语言模型在专业领域的性能。

Method: 从少量人工生成的领域特定问题开始，使用大语言模型系统性地扩展问题，然后动态检索领域相关资源为每个扩展问题生成准确且上下文合适的答案。

Result: 实验评估显示SearchInstruct提高了SFT数据集的多样性和质量，在专业领域显著提升了LLM性能，还能有效促进模型编辑等任务。

Conclusion: SearchInstruct为构建高质量指令数据集提供了有效解决方案，推动了专业领域大语言模型的发展，并开源了完整实现和数据集以促进社区采用。

Abstract: Supervised Fine-Tuning (SFT) is essential for training large language models
(LLMs), significantly enhancing critical capabilities such as instruction
following and in-context learning. Nevertheless, creating suitable training
datasets tailored for specific domains remains challenging due to unique domain
constraints and data scarcity. In this paper, we propose SearchInstruct, an
innovative method explicitly designed to construct high quality instruction
datasets for SFT. Our approach begins with a limited set of domain specific,
human generated questions, which are systematically expanded using a large
language model. Subsequently, domain relevant resources are dynamically
retrieved to generate accurate and contextually appropriate answers for each
augmented question. Experimental evaluation demonstrates that SearchInstruct
enhances both the diversity and quality of SFT datasets, leading to measurable
improvements in LLM performance within specialized domains. Additionally, we
show that beyond dataset generation, the proposed method can also effectively
facilitate tasks such as model editing, enabling efficient updates to existing
models. To facilitate reproducibility and community adoption, we provide full
implementation details, the complete set of generated instruction response
pairs, and the source code in a publicly accessible Git repository:
[https://github.com/mostafaamiri/SearchInstruct](https://github.com/mostafaamiri/SearchInstruct)

</details>


### [10] [PolyTruth: Multilingual Disinformation Detection using Transformer-Based Language Models](https://arxiv.org/abs/2509.10737)
*Zaur Gouliev,Jennifer Waters,Chengqian Wang*

Main category: cs.CL

TL;DR: 本文系统比较了5种多语言Transformer模型在假新闻检测任务上的表现，发现RemBERT在低资源语言中表现最佳，而mBERT和XLM在训练数据稀缺时存在明显局限。


<details>
  <summary>Details</summary>
Motivation: 虚假信息跨语言传播迅速，但大多数AI模型仅在英语上进行基准测试，缺乏多语言环境下的有效性评估。

Method: 使用新构建的PolyTruth虚假信息语料库（60,486个声明对，覆盖25种语言），对mBERT、XLM、XLM-RoBERTa、RemBERT和mT5五种模型进行假新闻分类任务的系统性比较。

Result: RemBERT整体准确率更高，尤其在低资源语言中表现突出；mBERT和XLM在训练数据稀缺时存在显著局限性。

Conclusion: 研究揭示了AI系统在多语言虚假信息检测方面的潜力和当前局限，为实际部署提供了重要参考，数据集已公开以促进进一步研究。

Abstract: Disinformation spreads rapidly across linguistic boundaries, yet most AI
models are still benchmarked only on English. We address this gap with a
systematic comparison of five multilingual transformer models: mBERT, XLM,
XLM-RoBERTa, RemBERT, and mT5 on a common fake-vs-true machine learning
classification task. While transformer-based language models have demonstrated
notable success in detecting disinformation in English, their effectiveness in
multilingual contexts still remains up for debate. To facilitate evaluation, we
introduce PolyTruth Disinfo Corpus, a novel corpus of 60,486 statement pairs
(false claim vs. factual correction) spanning over twenty five languages that
collectively cover five language families and a broad topical range from
politics, health, climate, finance, and conspiracy, half of which are
fact-checked disinformation claims verified by an augmented MindBugs Discovery
dataset. Our experiments revealed performance variations. Models such as
RemBERT achieved better overall accuracy, particularly excelling in
low-resource languages, whereas models like mBERT and XLM exhibit considerable
limitations when training data is scarce. We provide a discussion of these
performance patterns and implications for real-world deployment. The dataset is
publicly available on our GitHub repository to encourage further
experimentation and advancement. Our findings illuminate both the potential and
the current limitations of AI systems for multilingual disinformation
detection.

</details>


### [11] [Reasoning Under Uncertainty: Exploring Probabilistic Reasoning Capabilities of LLMs](https://arxiv.org/abs/2509.10739)
*Mobina Pournemat,Keivan Rezaei,Gaurang Sriramanan,Arman Zarei,Jiaxiang Fu,Yang Wang,Hamid Eghbalzadeh,Soheil Feizi*

Main category: cs.CL

TL;DR: 该研究首次全面评估了大语言模型在显式离散概率分布上的推理能力，发现大模型在概率推理任务上表现优于小模型，但对符号表示敏感且上下文长度增加时性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在语言理解和生成方面取得了广泛成功，但在需要概率推理的任务上表现出不明确且不一致的行为，因此需要系统评估其概率推理能力。

Method: 设计了三个精心设计的任务（模式识别、最大似然估计和样本生成），通过提示模型提供关于联合分布或其条件分布的响应，来评估模型在给定概率分布观测值下的表现。

Result: 发现大模型和小模型之间存在明显的性能差距，大模型展现出更强的推理能力和令人惊讶的样本生成能力，但对符号表示变化敏感，且随着上下文长度增加性能下降超过60%。

Conclusion: 研究结果提供了对大语言模型概率推理能力的详细理解，并确定了未来改进的关键方向。

Abstract: Despite widespread success in language understanding and generation, large
language models (LLMs) exhibit unclear and often inconsistent behavior when
faced with tasks that require probabilistic reasoning. In this work, we present
the first comprehensive study of the reasoning capabilities of LLMs over
explicit discrete probability distributions. Given observations from a
probability distribution, we evaluate models on three carefully designed tasks,
mode identification, maximum likelihood estimation, and sample generation, by
prompting them to provide responses to queries about either the joint
distribution or its conditionals. These tasks thus probe a range of
probabilistic skills, including frequency analysis, marginalization, and
generative behavior. Through comprehensive empirical evaluations, we
demonstrate that there exists a clear performance gap between smaller and
larger models, with the latter demonstrating stronger inference and surprising
capabilities in sample generation. Furthermore, our investigations reveal
notable limitations, including sensitivity to variations in the notation
utilized to represent probabilistic outcomes and performance degradation of
over 60% as context length increases. Together, our results provide a detailed
understanding of the probabilistic reasoning abilities of LLMs and identify key
directions for future improvement.

</details>


### [12] [Automated MCQA Benchmarking at Scale: Evaluating Reasoning Traces as Retrieval Sources for Domain Adaptation of Small Language Models](https://arxiv.org/abs/2509.10744)
*Ozan Gokdemir,Neil Getty,Robert Underwood,Sandeep Madireddy,Franck Cappello,Arvind Ramanathan,Ian T. Foster,Rick L. Stevens*

Main category: cs.CL

TL;DR: 提出了一个从科学论文自动生成多选题评测基准的可扩展框架，在放射和癌症生物学领域生成了16,000多道题目，并发现基于推理轨迹的检索增强能显著提升小模型性能


<details>
  <summary>Details</summary>
Motivation: 随着科学知识的快速增长，需要与时俱进的评测基准来测试语言模型对最新多样化文献的理解能力

Method: 开发了自动化流水线，包括PDF解析、语义分块、问题生成和模型评估，使用22,000篇开放获取论文生成MCQA基准，并比较了基础模型、基于论文语义块的RAG和基于GPT-4推理轨迹的RAG方法

Result: 推理轨迹检索持续提升性能，多个小模型在2023年Astro放射与癌症生物学考试中超越了GPT-4的表现

Conclusion: 该框架能够快速生成大规模科学评测基准，基于推理轨迹的检索增强是提升小模型科学问答能力的有效方法

Abstract: As scientific knowledge grows at an unprecedented pace, evaluation benchmarks
must evolve to reflect new discoveries and ensure language models are tested on
current, diverse literature. We propose a scalable, modular framework for
generating multiple-choice question-answering (MCQA) benchmarks directly from
large corpora of scientific papers. Our pipeline automates every stage of MCQA
creation, including PDF parsing, semantic chunking, question generation, and
model evaluation. As a case study, we generate more than 16,000 MCQs from
22,000 open-access articles in radiation and cancer biology. We then evaluate a
suite of small language models (1.1B-14B parameters) on these questions,
comparing baseline accuracy with retrieval-augmented generation (RAG) from
paper-derived semantic chunks and from reasoning traces distilled from GPT-4.1.
We find that reasoning-trace retrieval consistently improves performance on
both synthetic and expert-annotated benchmarks, enabling several small models
to surpass GPT-4 on the 2023 Astro Radiation and Cancer Biology exam.

</details>


### [13] [RECAP: Transparent Inference-Time Emotion Alignment for Medical Dialogue Systems](https://arxiv.org/abs/2509.10746)
*Adarsh Srinivasan,Jacob Dineen,Muhammad Umar Afzal,Muhammad Uzair Sarfraz,Irbaz B. Riaz,Ben Zhou*

Main category: cs.CL

TL;DR: RECAP是一个推理时框架，通过结构化情感推理在不重新训练的情况下提升医疗大语言模型的情感智能，在多个基准测试中显著改善情感推理能力


<details>
  <summary>Details</summary>
Motivation: 医疗大语言模型经常忽略关键情感线索，提供医学上正确但情感平淡的建议，这在患者处于痛苦和脆弱状态的临床环境中尤其成问题

Method: RECAP（Reflect-Extract-Calibrate-Align-Produce）框架，将同理心分解为透明的评估理论阶段，暴露每维度的Likert信号，产生细致且可审计的响应

Result: 在EmoBench、SECEU和EQ-Bench基准测试中，RECAP在8B模型上提升情感推理22-28%，在更大模型上提升10-13%。临床医生评估进一步确认了优越的同理心沟通能力

Conclusion: RECAP表明模块化、理论基础的提示工程可以系统性地增强医疗AI的情感智能，同时保持部署所需的问责性

Abstract: Large language models in healthcare often miss critical emotional cues,
delivering medically sound but emotionally flat advice. This is especially
problematic in clinical contexts where patients are distressed and vulnerable,
and require empathic communication to support safety, adherence, and trust. We
present RECAP (Reflect-Extract-Calibrate-Align-Produce), an inference-time
framework that adds structured emotional reasoning without retraining. By
decomposing empathy into transparent appraisal-theoretic stages and exposing
per-dimension Likert signals, RECAP produces nuanced, auditable responses.
Across EmoBench, SECEU, and EQ-Bench, RECAP improves emotional reasoning by
22-28% on 8B models and 10-13% on larger models over zero-shot baselines.
Clinician evaluations further confirm superior empathetic communication. RECAP
shows that modular, theory-grounded prompting can systematically enhance
emotional intelligence in medical AI while preserving the accountability
required for deployment.

</details>


### [14] [Judge Q: Trainable Queries for Optimized Information Retention in KV Cache Eviction](https://arxiv.org/abs/2509.10798)
*Yijun Liu,Yixuan Wang,Yuzhuang Xu,Shiyu Ji,Yang Xu,Qingfu Zhu,Wanxiang Che*

Main category: cs.CL

TL;DR: 提出Judge Q方法，通过软令牌列表训练嵌入层，使查询能更好捕获全局信息来评估KV缓存重要性，在相同缓存预算下比现有方法性能下降更少


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存淘汰方法过度关注局部信息，可能忽略重要全局信息，影响内存使用和解码效率

Method: 提出Judge Q训练方法，在输入序列末尾拼接软令牌列表，训练这些令牌对原始输入序列的注意力图与实际解码令牌对齐，仅调优嵌入层

Result: 在Llama-3.1-8B-Instruct和Mistral-7B-Instruct-v0.3模型上实验，LongBench提升约1分，RULER提升超过3分

Conclusion: 该方法能以最小训练开销集成到现有开源模型中，提升KV缓存淘汰场景下的性能

Abstract: Large language models (LLMs) utilize key-value (KV) cache to store historical
information during sequence processing. The size of KV cache grows linearly as
the length of the sequence extends, which seriously affects memory usage and
decoding efficiency. Current methods for KV cache eviction typically utilize
the last window from the pre-filling phase as queries to compute the KV
importance scores for eviction. Although this scheme is simple to implement, it
tends to overly focus on local information, potentially leading to the neglect
or omission of crucial global information. To mitigate this issue, we propose
Judge Q, a novel training method which incorporates a soft token list. This
method only tunes the model's embedding layer at a low training cost. By
concatenating the soft token list at the end of the input sequence, we train
these tokens' attention map to the original input sequence to align with that
of the actual decoded tokens. In this way, the queries corresponding to the
soft tokens can effectively capture global information and better evaluate the
importance of the keys and values within the KV cache, thus maintaining
decoding quality when KV cache is evicted. Under the same eviction budget, our
method exhibits less performance degradation compared to existing eviction
approaches. We validate our approach through experiments conducted on models
such as Llama-3.1-8B-Instruct and Mistral-7B-Instruct-v0.3, using benchmarks
including LongBench, RULER, and Needle-in-a-Haystack. Results indicate an
improvement of approximately 1 point on the LongBench and over 3 points on
RULER. This proposed methodology can be seamlessly integrated into existing
open-source models with minimal training overhead, thereby enhancing
performance in KV cache eviction scenarios.

</details>


### [15] [Towards Automated Error Discovery: A Study in Conversational AI](https://arxiv.org/abs/2509.10833)
*Dominic Petrak,Thy Thy Tran,Iryna Gurevych*

Main category: cs.CL

TL;DR: 提出了Automated Error Discovery框架和SEEED方法，通过增强的Soft Nearest Neighbor Loss和标签样本排序来检测对话AI中的未知错误，在多个数据集上优于GPT-4o和Phi-4等基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的对话代理虽然流畅连贯，但仍会产生不良行为（错误），且现有LLM难以检测指令中未明确指定的错误，特别是当生成模型更新或用户行为变化时。

Method: 提出了SEEED（Soft Clustering Extended Encoder-Based Error Detection）方法，通过增强负样本距离加权的Soft Nearest Neighbor Loss和Label-Based Sample Ranking来选择高对比度样本进行更好的表示学习。

Result: SEEED在多个错误标注对话数据集上优于GPT-4o和Phi-4等基线模型，检测未知错误的准确率提高了8个百分点，并在未知意图检测方面表现出强大的泛化能力。

Conclusion: 该框架和方法能有效检测对话AI中的未知错误，具有很好的泛化性能，为对话系统的错误检测提供了新的解决方案。

Abstract: Although LLM-based conversational agents demonstrate strong fluency and
coherence, they still produce undesirable behaviors (errors) that are
challenging to prevent from reaching users during deployment. Recent research
leverages large language models (LLMs) to detect errors and guide
response-generation models toward improvement. However, current LLMs struggle
to identify errors not explicitly specified in their instructions, such as
those arising from updates to the response-generation model or shifts in user
behavior. In this work, we introduce Automated Error Discovery, a framework for
detecting and defining errors in conversational AI, and propose SEEED (Soft
Clustering Extended Encoder-Based Error Detection), as an encoder-based
approach to its implementation. We enhance the Soft Nearest Neighbor Loss by
amplifying distance weighting for negative samples and introduce Label-Based
Sample Ranking to select highly contrastive examples for better representation
learning. SEEED outperforms adapted baselines -- including GPT-4o and Phi-4 --
across multiple error-annotated dialogue datasets, improving the accuracy for
detecting unknown errors by up to 8 points and demonstrating strong
generalization to unknown intent detection.

</details>


### [16] [Evaluating Large Language Models for Evidence-Based Clinical Question Answering](https://arxiv.org/abs/2509.10843)
*Can Wang,Yiqun Chen*

Main category: cs.CL

TL;DR: 该研究评估了大型语言模型在循证临床问答中的表现，发现模型在结构化指南上准确率最高（90%），在叙述性指南和系统评价问题上较低（60-70%）。检索增强提示能显著提升准确性，但需要精准的检索策略。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在生物医学和临床应用中取得进展，需要严格评估其回答基于证据的复杂临床问题的能力，以了解其在循证医学中的实际应用价值。

Method: 研究使用来自Cochrane系统评价和临床指南的多源基准测试，评估GPT-4o-mini和GPT-5的表现。采用检索增强提示策略，提供金标准摘要和PubMed相关摘要进行对比分析。

Result: 模型准确率与系统评价引用次数强相关（引用数翻倍，正确回答几率增加约30%）。提供金标准摘要可将准确率提升至0.79，而提供相关PubMed摘要仅提升至0.23，随机摘要反而降低准确率。

Conclusion: LLM在循证临床问答中既有潜力也有局限，检索增强提示是提高事实准确性的有效策略，但需要针对性检索和按专业领域分层评估来理解模型性能。

Abstract: Large Language Models (LLMs) have demonstrated substantial progress in
biomedical and clinical applications, motivating rigorous evaluation of their
ability to answer nuanced, evidence-based questions. We curate a multi-source
benchmark drawing from Cochrane systematic reviews and clinical guidelines,
including structured recommendations from the American Heart Association and
narrative guidance used by insurers. Using GPT-4o-mini and GPT-5, we observe
consistent performance patterns across sources and clinical domains: accuracy
is highest on structured guideline recommendations (90%) and lower on narrative
guideline and systematic review questions (60--70%). We also find a strong
correlation between accuracy and the citation count of the underlying
systematic reviews, where each doubling of citations is associated with roughly
a 30% increase in the odds of a correct answer. Models show moderate ability to
reason about evidence quality when contextual information is supplied. When we
incorporate retrieval-augmented prompting, providing the gold-source abstract
raises accuracy on previously incorrect items to 0.79; providing top 3 PubMed
abstracts (ranked by semantic relevance) improves accuracy to 0.23, while
random abstracts reduce accuracy (0.10, within temperature variation). These
effects are mirrored in GPT-4o-mini, underscoring that source clarity and
targeted retrieval -- not just model size -- drive performance. Overall, our
results highlight both the promise and current limitations of LLMs for
evidence-based clinical question answering. Retrieval-augmented prompting
emerges as a useful strategy to improve factual accuracy and alignment with
source evidence, while stratified evaluation by specialty and question type
remains essential to understand current knowledge access and to contextualize
model performance.

</details>


### [17] [GAPrune: Gradient-Alignment Pruning for Domain-Aware Embeddings](https://arxiv.org/abs/2509.10844)
*Yixuan Tang,Yi Yang*

Main category: cs.CL

TL;DR: GAPrune是一个针对领域特定嵌入模型的剪枝框架，通过考虑领域重要性和保持通用语言基础，在50%稀疏度下性能损失小于2.5%，重训练后还能提升领域性能


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法对所有参数统一处理，无法区分通用语义表示和领域特定模式，导致在资源受限环境中部署大型嵌入模型时剪枝决策不理想

Method: 使用Fisher信息衡量重要性，通过通用领域梯度对齐评估参数行为，结合这两种信号形成领域对齐重要性(DAI)评分，低DAI分数表示参数对领域任务不重要或在领域与通用目标间产生冲突

Result: 在FinMTEB和ChemTEB两个领域基准测试中，GAPrune在50%稀疏度的一次剪枝中性能保持在密集模型的2.5%以内，重训练100步后在FinMTEB上提升4.51%，在ChemTEB上提升1.73%

Conclusion: 有原则的剪枝策略可以实现模型压缩和增强领域专业化，为研究社区提供了新的开发方法

Abstract: Domain-specific embedding models have shown promise for applications that
require specialized semantic understanding, such as coding agents and financial
retrieval systems, often achieving higher performance gains than general
models. However, state-of-the-art embedding models are typically based on LLMs,
which contain billions of parameters, making deployment challenging in
resource-constrained environments. Model compression through pruning offers a
promising solution, but existing pruning methods treat all parameters
uniformly, failing to distinguish between general semantic representations and
domain-specific patterns, leading to suboptimal pruning decisions. Thus, we
propose GAPrune, a pruning framework that addresses this challenge by
considering both domain importance and preserving general linguistic
foundation. Our method uses Fisher Information to measure importance and
general-domain gradient alignment to assess parameter behavior, then combines
these signals using our Domain Alignment Importance (DAI) scoring. Lower DAI
scores indicate that the parameter is either less important for the domain task
or creates conflicts between domain and general objectives. Experiments on two
domain benchmarks, FinMTEB and ChemTEB, show that GAPrune maintains performance
within 2.5% of dense models in one-shot pruning at 50% sparsity, while
outperforming all baselines. With retraining in 100 steps, GAPrune achieves
+4.51% improvement on FinMTEB and +1.73% on ChemTEB, demonstrating that our
pruning strategy not only preserves but enhances domain-specific capabilities.
Our findings demonstrate that principled pruning strategies can achieve model
compression and enhanced domain specialization, providing the research
community with a new approach for development.

</details>


### [18] [A funny companion: Distinct neural responses to perceived AI- versus human- generated humor](https://arxiv.org/abs/2509.10847)
*Xiaohui Rao,Hanlin Wu,Zhenguang G. Cai*

Main category: cs.CL

TL;DR: 研究发现AI和人类幽默在行为评分上相似，但神经生理数据显示AI幽默引发更小的N400（认知努力减少）和更大的LPP（惊喜和情感反应增强），表明大脑对AI幽默有积极动态适应过程。


<details>
  <summary>Details</summary>
Motivation: 随着AI伴侣具备类人沟通能力（包括讲笑话），了解人们对AI幽默的认知和情感反应变得日益重要。

Method: 使用脑电图（EEG）比较人们处理AI与人类来源幽默的方式，分析行为评分和神经生理数据（N400和LPP效应）。

Result: 行为上AI和人类幽默评分相当；神经生理上AI幽默显示更小的N400（认知努力减少）和更大的LPP（惊喜增强）；AI幽默呈现处理效率提升和情感奖励增加的趋势；社会态度调节神经反应。

Conclusion: 大脑对AI幽默产生出乎意料的积极强烈反应，幽默具有促进人机社交互动中真正参与的潜力，挑战了算法厌恶观念。

Abstract: As AI companions become capable of human-like communication, including
telling jokes, understanding how people cognitively and emotionally respond to
AI humor becomes increasingly important. This study used electroencephalography
(EEG) to compare how people process humor from AI versus human sources.
Behavioral analysis revealed that participants rated AI and human humor as
comparably funny. However, neurophysiological data showed that AI humor
elicited a smaller N400 effect, suggesting reduced cognitive effort during the
processing of incongruity. This was accompanied by a larger Late Positive
Potential (LPP), indicating a greater degree of surprise and emotional
response. This enhanced LPP likely stems from the violation of low initial
expectations regarding AI's comedic capabilities. Furthermore, a key temporal
dynamic emerged: human humor showed habituation effects, marked by an
increasing N400 and a decreasing LPP over time. In contrast, AI humor
demonstrated increasing processing efficiency and emotional reward, with a
decreasing N400 and an increasing LPP. This trajectory reveals how the brain
can dynamically update its predictive model of AI capabilities. This process of
cumulative reinforcement challenges "algorithm aversion" in humor, as it
demonstrates how cognitive adaptation to AI's language patterns can lead to an
intensified emotional reward. Additionally, participants' social attitudes
toward AI modulated these neural responses, with higher perceived AI
trustworthiness correlating with enhanced emotional engagement. These findings
indicate that the brain responds to AI humor with surprisingly positive and
intense reactions, highlighting humor's potential for fostering genuine
engagement in human-AI social interaction.

</details>


### [19] [Pre-Storage Reasoning for Episodic Memory: Shifting Inference Burden to Memory for Personalized Dialogue](https://arxiv.org/abs/2509.10852)
*Sangyeop Kim,Yohan Lee,Sanghwa Kim,Hyunjong Kim,Sungzoon Cho*

Main category: cs.CL

TL;DR: PREMem是一种新的对话AI长期记忆方法，通过在记忆构建阶段而非响应生成阶段进行复杂推理，将细粒度记忆片段分类并建立跨会话关系，显著提升了各种规模模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前对话AI系统在长期记忆方面过度依赖响应生成阶段的推理，导致性能严重受模型规模限制，需要一种能够减轻推理负担的方法。

Method: PREMem在预存储阶段提取细粒度记忆片段（事实性、经验性、主观性信息），建立跨会话记忆项之间的显式关系，捕捉扩展、转换、影响等演化模式。

Result: 实验显示所有模型规模都有显著性能提升，小模型能达到与大基线模型相当的结果，且在有限token预算下仍保持有效性。

Conclusion: PREMem通过将复杂推理从推理阶段转移到记忆构建阶段，有效降低了交互时的计算需求，同时创建了丰富的记忆表示，为对话AI的长期记忆提供了有效解决方案。

Abstract: Effective long-term memory in conversational AI requires synthesizing
information across multiple sessions. However, current systems place excessive
reasoning burden on response generation, making performance significantly
dependent on model sizes. We introduce PREMem (Pre-storage Reasoning for
Episodic Memory), a novel approach that shifts complex reasoning processes from
inference to memory construction. PREMem extracts fine-grained memory fragments
categorized into factual, experiential, and subjective information; it then
establishes explicit relationships between memory items across sessions,
capturing evolution patterns like extensions, transformations, and
implications. By performing this reasoning during pre-storage rather than when
generating a response, PREMem creates enriched representations while reducing
computational demands during interactions. Experiments show significant
performance improvements across all model sizes, with smaller models achieving
results comparable to much larger baselines while maintaining effectiveness
even with constrained token budgets. Code and dataset are available at
https://github.com/sangyeop-kim/PREMem.

</details>


### [20] [Quantifier Scope Interpretation in Language Learners and LLMs](https://arxiv.org/abs/2509.10860)
*Shaohua Fang,Yue Li,Yan Cong*

Main category: cs.CL

TL;DR: 这篇论文研究了大型语言模型在英语和汉语中处理量词范围解释的能力，发现大多数模型偏向表面范围解释，与人类偏向一致，但在逆范围偏好上存在语言差异


<details>
  <summary>Details</summary>
Motivation: 研究不同语言中多量词句子导致的解释涵约性，以及大型语言模型如何处理这种语言现象

Method: 采用跨语言方法，通过概率评估解释可能性，使用人类相似性分数来量化LLMs模仿人类表现的程度

Result: 结果显示大多数LLMs偏好表面范围解释，与人类偏向一致，但只有部分模型在英语和汉语的逆范围偏好上存在差异，反映了类似于人类的模式

Conclusion: 模型架构、规模和预训练数据的语言背景显著影响LLMs近似人类量词范围解释的程度，模型整体上具有与人类对齐的潜力

Abstract: Sentences with multiple quantifiers often lead to interpretive ambiguities,
which can vary across languages. This study adopts a cross-linguistic approach
to examine how large language models (LLMs) handle quantifier scope
interpretation in English and Chinese, using probabilities to assess
interpretive likelihood. Human similarity (HS) scores were used to quantify the
extent to which LLMs emulate human performance across language groups. Results
reveal that most LLMs prefer the surface scope interpretations, aligning with
human tendencies, while only some differentiate between English and Chinese in
the inverse scope preferences, reflecting human-similar patterns. HS scores
highlight variability in LLMs' approximation of human behavior, but their
overall potential to align with humans is notable. Differences in model
architecture, scale, and particularly models' pre-training data language
background, significantly influence how closely LLMs approximate human
quantifier scope interpretations.

</details>


### [21] [Term2Note: Synthesising Differentially Private Clinical Notes from Medical Terms](https://arxiv.org/abs/2509.10882)
*Yuping Wu,Viktor Schlegel,Warren Del-Pinto,Srinivasan Nandakumar,Iqra Zahid,Yidan Sun,Usama Farghaly Omar,Amirah Jasmine,Arun-Kumar Kaliya-Perumal,Chun Shen Tham,Gabriel Connors,Anil A Bharath,Goran Nenadic*

Main category: cs.CL

TL;DR: Term2Note是一种在强差分隐私约束下合成临床笔记的方法，通过分离内容和形式，生成基于隐私保护医学术语的章节内容，并在质量和效用方面优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 在医疗等高风险领域，使用真实训练数据受到隐私泄露的严重限制，需要找到在隐私保护和数据效用之间平衡的解决方案。

Method: 通过结构性地分离内容和形式，生成基于差分隐私医学术语的章节式笔记内容，每个部分受不同的隐私约束控制，并使用差分隐私质量最大化器选择高质量输出。

Result: 实验结果显示Term2Note生成的合成笔记在统计特性上与真实临床笔记高度一致，基于合成笔记训练的多标签分类模型性能与使用真实数据训练的模型相当。

Conclusion: Term2Note在较少假设条件下实现了保真度和效用的显著提升，有望成为使用敏感临床笔记的可行隐私保护替代方案。

Abstract: Training data is fundamental to the success of modern machine learning
models, yet in high-stakes domains such as healthcare, the use of real-world
training data is severely constrained by concerns over privacy leakage. A
promising solution to this challenge is the use of differentially private (DP)
synthetic data, which offers formal privacy guarantees while maintaining data
utility. However, striking the right balance between privacy protection and
utility remains challenging in clinical note synthesis, given its domain
specificity and the complexity of long-form text generation. In this paper, we
present Term2Note, a methodology to synthesise long clinical notes under strong
DP constraints. By structurally separating content and form, Term2Note
generates section-wise note content conditioned on DP medical terms, with each
governed by separate DP constraints. A DP quality maximiser further enhances
synthetic notes by selecting high-quality outputs. Experimental results show
that Term2Note produces synthetic notes with statistical properties closely
aligned with real clinical notes, demonstrating strong fidelity. In addition,
multi-label classification models trained on these synthetic notes perform
comparably to those trained on real data, confirming their high utility.
Compared to existing DP text generation baselines, Term2Note achieves
substantial improvements in both fidelity and utility while operating under
fewer assumptions, suggesting its potential as a viable privacy-preserving
alternative to using sensitive clinical notes.

</details>


### [22] [CultureSynth: A Hierarchical Taxonomy-Guided and Retrieval-Augmented Framework for Cultural Question-Answer Synthesis](https://arxiv.org/abs/2509.10886)
*Xinyu Zhang,Pei Zhang,Shuang Luo,Jialong Tang,Yu Wan,Baosong Yang,Fei Huang*

Main category: cs.CL

TL;DR: CultureSynth是一个用于评估大语言模型文化能力的新框架，包含多语言文化分类法和基于RAG的问答对生成方法，在7种语言上测试了14个主流LLM。


<details>
  <summary>Details</summary>
Motivation: 现有文化能力评估存在分类法碎片化、领域特定性和依赖人工标注的问题，需要更全面、可扩展的评估框架。

Method: 提出了CultureSynth框架：1)包含12个主要和130个次要主题的层次化多语言文化分类法；2)基于检索增强生成(RAG)的方法，利用事实知识合成文化相关问答对。

Result: 评估14个不同规模的LLM发现：ChatGPT-4o-Latest和Qwen2.5-72B-Instruct表现最佳；3B参数是达到基本文化能力的最低阈值；模型在知识处理上存在架构偏见；存在显著的地理差异。

Conclusion: CultureSynth为开发文化感知AI系统提供了可扩展框架，减少了对手动标注的依赖，有助于提升LLM的跨文化理解能力。

Abstract: Cultural competence, defined as the ability to understand and adapt to
multicultural contexts, is increasingly vital for large language models (LLMs)
in global environments. While several cultural benchmarks exist to assess LLMs'
cultural competence, current evaluations suffer from fragmented taxonomies,
domain specificity, and heavy reliance on manual data annotation. To address
these limitations, we introduce CultureSynth, a novel framework comprising (1)
a comprehensive hierarchical multilingual cultural taxonomy covering 12 primary
and 130 secondary topics, and (2) a Retrieval-Augmented Generation (RAG)-based
methodology leveraging factual knowledge to synthesize culturally relevant
question-answer pairs. The CultureSynth-7 synthetic benchmark contains 19,360
entries and 4,149 manually verified entries across 7 languages. Evaluation of
14 prevalent LLMs of different sizes reveals clear performance stratification
led by ChatGPT-4o-Latest and Qwen2.5-72B-Instruct. The results demonstrate that
a 3B-parameter threshold is necessary for achieving basic cultural competence,
models display varying architectural biases in knowledge processing, and
significant geographic disparities exist across models. We believe that
CultureSynth offers a scalable framework for developing culturally aware AI
systems while reducing reliance on manual annotation\footnote{Benchmark is
available at https://github.com/Eyr3/CultureSynth.}.

</details>


### [23] [Aligning ESG Controversy Data with International Guidelines through Semi-Automatic Ontology Construction](https://arxiv.org/abs/2509.10922)
*Tsuyoshi Iwata,Guillaume Comte,Melissa Flores,Ryoma Kondo,Ryohei Hisano*

Main category: cs.CL

TL;DR: 提出了一种半自动方法，使用轻量级本体设计、形式化模式建模和大语言模型，将ESG新闻事件转化为结构化知识图谱，以连接报道事件与国际可持续发展准则。


<details>
  <summary>Details</summary>
Motivation: ESG数据在监管和投资中日益重要，但将非结构化新闻中的争议数据与基于原则的规范性框架（如联合国全球契约或可持续发展目标）对齐存在挑战，因为这些框架语言抽象、缺乏标准化分类法，且与商业数据提供商的专有系统不同。

Method: 使用轻量级本体设计、形式化模式建模和大语言模型，将规范性原则转化为可重用的RDF模板，从新闻内容中提取相关信息并构建结构化知识图谱。

Result: 开发了一个可扩展且透明的框架，用于识别和解释与国际可持续发展准则的不合规情况。

Conclusion: 该方法能够有效解决ESG数据与规范性框架对齐的挑战，提供了一种系统化的解决方案来构建结构化的ESG知识表示。

Abstract: The growing importance of environmental, social, and governance data in
regulatory and investment contexts has increased the need for accurate,
interpretable, and internationally aligned representations of non-financial
risks, particularly those reported in unstructured news sources. However,
aligning such controversy-related data with principle-based normative
frameworks, such as the United Nations Global Compact or Sustainable
Development Goals, presents significant challenges. These frameworks are
typically expressed in abstract language, lack standardized taxonomies, and
differ from the proprietary classification systems used by commercial data
providers. In this paper, we present a semi-automatic method for constructing
structured knowledge representations of environmental, social, and governance
events reported in the news. Our approach uses lightweight ontology design,
formal pattern modeling, and large language models to convert normative
principles into reusable templates expressed in the Resource Description
Framework. These templates are used to extract relevant information from news
content and populate a structured knowledge graph that links reported incidents
to specific framework principles. The result is a scalable and transparent
framework for identifying and interpreting non-compliance with international
sustainability guidelines.

</details>


### [24] [Introducing Spotlight: A Novel Approach for Generating Captivating Key Information from Documents](https://arxiv.org/abs/2509.10935)
*Ankan Mullick,Sombit Bose,Rounak Saha,Ayan Kumar Bhowmick,Aditya Vempaty,Prasenjit Dey,Ravi Kokku,Pawan Goyal,Niloy Ganguly*

Main category: cs.CL

TL;DR: Spotlight是一种新颖的信息提取范式，通过突出文档中最吸引人的内容来生成简洁、引人入胜的叙述，与传统摘要追求全面覆盖不同，它选择性地强调有趣内容以促进读者更深入参与源材料。


<details>
  <summary>Details</summary>
Motivation: 传统摘要方法过于注重全面性而忽略了内容的吸引力和读者参与度，需要一种新的信息提取方式来更好地激发读者对源文档的兴趣和参与。

Method: 采用两阶段方法：首先在基准数据上微调大型语言模型，然后通过直接偏好优化（DPO）进行对齐训练。

Result: 评估表明，生成的模型不仅能精确识别关键元素，还能提高可读性并显著增强原始文档的参与价值。

Conclusion: Spotlight范式成功实现了从全面性摘要向选择性强调有趣内容的转变，有效提升了文档的吸引力和读者参与度，为信息提取领域提供了新的方向。

Abstract: In this paper, we introduce Spotlight, a novel paradigm for information
extraction that produces concise, engaging narratives by highlighting the most
compelling aspects of a document. Unlike traditional summaries, which
prioritize comprehensive coverage, spotlights selectively emphasize intriguing
content to foster deeper reader engagement with the source material. We
formally differentiate spotlights from related constructs and support our
analysis with a detailed benchmarking study using new datasets curated for this
work. To generate high-quality spotlights, we propose a two-stage approach:
fine-tuning a large language model on our benchmark data, followed by alignment
via Direct Preference Optimization (DPO). Our comprehensive evaluation
demonstrates that the resulting model not only identifies key elements with
precision but also enhances readability and boosts the engagement value of the
original document.

</details>


### [25] [An Interpretable Benchmark for Clickbait Detection and Tactic Attribution](https://arxiv.org/abs/2509.10937)
*Lihi Nofar,Tomer Portal,Aviv Elbaz,Alexander Apartsin,Yehudit Aperstein*

Main category: cs.CL

TL;DR: 本文提出了一个可解释的点击诱饵检测模型，不仅能识别点击诱饵标题，还能归因于特定的语言操纵策略，使用合成数据集和两阶段框架（检测+策略归因）进行实验。


<details>
  <summary>Details</summary>
Motivation: 点击诱饵标题的泛滥对信息可信度和用户信任构成挑战，现有机器学习方法缺乏可解释性限制了实际应用。

Method: 使用系统增强真实新闻标题生成的合成数据集，采用两阶段框架：第一阶段比较微调BERT与LLM（GPT-4.0和Gemini 2.4 Flash）的零样本和少样本提示；第二阶段用专用BERT分类器预测具体点击诱饵策略。

Result: 开发了透明可信的AI系统来对抗操纵性媒体内容，并公开了数据集供研究社区使用。

Conclusion: 该工作推进了可解释点击诱饵检测的发展，为构建透明AI系统提供了有效方法。

Abstract: The proliferation of clickbait headlines poses significant challenges to the
credibility of information and user trust in digital media. While recent
advances in machine learning have improved the detection of manipulative
content, the lack of explainability limits their practical adoption. This paper
presents a model for explainable clickbait detection that not only identifies
clickbait titles but also attributes them to specific linguistic manipulation
strategies. We introduce a synthetic dataset generated by systematically
augmenting real news headlines using a predefined catalogue of clickbait
strategies. This dataset enables controlled experimentation and detailed
analysis of model behaviour. We present a two-stage framework for automatic
clickbait analysis comprising detection and tactic attribution. In the first
stage, we compare a fine-tuned BERT classifier with large language models
(LLMs), specifically GPT-4.0 and Gemini 2.4 Flash, under both zero-shot
prompting and few-shot prompting enriched with illustrative clickbait headlines
and their associated persuasive tactics. In the second stage, a dedicated
BERT-based classifier predicts the specific clickbait strategies present in
each headline. This work advances the development of transparent and
trustworthy AI systems for combating manipulative media content. We share the
dataset with the research community at
https://github.com/LLM-HITCS25S/ClickbaitTacticsDetection

</details>


### [26] [EmoBench-Reddit: A Hierarchical Benchmark for Evaluating the Emotional Intelligence of Multimodal Large Language Models](https://arxiv.org/abs/2509.11101)
*Haokun Li,Yazhou Zhang,Jizhi Ding,Qiuchi Li,Peng Zhang*

Main category: cs.CL

TL;DR: EmoBench-Reddit是一个新颖的多模态情感理解基准数据集，包含350个来自Reddit的精心策划样本，每个样本包含图像、文本和情感类别，采用分层任务框架从基础感知到高级认知进行评估。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型的评估基准主要关注客观视觉问答或字幕生成，无法充分评估模型理解复杂主观人类情感的能力，需要专门的情感理解评估工具。

Method: 构建包含350个Reddit样本的数据集，每个样本包含图像、用户文本和情感标签；设计分层任务框架，包含6个选择题和1个开放式问题，从基础感知（颜色、物体识别）到高级认知（场景推理、意图理解、深度共情）逐步提升难度；采用AI辅助（Claude 4）和人工验证确保标注质量。

Result: 开发了EmoBench-Reddit基准数据集，为多模态情感理解提供了系统的评估框架，包含感知和认知两个层次的任务设计。

Conclusion: 该研究填补了多模态情感理解评估的空白，为MLLMs在复杂主观情感理解方面的能力评估提供了重要工具，有助于推动情感AI的发展。

Abstract: With the rapid advancement of Multimodal Large Language Models (MLLMs), they
have demonstrated exceptional capabilities across a variety of vision-language
tasks. However, current evaluation benchmarks predominantly focus on objective
visual question answering or captioning, inadequately assessing the models'
ability to understand complex and subjective human emotions. To bridge this
gap, we introduce EmoBench-Reddit, a novel, hierarchical benchmark for
multimodal emotion understanding. The dataset comprises 350 meticulously
curated samples from the social media platform Reddit, each containing an
image, associated user-provided text, and an emotion category (sad, humor,
sarcasm, happy) confirmed by user flairs. We designed a hierarchical task
framework that progresses from basic perception to advanced cognition, with
each data point featuring six multiple-choice questions and one open-ended
question of increasing difficulty. Perception tasks evaluate the model's
ability to identify basic visual elements (e.g., colors, objects), while
cognition tasks require scene reasoning, intent understanding, and deep empathy
integrating textual context. We ensured annotation quality through a
combination of AI assistance (Claude 4) and manual verification.

</details>


### [27] [Fluid Language Model Benchmarking](https://arxiv.org/abs/2509.11106)
*Valentin Hofmann,David Heineman,Ian Magnusson,Kyle Lo,Jesse Dodge,Maarten Sap,Pang Wei Koh,Chun Wang,Hannaneh Hajishirzi,Noah A. Smith*

Main category: cs.CL

TL;DR: Fluid Benchmarking是一种新的语言模型评估方法，通过项目反应理论和动态项目选择来提升评估效率、有效性、方差和饱和度的综合性能


<details>
  <summary>Details</summary>
Motivation: 解决语言模型基准测试面临的成本高、测量不准确、标签错误和基准饱和等问题，现有方法往往孤立处理单个方面而忽视整体评估质量

Method: 基于项目反应理论从现有评估结果估计项目反应模型，使用推断量动态选择评估项目，类似于教育中的计算机化自适应测试

Result: 在效率、有效性、方差和饱和度四个维度上均优于随机抽样和其他基于项目反应理论的基线方法，例如在MMLU上使用少50倍的项目获得更高的有效性和更低的方差

Conclusion: 语言模型基准测试可以通过超越静态评估而得到显著改进，项目反应理论提高有效性，动态项目选择减少方差

Abstract: Language model (LM) benchmarking faces several challenges: comprehensive
evaluations are costly, benchmarks often fail to measure the intended
capabilities, and evaluation quality can degrade due to labeling errors and
benchmark saturation. Although various strategies have been proposed to
mitigate these issues, they tend to address individual aspects in isolation,
neglecting broader questions about overall evaluation quality. Here, we
introduce Fluid Benchmarking, a new evaluation approach that advances LM
benchmarking across multiple dimensions. Inspired by psychometrics, Fluid
Benchmarking is based on the insight that the relative value of benchmark items
depends on an LM's capability level, suggesting that evaluation should adapt to
each LM. Methodologically, Fluid Benchmarking estimates an item response model
based on existing LM evaluation results and uses the inferred quantities to
select evaluation items dynamically, similar to computerized adaptive testing
in education. In our experiments, we compare Fluid Benchmarking against the
common practice of random item sampling as well as more sophisticated
baselines, including alternative methods grounded in item response theory. We
examine four dimensions -- efficiency, validity, variance, and saturation --
and find that Fluid Benchmarking achieves superior performance in all of them
(e.g., higher validity and less variance on MMLU with fifty times fewer items).
Our analysis shows that the two components of Fluid Benchmarking have distinct
effects: item response theory, used to map performance into a latent ability
space, increases validity, while dynamic item selection reduces variance.
Overall, our results suggest that LM benchmarking can be substantially improved
by moving beyond static evaluation.

</details>


### [28] [We Argue to Agree: Towards Personality-Driven Argumentation-Based Negotiation Dialogue Systems for Tourism](https://arxiv.org/abs/2509.11118)
*Priyanshu Priya,Saurav Dudhate,Desai Vishesh Yasheshbhai,Asif Ekbal*

Main category: cs.CL

TL;DR: 提出了基于人格驱动的论证谈判对话生成任务(PAN-DG)和PACT数据集，通过微调LLM能够有效生成个性化谈判对话


<details>
  <summary>Details</summary>
Motivation: 将论证机制融入谈判对话系统可以改善冲突解决，而加入人格属性能够增强系统适应性，使其更好地与个人偏好和风格对齐

Method: 提出PAN-DG任务，构建包含三种人格特征(论证特征、偏好特征、购买风格特征)的PACT数据集，使用LLM生成高质量对话，并进行预训练和微调LLM的对比实验

Result: 自动和人工评估显示数据集质量高，微调后的LLM能够有效生成人格驱动的理性谈判响应

Conclusion: PACT数据集有效提升了谈判对话系统的个性化和推理能力，为该领域未来研究奠定了基础

Abstract: Integrating argumentation mechanisms into negotiation dialogue systems
improves conflict resolution through exchanges of arguments and critiques.
Moreover, incorporating personality attributes enhances adaptability by
aligning interactions with individuals' preferences and styles. To advance
these capabilities in negotiation dialogue systems, we propose a novel
Personality-driven Argumentation-based Negotiation Dialogue Generation (PAN-DG)
task. To support this task, we introduce PACT, a dataset of Personality-driven
Argumentation-based negotiation Conversations for Tourism sector. This dataset,
generated using Large Language Models (LLMs), features three distinct
personality profiles, viz. Argumentation Profile, Preference Profile, and
Buying Style Profile to simulate a variety of negotiation scenarios involving
diverse personalities. Thorough automatic and manual evaluations indicate that
the dataset comprises high-quality dialogues. Further, we conduct comparative
experiments between pre-trained and fine-tuned LLMs for the PAN-DG task.
Multi-dimensional evaluation demonstrates that the fine-tuned LLMs effectively
generate personality-driven rational responses during negotiations. This
underscores the effectiveness of PACT in enhancing personalization and
reasoning capabilities in negotiation dialogue systems, thereby establishing a
foundation for future research in this domain.

</details>


### [29] [Joint Effects of Argumentation Theory, Audio Modality and Data Enrichment on LLM-Based Fallacy Classification](https://arxiv.org/abs/2509.11127)
*Hongxu Zhou,Hylke Westerdijk,Khondoker Ittehadul Islam*

Main category: cs.CL

TL;DR: 本研究探讨了上下文和情感语调元数据如何影响大语言模型在谬误分类任务中的推理和性能，特别是在政治辩论场景中。研究发现情感元数据会带来偏见，而基础提示往往比增强提示表现更好。


<details>
  <summary>Details</summary>
Motivation: 研究动机是了解上下文和情感元数据对LLM在政治辩论谬误分类中的影响，探索理论框架是否能提升模型性能。

Method: 使用美国大选辩论数据，通过Qwen-3模型进行六种谬误分类，比较了三种输入设置（纯文本、文本+上下文、文本+上下文+情感语调）和三种提示策略（基础提示、语用辩证框架、论证周期表框架）。

Result: 理论提示能提高可解释性，但添加上下文和情感语调元数据通常导致性能下降。情感元数据使模型偏向将陈述标记为"诉诸情感"谬误，损害逻辑推理。基础提示往往优于增强提示。

Conclusion: 额外的输入信息可能导致注意力分散，反而恶化LLM的谬误分类性能，情感元数据会引入偏见，基础方法在某些情况下更有效。

Abstract: This study investigates how context and emotional tone metadata influence
large language model (LLM) reasoning and performance in fallacy classification
tasks, particularly within political debate settings. Using data from U.S.
presidential debates, we classify six fallacy types through various prompting
strategies applied to the Qwen-3 (8B) model. We introduce two theoretically
grounded Chain-of-Thought frameworks: Pragma-Dialectics and the Periodic Table
of Arguments, and evaluate their effectiveness against a baseline prompt under
three input settings: text-only, text with context, and text with both context
and audio-based emotional tone metadata. Results suggest that while theoretical
prompting can improve interpretability and, in some cases, accuracy, the
addition of context and especially emotional tone metadata often leads to
lowered performance. Emotional tone metadata biases the model toward labeling
statements as \textit{Appeal to Emotion}, worsening logical reasoning. Overall,
basic prompts often outperformed enhanced ones, suggesting that attention
dilution from added inputs may worsen rather than improve fallacy
classification in LLMs.

</details>


### [30] [When Smiley Turns Hostile: Interpreting How Emojis Trigger LLMs' Toxicity](https://arxiv.org/abs/2509.11141)
*Shiyao Cui,Xijia Feng,Yingkang Wang,Junxiao Yang,Zhexin Zhang,Biplab Sikdar,Hongning Wang,Han Qiu,Minlie Huang*

Main category: cs.CL

TL;DR: 研究发现表情符号可以触发大型语言模型生成有毒内容，通过构建含表情符号的提示词可以绕过安全机制诱导毒性生成，这种现象与预训练数据中的表情符号污染相关。


<details>
  <summary>Details</summary>
Motivation: 观察到表情符号可能触发大型语言模型生成有毒内容，旨在研究表情符号是否确实能增强毒性生成以及如何解释这一现象。

Method: 通过自动化构建含表情符号的提示词来微妙表达有毒意图，在5种主流语言的7个知名LLM上进行实验，并进行模型层面的语义认知、序列生成和分词分析，同时探查预训练语料库。

Result: 实验表明含表情符号的提示词容易诱导毒性生成，表情符号可作为异质语义通道绕过安全机制，预训练语料中的表情符号相关数据污染与毒性生成行为存在潜在关联。

Conclusion: 表情符号确实能显著增强LLM的毒性生成能力，这种现象源于表情符号作为异质语义通道绕过安全机制，且与预训练数据污染相关，需要关注数字通信中的这种安全隐患。

Abstract: Emojis are globally used non-verbal cues in digital communication, and
extensive research has examined how large language models (LLMs) understand and
utilize emojis across contexts. While usually associated with friendliness or
playfulness, it is observed that emojis may trigger toxic content generation in
LLMs. Motivated by such a observation, we aim to investigate: (1) whether
emojis can clearly enhance the toxicity generation in LLMs and (2) how to
interpret this phenomenon. We begin with a comprehensive exploration of
emoji-triggered LLM toxicity generation by automating the construction of
prompts with emojis to subtly express toxic intent. Experiments across 5
mainstream languages on 7 famous LLMs along with jailbreak tasks demonstrate
that prompts with emojis could easily induce toxicity generation. To understand
this phenomenon, we conduct model-level interpretations spanning semantic
cognition, sequence generation and tokenization, suggesting that emojis can act
as a heterogeneous semantic channel to bypass the safety mechanisms. To pursue
deeper insights, we further probe the pre-training corpus and uncover potential
correlation between the emoji-related data polution with the toxicity
generation behaviors. Supplementary materials provide our implementation code
and data. (Warning: This paper contains potentially sensitive contents)

</details>


### [31] [Text2Mem: A Unified Memory Operation Language for Memory Operating System](https://arxiv.org/abs/2509.11145)
*Felix Wang,Boyu Chen,Kerun Xu,Bo Tang,Feiyu Xiong,Zhiyu Li*

Main category: cs.CL

TL;DR: Text2Mem是一个统一的内存操作语言，为LLM代理提供从自然语言到可靠执行的标准路径，解决了现有内存框架功能有限、缺乏正式规范的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理内存框架功能有限，只提供基本操作，缺乏高级操作和正式规范，导致跨系统行为不可预测。需要统一的标准来确保内存操作的安全性、确定性和可移植性。

Method: 设计Text2Mem语言，定义紧凑而富有表现力的操作集，使用JSON模式表示指令，包含解析器、验证器和适配器，支持SQL原型后端和实际内存框架的映射。

Result: 建立了第一个标准化的内存控制基础，确保操作的安全性、确定性和跨异构后端的可移植性，并计划开发Text2Mem Bench基准测试。

Conclusion: Text2Mem为解决LLM代理内存管理中的标准化问题提供了有效解决方案，为未来的系统评估和开发奠定了基础。

Abstract: Large language model agents increasingly depend on memory to sustain long
horizon interaction, but existing frameworks remain limited. Most expose only a
few basic primitives such as encode, retrieve, and delete, while higher order
operations like merge, promote, demote, split, lock, and expire are missing or
inconsistently supported. Moreover, there is no formal and executable
specification for memory commands, leaving scope and lifecycle rules implicit
and causing unpredictable behavior across systems. We introduce Text2Mem, a
unified memory operation language that provides a standardized pathway from
natural language to reliable execution. Text2Mem defines a compact yet
expressive operation set aligned with encoding, storage, and retrieval. Each
instruction is represented as a JSON based schema instance with required fields
and semantic invariants, which a parser transforms into typed operation objects
with normalized parameters. A validator ensures correctness before execution,
while adapters map typed objects either to a SQL prototype backend or to real
memory frameworks. Model based services such as embeddings or summarization are
integrated when required. All results are returned through a unified execution
contract. This design ensures safety, determinism, and portability across
heterogeneous backends. We also outline Text2Mem Bench, a planned benchmark
that separates schema generation from backend execution to enable systematic
evaluation. Together, these components establish the first standardized
foundation for memory control in agents.

</details>


### [32] [Differentially-private text generation degrades output language quality](https://arxiv.org/abs/2509.11176)
*Erion Çano,Ivan Habernal*

Main category: cs.CL

TL;DR: 本文研究了在差分隐私约束下微调大语言模型对生成文本质量和下游任务效用的影响，发现更强的隐私保护会导致文本更短、语法正确性下降、词汇多样性减少，以及分类任务准确率降低。


<details>
  <summary>Details</summary>
Motivation: 虽然使用差分隐私微调LLMs来保护用户隐私已成为流行方法，但这种方法对生成文本质量和实用性的影响尚未得到充分研究。

Method: 使用5个LLMs在3个语料库上以4种隐私级别进行微调，评估生成文本的长度、语法正确性、词汇多样性，并测试在下游分类任务（书籍类型识别和死因识别）中的效用。

Result: 更强的隐私约束导致文本长度减少至少77%，语法正确性下降至少9%，二元词汇多样性减少至少10%，下游分类任务准确率也相应下降。

Conclusion: 差分隐私微调虽然保护了隐私，但显著降低了生成文本的质量和实用性，这可能影响合成数据的实际应用价值。

Abstract: Ensuring user privacy by synthesizing data from large language models (LLMs)
tuned under differential privacy (DP) has become popular recently. However, the
impact of DP fine-tuned LLMs on the quality of the language and the utility of
the texts they produce has not been investigated. In this work, we tune five
LLMs with three corpora under four levels of privacy and assess the length, the
grammatical correctness, and the lexical diversity of the text outputs they
produce. We also probe the utility of the synthetic outputs in downstream
classification tasks such as book genre recognition based on book descriptions
and cause of death recognition based on verbal autopsies. The results indicate
that LLMs tuned under stronger privacy constrains produce texts that are
shorter by at least 77 %, that are less grammatically correct by at least 9 %,
and are less diverse by at least 10 % in bi-gram diversity. Furthermore, the
accuracy they reach in downstream classification tasks decreases, which might
be detrimental to the usefulness of the generated synthetic data.

</details>


### [33] [Optimal Brain Restoration for Joint Quantization and Sparsification of LLMs](https://arxiv.org/abs/2509.11177)
*Hang Guo,Yawei Li,Luca Benini*

Main category: cs.CL

TL;DR: OBR是一个无需训练的联合压缩框架，通过误差补偿将量化和剪枝结合，在W4A4KV4量化和50%稀疏度下实现4.72倍加速和6.4倍内存减少


<details>
  <summary>Details</summary>
Motivation: 随着单一压缩方法逐渐接近极限，需要探索联合压缩方案。但量化和剪枝对权重分布有冲突要求：量化偏好紧凑范围，剪枝需要高方差

Method: 提出Optimal Brain Restoration (OBR)框架，基于二阶Hessian目标，通过代理近似和组误差补偿获得闭式解，无需训练即可对齐剪枝和量化

Result: 在现有LLM上实现激进的W4A4KV4量化和50%稀疏度，相比FP16密集基线获得4.72倍加速和6.4倍内存减少

Conclusion: OBR提供了一个通用且无需训练的框架，成功解决了量化和剪枝联合压缩中的冲突问题，实现了显著的性能提升

Abstract: Recent advances in Large Language Model (LLM) compression, such as
quantization and pruning, have achieved notable success. However, as these
techniques gradually approach their respective limits, relying on a single
method for further compression has become increasingly challenging. In this
work, we explore an alternative solution by combining quantization and
sparsity. This joint approach, though promising, introduces new difficulties
due to the inherently conflicting requirements on weight distributions:
quantization favors compact ranges, while pruning benefits from high variance.
To attack this problem, we propose Optimal Brain Restoration (OBR), a general
and training-free framework that aligns pruning and quantization by error
compensation between both. OBR minimizes performance degradation on downstream
tasks by building on a second-order Hessian objective, which is then
reformulated into a tractable problem through surrogate approximation and
ultimately reaches a closed-form solution via group error compensation.
Experiments show that OBR enables aggressive W4A4KV4 quantization with 50%
sparsity on existing LLMs, and delivers up to 4.72x speedup and 6.4x memory
reduction compared to the FP16-dense baseline.

</details>


### [34] [RanAT4BIE: Random Adversarial Training for Biomedical Information Extraction](https://arxiv.org/abs/2509.11191)
*Jian Chen,Shengyi Lv,Leilei Su*

Main category: cs.CL

TL;DR: RAT（随机对抗训练）是一种结合随机采样和对抗训练的新框架，在生物医学信息抽取任务中显著提升模型性能并大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统对抗训练虽然能提升预训练语言模型在生物医学信息抽取任务中的性能，但带来了巨大的计算开销，需要一种更高效的解决方案。

Method: 基于PubMedBERT架构，将随机采样机制与对抗训练原则策略性结合，在保持模型泛化能力和鲁棒性的同时显著减少计算成本。

Result: RAT在生物医学信息抽取任务中表现出优于基线模型的性能，验证了其有效性。

Conclusion: RAT为生物医学自然语言处理提供了一个平衡模型性能和计算效率的变革性框架，具有重要应用潜力。

Abstract: We introduce random adversarial training (RAT), a novel framework
successfully applied to biomedical information extraction (BioIE) tasks.
Building on PubMedBERT as the foundational architecture, our study first
validates the effectiveness of conventional adversarial training in enhancing
pre-trained language models' performance on BioIE tasks. While adversarial
training yields significant improvements across various performance metrics, it
also introduces considerable computational overhead. To address this
limitation, we propose RAT as an efficiency solution for biomedical information
extraction. This framework strategically integrates random sampling mechanisms
with adversarial training principles, achieving dual objectives: enhanced model
generalization and robustness while significantly reducing computational costs.
Through comprehensive evaluations, RAT demonstrates superior performance
compared to baseline models in BioIE tasks. The results highlight RAT's
potential as a transformative framework for biomedical natural language
processing, offering a balanced solution to the model performance and
computational efficiency.

</details>


### [35] [The Prompt Engineering Report Distilled: Quick Start Guide for Life Sciences](https://arxiv.org/abs/2509.11295)
*Valentin Romanov,Steven A Niederer*

Main category: cs.CL

TL;DR: 该论文将58种提示工程技术提炼为6种核心方法（零样本、少样本、思维生成、集成、自我批评和分解），为生命科学领域提供实用的提示工程指南，旨在提高研究效率和质量。


<details>
  <summary>Details</summary>
Motivation: 开发有效的提示需要大量认知投入，研究人员通过掌握特定的提示工程技术可以在生命科学工作流中获得远超初始时间投入的效率提升。

Method: 将2025年Prompt Report中的58种文本提示工程技术提炼为6种核心方法，分析每种方法的意义并在生命科学用例中验证，提供结构化建议和常见陷阱解决方案。

Result: 提供了详细的提示结构建议，解决了多轮对话退化、幻觉等问题，分析了不同平台工具的有效性和当前限制，展示了提示工程如何增强而非替代现有数据处理实践。

Conclusion: 旨在为核心提示工程原则提供可操作指导，促进从机会性提示向有效、低摩擦的系统化实践过渡，从而贡献更高质量的研究成果。

Abstract: Developing effective prompts demands significant cognitive investment to
generate reliable, high-quality responses from Large Language Models (LLMs). By
deploying case-specific prompt engineering techniques that streamline
frequently performed life sciences workflows, researchers could achieve
substantial efficiency gains that far exceed the initial time investment
required to master these techniques. The Prompt Report published in 2025
outlined 58 different text-based prompt engineering techniques, highlighting
the numerous ways prompts could be constructed. To provide actionable
guidelines and reduce the friction of navigating these various approaches, we
distil this report to focus on 6 core techniques: zero-shot, few-shot
approaches, thought generation, ensembling, self-criticism, and decomposition.
We breakdown the significance of each approach and ground it in use cases
relevant to life sciences, from literature summarization and data extraction to
editorial tasks. We provide detailed recommendations for how prompts should and
shouldn't be structured, addressing common pitfalls including multi-turn
conversation degradation, hallucinations, and distinctions between reasoning
and non-reasoning models. We examine context window limitations, agentic tools
like Claude Code, while analyzing the effectiveness of Deep Research tools
across OpenAI, Google, Anthropic and Perplexity platforms, discussing current
limitations. We demonstrate how prompt engineering can augment rather than
replace existing established individual practices around data processing and
document editing. Our aim is to provide actionable guidance on core prompt
engineering principles, and to facilitate the transition from opportunistic
prompting to an effective, low-friction systematic practice that contributes to
higher quality research.

</details>


### [36] [Ko-PIQA: A Korean Physical Commonsense Reasoning Dataset with Cultural Context](https://arxiv.org/abs/2509.11303)
*Dasol Choi,Jungwhan Kim,Guijin Son*

Main category: cs.CL

TL;DR: Ko-PIQA是一个韩语物理常识推理数据集，包含文化特定元素，填补了英语主导数据集的多样性空白。通过多阶段过滤和人工验证，从301万个问题中筛选出441个高质量问题对，其中19.7%包含韩国文化元素。


<details>
  <summary>Details</summary>
Motivation: 现有的物理常识推理数据集（如PIQA）主要基于英语，缺乏文化多样性。为了促进多语言和跨文化常识推理研究，需要创建包含文化背景的数据集。

Method: 从301万个网络爬取问题开始，采用多阶段过滤方法，使用三个语言模型识别11,553个PIQA风格问题。通过GPT-4o精炼和人工验证，最终获得441个高质量问题-答案对。

Result: 评估了七个语言模型，最佳模型准确率达到83.22%，最差模型仅为59.86%。模型在文化特定场景上表现尤其困难，显示出文化多样性数据集的重要性。

Conclusion: Ko-PIQA不仅为韩语语言模型提供了基准测试，也为更具包容性的常识推理研究奠定了基础。数据集和代码将公开提供，促进跨文化AI研究发展。

Abstract: Physical commonsense reasoning datasets like PIQA are predominantly
English-centric and lack cultural diversity. We introduce Ko-PIQA, a Korean
physical commonsense reasoning dataset that incorporates cultural context.
Starting from 3.01 million web-crawled questions, we employed a multi-stage
filtering approach using three language models to identify 11,553 PIQA-style
questions. Through GPT-4o refinement and human validation, we obtained 441
high-quality question-answer pairs. A key feature of Ko-PIQA is its cultural
grounding: 19.7\% of questions contain culturally specific elements like
traditional Korean foods (kimchi), clothing (hanbok), and specialized
appliances (kimchi refrigerators) that require culturally-aware reasoning
beyond direct translation. We evaluate seven language models on Ko-PIQA, with
the best model achieving 83.22\% accuracy while the weakest reaches only
59.86\%, demonstrating significant room for improvement. Models particularly
struggle with culturally specific scenarios, highlighting the importance of
culturally diverse datasets. Ko-PIQA serves as both a benchmark for Korean
language models and a foundation for more inclusive commonsense reasoning
research. The dataset and code will be publicly available.

</details>


### [37] [!MSA at AraHealthQA 2025 Shared Task: Enhancing LLM Performance for Arabic Clinical Question Answering through Prompt Engineering and Ensemble Learning](https://arxiv.org/abs/2509.11365)
*Mohamed Tarek,Seif Ahmed,Mohamed Basem*

Main category: cs.CL

TL;DR: 本文介绍了在AraHealthQA-2025共享任务Track 2中取得第二名的方法，使用Gemini 2.5 Flash模型通过few-shot提示、数据预处理和集成策略来处理阿拉伯语医疗问答任务。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语临床环境中的健康问答挑战，提升在多项选择和开放式问答任务中的性能表现。

Method: 对于子任务1（多项选择）：使用Gemini 2.5 Flash模型，采用few-shot提示、数据集预处理和三种提示配置的集成方法。对于子任务2（开放式问答）：使用统一提示策略，结合角色扮演（阿拉伯医学专家）、few-shot示例和后处理技术。

Result: 在两个子任务中都获得了第二名：子任务1（多项选择问答）和子任务2（开放式问答）在阿拉伯临床语境中均表现优异。

Conclusion: 提出的基于Gemini 2.5 Flash的方法在阿拉伯语医疗问答任务中表现卓越，few-shot提示和集成策略能有效提升模型在临床语境下的准确性和响应质量。

Abstract: We present our systems for Track 2 (General Arabic Health QA, MedArabiQ) of
the AraHealthQA-2025 shared task, where our methodology secured 2nd place in
both Sub-Task 1 (multiple-choice question answering) and Sub-Task 2 (open-ended
question answering) in Arabic clinical contexts. For Sub-Task 1, we leverage
the Gemini 2.5 Flash model with few-shot prompting, dataset preprocessing, and
an ensemble of three prompt configurations to improve classification accuracy
on standard, biased, and fill-in-the-blank questions. For Sub-Task 2, we employ
a unified prompt with the same model, incorporating role-playing as an Arabic
medical expert, few-shot examples, and post-processing to generate concise
responses across fill-in-the-blank, patient-doctor Q&A, GEC, and paraphrased
variants.

</details>


### [38] [Transformer Enhanced Relation Classification: A Comparative Analysis of Contextuality, Data Efficiency and Sequence Complexity](https://arxiv.org/abs/2509.11374)
*Bowen Jing,Yang Cui,Tianpeng Huang*

Main category: cs.CL

TL;DR: 本文系统比较了基于transformer和非transformer的深度学习模型在关系抽取任务上的性能表现，发现transformer模型显著优于传统模型


<details>
  <summary>Details</summary>
Motivation: 在大语言模型时代，关系抽取作为信息抽取的重要环节，需要系统评估不同架构模型的性能差异，为研究提供指导

Method: 使用PA-LSTM、C-GCN、AGGCN等非transformer架构和BERT、RoBERTa、R-BERT等transformer架构，在TACRED、TACREV、RE-TACRED数据集上进行对比实验，评估不同句子长度、训练数据比例等场景下的性能

Result: transformer模型在micro F1指标上达到80-90%，显著优于非transformer模型的64-67%

Conclusion: transformer架构在关系抽取任务上具有明显优势，同时论文还回顾了监督关系分类的研究历程并讨论了大型语言模型在关系抽取中的作用和现状

Abstract: In the era of large language model, relation extraction (RE) plays an
important role in information extraction through the transformation of
unstructured raw text into structured data (Wadhwa et al., 2023). In this
paper, we systematically compare the performance of deep supervised learning
approaches without transformers and those with transformers. We used a series
of non-transformer architectures such as PA-LSTM(Zhang et al., 2017),
C-GCN(Zhang et al., 2018), and AGGCN(attention guide GCN)(Guo et al., 2019),
and a series of transformer architectures such as BERT, RoBERTa, and R-BERT(Wu
and He, 2019). Our comparison included traditional metrics like micro F1, as
well as evaluations in different scenarios, varying sentence lengths, and
different percentages of the dataset for training. Our experiments were
conducted on TACRED, TACREV, and RE-TACRED. The results show that
transformer-based models outperform non-transformer models, achieving micro F1
scores of 80-90% compared to 64-67% for non-transformer models. Additionally,
we briefly review the research journey in supervised relation classification
and discuss the role and current status of large language models (LLMs) in
relation extraction.

</details>


### [39] [Continually Adding New Languages to Multilingual Language Models](https://arxiv.org/abs/2509.11414)
*Abraham Toluwase Owodunni,Sachin Kumar*

Main category: cs.CL

TL;DR: 提出了Layer-Selective LoRA（LayRA）方法，通过选择性地在初始和最终层添加低秩适配器来解决多语言模型新增语言时的灾难性遗忘问题，无需原始预训练数据。


<details>
  <summary>Details</summary>
Motivation: 多语言模型通常需要从头重新训练来支持新语言，成本高昂且不现实。现有方法如持续预训练会导致灾难性遗忘，而经验回放等方法因缺乏原始预训练数据而无法应用。

Method: 提出Layer-Selective LoRA（LayRA）方法，基于两个关键发现：1）LoRA可以减少遗忘；2）多语言模型在初始层编码源语言，中间层用英语推理，最终层翻译回源语言。LayRA选择性地在初始和最终层添加LoRA适配器，其余层保持冻结。

Result: 在添加加利西亚语、斯瓦希里语和乌尔都语的实验中，LayRA在保持原有语言能力的同时，在新语言学习方面与现有方法（如LoRA）竞争力相当，提供了最佳的整体权衡。通过模型算术，适应后的模型还获得了强大的指令跟随能力，无需目标语言的指令调优数据。

Conclusion: LayRA是一种有效的多语言模型持续学习方法，能够以较低成本添加新语言，同时保持原有性能，为解决多语言模型扩展问题提供了实用解决方案。

Abstract: Multilingual language models are trained on a fixed set of languages, and to
support new languages, the models need to be retrained from scratch. This is an
expensive endeavor and is often infeasible, as model developers tend not to
release their pre-training data. Naive approaches, such as continued
pretraining, suffer from catastrophic forgetting; however, mitigation
strategies like experience replay cannot be applied due to the lack of original
pretraining data. In this work, we investigate the problem of continually
adding new languages to a multilingual model, assuming access to pretraining
data in only the target languages. We explore multiple approaches to address
this problem and propose Layer-Selective LoRA (LayRA), which adds Low-Rank
Adapters (LoRA) to selected initial and final layers while keeping the rest of
the model frozen. LayRA builds on two insights: (1) LoRA reduces forgetting,
and (2) multilingual models encode inputs in the source language in the initial
layers, reason in English in intermediate layers, and translate back to the
source language in final layers. We experiment with adding multiple
combinations of Galician, Swahili, and Urdu to pretrained language models and
evaluate each method on diverse multilingual tasks. We find that LayRA provides
the overall best tradeoff between preserving models' capabilities in previously
supported languages, while being competitive with existing approaches such as
LoRA in learning new languages. We also demonstrate that using model
arithmetic, the adapted models can be equipped with strong instruction
following abilities without access to any instruction tuning data in the target
languages.

</details>


### [40] [A Transformer-Based Cross-Platform Analysis of Public Discourse on the 15-Minute City Paradigm](https://arxiv.org/abs/2509.11443)
*Gaurab Chhetri,Darrell Anderson,Boniphace Kutela,Subasish Das*

Main category: cs.CL

TL;DR: 本研究首次对15分钟城市概念在Twitter、Reddit和新闻媒体上的公众意见进行多平台情感分析，使用压缩Transformer模型和Llama-3-8B进行标注，发现压缩模型性能具有竞争力，挑战了大模型必要的假设。


<details>
  <summary>Details</summary>
Motivation: 研究15分钟城市概念的公众情感态度，开发能够处理多平台异构文本的情感分析框架，探索压缩模型在实际应用中的效果。

Method: 使用压缩Transformer模型（DistilRoBERTa、DistilBERT、MiniLM、ELECTRA、TinyBERT）和Llama-3-8B进行标注，采用分层5折交叉验证，评估F1分数、AUC和训练时间。

Result: DistilRoBERTa获得最高F1分数（0.8292），TinyBERT效率最佳，MiniLM跨平台一致性最好。新闻数据因类别不平衡导致性能虚高，Reddit存在摘要损失，Twitter提供中等挑战。

Conclusion: 压缩模型在情感分类中表现竞争力强，挑战了大模型必要性的假设，识别了平台特定的权衡，为城市规划讨论中的可扩展实时情感分类提供了方向。

Abstract: This study presents the first multi-platform sentiment analysis of public
opinion on the 15-minute city concept across Twitter, Reddit, and news media.
Using compressed transformer models and Llama-3-8B for annotation, we classify
sentiment across heterogeneous text domains. Our pipeline handles long-form and
short-form text, supports consistent annotation, and enables reproducible
evaluation. We benchmark five models (DistilRoBERTa, DistilBERT, MiniLM,
ELECTRA, TinyBERT) using stratified 5-fold cross-validation, reporting
F1-score, AUC, and training time. DistilRoBERTa achieved the highest F1
(0.8292), TinyBERT the best efficiency, and MiniLM the best cross-platform
consistency. Results show News data yields inflated performance due to class
imbalance, Reddit suffers from summarization loss, and Twitter offers moderate
challenge. Compressed models perform competitively, challenging assumptions
that larger models are necessary. We identify platform-specific trade-offs and
propose directions for scalable, real-world sentiment classification in urban
planning discourse.

</details>


### [41] [CognitiveSky: Scalable Sentiment and Narrative Analysis for Decentralized Social Media](https://arxiv.org/abs/2509.11444)
*Gaurab Chhetri,Anandi Dutta,Subasish Das*

Main category: cs.CL

TL;DR: CognitiveSky是一个开源、可扩展的框架，用于在去中心化社交媒体Bluesky上进行情感、情绪和叙事分析，使用基于Transformer的模型处理大规模用户生成内容，并通过动态仪表板可视化分析结果。


<details>
  <summary>Details</summary>
Motivation: 随着去中心化社交媒体平台的出现，需要新的工具来实时分析公共话语。Bluesky作为Twitter/X的联邦替代方案，为计算社会科学提供了新的机会和挑战。

Method: 通过Bluesky API获取数据，应用基于Transformer的模型对大规模用户生成内容进行标注，生成结构化可分析输出，并构建动态仪表板可视化情绪、活动和话题的演变模式。

Result: 构建了一个完全基于免费层基础设施的框架，实现了低运营成本和高可访问性。虽然以心理健康话语监测为例，但其模块化设计可应用于虚假信息检测、危机响应和公民情绪分析等多个领域。

Conclusion: CognitiveSky通过将大语言模型与去中心化网络相结合，为数字生态系统转型时代的计算社会科学提供了一个透明、可扩展的工具。

Abstract: The emergence of decentralized social media platforms presents new
opportunities and challenges for real-time analysis of public discourse. This
study introduces CognitiveSky, an open-source and scalable framework designed
for sentiment, emotion, and narrative analysis on Bluesky, a federated Twitter
or X.com alternative. By ingesting data through Bluesky's Application
Programming Interface (API), CognitiveSky applies transformer-based models to
annotate large-scale user-generated content and produces structured and
analyzable outputs. These summaries drive a dynamic dashboard that visualizes
evolving patterns in emotion, activity, and conversation topics. Built entirely
on free-tier infrastructure, CognitiveSky achieves both low operational cost
and high accessibility. While demonstrated here for monitoring mental health
discourse, its modular design enables applications across domains such as
disinformation detection, crisis response, and civic sentiment analysis. By
bridging large language models with decentralized networks, CognitiveSky offers
a transparent, extensible tool for computational social science in an era of
shifting digital ecosystems.

</details>


### [42] [CEMTM: Contextual Embedding-based Multimodal Topic Modeling](https://arxiv.org/abs/2509.11465)
*Amirhossein Abaskohi,Raymond Li,Chuyuan Li,Shafiq Joty,Giuseppe Carenini*

Main category: cs.CL

TL;DR: CEMTM是一个基于上下文增强的多模态主题模型，能够从包含文本和图像的短/长文档中推断出连贯且可解释的主题结构，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态主题模型在处理多图像文档时需要重复编码，且难以保持跨模态的语义一致性，需要一种能够有效处理多模态内容并保持可解释性的新方法。

Method: 基于微调的大型视觉语言模型获取上下文嵌入，采用分布注意力机制加权token级贡献，通过重构目标将基于主题的表征与文档嵌入对齐，支持多图像处理而无需重复编码。

Result: 在六个多模态基准测试中 consistently 超越单模态和多模态基线，平均LLM得分达到2.61，在下游少样本检索任务中表现优异，能够捕捉复杂领域（如科学文章）中的视觉基础语义。

Conclusion: CEMTM通过上下文增强和分布注意力机制，成功实现了从多模态文档中推断连贯主题结构的能力，在性能和可解释性方面均优于现有方法，为多模态主题建模提供了有效解决方案。

Abstract: We introduce CEMTM, a context-enhanced multimodal topic model designed to
infer coherent and interpretable topic structures from both short and long
documents containing text and images. CEMTM builds on fine-tuned large vision
language models (LVLMs) to obtain contextualized embeddings, and employs a
distributional attention mechanism to weight token-level contributions to topic
inference. A reconstruction objective aligns topic-based representations with
the document embedding, encouraging semantic consistency across modalities.
Unlike existing approaches, CEMTM can process multiple images per document
without repeated encoding and maintains interpretability through explicit
word-topic and document-topic distributions. Extensive experiments on six
multimodal benchmarks show that CEMTM consistently outperforms unimodal and
multimodal baselines, achieving a remarkable average LLM score of 2.61. Further
analysis shows its effectiveness in downstream few-shot retrieval and its
ability to capture visually grounded semantics in complex domains such as
scientific articles.

</details>


### [43] [Improving LLMs' Learning for Coreference Resolution](https://arxiv.org/abs/2509.11466)
*Yujian Gan,Yuan Liang,Yanni Lin,Juntao Yu,Massimo Poesio*

Main category: cs.CL

TL;DR: 本文针对大语言模型在指代消解任务中的幻觉和性能不足问题，提出了两种新技术：反向训练联合推理和迭代文档生成，有效提升了QA模板方法的性能并消除了生成文本中的幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的指代消解方法存在幻觉问题和性能不足，特别是问答模板和文档模板方法存在明显局限性，需要新的技术来解决这些问题。

Method: 提出了两种新技术：1）反向训练联合推理 - 改进问答模板方法；2）迭代文档生成 - 消除生成源文本中的幻觉并提升指代消解性能。

Result: 实验表明反向训练显著提升了问答模板方法的性能，迭代文档生成有效消除了幻觉问题并提高了指代消解准确率。

Conclusion: 通过整合这两种方法，为基于大语言模型的指代消解提供了一个有效且鲁棒的解决方案。

Abstract: Coreference Resolution (CR) is crucial for many NLP tasks, but existing LLMs
struggle with hallucination and under-performance. In this paper, we
investigate the limitations of existing LLM-based approaches to CR-specifically
the Question-Answering (QA) Template and Document Template methods and propose
two novel techniques: Reversed Training with Joint Inference and Iterative
Document Generation. Our experiments show that Reversed Training improves the
QA Template method, while Iterative Document Generation eliminates
hallucinations in the generated source text and boosts coreference resolution.
Integrating these methods and techniques offers an effective and robust
solution to LLM-based coreference resolution.

</details>


### [44] [ClaimIQ at CheckThat! 2025: Comparing Prompted and Fine-Tuned Language Models for Verifying Numerical Claims](https://arxiv.org/abs/2509.11492)
*Anirban Saha Anik,Md Fahimul Kabir Chowdhury,Andrew Wyckoff,Sagnik Ray Choudhury*

Main category: cs.CL

TL;DR: 本文介绍了CLEF 2025 CheckThat! Lab任务3的系统，使用零样本提示和LoRA微调两种方法进行数值和时间声明验证，通过不同证据选择策略提升证据质量，最佳模型在验证集表现良好但测试集泛化能力有待提升。


<details>
  <summary>Details</summary>
Motivation: 解决数值和时间声明的自动验证问题，探索如何利用检索证据和大语言模型来有效验证事实声明，特别关注证据粒度选择对验证性能的影响。

Method: 采用两种互补方法：1）使用指令调优大语言模型的零样本提示方法；2）使用参数高效的LoRA进行监督微调。同时研究多种证据选择策略，包括完整文档输入和使用BM25和MiniLM的top-k句子过滤。

Result: 使用LoRA微调的LLaMA模型在英语验证集上取得了强劲性能，但在测试集上出现显著性能下降，表明存在泛化挑战。证据粒度选择策略对性能有重要影响。

Conclusion: 证据粒度和模型适应性对于构建鲁棒的数字事实验证系统至关重要，需要进一步研究如何提高模型在未见数据上的泛化能力。

Abstract: This paper presents our system for Task 3 of the CLEF 2025 CheckThat! Lab,
which focuses on verifying numerical and temporal claims using retrieved
evidence. We explore two complementary approaches: zero-shot prompting with
instruction-tuned large language models (LLMs) and supervised fine-tuning using
parameter-efficient LoRA. To enhance evidence quality, we investigate several
selection strategies, including full-document input and top-k sentence
filtering using BM25 and MiniLM. Our best-performing model LLaMA fine-tuned
with LoRA achieves strong performance on the English validation set. However, a
notable drop in the test set highlights a generalization challenge. These
findings underscore the importance of evidence granularity and model adaptation
for robust numerical fact verification.

</details>


### [45] [AKCIT-FN at CheckThat! 2025: Switching Fine-Tuned SLMs and LLM Prompting for Multilingual Claim Normalization](https://arxiv.org/abs/2509.11496)
*Fabrycio Leite Nakano Almada,Kauan Divino Pouso Mariano,Maykon Adriell Dutra,Victor Emanuel da Silva Monteiro,Juliana Resplande Sant'Anna Gomes,Arlindo Rodrigues Galvão Filho,Anderson da Silva Soares*

Main category: cs.CL

TL;DR: 本文介绍了在CLEF-2025 CheckThat! Task 2中使用的声明规范化方法，通过微调小型语言模型处理有监督语言，使用大型语言模型提示处理零样本语言，在20种语言中的15种获得前三名成绩


<details>
  <summary>Details</summary>
Motivation: 声明规范化是将非正式社交媒体帖子转化为简洁、自包含陈述的关键步骤，是自动化事实核查流程中的重要环节

Method: 针对有监督语言使用微调的小型语言模型(SLMs)，针对零样本语言使用大型语言模型(LLM)提示技术

Result: 在20种语言中的15种获得前三名，其中8种语言获得第二名（包括5种零样本语言），葡萄牙语获得第三名（METEOR得分0.5290）

Conclusion: LLM基础的零样本策略非常有效，特别是在缺乏训练数据的语言上表现优异，所有实现代码和配置均已开源

Abstract: Claim normalization, the transformation of informal social media posts into
concise, self-contained statements, is a crucial step in automated
fact-checking pipelines. This paper details our submission to the CLEF-2025
CheckThat! Task~2, which challenges systems to perform claim normalization
across twenty languages, divided into thirteen supervised (high-resource) and
seven zero-shot (no training data) tracks.
  Our approach, leveraging fine-tuned Small Language Models (SLMs) for
supervised languages and Large Language Model (LLM) prompting for zero-shot
scenarios, achieved podium positions (top three) in fifteen of the twenty
languages. Notably, this included second-place rankings in eight languages,
five of which were among the seven designated zero-shot languages, underscoring
the effectiveness of our LLM-based zero-shot strategy. For Portuguese, our
initial development language, our system achieved an average METEOR score of
0.5290, ranking third. All implementation artifacts, including inference,
training, evaluation scripts, and prompt configurations, are publicly available
at https://github.com/ju-resplande/checkthat2025_normalization.

</details>


### [46] [DeDisCo at the DISRPT 2025 Shared Task: A System for Discourse Relation Classification](https://arxiv.org/abs/2509.11498)
*Zhuoxuan Ju,Jingni Wu,Abhishek Purushothama,Amir Zeldes*

Main category: cs.CL

TL;DR: DeDisCo系统在DISRPT 2025语篇关系分类任务中测试了mt5编码器和Qwen解码器两种方法，使用自动翻译的数据增强和额外语言学特征，取得了71.28的宏准确率


<details>
  <summary>Details</summary>
Motivation: 参与DISRPT 2025共享任务，探索在语篇关系分类中结合预训练模型和数据增强方法的有效性，特别是针对低资源语言的处理

Method: 使用基于mt5的编码器方法和基于Qwen模型的解码器方法，通过自动翻译英语数据来增强低资源语言的训练集，并加入额外的语言学特征

Result: 系统获得了71.28的宏准确率分数，并对结果进行了详细的解释和错误分析

Conclusion: 该方法在语篇关系分类任务中表现良好，数据增强和语言学特征的加入对提升低资源语言性能有积极作用

Abstract: This paper presents DeDisCo, Georgetown University's entry in the DISRPT 2025
shared task on discourse relation classification. We test two approaches, using
an mt5-based encoder and a decoder based approach using the openly available
Qwen model. We also experiment on training with augmented dataset for
low-resource languages using matched data translated automatically from
English, as well as using some additional linguistic features inspired by
entries in previous editions of the Shared Task. Our system achieves a
macro-accuracy score of 71.28, and we provide some interpretation and error
analysis for our results.

</details>


### [47] [Unsupervised Candidate Ranking for Lexical Substitution via Holistic Sentence Semantics](https://arxiv.org/abs/2509.11513)
*Zhongyang Hu,Naijie Gu,Xiangzhi Tao,Tianhui Gu,Yibing Zhou*

Main category: cs.CL

TL;DR: 论文提出两种基于注意力权重和积分梯度的方法来改进词汇替换任务中的候选词排序，通过建模目标词与上下文的双向影响来更准确地衡量语义变化。


<details>
  <summary>Details</summary>
Motivation: 现有词汇替换方法主要关注目标位置的语义变化或依赖多指标参数调优，难以准确建模候选替换对目标词和上下文双向影响的语义变化。

Method: 提出两种方法：基于注意力权重的方法和基于积分梯度的方法，通过衡量上下文词对目标词的影响，并结合原句与替换句的语义相似性来排序候选词。

Result: 在LS07和SWORDS数据集上的实验表明，两种方法都提升了排序性能。

Conclusion: 基于注意力权重和积分梯度的方法能有效建模词汇替换中的语义变化，提高候选词排序的准确性。

Abstract: A key subtask in lexical substitution is ranking the given candidate words. A
common approach is to replace the target word with a candidate in the original
sentence and feed the modified sentence into a model to capture semantic
differences before and after substitution. However, effectively modeling the
bidirectional influence of candidate substitution on both the target word and
its context remains challenging. Existing methods often focus solely on
semantic changes at the target position or rely on parameter tuning over
multiple evaluation metrics, making it difficult to accurately characterize
semantic variation. To address this, we investigate two approaches: one based
on attention weights and another leveraging the more interpretable integrated
gradients method, both designed to measure the influence of context tokens on
the target token and to rank candidates by incorporating semantic similarity
between the original and substituted sentences. Experiments on the LS07 and
SWORDS datasets demonstrate that both approaches improve ranking performance.

</details>


### [48] [LVLMs are Bad at Overhearing Human Referential Communication](https://arxiv.org/abs/2509.11514)
*Zhengxiang Wang,Weiling Li,Panagiotis Kaliosis,Owen Rambow,Susan E. Brennan*

Main category: cs.CL

TL;DR: 研究评估了7种最先进的大型视觉语言模型作为旁听者理解人类自发对话中协作指代表达的能力，发现当前模型在此任务上仍有挑战，且无法通过多次对话学习改进表现。


<details>
  <summary>Details</summary>
Motivation: 理解人类自发对话中的协作指代表达对于具身智能体在现实世界中执行任务至关重要，需要整合语言、视觉和对话交互的理解能力。

Method: 使用7种state-of-the-art大型视觉语言模型作为旁听者，分析人类在协作对象匹配任务中的自发对话语料库，评估模型理解指代表达的能力。

Result: 所有测试的LVLM在此任务上都表现不佳，未能随着旁听更多相同参与者的重复对话而显示出持续的性能改进。

Conclusion: 当前的大型视觉语言模型在理解人类自发对话中的协作指代表达方面仍有很大挑战，需要进一步研究来提升这方面的能力。

Abstract: During spontaneous conversations, speakers collaborate on novel referring
expressions, which they can then re-use in subsequent conversations.
Understanding such referring expressions is an important ability for an
embodied agent, so that it can carry out tasks in the real world. This requires
integrating and understanding language, vision, and conversational interaction.
We study the capabilities of seven state-of-the-art Large Vision Language
Models (LVLMs) as overhearers to a corpus of spontaneous conversations between
pairs of human discourse participants engaged in a collaborative
object-matching task. We find that such a task remains challenging for current
LVLMs and they all fail to show a consistent performance improvement as they
overhear more conversations from the same discourse participants repeating the
same task for multiple rounds. We release our corpus and code for
reproducibility and to facilitate future research.

</details>


### [49] [PeruMedQA: Benchmarking Large Language Models (LLMs) on Peruvian Medical Exams -- Dataset Construction and Evaluation](https://arxiv.org/abs/2509.11517)
*Rodrigo M. Carrillo-Larco,Jesus Lovón Melgarejo,Manuel Castillo-Cara,Gusseppe Bravo-Rocca*

Main category: cs.CL

TL;DR: 该研究构建了秘鲁医学考试数据集PeruMedQA，评估了多个医学大语言模型在西班牙语医学问题上的表现，发现medgemma-27b-text-it表现最佳，微调后的medgemma-4b-it也能媲美更大参数量的模型。


<details>
  <summary>Details</summary>
Motivation: 探索医学大语言模型在西班牙语和拉丁美洲国家医学问题上的表现，因为现有研究主要关注英语环境，而拉丁美洲地区正在广泛应用基于LLM的医疗应用。

Method: 构建包含8,380个问题的秘鲁医学考试数据集PeruMedQA，选择8个医学LLM进行零样本测试，使用PEFT和LoRA技术对medgemma-4b-it进行微调。

Result: medgemma-27b-text-it在多个考试中正确率超过90%，参数小于100亿的模型正确率低于60%，微调后的medgemma-4b-it表现优于所有小于100亿参数的模型，并能与700亿参数模型相媲美。

Conclusion: 对于需要西班牙语国家和类似秘鲁流行病学特征知识库的医学AI应用，推荐使用medgemma-27b-text-it或微调版的medgemma-4b-it。

Abstract: BACKGROUND: Medical large language models (LLMS) have demonstrated remarkable
performance in answering medical examinations. However, the extent to which
this high performance is transferable to medical questions in Spanish and from
a Latin American country remains unexplored. This knowledge is crucial as
LLM-based medical applications gain traction in Latin America. AIMS: to build a
dataset of questions from medical examinations taken by Peruvian physicians
pursuing specialty training; to fine-tune a LLM on this dataset; to evaluate
and compare the performance in terms of accuracy between vanilla LLMs and the
fine-tuned LLM. METHODS: We curated PeruMedQA, a multiple-choice
question-answering (MCQA) datasets containing 8,380 questions spanning 12
medical domains (2018-2025). We selected eight medical LLMs including
medgemma-4b-it and medgemma-27b-text-it, and developed zero-shot task-specific
prompts to answer the questions appropriately. We employed parameter-efficient
fine tuning (PEFT)and low-rant adaptation (LoRA) to fine-tune medgemma-4b-it
utilizing all questions except those from 2025 (test set). RESULTS:
medgemma-27b-text-it outperformed all other models, achieving a proportion of
correct answers exceeding 90% in several instances. LLMs with <10 billion
parameters exhibited <60% of correct answers, while some exams yielded results
<50%. The fine-tuned version of medgemma-4b-it emerged victorious agains all
LLMs with <10 billion parameters and rivaled a LLM with 70 billion parameters
across various examinations. CONCLUSIONS: For medical AI application and
research that require knowledge bases from Spanish-speaking countries and those
exhibiting similar epidemiological profiles to Peru's, interested parties
should utilize medgemma-27b-text-it or a fine-tuned version of medgemma-4b-it.

</details>


### [50] [On the Distinctive Co-occurrence Characteristics of Antonymy](https://arxiv.org/abs/2509.11534)
*Zhihan Cao,Hiroaki Yamada,Takenobu Tokunaga*

Main category: cs.CL

TL;DR: 本研究通过比较反义词与其他语义关系的共现模式，发现反义词在共现强度、线性顺序偏好和短距离共现三个方面具有独特性


<details>
  <summary>Details</summary>
Motivation: 反义词在文本中频繁共现已被证实，但缺乏与其他语义关系的比较，无法确定这种共现模式是否为反义词所特有

Method: 使用稳健的共现度量方法，比较反义词与另外三种语义关系在不同词性间的共现模式

Result: 反义词在三个维度上表现出独特性：高强度的共现、偏好的线性顺序以及短距离内的共现

Conclusion: 反义词的共现模式确实具有独特性，这为反义词识别和语义关系研究提供了重要依据

Abstract: Antonymy has long received particular attention in lexical semantics.
Previous studies have shown that antonym pairs frequently co-occur in text,
across genres and parts of speech, more often than would be expected by chance.
However, whether this co-occurrence pattern is distinctive of antonymy remains
unclear, due to a lack of comparison with other semantic relations. This work
fills the gap by comparing antonymy with three other relations across parts of
speech using robust co-occurrence metrics. We find that antonymy is distinctive
in three respects: antonym pairs co-occur with high strength, in a preferred
linear order, and within short spans. All results are available online.

</details>


### [51] [HARP: Hallucination Detection via Reasoning Subspace Projection](https://arxiv.org/abs/2509.11536)
*Junjie Hu,Gang Tu,ShengYu Cheng,Jinxin Li,Jinting Wang,Rui Chen,Zhilong Zhou,Dongbo Shan*

Main category: cs.CL

TL;DR: HARP是一个新的幻觉检测框架，通过将LLM隐藏状态空间分解为语义子空间和推理子空间，利用SVD获得基向量，并将隐藏状态投影到推理子空间来检测幻觉，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法在分离语义和推理信息以及保持鲁棒性方面存在困难，需要更有效的检测框架。

Method: 提出HARP框架：1）证明LLM隐藏状态空间可分解为语义子空间和推理子空间；2）通过SVD分解Unembedding层参数获得基向量；3）将隐藏状态投影到推理子空间作为检测特征

Result: 在多个数据集上达到最先进性能，TriviaQA上AUROC达到92.8%，比之前最佳方法提升7.5%，特征维度降至原始的5%并有效过滤噪声

Conclusion: HARP通过子空间分解和投影方法有效解决了幻觉检测中的语义-推理分离和鲁棒性问题，为LLM可靠应用提供了重要技术支撑

Abstract: Hallucinations in Large Language Models (LLMs) pose a major barrier to their
reliable use in critical decision-making. Although existing hallucination
detection methods have improved accuracy, they still struggle with
disentangling semantic and reasoning information and maintaining robustness. To
address these challenges, we propose HARP (Hallucination detection via
reasoning subspace projection), a novel hallucination detection framework. HARP
establishes that the hidden state space of LLMs can be decomposed into a direct
sum of a semantic subspace and a reasoning subspace, where the former encodes
linguistic expression and the latter captures internal reasoning processes.
Moreover, we demonstrate that the Unembedding layer can disentangle these
subspaces, and by applying Singular Value Decomposition (SVD) to its
parameters, the basis vectors spanning the semantic and reasoning subspaces are
obtained. Finally, HARP projects hidden states onto the basis vectors of the
reasoning subspace, and the resulting projections are then used as input
features for hallucination detection in LLMs. By using these projections, HARP
reduces the dimension of the feature to approximately 5% of the original,
filters out most noise, and achieves enhanced robustness. Experiments across
multiple datasets show that HARP achieves state-of-the-art hallucination
detection performance; in particular, it achieves an AUROC of 92.8% on
TriviaQA, outperforming the previous best method by 7.5%.

</details>


### [52] [HiChunk: Evaluating and Enhancing Retrieval-Augmented Generation with Hierarchical Chunking](https://arxiv.org/abs/2509.11552)
*Wensheng Lu,Keyu Chen,Ruizhi Qiao,Xing Sun*

Main category: cs.CL

TL;DR: 提出了HiCBench评估基准和HiChunk框架，用于解决RAG系统中文档分块质量评估不足的问题，通过多级分块标注和证据密集QA对来提升评估效果。


<details>
  <summary>Details</summary>
Motivation: 现有RAG评估基准在评估文档分块质量方面存在不足，特别是证据稀疏性问题，需要更有效的评估工具。

Method: 提出HiCBench评估基准（包含手动标注的多级文档分块点、合成的证据密集QA对及其证据源）和HiChunk框架（基于微调LLM的多级文档结构化框架，结合Auto-Merge检索算法）。

Result: 实验表明HiCBench能有效评估不同分块方法在整个RAG流程中的影响，HiChunk在合理时间消耗内获得更好的分块质量，提升RAG系统整体性能。

Conclusion: HiCBench和HiChunk框架为RAG系统的文档分块质量评估和优化提供了有效解决方案，显著提升了检索增强生成系统的性能。

Abstract: Retrieval-Augmented Generation (RAG) enhances the response capabilities of
language models by integrating external knowledge sources. However, document
chunking as an important part of RAG system often lacks effective evaluation
tools. This paper first analyzes why existing RAG evaluation benchmarks are
inadequate for assessing document chunking quality, specifically due to
evidence sparsity. Based on this conclusion, we propose HiCBench, which
includes manually annotated multi-level document chunking points, synthesized
evidence-dense quetion answer(QA) pairs, and their corresponding evidence
sources. Additionally, we introduce the HiChunk framework, a multi-level
document structuring framework based on fine-tuned LLMs, combined with the
Auto-Merge retrieval algorithm to improve retrieval quality. Experiments
demonstrate that HiCBench effectively evaluates the impact of different
chunking methods across the entire RAG pipeline. Moreover, HiChunk achieves
better chunking quality within reasonable time consumption, thereby enhancing
the overall performance of RAG systems.

</details>


### [53] [D$^2$HScore: Reasoning-Aware Hallucination Detection via Semantic Breadth and Depth Analysis in LLMs](https://arxiv.org/abs/2509.11569)
*Yue Ding,Xiaofang Zhu,Tianze Xia,Junfei Wu,Xinlong Chen,Qiang Liu,Liang Wang*

Main category: cs.CL

TL;DR: 提出了D²HScore框架，通过分析LLM内部表示层的分散度和跨层漂移来检测幻觉，无需训练和标签，在多个基准测试中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成非事实内容（幻觉）的问题，特别是在金融、安全和医疗等高风险领域，需要可靠的方法来确保输出真实性

Method: 基于LLM的多层结构和自回归解码过程，提出D²HScore框架：1）层内分散度 - 量化每层token表示的语义多样性；2）跨层漂移 - 跟踪关键token表示在层间的渐进变换，使用注意力信号指导token选择

Result: 在5个开源LLM和5个广泛使用的基准测试上进行大量实验，D²HScore始终优于现有的无需训练基线方法

Conclusion: D²HScore通过捕捉推理过程中表示的水平和垂直动态，为幻觉检测提供了可解释且轻量级的解决方案，在多个模型和基准上表现出色

Abstract: Although large Language Models (LLMs) have achieved remarkable success, their
practical application is often hindered by the generation of non-factual
content, which is called "hallucination". Ensuring the reliability of LLMs'
outputs is a critical challenge, particularly in high-stakes domains such as
finance, security, and healthcare. In this work, we revisit hallucination
detection from the perspective of model architecture and generation dynamics.
Leveraging the multi-layer structure and autoregressive decoding process of
LLMs, we decompose hallucination signals into two complementary dimensions: the
semantic breadth of token representations within each layer, and the semantic
depth of core concepts as they evolve across layers. Based on this insight, we
propose \textbf{D$^2$HScore (Dispersion and Drift-based Hallucination Score)},
a training-free and label-free framework that jointly measures: (1)
\textbf{Intra-Layer Dispersion}, which quantifies the semantic diversity of
token representations within each layer; and (2) \textbf{Inter-Layer Drift},
which tracks the progressive transformation of key token representations across
layers. To ensure drift reflects the evolution of meaningful semantics rather
than noisy or redundant tokens, we guide token selection using attention
signals. By capturing both the horizontal and vertical dynamics of
representation during inference, D$^2$HScore provides an interpretable and
lightweight proxy for hallucination detection. Extensive experiments across
five open-source LLMs and five widely used benchmarks demonstrate that
D$^2$HScore consistently outperforms existing training-free baselines.

</details>


### [54] [Bhaasha, Bhasa, Zaban: A Survey for Low-Resourced Languages in South Asia -- Current Stage and Challenges](https://arxiv.org/abs/2509.11570)
*Sampoorna Poria,Xiaolei Huang*

Main category: cs.CL

TL;DR: 这篇论文调查了南亚语言NLP模型的现状和挑战，重点关注数据、模型和任务三个核心方面，揭示了数据缺失、代码混合和缺乏标准化评估基准等关键问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在英语数据上取得了革命性进展，但南亚等低资源语言被忽视。南亚有650多种语言，许多语言计算资源有限或完全缺失，需要评估当前状况以促进模型发展。

Method: 全面检索2020年以来的研究，重点关注基于Transformer的模型（如BERT、T5、GPT），从数据、模型和任务三个维度分析南亚语言NLP的进展和差距。

Result: 发现存在严重问题：关键领域（如医疗）数据缺失、代码混合现象普遍、缺乏针对南亚文化和语言特点的标准化评估基准。

Conclusion: 呼吁NLP社区提高对南亚语言的关注，进行更有针对性的数据整理，建立适合南亚语言文化特点的统一基准，促进南亚语言的公平代表性。

Abstract: Rapid developments of large language models have revolutionized many NLP
tasks for English data. Unfortunately, the models and their evaluations for
low-resource languages are being overlooked, especially for languages in South
Asia. Although there are more than 650 languages in South Asia, many of them
either have very limited computational resources or are missing from existing
language models. Thus, a concrete question to be answered is: Can we assess the
current stage and challenges to inform our NLP community and facilitate model
developments for South Asian languages? In this survey, we have comprehensively
examined current efforts and challenges of NLP models for South Asian languages
by retrieving studies since 2020, with a focus on transformer-based models,
such as BERT, T5, & GPT. We present advances and gaps across 3 essential
aspects: data, models, & tasks, such as available data sources, fine-tuning
strategies, & domain applications. Our findings highlight substantial issues,
including missing data in critical domains (e.g., health), code-mixing, and
lack of standardized evaluation benchmarks. Our survey aims to raise awareness
within the NLP community for more targeted data curation, unify benchmarks
tailored to cultural and linguistic nuances of South Asia, and encourage an
equitable representation of South Asian languages. The complete list of
resources is available at: https://github.com/trust-nlp/LM4SouthAsia-Survey.

</details>


### [55] [Analyzing Information-Seeking Behaviors in a Hakka AI Chatbot: A Cognitive-Pragmatic Study](https://arxiv.org/abs/2509.11591)
*Chu-Hsuan Lee,Chen-Chi Chang,Hung-Shin Lee,Yun-Hsiang Hsu,Ching-Yuan Chen*

Main category: cs.CL

TL;DR: 本研究通过分析Hakka语言AI聊天机器人TALKA中7077条用户对话，结合布鲁姆认知分类和对话行为分类框架，发现生成式AI能有效支持低资源语言学习，促进认知发展和文化认同。


<details>
  <summary>Details</summary>
Motivation: 随着濒危语言面临消失风险，需要结合技术和文化教学策略进行保护。研究旨在探索生成式AI聊天机器人如何支持语言学习和文化传承。

Method: 采用双层次分析框架：布鲁姆认知分类（6个认知层级）和对话行为分类（11种对话类型），对7077条用户话语进行精细标注和分析。

Result: 生成式AI聊天机器人能有效支持语言学习，帮助学习者更自信地表达并与文化身份建立联系，特别是在低资源语言环境中促进认知发展和语用协商。

Conclusion: AI辅助语言学习为语言保护和教育实践提供了新见解，设计时需要理解用户的思维和沟通方式，技术可以成为语言保存的有力工具。

Abstract: With many endangered languages at risk of disappearing, efforts to preserve
them now rely more than ever on using technology alongside culturally informed
teaching strategies. This study examines user behaviors in TALKA, a generative
AI-powered chatbot designed for Hakka language engagement, by employing a
dual-layered analytical framework grounded in Bloom's Taxonomy of cognitive
processes and dialogue act categorization. We analyzed 7,077 user utterances,
each carefully annotated according to six cognitive levels and eleven dialogue
act types. These included a variety of functions, such as asking for
information, requesting translations, making cultural inquiries, and using
language creatively. Pragmatic classifications further highlight how different
types of dialogue acts--such as feedback, control commands, and social
greetings--align with specific cognitive intentions. The results suggest that
generative AI chatbots can support language learning in meaningful
ways--especially when they are designed with an understanding of how users
think and communicate. They may also help learners express themselves more
confidently and connect with their cultural identity. The TALKA case provides
empirical insights into how AI-mediated dialogue facilitates cognitive
development in low-resource language learners, as well as pragmatic negotiation
and socio-cultural affiliation. By focusing on AI-assisted language learning,
this study offers new insights into how technology can support language
preservation and educational practice.

</details>


### [56] [Dynamic Span Interaction and Graph-Aware Memory for Entity-Level Sentiment Classification](https://arxiv.org/abs/2509.11604)
*Md. Mithun Hossain,Sanjara,Md. Shakil Hossain,Sudipto Chaki*

Main category: cs.CL

TL;DR: SpanEIT是一个新颖的实体级情感分类框架，通过动态跨度交互和图感知记忆机制增强实体-情感关系建模，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 实体级情感分类面临多个挑战：需要建模实体与情感表达的复杂交互、处理跨句依赖关系、确保同一实体多次提及的情感一致性，以及处理否定、歧义等语言现象。

Method: 提出SpanEIT框架，构建基于跨度的实体和情感短语表示，使用双向注意力进行细粒度交互，采用图注意力网络捕获句法和共现关系，并通过共指感知记忆模块确保文档级一致性。

Result: 在FSAD、BARU和IMDB数据集上的实验表明，SpanEIT在准确率和F1分数上均优于最先进的transformer和混合基线方法。消融实验和可解释性分析验证了方法的有效性。

Conclusion: SpanEIT框架在细粒度情感分析方面具有显著优势，特别适用于社交媒体监控和客户反馈分析等实际应用场景。

Abstract: Entity-level sentiment classification involves identifying the sentiment
polarity linked to specific entities within text. This task poses several
challenges: effectively modeling the subtle and complex interactions between
entities and their surrounding sentiment expressions; capturing dependencies
that may span across sentences; and ensuring consistent sentiment predictions
for multiple mentions of the same entity through coreference resolution.
Additionally, linguistic phenomena such as negation, ambiguity, and overlapping
opinions further complicate the analysis. These complexities make entity-level
sentiment classification a difficult problem, especially in real-world, noisy
textual data. To address these issues, we propose SpanEIT, a novel framework
integrating dynamic span interaction and graph-aware memory mechanisms for
enhanced entity-sentiment relational modeling. SpanEIT builds span-based
representations for entities and candidate sentiment phrases, employs
bidirectional attention for fine-grained interactions, and uses a graph
attention network to capture syntactic and co-occurrence relations. A
coreference-aware memory module ensures entity-level consistency across
documents. Experiments on FSAD, BARU, and IMDB datasets show SpanEIT
outperforms state-of-the-art transformer and hybrid baselines in accuracy and
F1 scores. Ablation and interpretability analyses validate the effectiveness of
our approach, underscoring its potential for fine-grained sentiment analysis in
applications like social media monitoring and customer feedback analysis.

</details>


### [57] [HalluDetect: Detecting, Mitigating, and Benchmarking Hallucinations in Conversational Systems](https://arxiv.org/abs/2509.11619)
*Spandan Anaokar,Shrey Ganatra,Harshvivek Kashid,Swapnil Bhattacharyya,Shruti Nair,Reshma Sekhar,Siddharth Manohar,Rahul Hemrajani,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 开发了基于LLM的幻觉检测系统HalluDetect，在消费者投诉聊天机器人中显著减少幻觉，F1分数达69%，比基线提升25.44%。AgentBot架构将每轮幻觉降至0.4159个，同时保持96.13%的最高token准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在工业应用中广泛使用但仍容易产生幻觉，限制了其在关键应用中的可靠性，特别是在消费者投诉处理等高风险领域需要提高事实准确性。

Method: 基于LLaMA 3.1 8B Instruct模型开发HalluDetect幻觉检测系统，对五种聊天机器人架构进行基准测试，重点评估AgentBot架构的幻觉缓解效果。

Result: HalluDetect系统F1分数达到69%，比基线检测器提升25.44%。AgentBot架构表现最佳，每轮幻觉降至0.4159个，token准确率达96.13%。

Conclusion: 研究提供了一个可扩展的幻觉缓解框架，证明优化的推理策略能显著提高事实准确性，该方法不仅适用于消费者法律领域，还可推广到其他高风险领域，增强对LLM驱动助手的信任。

Abstract: Large Language Models (LLMs) are widely used in industry but remain prone to
hallucinations, limiting their reliability in critical applications. This work
addresses hallucination reduction in consumer grievance chatbots built using
LLaMA 3.1 8B Instruct, a compact model frequently used in industry. We develop
HalluDetect, an LLM-based hallucination detection system that achieves an F1
score of 69% outperforming baseline detectors by 25.44%. Benchmarking five
chatbot architectures, we find that out of them, AgentBot minimizes
hallucinations to 0.4159 per turn while maintaining the highest token accuracy
(96.13%), making it the most effective mitigation strategy. Our findings
provide a scalable framework for hallucination mitigation, demonstrating that
optimized inference strategies can significantly improve factual accuracy.
While applied to consumer law, our approach generalizes to other high-risk
domains, enhancing trust in LLM-driven assistants. We will release the code and
dataset

</details>


### [58] [AesBiasBench: Evaluating Bias and Alignment in Multimodal Language Models for Personalized Image Aesthetic Assessment](https://arxiv.org/abs/2509.11620)
*Kun Li,Lai-Man Po,Hongzheng Yang,Xuyuan Xu,Kangcheng Liu,Yuzhi Zhao*

Main category: cs.CL

TL;DR: 提出了AesBiasBench基准，用于评估多模态大语言模型在个性化图像美学评估中的刻板印象偏见和人类偏好对齐程度，测试了19个模型发现小模型偏见更强，大模型更符合人类偏好。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在个性化图像美学评估中存在受人口统计因素（性别、年龄、教育等）影响的微妙偏见，需要系统评估这些偏见和对齐程度。

Method: 构建AesBiasBench基准，包含三个子任务（美学感知、评估、共情），引入结构化指标（IFD、NRD、AAS）来评估偏见和对齐，测试了19个MLLM模型。

Result: 小模型表现出更强的刻板印象偏见，大模型与人类偏好更一致；加入身份信息通常会加剧偏见，特别是在情感判断方面。

Conclusion: 研究强调了在主观视觉语言任务中身份感知评估框架的重要性，需要关注模型偏见和对齐问题。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly applied in
Personalized Image Aesthetic Assessment (PIAA) as a scalable alternative to
expert evaluations. However, their predictions may reflect subtle biases
influenced by demographic factors such as gender, age, and education. In this
work, we propose AesBiasBench, a benchmark designed to evaluate MLLMs along two
complementary dimensions: (1) stereotype bias, quantified by measuring
variations in aesthetic evaluations across demographic groups; and (2)
alignment between model outputs and genuine human aesthetic preferences. Our
benchmark covers three subtasks (Aesthetic Perception, Assessment, Empathy) and
introduces structured metrics (IFD, NRD, AAS) to assess both bias and
alignment. We evaluate 19 MLLMs, including proprietary models (e.g., GPT-4o,
Claude-3.5-Sonnet) and open-source models (e.g., InternVL-2.5, Qwen2.5-VL).
Results indicate that smaller models exhibit stronger stereotype biases,
whereas larger models align more closely with human preferences. Incorporating
identity information often exacerbates bias, particularly in emotional
judgments. These findings underscore the importance of identity-aware
evaluation frameworks in subjective vision-language tasks.

</details>


### [59] [EthicsMH: A Pilot Benchmark for Ethical Reasoning in Mental Health AI](https://arxiv.org/abs/2509.11648)
*Sai Kartheek Reddy Kasu*

Main category: cs.CL

TL;DR: 提出了EthicsMH数据集，包含125个心理健康领域的伦理困境场景，用于评估AI系统在治疗和精神病学背景下的伦理推理能力


<details>
  <summary>Details</summary>
Motivation: 现有道德和临床决策基准无法充分捕捉心理健康实践中独特的伦理困境，如保密性、自主性、仁慈和偏见等问题的交集

Method: 开发了包含125个场景的数据集，每个场景都有结构化字段：多种决策选项、专家对齐的推理、预期模型行为、现实世界影响和多利益相关者观点

Result: 建立了连接AI伦理和心理健康决策的任务框架，能够评估决策准确性、解释质量和专业规范对齐性

Conclusion: EthicsMH作为种子资源发布，旨在通过社区和专家贡献进行扩展，促进开发能够负责任处理社会最微妙决策的AI系统

Abstract: The deployment of large language models (LLMs) in mental health and other
sensitive domains raises urgent questions about ethical reasoning, fairness,
and responsible alignment. Yet, existing benchmarks for moral and clinical
decision-making do not adequately capture the unique ethical dilemmas
encountered in mental health practice, where confidentiality, autonomy,
beneficence, and bias frequently intersect. To address this gap, we introduce
Ethical Reasoning in Mental Health (EthicsMH), a pilot dataset of 125 scenarios
designed to evaluate how AI systems navigate ethically charged situations in
therapeutic and psychiatric contexts. Each scenario is enriched with structured
fields, including multiple decision options, expert-aligned reasoning, expected
model behavior, real-world impact, and multi-stakeholder viewpoints. This
structure enables evaluation not only of decision accuracy but also of
explanation quality and alignment with professional norms. Although modest in
scale and developed with model-assisted generation, EthicsMH establishes a task
framework that bridges AI ethics and mental health decision-making. By
releasing this dataset, we aim to provide a seed resource that can be expanded
through community and expert contributions, fostering the development of AI
systems capable of responsibly handling some of society's most delicate
decisions.

</details>


### [60] [A Dynamic Knowledge Update-Driven Model with Large Language Models for Fake News Detection](https://arxiv.org/abs/2509.11687)
*Di Jin,Jun Yang,Xiaobao Wang,Junwei Zhang,Shuqi Li,Dongxiao He*

Main category: cs.CL

TL;DR: DYNAMO模型通过知识图谱动态更新和大型语言模型集成，解决假新闻检测中的知识真实性和语义深度挖掘问题，在真实数据集上表现最佳


<details>
  <summary>Details</summary>
Motivation: 互联网和社交媒体快速发展，海量复杂信息中区分可信新闻面临挑战。新闻事件的突发性和不稳定性导致真实性标签可能变化，需要获取最新事件更新。现有检索增强生成方法存在检索内容可信度不足和噪声信息干扰问题

Method: 构建新闻领域特定知识图谱，使用蒙特卡洛树搜索分解复杂新闻并逐步验证，从已验证的真实新闻文本和推理路径中提取更新新知识

Result: 在两个真实世界数据集上实现了最佳性能

Conclusion: DYNAMO模型通过动态知识更新机制有效解决了假新闻检测中的关键问题，确保了新知识的真实性和新闻语义的深度挖掘

Abstract: As the Internet and social media evolve rapidly, distinguishing credible news
from a vast amount of complex information poses a significant challenge. Due to
the suddenness and instability of news events, the authenticity labels of news
can potentially shift as events develop, making it crucial for fake news
detection to obtain the latest event updates. Existing methods employ
retrieval-augmented generation to fill knowledge gaps, but they suffer from
issues such as insufficient credibility of retrieved content and interference
from noisy information. We propose a dynamic knowledge update-driven model for
fake news detection (DYNAMO), which leverages knowledge graphs to achieve
continuous updating of new knowledge and integrates with large language models
to fulfill dual functions: news authenticity detection and verification of new
knowledge correctness, solving the two key problems of ensuring the
authenticity of new knowledge and deeply mining news semantics. Specifically,
we first construct a news-domain-specific knowledge graph. Then, we use Monte
Carlo Tree Search to decompose complex news and verify them step by step.
Finally, we extract and update new knowledge from verified real news texts and
reasoning paths. Experimental results demonstrate that DYNAMO achieves the best
performance on two real-world datasets.

</details>


### [61] [CoachMe: Decoding Sport Elements with a Reference-Based Coaching Instruction Generation Model](https://arxiv.org/abs/2509.11698)
*Wei-Hsin Yeh,Yu-An Su,Chih-Ning Chen,Yi-Hsueh Lin,Calvin Ku,Wen-Hsin Chiu,Min-Chun Hu,Lun-Wei Ku*

Main category: cs.CL

TL;DR: CoachMe是一个基于参考的运动指导模型，通过分析学习者动作与参考动作在时间和物理方面的差异，提供高质量的运动纠正指导，在花样滑冰和拳击等特定运动项目中表现优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 运动指导对于运动员技术精进至关重要，但现有多模态模型在生成精确、运动专项的指导方面仍面临挑战，主要由于运动的高度领域特定性和需要提供信息性指导的需求。

Method: 提出CoachMe模型，采用基于参考的方法分析学习者动作与参考动作在时间和物理维度上的差异，实现领域知识学习和教练式思维过程的获取，能够有效识别运动错误并提供改进反馈。

Result: 实验显示CoachMe在花样滑冰的G-Eval评估中比GPT-4o高出31.6%，在拳击项目中高出58.3%，能够生成包含错误分析和具体改进方法的高质量指导。

Conclusion: CoachMe通过从通用运动学习并利用有限数据，能够很好地适应特定运动项目，提供具有关键信息的专业运动指导，而不是仅仅模仿教练语气但缺乏实质内容的方向性建议。

Abstract: Motion instruction is a crucial task that helps athletes refine their
technique by analyzing movements and providing corrective guidance. Although
recent advances in multimodal models have improved motion understanding,
generating precise and sport-specific instruction remains challenging due to
the highly domain-specific nature of sports and the need for informative
guidance. We propose CoachMe, a reference-based model that analyzes the
differences between a learner's motion and a reference under temporal and
physical aspects. This approach enables both domain-knowledge learning and the
acquisition of a coach-like thinking process that identifies movement errors
effectively and provides feedback to explain how to improve. In this paper, we
illustrate how CoachMe adapts well to specific sports such as skating and
boxing by learning from general movements and then leveraging limited data.
Experiments show that CoachMe provides high-quality instructions instead of
directions merely in the tone of a coach but without critical information.
CoachMe outperforms GPT-4o by 31.6% in G-Eval on figure skating and by 58.3% on
boxing. Analysis further confirms that it elaborates on errors and their
corresponding improvement methods in the generated instructions. You can find
CoachMe here: https://motionxperts.github.io/

</details>


### [62] [Room acoustics affect communicative success in hybrid meeting spaces: a pilot study](https://arxiv.org/abs/2509.11709)
*Robert Einig,Stefan Janscha,Jonas Schuster,Julian Koch,Martin Hagmueller,Barbara Schuppler*

Main category: cs.CL

TL;DR: 本研究探讨了在混合会议中改善房间声学条件对沟通效果的影响，通过在格拉茨技术大学研讨室进行声学干预前后的对比实验，发现声学改善有助于提升混合会议的沟通成功率。


<details>
  <summary>Details</summary>
Motivation: COVID-19疫情后混合会议日益普及，但研讨室的声学设计常被忽视。不良声学条件（特别是过度混响）会导致误解、语音清晰度下降以及认知和声音疲劳等问题。

Method: 在格拉茨技术大学的一个研讨室进行声学干预前后对比研究。记录两组人员在声学改善前后的表现，分析沟通效果的变化。

Result: 尽管由于样本量较小未达到统计显著性，但研究结果明确显示空间声学干预改善了混合会议中的沟通成功率。

Conclusion: 房间声学设计对混合会议的成功至关重要，声学干预能够有效提升沟通效果，这一发现对学术机构和企业的会议空间设计具有重要指导意义。

Abstract: Since the COVID-19 pandemic in 2020, universities and companies have
increasingly integrated hybrid features into their meeting spaces, or even
created dedicated rooms for this purpose. While the importance of a fast and
stable internet connection is often prioritized, the acoustic design of seminar
rooms is frequently overlooked. Poor acoustics, particularly excessive
reverberation, can lead to issues such as misunderstandings, reduced speech
intelligibility or cognitive and vocal fatigue. This pilot study investigates
whether room acoustic interventions in a seminar room at Graz University of
Technology support better communication in hybrid meetings. For this purpose,
we recorded two groups of persons twice, once before and once after improving
the acoustics of the room. Our findings -- despite not reaching statistical
significance due to the small sample size - indicate clearly that our spatial
interventions improve communicative success in hybrid meetings. To make the
paper accessible also for readers from the speech communication community, we
explain room acoustics background, relevant for the interpretation of our
results.

</details>


### [63] [An Agentic Toolkit for Adaptive Information Extraction from Regulatory Documents](https://arxiv.org/abs/2509.11773)
*Gaye Colakoglu,Gürkan Solmaz,Jonathan Fürst*

Main category: cs.CL

TL;DR: 本文提出了一个针对欧盟建筑产品性能声明(DoP)文档的领域特定智能体系统，通过规划器-执行器-响应器架构解决文档格式多样性带来的自动化信息抽取挑战


<details>
  <summary>Details</summary>
Motivation: 欧盟法规要求的性能声明文档在布局、语言、模式和格式上差异很大，现有的静态或纯LLM信息抽取管道经常产生幻觉且无法适应这种结构多样性

Method: 采用领域特定的状态智能体系统，通过规划器-执行器-响应器架构，推断用户意图、检测文档模态，并动态编排工具进行稳健、可追溯的推理

Result: 在精心策划的DoP数据集上的评估显示，该系统在多种格式和语言下都表现出改进的鲁棒性

Conclusion: 该系统为受监管工作流程中的结构化数据提取提供了一个可扩展的解决方案，能够避免工具误用和执行循环

Abstract: Declaration of Performance (DoP) documents, mandated by EU regulation,
certify the performance of construction products. While some of their content
is standardized, DoPs vary widely in layout, language, schema, and format,
posing challenges for automated key-value pair extraction (KVP) and question
answering (QA). Existing static or LLM-only IE pipelines often hallucinate and
fail to adapt to this structural diversity. Our domain-specific, stateful
agentic system addresses these challenges through a planner-executor-responder
architecture. The system infers user intent, detects document modality, and
orchestrates tools dynamically for robust, traceable reasoning while avoiding
tool misuse or execution loops. Evaluation on a curated DoP dataset
demonstrates improved robustness across formats and languages, offering a
scalable solution for structured data extraction in regulated workflows.

</details>


### [64] [User eXperience Perception Insights Dataset (UXPID): Synthetic User Feedback from Public Industrial Forums](https://arxiv.org/abs/2509.11777)
*Mikhail Kulyabin,Jan Joosten,Choro Ulan uulu,Nuno Miguel Martins Pacheco,Fabian Ries,Filippos Petridis,Jan Bosch,Helena Holmström Olsson*

Main category: cs.CL

TL;DR: 本文提出了UXPID数据集，包含7130条合成的工业自动化论坛用户反馈，用于促进用户体验分析和AI反馈处理研究


<details>
  <summary>Details</summary>
Motivation: 工业论坛中的客户反馈是宝贵但未被充分挖掘的信息源，传统分析方法难以处理这种非结构化和领域特定的内容

Method: 使用大型语言模型对从公开工业自动化论坛提取的7130条合成匿名用户反馈分支进行系统分析和标注

Result: 创建了包含多帖子评论、元数据和上下文对话数据的JSON格式数据集，支持用户体验洞察、用户期望、严重性评分和主题分类

Conclusion: UXPID数据集为技术论坛中的问题检测、情感分析和需求提取等任务提供了训练和评估基础，特别适用于隐私和许可限制下的研究

Abstract: Customer feedback in industrial forums reflect a rich but underexplored
source of insight into real-world product experience. These publicly shared
discussions offer an organic view of user expectations, frustrations, and
success stories shaped by the specific contexts of use. Yet, harnessing this
information for systematic analysis remains challenging due to the unstructured
and domain-specific nature of the content. The lack of structure and
specialized vocabulary makes it difficult for traditional data analysis
techniques to accurately interpret, categorize, and quantify the feedback,
thereby limiting its potential to inform product development and support
strategies. To address these challenges, this paper presents the User
eXperience Perception Insights Dataset (UXPID), a collection of 7130
artificially synthesized and anonymized user feedback branches extracted from a
public industrial automation forum. Each JavaScript object notation (JSON)
record contains multi-post comments related to specific hardware and software
products, enriched with metadata and contextual conversation data. Leveraging a
large language model (LLM), each branch is systematically analyzed and
annotated for UX insights, user expectations, severity and sentiment ratings,
and topic classifications. The UXPID dataset is designed to facilitate research
in user requirements, user experience (UX) analysis, and AI-driven feedback
processing, particularly where privacy and licensing restrictions limit access
to real-world data. UXPID supports the training and evaluation of
transformer-based models for tasks such as issue detection, sentiment analysis,
and requirements extraction in the context of technical forums.

</details>


### [65] [When Curiosity Signals Danger: Predicting Health Crises Through Online Medication Inquiries](https://arxiv.org/abs/2509.11802)
*Dvora Goncharok,Arbel Shifman,Alexander Apartsin,Yehudit Aperstein*

Main category: cs.CL

TL;DR: 该研究创建了一个标注数据集，用于检测在线医疗论坛中药物相关问题的关键性，并比较了传统机器学习方法和大型语言模型在识别高风险问题方面的性能。


<details>
  <summary>Details</summary>
Motivation: 在线医疗论坛包含大量患者关于药物使用的疑问，其中一些问题可能预示着混淆、误用甚至健康危机。及时检测这些关键问题对于干预和提高患者安全至关重要。

Method: 研究构建了一个手动标注的药物相关问题数据集，基于临床风险因素标注关键性。使用了6种传统机器学习分类器（TF-IDF特征）和3种最先进的大型语言模型方法进行性能对比。

Result: 研究结果表明传统方法和现代方法都有潜力支持数字健康空间的实时分诊和警报系统。

Conclusion: 该研究提供了一个公开可用的标注数据集，鼓励在患者生成数据、自然语言处理和健康事件早期预警系统交叉领域的进一步研究。

Abstract: Online medical forums are a rich and underutilized source of insight into
patient concerns, especially regarding medication use. Some of the many
questions users pose may signal confusion, misuse, or even the early warning
signs of a developing health crisis. Detecting these critical questions that
may precede severe adverse events or life-threatening complications is vital
for timely intervention and improving patient safety. This study introduces a
novel annotated dataset of medication-related questions extracted from online
forums. Each entry is manually labelled for criticality based on clinical risk
factors. We benchmark the performance of six traditional machine learning
classifiers using TF-IDF textual representations, alongside three
state-of-the-art large language model (LLM)-based classification approaches
that leverage deep contextual understanding. Our results highlight the
potential of classical and modern methods to support real-time triage and alert
systems in digital health spaces. The curated dataset is made publicly
available to encourage further research at the intersection of
patient-generated data, natural language processing, and early warning systems
for critical health events. The dataset and benchmark are available at:
https://github.com/Dvora-coder/LLM-Medication-QA-Risk-Classifier-MediGuard.

</details>


### [66] [From Fuzzy Speech to Medical Insight: Benchmarking LLMs on Noisy Patient Narratives](https://arxiv.org/abs/2509.11803)
*Eden Mama,Liel Sheri,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CL

TL;DR: 提出了一个名为Noisy Diagnostic Benchmark (NDB)的合成数据集，用于测试大型语言模型在嘈杂、非正式的医疗叙述文本中的诊断能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要使用清洁、结构化的临床文本，无法真实反映LLM在实际医疗环境中处理患者自述（通常是非正式、模糊和嘈杂的）的能力。

Method: 创建了一个包含不同语言噪声水平、模糊语言和通俗术语的合成数据集，包含临床一致的场景和真实诊断标注。使用该数据集对BERT和T5等最先进模型进行微调和评估。

Result: 开发并发布了NDB基准测试，这是一个结构化的嘈杂合成患者描述数据集，用于在真实语言条件下压力测试和比较LLM的诊断能力。

Conclusion: NDB基准测试填补了现有医疗NLP评估的空白，为研究社区提供了在更真实条件下评估LLM诊断能力的工具，支持可重复性和未来研究。

Abstract: The widespread adoption of large language models (LLMs) in healthcare raises
critical questions about their ability to interpret patient-generated
narratives, which are often informal, ambiguous, and noisy. Existing benchmarks
typically rely on clean, structured clinical text, offering limited insight
into model performance under realistic conditions. In this work, we present a
novel synthetic dataset designed to simulate patient self-descriptions
characterized by varying levels of linguistic noise, fuzzy language, and
layperson terminology. Our dataset comprises clinically consistent scenarios
annotated with ground-truth diagnoses, spanning a spectrum of communication
clarity to reflect diverse real-world reporting styles. Using this benchmark,
we fine-tune and evaluate several state-of-the-art models (LLMs), including
BERT-based and encoder-decoder T5 models. To support reproducibility and future
research, we release the Noisy Diagnostic Benchmark (NDB), a structured dataset
of noisy, synthetic patient descriptions designed to stress-test and compare
the diagnostic capabilities of large language models (LLMs) under realistic
linguistic conditions. We made the benchmark available for the community:
https://github.com/lielsheri/PatientSignal

</details>


### [67] [PledgeTracker: A System for Monitoring the Fulfilment of Pledges](https://arxiv.org/abs/2509.11804)
*Yulong Chen,Michael Sejr Schlichtkrull,Zhenyun Deng,David Corney,Nasim Asl,Joshua Salisbury,Andrew Dudfield,Andreas Vlachos*

Main category: cs.CL

TL;DR: PledgeTracker是一个将政治承诺验证重新定义为结构化事件时间线构建的系统，通过多步骤证据检索、时间线构建和履行过滤模块来跟踪政治承诺的履行情况。


<details>
  <summary>Details</summary>
Motivation: 现有方法将政治承诺验证简化为文档分类任务，忽略了其动态性、时间性和多文档特性，需要一种能够处理增量证据和动态更新的方法。

Method: 系统包含三个核心组件：(1)多步骤证据检索模块；(2)时间线构建模块；(3)履行过滤模块，通过构建结构化事件时间线来捕捉承诺履行的演变过程。

Result: 与专业事实核查人员在真实工作流程中合作评估，证明系统在检索相关证据和减少人工验证工作量方面具有有效性。

Conclusion: PledgeTracker通过重新定义问题为事件时间线构建，能够更好地处理政治承诺验证的动态性和复杂性，提供可解释的结构化时间线。

Abstract: Political pledges reflect candidates' policy commitments, but tracking their
fulfilment requires reasoning over incremental evidence distributed across
multiple, dynamically updated sources. Existing methods simplify this task into
a document classification task, overlooking its dynamic, temporal and
multi-document nature. To address this issue, we introduce
\textsc{PledgeTracker}, a system that reformulates pledge verification into
structured event timeline construction. PledgeTracker consists of three core
components: (1) a multi-step evidence retrieval module; (2) a timeline
construction module and; (3) a fulfilment filtering module, allowing the
capture of the evolving nature of pledge fulfilment and producing interpretable
and structured timelines. We evaluate PledgeTracker in collaboration with
professional fact-checkers in real-world workflows, demonstrating its
effectiveness in retrieving relevant evidence and reducing human verification
effort.

</details>


### [68] [SCDTour: Embedding Axis Ordering and Merging for Interpretable Semantic Change Detection](https://arxiv.org/abs/2509.11818)
*Taichi Aida,Danushka Bollegala*

Main category: cs.CL

TL;DR: SCDTour方法通过排序和合并可解释轴来解决语义变化检测中可解释性与性能之间的权衡问题，在保持高可解释性的同时维持检测性能


<details>
  <summary>Details</summary>
Motivation: 解决语义变化检测中可解释性与性能之间的固有矛盾——提升可解释性通常会导致检测性能下降，反之亦然

Method: SCDTour方法通过考虑(a)嵌入空间中轴之间的语义相似性，以及(b)每个轴对语义变化的贡献程度，来排序和合并可解释轴

Result: 实验结果表明SCDTour在保持语义变化检测性能的同时维持高可解释性，聚合排序后的轴能产生更精细的词义集合，在SCD任务中达到与原始全维嵌入相当或更好的性能

Conclusion: SCDTour有效平衡了可解释性和SCD性能，通过少量精炼轴实现对语义变化的有意义解释

Abstract: In Semantic Change Detection (SCD), it is a common problem to obtain
embeddings that are both interpretable and high-performing. However, improving
interpretability often leads to a loss in the SCD performance, and vice versa.
To address this problem, we propose SCDTour, a method that orders and merges
interpretable axes to alleviate the performance degradation of SCD. SCDTour
considers both (a) semantic similarity between axes in the embedding space, as
well as (b) the degree to which each axis contributes to semantic change.
Experimental results show that SCDTour preserves performance in semantic change
detection while maintaining high interpretability. Moreover, agglomerating the
sorted axes produces a more refined set of word senses, which achieves
comparable or improved performance against the original full-dimensional
embeddings in the SCD task. These findings demonstrate that SCDTour effectively
balances interpretability and SCD performance, enabling meaningful
interpretation of semantic shifts through a small number of refined axes.
Source code is available at https://github.com/LivNLP/svp-tour .

</details>


### [69] [MOOM: Maintenance, Organization and Optimization of Memory in Ultra-Long Role-Playing Dialogues](https://arxiv.org/abs/2509.11860)
*Weishu Chen,Jinyi Tang,Zhouhui Hou,Shihao Han,Mingjie Zhan,Zhiyuan Huang,Delong Liu,Jiawei Guo,Zhicheng Zhao,Fei Su*

Main category: cs.CL

TL;DR: MOOM是一个基于文学理论的双分支记忆插件，通过建模情节发展和角色刻画来控制超长对话中的记忆增长，并整合遗忘机制来约束记忆容量。


<details>
  <summary>Details</summary>
Motivation: 解决人机角色扮演场景中超长对话中记忆提取的不可控增长问题，现有方法往往无法有效控制记忆容量。

Method: 提出MOOM双分支记忆插件：一个分支总结多时间尺度的情节冲突，另一个分支提取用户角色画像；整合基于"竞争抑制"记忆理论的遗忘机制来约束记忆容量。

Result: MOOM在ZH-4O中文超长对话数据集上表现优于所有最先进的记忆提取方法，需要更少的大语言模型调用，同时保持可控的记忆容量。

Conclusion: MOOM通过结合文学理论和记忆理论，有效解决了角色扮演对话中的记忆不可控增长问题，为超长对话记忆管理提供了新的解决方案。

Abstract: Memory extraction is crucial for maintaining coherent ultra-long dialogues in
human-robot role-playing scenarios. However, existing methods often exhibit
uncontrolled memory growth. To address this, we propose MOOM, the first
dual-branch memory plugin that leverages literary theory by modeling plot
development and character portrayal as core storytelling elements.
Specifically, one branch summarizes plot conflicts across multiple time scales,
while the other extracts the user's character profile. MOOM further integrates
a forgetting mechanism, inspired by the ``competition-inhibition'' memory
theory, to constrain memory capacity and mitigate uncontrolled growth.
Furthermore, we present ZH-4O, a Chinese ultra-long dialogue dataset
specifically designed for role-playing, featuring dialogues that average 600
turns and include manually annotated memory information. Experimental results
demonstrate that MOOM outperforms all state-of-the-art memory extraction
methods, requiring fewer large language model invocations while maintaining a
controllable memory capacity.

</details>


### [70] [Growing Perspectives: Modelling Embodied Perspective Taking and Inner Narrative Development Using Large Language Models](https://arxiv.org/abs/2509.11868)
*Sabrina Patania,Luca Annese,Anna Lambiase,Anita Pellegrini,Tom Foulsham,Azzurra Ruggeri,Silvia Rossi,Silvia Serino,Dimitri Ognibene*

Main category: cs.CL

TL;DR: 本研究探讨PerspAct系统如何将ReAct范式与大型语言模型结合，模拟Selman理论中的观点采择发展阶段，通过导演任务评估GPT生成发展一致性叙事的能力及其对协作性能的影响。


<details>
  <summary>Details</summary>
Motivation: 语言和具身观点采择对人类协作至关重要，但目前很少有计算模型能同时处理这两个方面。研究旨在探索如何将具身观点采择与语言能力整合到LLMs中，以更好地模拟发展动态。

Method: 使用扩展的导演任务，评估GPT生成与指定发展阶段一致的内在叙事能力，并分析这些叙事如何影响协作性能（包括定性行动选择和定量任务效率）。基于Selman的观点采择理论和ReAct范式。

Result: GPT能在任务执行前可靠地生成发展一致性的叙事，但在交互过程中往往向更高级阶段转变。高级发展阶段通常能提高协作效果，而早期阶段在复杂情境中产生更多变的结果。语言交流有助于精炼内在表征。

Conclusion: 研究强调了将具身观点采择与语言整合到LLMs中的潜力，以更好地建模发展动态，并强调了在结合语言和具身任务时评估内在言语的重要性。

Abstract: Language and embodied perspective taking are essential for human
collaboration, yet few computational models address both simultaneously. This
work investigates the PerspAct system [1], which integrates the ReAct (Reason
and Act) paradigm with Large Language Models (LLMs) to simulate developmental
stages of perspective taking, grounded in Selman's theory [2]. Using an
extended director task, we evaluate GPT's ability to generate internal
narratives aligned with specified developmental stages, and assess how these
influence collaborative performance both qualitatively (action selection) and
quantitatively (task efficiency). Results show that GPT reliably produces
developmentally-consistent narratives before task execution but often shifts
towards more advanced stages during interaction, suggesting that language
exchanges help refine internal representations. Higher developmental stages
generally enhance collaborative effectiveness, while earlier stages yield more
variable outcomes in complex contexts. These findings highlight the potential
of integrating embodied perspective taking and language in LLMs to better model
developmental dynamics and stress the importance of evaluating internal speech
during combined linguistic and embodied tasks.

</details>


### [71] [Uncertainty in Authorship: Why Perfect AI Detection Is Mathematically Impossible](https://arxiv.org/abs/2509.11915)
*Aadil Gani Ganie*

Main category: cs.CL

TL;DR: 论文通过量子不确定性类比，论证了AI文本检测存在根本性限制：检测精度与文本真实性之间存在不可调和的矛盾，完美检测在理论上是不可能的


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型发展，区分人类写作和AI生成文本变得越来越困难，需要探讨检测方法的理论极限

Method: 采用概念类比方法，将量子系统中的测不准原理与文本检测中的精度-干扰权衡进行平行比较，分析现有检测方法（风格计量、水印技术、神经网络分类器）的内在局限性

Result: 发现提高检测准确性往往会导致AI输出发生变化，使其他特征可靠性降低，检测行为本身会在文本中引入不确定性

Conclusion: AI文本检测的挑战不仅仅是技术工具问题，而是反映了语言本质中更深层次、不可避免的张力，对作者身份、伦理和政策具有广泛影响

Abstract: As large language models (LLMs) become more advanced, it is increasingly
difficult to distinguish between human-written and AI-generated text. This
paper draws a conceptual parallel between quantum uncertainty and the limits of
authorship detection in natural language. We argue that there is a fundamental
trade-off: the more confidently one tries to identify whether a text was
written by a human or an AI, the more one risks disrupting the text's natural
flow and authenticity. This mirrors the tension between precision and
disturbance found in quantum systems. We explore how current detection
methods--such as stylometry, watermarking, and neural classifiers--face
inherent limitations. Enhancing detection accuracy often leads to changes in
the AI's output, making other features less reliable. In effect, the very act
of trying to detect AI authorship introduces uncertainty elsewhere in the text.
Our analysis shows that when AI-generated text closely mimics human writing,
perfect detection becomes not just technologically difficult but theoretically
impossible. We address counterarguments and discuss the broader implications
for authorship, ethics, and policy. Ultimately, we suggest that the challenge
of AI-text detection is not just a matter of better tools--it reflects a
deeper, unavoidable tension in the nature of language itself.

</details>


### [72] [Designing LLMs for cultural sensitivity: Evidence from English-Japanese translation](https://arxiv.org/abs/2509.11921)
*Helene Tenzer,Oumnia Abidi,Stefan Feuerriegel*

Main category: cs.CL

TL;DR: 本研究分析了不同LLM提示策略在英日职场邮件翻译中的文化敏感性，发现文化定制提示能改善文化适应性


<details>
  <summary>Details</summary>
Motivation: 虽然LLM能生成近乎完美的字面翻译，但尚不清楚是否支持文化适宜的沟通，特别是在跨文化职场交流中

Method: 采用混合研究方法，比较三种提示策略：朴素翻译提示、受众定向提示（指定文化背景）、教学提示（明确日本沟通规范指导），分析文化特定语言模式并评估母语者对翻译语气适宜性的感知

Result: 研究发现文化定制的提示策略能够提高翻译的文化适应性

Conclusion: 研究结果为在多语言环境中设计文化包容性LLM提供了建议

Abstract: Large language models (LLMs) are increasingly used in everyday communication,
including multilingual interactions across different cultural contexts. While
LLMs can now generate near-perfect literal translations, it remains unclear
whether LLMs support culturally appropriate communication. In this paper, we
analyze the cultural sensitivity of different LLM designs when applied to
English-Japanese translations of workplace e-mails. Here, we vary the prompting
strategies: (1) naive "just translate" prompts, (2) audience-targeted prompts
specifying the recipient's cultural background, and (3) instructional prompts
with explicit guidance on Japanese communication norms. Using a mixed-methods
study, we then analyze culture-specific language patterns to evaluate how well
translations adapt to cultural norms. Further, we examine the appropriateness
of the tone of the translations as perceived by native speakers. We find that
culturally-tailored prompting can improve cultural fit, based on which we offer
recommendations for designing culturally inclusive LLMs in multilingual
settings.

</details>


### [73] [Spec-LLaVA: Accelerating Vision-Language Models with Dynamic Tree-Based Speculative Decoding](https://arxiv.org/abs/2509.11961)
*Mingxiao Huo,Jiayi Zhang,Hewei Wang,Jinfeng Xu,Zheyu Chen,Huilin Tai,Yijun Chen*

Main category: cs.CL

TL;DR: Spec-LLaVA使用推测解码技术加速视觉语言模型推理，通过轻量级草稿模型预测token，目标模型并行验证，实现3.28倍加速且不损失生成质量。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型(VLMs)的自回归推理速度慢，限制了其在实时应用中的部署，需要一种无损加速方法。

Method: 采用动态树形推测解码框架，配对轻量级草稿VLM和大型目标模型，草稿模型推测未来token，目标模型并行验证，并根据置信度自适应扩展和修剪推测分支。

Result: 在MS COCO域外图像上，Spec-LLaVA在LLaVA-1.5(7B, 13B)上实现最高3.28倍的解码加速，生成质量无损失。

Conclusion: 提出了基于动态树形推测解码的无损VLM加速框架，为实用实时多模态助手开辟了道路，轻量级草稿模型设计使其适用于资源受限或设备端部署场景。

Abstract: Vision-Language Models (VLMs) enable powerful multimodal reasoning but suffer
from slow autoregressive inference, limiting their deployment in real-time
applications. We introduce Spec-LLaVA, a system that applies speculative
decoding to accelerate VLMs without sacrificing output quality. Spec-LLaVA
pairs a lightweight draft VLM with a large target model: the draft speculates
future tokens, which the target verifies in parallel, allowing multiple tokens
to be generated per step. To maximize efficiency, we design a dynamic
tree-based verification algorithm that adaptively expands and prunes
speculative branches using draft model confidence. On MS COCO out-of-domain
images, Spec-LLaVA achieves up to 3.28$\times$ faster decoding on LLaVA-1.5
(7B, 13B) with no loss in generation quality. This work presents a lossless
acceleration framework for VLMs using dynamic tree-structured speculative
decoding, opening a path toward practical real-time multimodal assistants.
Importantly, the lightweight draft model design makes the framework amenable to
resource-constrained or on-device deployment settings.

</details>


### [74] [ToolRM: Outcome Reward Models for Tool-Calling Large Language Models](https://arxiv.org/abs/2509.11963)
*Mayank Agarwal,Ibrahim Abdelaziz,Kinjal Basu,Merve Unuvar,Luis A. Lastras,Yara Rizk,Pavan Kapanipathi*

Main category: cs.CL

TL;DR: 提出了FC-RewardBench基准测试，发现现有奖励模型在评估工具调用方面存在不足，并开发了基于结果的奖励模型训练框架，在7个域外基准上平均提升25%性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地与外部工具交互，但现有的奖励模型主要针对自然语言输出训练，难以有效评估基于工具的推理和执行过程，存在明显的评估差距。

Method: 引入FC-RewardBench基准系统评估奖励模型在工具调用场景的性能；提出使用开源LLM合成数据训练基于结果的奖励模型的框架；训练了1.7B到14B参数规模的模型。

Result: 训练的奖励模型在7个域外基准测试中一致优于通用基线模型，下游任务性能平均提升达25%，并通过奖励引导过滤实现了数据高效的微调。

Conclusion: 现有奖励模型在工具使用评估方面存在显著不足，需要领域特定的建模方法；提出的基于结果的奖励模型训练框架有效提升了工具调用场景的评估性能。

Abstract: As large language models (LLMs) increasingly interact with external tools,
reward modeling for tool use has become a critical yet underexplored area.
Existing reward models, trained primarily on natural language outputs, struggle
to evaluate tool-based reasoning and execution. To quantify this gap, we
introduce FC-RewardBench, the first benchmark designed to systematically assess
reward models' performance in tool-calling scenarios. Our analysis shows that
current reward models often miss key signals of effective tool use,
highlighting the need for domain-specific modeling. To address this, we propose
a training framework for outcome-based reward models using data synthesized
from permissively licensed, open-weight LLMs. We train models ranging from 1.7B
to 14B parameters and evaluate them across seven out-of-domain benchmarks.
These models consistently outperform general-purpose baselines, achieving up to
25\% average improvement in downstream task performance and enabling
data-efficient fine-tuning through reward-guided filtering.

</details>


### [75] [Query-Focused Extractive Summarization for Sentiment Explanation](https://arxiv.org/abs/2509.11989)
*Ahmed Moubtahij,Sylvie Ratté,Yazid Attabi,Maxime Dumas*

Main category: cs.CL

TL;DR: 提出多偏差框架解决查询聚焦摘要中的语言差异问题，通过情感偏差和查询扩展方法在情感解释任务上超越基线模型


<details>
  <summary>Details</summary>
Motivation: 客户反馈分析需要从大量文本中确定情感原因，查询聚焦摘要模型常因查询与源文档间的语言差异而受限

Method: 提出多偏差框架（领域无关通用方法），专门针对情感解释问题设计基于情感的偏差和查询扩展方法

Result: 在真实世界专有情感感知QFS数据集上取得优于基线模型的实验结果

Conclusion: 多偏差框架能有效弥合查询与文档间的语言鸿沟，提升情感解释任务的性能

Abstract: Constructive analysis of feedback from clients often requires determining the
cause of their sentiment from a substantial amount of text documents. To assist
and improve the productivity of such endeavors, we leverage the task of
Query-Focused Summarization (QFS). Models of this task are often impeded by the
linguistic dissonance between the query and the source documents. We propose
and substantiate a multi-bias framework to help bridge this gap at a
domain-agnostic, generic level; we then formulate specialized approaches for
the problem of sentiment explanation through sentiment-based biases and query
expansion. We achieve experimental results outperforming baseline models on a
real-world proprietary sentiment-aware QFS dataset.

</details>


### [76] [Text Adaptation to Plain Language and Easy Read via Automatic Post-Editing Cycles](https://arxiv.org/abs/2509.11991)
*Jesús Calleja,David Ponce,Thierry Etchegoyhen*

Main category: cs.CL

TL;DR: Vicomtech团队在CLEARS挑战赛中采用自动后编辑和迭代优化方法，在西班牙语简化文本和易读文本生成任务中分别获得第一和第二名


<details>
  <summary>Details</summary>
Motivation: 参与CLEARS挑战赛，旨在开发有效的文本简化技术，将复杂文本转换为普通语言和易读格式，提高文本可读性

Method: 使用大型语言模型进行自动后编辑，通过迭代生成连续的文本简化版本，直到可读性和相似性指标显示无法进一步优化

Result: 在官方评估指标的平均得分上，该方法在普通语言简化任务中获得第一名，在易读文本生成任务中获得第二名

Conclusion: 基于大型语言模型的迭代后编辑方法在文本简化任务中表现优异，证明了该方法在提高文本可读性方面的有效性

Abstract: We describe Vicomtech's participation in the CLEARS challenge on text
adaptation to Plain Language and Easy Read in Spanish. Our approach features
automatic post-editing of different types of initial Large Language Model
adaptations, where successive adaptations are generated iteratively until
readability and similarity metrics indicate that no further adaptation
refinement can be successfully performed. Taking the average of all official
metrics, our submissions achieved first and second place in Plain language and
Easy Read adaptation, respectively.

</details>


### [77] [Steering Language Models in Multi-Token Generation: A Case Study on Tense and Aspect](https://arxiv.org/abs/2509.12065)
*Alina Klerings,Jannik Brinkmann,Daniel Ruffinelli,Simone Ponzetto*

Main category: cs.CL

TL;DR: 该研究通过线性判别分析识别了大语言模型中动词时态和体两个多维语法现象的正交方向，并通过概念导向实现了对这两个语法特征的因果控制，发现导向强度、位置和持续时间是减少副作用的关键参数。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型如何内部编码句法知识，特别是多维层次语法现象（动词时态和体）的表征和控制方式。

Method: 使用线性判别分析识别语法特征的正交方向，通过概念导向在三个生成任务中进行因果控制实验，并研究多标记生成中有效导向的影响因素。

Result: 发现模型以结构化的、类似人类的方式编码时态和体，但生成过程中对这些特征的有效控制对多个因素敏感，需要手动调优或自动优化。

Conclusion: 大语言模型编码语法知识的方式具有结构性，但语法特征的控制需要精细的参数调节，导向强度、位置和持续时间是影响控制效果的关键因素。

Abstract: Large language models (LLMs) are able to generate grammatically well-formed
text, but how do they encode their syntactic knowledge internally? While prior
work has focused largely on binary grammatical contrasts, in this work, we
study the representation and control of two multidimensional hierarchical
grammar phenomena - verb tense and aspect - and for each, identify distinct,
orthogonal directions in residual space using linear discriminant analysis.
Next, we demonstrate causal control over both grammatical features through
concept steering across three generation tasks. Then, we use these identified
features in a case study to investigate factors influencing effective steering
in multi-token generation. We find that steering strength, location, and
duration are crucial parameters for reducing undesirable side effects such as
topic shift and degeneration. Our findings suggest that models encode tense and
aspect in structurally organized, human-like ways, but effective control of
such features during generation is sensitive to multiple factors and requires
manual tuning or automated optimization.

</details>


### [78] [SENSE models: an open source solution for multilingual and multimodal semantic-based tasks](https://arxiv.org/abs/2509.12093)
*Salima Mdhaffar,Haroun Elleuch,Chaimae Chellaf,Ha Nguyen,Yannick Estève*

Main category: cs.CL

TL;DR: SENSE是一个开源的多语言语音-文本共享嵌入模型，基于SAMU-XLSR框架，通过师生框架将自监督语音编码器与语言无关的文本编码器表示对齐。


<details>
  <summary>Details</summary>
Motivation: 受到SAMU-XLSR和Meta AI的SONAR模型启发，旨在开发一个更好的多语言语音-文本语义对齐模型，提升跨语言和跨模态语义任务的性能。

Method: 采用师生框架，选择更强的教师文本模型和更好的初始语音编码器来改进原始SAMU-XLSR方法，并将代码集成到SpeechBrain工具包中。

Result: 在多语言和多模态语义任务上取得了极具竞争力的性能表现。

Conclusion: 该研究为理解语义在语音-文本对齐编码器中的捕获方式提供了新的见解，并发布了首个公开可用的SENSE模型。

Abstract: This paper introduces SENSE (Shared Embedding for N-lingual Speech and tExt),
an open-source solution inspired by the SAMU-XLSR framework and conceptually
similar to Meta AI's SONAR models. These approaches rely on a teacher-student
framework to align a self-supervised speech encoder with the language-agnostic
continuous representations of a text encoder at the utterance level. We
describe how the original SAMU-XLSR method has been updated by selecting a
stronger teacher text model and a better initial speech encoder. The source
code for training and using SENSE models has been integrated into the
SpeechBrain toolkit, and the first SENSE model we trained has been publicly
released. We report experimental results on multilingual and multimodal
semantic tasks, where our SENSE model achieves highly competitive performance.
Finally, this study offers new insights into how semantics are captured in such
semantically aligned speech encoders.

</details>


### [79] [Is 'Hope' a person or an idea? A pilot benchmark for NER: comparing traditional NLP tools and large language models on ambiguous entities](https://arxiv.org/abs/2509.12098)
*Payam Latifi*

Main category: cs.CL

TL;DR: 本研究比较了6个NER系统（3个传统NLP工具和3个LLM）在小型标注数据集上的性能，发现LLM在上下文敏感实体识别上表现更好，但传统工具在结构化标签上更稳定。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型与传统NLP工具在命名实体识别任务上的性能差异，为模型选择提供实证依据。

Method: 使用包含119个标记、5种实体类型的手动标注黄金标准数据集，对6个系统（NLTK、spaCy、Stanza、Gemini、DeepSeek、Qwen）进行F1分数评估。

Result: LLM整体优于传统工具，特别是在人名识别上；Gemini获得最高平均F1分数；传统工具如Stanza在LOCATION和DATE等结构化标签上表现更一致；LLM在处理时间表达式和多词组织名时存在变异性。

Conclusion: LLM提供更好的上下文理解能力，但传统工具在特定任务上仍具竞争力，模型选择应根据具体需求决定。

Abstract: This pilot study presents a small-scale but carefully annotated benchmark of
Named Entity Recognition (NER) performance across six systems: three non-LLM
NLP tools (NLTK, spaCy, Stanza) and three general-purpose large language models
(LLMs: Gemini-1.5-flash, DeepSeek-V3, Qwen-3-4B). The dataset contains 119
tokens covering five entity types (PERSON, LOCATION, ORGANIZATION, DATE, TIME).
We evaluated each system's output against the manually annotated gold standard
dataset using F1-score. The results show that LLMs generally outperform
conventional tools in recognizing context-sensitive entities like person names,
with Gemini achieving the highest average F1-score. However, traditional
systems like Stanza demonstrate greater consistency in structured tags such as
LOCATION and DATE. We also observed variability among LLMs, particularly in
handling temporal expressions and multi-word organizations. Our findings
highlight that while LLMs offer improved contextual understanding, traditional
tools remain competitive in specific tasks, informing model selection.

</details>


### [80] [In-domain SSL pre-training and streaming ASR](https://arxiv.org/abs/2509.12101)
*Jarod Duret,Salima Mdhaffar,Gaëlle Laperrière,Ryan Whetten,Audrey Galametz,Catherine Kobus,Marion-Cécile Martin,Jo Oleiwan,Yannick Estève*

Main category: cs.CL

TL;DR: 该研究探索了在航空交通管制领域使用领域特定的自监督预训练方法，结合流式处理技术，显著提升了语音识别准确率和实时性能


<details>
  <summary>Details</summary>
Motivation: 航空交通管制环境对语音识别的准确性和实时性要求极高，通用语音编码器在该领域表现有限，需要专门针对ATC数据的优化方案

Method: 使用4.5千小时无标注ATC数据训练BEST-RQ模型，然后在有监督ATC数据集上微调；提出分块注意力和动态卷积技术实现低延迟流式处理

Result: 领域自适应预训练显著降低了词错误率，在标准ATC基准测试中表现优于w2v-BERT 2.0和HuBERT等通用语音编码器；流式方法在严格延迟约束下进一步提升了性能

Conclusion: 针对ATC数据的自监督学习专业化是提高实际应用场景中ASR系统准确性和效率的有效途径，特别适用于安全关键的航空应用

Abstract: In this study, we investigate the benefits of domain-specific self-supervised
pre-training for both offline and streaming ASR in Air Traffic Control (ATC)
environments. We train BEST-RQ models on 4.5k hours of unlabeled ATC data, then
fine-tune on a smaller supervised ATC set. To enable real-time processing, we
propose using chunked attention and dynamic convolutions, ensuring low-latency
inference. We compare these in-domain SSL models against state-of-the-art,
general-purpose speech encoders such as w2v-BERT 2.0 and HuBERT. Results show
that domain-adapted pre-training substantially improves performance on standard
ATC benchmarks, significantly reducing word error rates when compared to models
trained on broad speech corpora. Furthermore, the proposed streaming approach
further improves word error rate under tighter latency constraints, making it
particularly suitable for safety-critical aviation applications. These findings
highlight that specializing SSL representations for ATC data is a practical
path toward more accurate and efficient ASR systems in real-world operational
settings.

</details>


### [81] [GTA: Supervised-Guided Reinforcement Learning for Text Classification with Large Language Models](https://arxiv.org/abs/2509.12108)
*Min Zeng,Jinfei Sun,Xueyou Luo,Caiquan Liu,Shiqi Zhang,Li Xie,Xiaoxin Chen*

Main category: cs.CL

TL;DR: GTA框架结合监督微调(SFT)的效率与强化学习(RL)的能力提升，通过先猜测后反思的流程，在文本分类任务上实现了比纯SFT和RL更好的性能和更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 解决纯RL方法探索效率低、收敛慢，而SFT方法性能上限有限、理论基础薄弱的问题，寻求效率与能力的最佳平衡。

Method: 提出Guess-Think-Answer框架：模型先产生临时猜测（交叉熵损失优化），然后反思猜测，最后生成答案，RL奖励同时优化最终输出和整个GTA结构格式。使用损失掩码和梯度约束缓解训练信号冲突。

Result: 在四个文本分类基准测试中，GTA显著加速收敛速度，同时超越单独的SFT和RL基线方法。

Conclusion: GTA框架成功实现了SFT效率与RL能力的结合，为自然语言处理任务提供了一种高效的混合训练范式。

Abstract: In natural language processing tasks, pure reinforcement learning (RL)
fine-tuning methods often suffer from inefficient exploration and slow
convergence; while supervised fine-tuning (SFT) methods, although efficient in
training, have limited performance ceiling and less solid theoretical
foundation compared to RL. To address efficiency-capability trade-off, we
propose the Guess-Think-Answer (GTA) framework that combines the efficiency of
SFT with the capability gains of RL in a unified training paradigm. GTA works
by having the model first produce a provisional guess (optimized via
cross-entropy loss), then reflect on this guess before generating the final
answer, with RL rewards shaping both the final output and the format of the
entire GTA structure. This hybrid approach achieves both faster convergence
than pure RL and higher performance ceiling than pure SFT. To mitigate gradient
conflicts between the two training signals, we employ loss masking and gradient
constraints. Empirical results on four text classification benchmarks
demonstrate that GTA substantially accelerates convergence while outperforming
both standalone SFT and RL baselines.

</details>


### [82] [CBP-Tuning: Efficient Local Customization for Black-box Large Language Models](https://arxiv.org/abs/2509.12112)
*Jiaxuan Zhao,Naibin Gu,Yuchen Feng,Xiyu Liu,Peng Fu,Zheng Lin,Weiping Wang*

Main category: cs.CL

TL;DR: CBP-Tuning是一个新颖的黑盒提示调优框架，通过两阶段方法实现高效本地定制，同时保护双向隐私，无需访问模型权重或上传私有数据。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型定制成本高，云服务模式存在个性化定制困难和用户隐私风险的双重挑战。

Method: 两阶段框架：1）服务器端训练提示生成器捕获领域特定能力；2）用户端进行无梯度优化，为单个任务定制软提示。

Result: 在常识推理、医疗和金融领域设置中表现出优于基线的性能，展示了任务无关处理和隐私保护的优势。

Conclusion: CBP-Tuning有效解决了LLM定制化的成本和隐私问题，为个性化定制提供了实用且安全的解决方案。

Abstract: The high costs of customizing large language models (LLMs) fundamentally
limit their adaptability to user-specific needs. Consequently, LLMs are
increasingly offered as cloud-based services, a paradigm that introduces
critical limitations: providers struggle to support personalized customization
at scale, while users face privacy risks when exposing sensitive data. To
address this dual challenge, we propose Customized Black-box Prompt Tuning
(CBP-Tuning), a novel framework that facilitates efficient local customization
while preserving bidirectional privacy. Specifically, we design a two-stage
framework: (1) a prompt generator trained on the server-side to capture
domain-specific and task-agnostic capabilities, and (2) user-side gradient-free
optimization that tailors soft prompts for individual tasks. This approach
eliminates the need for users to access model weights or upload private data,
requiring only a single customized vector per task while achieving effective
adaptation. Furthermore, the evaluation of CBP-Tuning in the commonsense
reasoning, medical and financial domain settings demonstrates superior
performance compared to baselines, showcasing its advantages in task-agnostic
processing and privacy preservation.

</details>


### [83] [XplaiNLP at CheckThat! 2025: Multilingual Subjectivity Detection with Finetuned Transformers and Prompt-Based Inference with Large Language Models](https://arxiv.org/abs/2509.12130)
*Ariana Sahitaj,Jiaao Li,Pia Wenzel Neves,Fedor Splitt,Premtim Sahitaj,Charlott Jakob,Veronika Solopova,Vera Schmitt*

Main category: cs.CL

TL;DR: XplaiNLP在CheckThat! 2025多语言主观性检测任务中提交了两种方法：基于Transformer的监督微调和零样本提示LLM，在意大利语任务中获得第一名，罗马尼亚语排名第三，但在乌克兰语和波兰语等低资源语言上表现略低于基线。


<details>
  <summary>Details</summary>
Motivation: 解决多语言主观性检测任务，特别是在低资源语言环境下如何有效进行跨语言泛化的问题。

Method: 使用两种方法：(1) 对EuroBERT、XLM-RoBERTa和German-BERT进行监督微调，使用单语和机器翻译的训练数据；(2) 零样本提示使用o3-mini进行基于规则的标注，以及gpt-4.1-mini进行对比重写和比较推理。

Result: 意大利语单语任务F1得分0.8104（第一名，基线0.6941）；罗马尼亚语零样本设置中XLM-RoBERTa获得0.7917 F1得分（第三名，基线0.6461）；德语使用翻译数据微调的German-BERT表现竞争力；但乌克兰语和波兰语零样本设置略低于基线。

Conclusion: 监督微调在多语言主观性检测任务中表现良好，特别是在资源相对丰富的语言上，但在低资源跨语言场景中的泛化仍然具有挑战性。

Abstract: This notebook reports the XplaiNLP submission to the CheckThat! 2025 shared
task on multilingual subjectivity detection. We evaluate two approaches: (1)
supervised fine-tuning of transformer encoders, EuroBERT, XLM-RoBERTa, and
German-BERT, on monolingual and machine-translated training data; and (2)
zero-shot prompting using two LLMs: o3-mini for Annotation (rule-based
labelling) and gpt-4.1-mini for DoubleDown (contrastive rewriting) and
Perspective (comparative reasoning). The Annotation Approach achieves 1st place
in the Italian monolingual subtask with an F_1 score of 0.8104, outperforming
the baseline of 0.6941. In the Romanian zero-shot setting, the fine-tuned
XLM-RoBERTa model obtains an F_1 score of 0.7917, ranking 3rd and exceeding the
baseline of 0.6461. The same model also performs reliably in the multilingual
task and improves over the baseline in Greek. For German, a German-BERT model
fine-tuned on translated training data from typologically related languages
yields competitive performance over the baseline. In contrast, performance in
the Ukrainian and Polish zero-shot settings falls slightly below the respective
baselines, reflecting the challenge of generalization in low-resource
cross-lingual scenarios.

</details>


### [84] [Pun Unintended: LLMs and the Illusion of Humor Understanding](https://arxiv.org/abs/2509.12158)
*Alessandro Zangari,Matteo Marcuzzo,Andrea Albarelli,Mohammad Taher Pilehvar,Jose Camacho-Collados*

Main category: cs.CL

TL;DR: LLMs在双关语检测方面表现有限，容易被细微变化误导，缺乏人类般的深层理解


<details>
  <summary>Details</summary>
Motivation: 虽然大型语言模型在双关语检测方面显示出潜力，但其理解往往停留在表面层次，缺乏人类般的细腻把握，需要系统评估其鲁棒性挑战

Method: 通过系统分析和重构现有的双关语基准测试，展示双关语的细微变化如何误导LLMs，包括创建全面的双关语检测基准和进行人类评估

Result: 研究表明LLMs对双关语的理解较为肤浅，容易被微妙的变化所欺骗，揭示了这些模型在处理双关语时面临的鲁棒性挑战

Conclusion: 当前LLMs在理解双关语这种需要深层语义和语音相似性把握的幽默形式方面仍有明显局限，需要进一步改进模型的理解深度和鲁棒性

Abstract: Puns are a form of humorous wordplay that exploits polysemy and phonetic
similarity. While LLMs have shown promise in detecting puns, we show in this
paper that their understanding often remains shallow, lacking the nuanced grasp
typical of human interpretation. By systematically analyzing and reformulating
existing pun benchmarks, we demonstrate how subtle changes in puns are
sufficient to mislead LLMs. Our contributions include comprehensive and nuanced
pun detection benchmarks, human evaluation across recent LLMs, and an analysis
of the robustness challenges these models face in processing puns.

</details>


### [85] [RAGs to Riches: RAG-like Few-shot Learning for Large Language Model Role-playing](https://arxiv.org/abs/2509.12168)
*Timothy Rupprecht,Enfu Nan,Arash Akbari,Arman Akbari,Lei Lu,Priyanka Maan,Sean Duffy,Pu Zhao,Yumei He,David Kaeli,Yanzhi Wang*

Main category: cs.CL

TL;DR: RAGs-to-Riches框架通过将LLM角色扮演重新定义为文本检索问题，利用精心策划的参考演示来增强模型响应，显著提高了在敌对用户交互中的角色保持能力。


<details>
  <summary>Details</summary>
Motivation: LLM在医疗、教育等高风险领域部署时，少样本学习方法经常导致模型在敌对用户交互中意外脱戏，可能对用户信任和福祉造成危害。

Method: 受RAG启发，将LLM角色扮演重新定义为文本检索问题，提出RAGs-to-Riches提示框架，利用参考演示来调节LLM响应，并引入IOO和IOR两个新的token级ROUGE指标进行评估。

Result: 在与敌对用户模拟交互中，该方法在推理过程中从参考演示中多纳入了35%的token，在453次角色扮演交互中被一致评为更真实、更少脱戏，优于零样本和ICL方法。

Conclusion: 该方法为构建稳健、人类对齐的LLM角色扮演框架提供了可扩展策略，能够有效提升模型在敌对环境下的角色保持能力。

Abstract: Role-playing Large language models (LLMs) are increasingly deployed in
high-stakes domains such as healthcare, education, and governance, where
failures can directly impact user trust and well-being. A cost effective
paradigm for LLM role-playing is few-shot learning, but existing approaches
often cause models to break character in unexpected and potentially harmful
ways, especially when interacting with hostile users. Inspired by
Retrieval-Augmented Generation (RAG), we reformulate LLM role-playing into a
text retrieval problem and propose a new prompting framework called
RAGs-to-Riches, which leverages curated reference demonstrations to condition
LLM responses. We evaluate our framework with LLM-as-a-judge preference voting
and introduce two novel token-level ROUGE metrics: Intersection over Output
(IOO) to quantity how much an LLM improvises and Intersection over References
(IOR) to measure few-shot demonstrations utilization rate during the evaluation
tasks. When simulating interactions with a hostile user, our prompting strategy
incorporates in its responses during inference an average of 35% more tokens
from the reference demonstrations. As a result, across 453 role-playing
interactions, our models are consistently judged as being more authentic, and
remain in-character more often than zero-shot and in-context Learning (ICL)
methods. Our method presents a scalable strategy for building robust,
human-aligned LLM role-playing frameworks.

</details>


### [86] [Preservation of Language Understanding Capabilities in Speech-aware Large Language Models](https://arxiv.org/abs/2509.12171)
*Marek Kubis,Paweł Skórzewski,Iwona Christop,Mateusz Czyżnikiewicz,Jakub Kubiak,Łukasz Bondaruk,Marcin Lewandowski*

Main category: cs.CL

TL;DR: C3T是一个新的基准测试，用于评估语音感知大语言模型在不同模态下的性能表现，通过文本任务和语音克隆技术来量化模型在语音输入时的语言理解能力保持程度。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统评估语音感知大语言模型在语音和文本模态下性能一致性的基准测试，需要量化模型在不同说话人群体间的公平性和跨模态鲁棒性。

Method: 利用文本任务和语音克隆文本转语音模型，将文本输入转换为语音输入，测试模型在语音模态下的语言理解能力，并与文本模态下的性能进行对比。

Result: 提出了C3T基准测试框架，能够系统评估模型在不同说话人群体间的公平性和跨文本-语音模态的鲁棒性表现。

Conclusion: C3T基准为评估语音感知大语言模型的跨模态能力保持提供了有效的测试工具，有助于推动模型在语音输入场景下的公平性和鲁棒性发展。

Abstract: The paper presents C3T (Cross-modal Capabilities Conservation Test), a new
benchmark for assessing the performance of speech-aware large language models.
The benchmark utilizes textual tasks and a voice cloning text-to-speech model
to quantify the extent to which language understanding capabilities are
preserved when the model is accessed via speech input. C3T quantifies the
fairness of the model for different categories of speakers and its robustness
across text and speech modalities.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [87] [Combining Audio and Non-Audio Inputs in Evolved Neural Networks for Ovenbird](https://arxiv.org/abs/2509.10566)
*Sergio Poo Hernandez,Vadim Bulitko,Erin Bayne*

Main category: cs.SD

TL;DR: 使用非音频数据（如栖息地偏好、物候学和分布范围信息）与声谱图结合，可以提高单物种识别神经网络的分类准确率，且这种改进不是单纯由于参数数量增加所致。


<details>
  <summary>Details</summary>
Motivation: 当前基于CNN的物种分类器主要使用声谱图作为唯一输入，但研究人员还拥有其他非音频数据，这些数据可能有助于提高物种分类的准确性。

Method: 构建神经网络模型，同时使用声谱图和非音频数据作为输入，并与仅使用单一输入的相似规模网络进行对比分析。

Result: 使用两种不同输入的网络比仅使用单一输入的相似规模网络具有更高的分类准确率。

Conclusion: 结合声谱图和非音频数据的多模态输入方法能有效提升物种识别神经网络的性能，且性能提升不是单纯由参数数量增加带来的。

Abstract: In the last several years the use of neural networks as tools to automate
species classification from digital data has increased. This has been due in
part to the high classification accuracy of image classification through
Convolutional Neural Networks (CNN). In the case of audio data CNN based
recognizers are used to automate the classification of species in audio
recordings by using information from sound visualization (i.e., spectrograms).
It is common for these recognizers to use the spectrogram as their sole input.
However, researchers have other non-audio data, such as habitat preferences of
a species, phenology, and range information, available that could improve
species classification. In this paper we present how a single-species
recognizer neural network's accuracy can be improved by using non-audio data as
inputs in addition to spectrogram information. We also analyze if the
improvements are merely a result of having a neural network with a higher
number of parameters instead of combining the two inputs. We find that networks
that use the two different inputs have a higher classification accuracy than
networks of similar size that use only one of the inputs.

</details>


### [88] [Emoanti: audio anti-deepfake with refined emotion-guided representations](https://arxiv.org/abs/2509.10781)
*Xiaokang Li,Yicheng Gong,Dinghao Zou,Xin Cao,Sunbowen Lee*

Main category: cs.SD

TL;DR: 提出基于情感特征的音频反深度伪造系统EmoAnti，利用情感识别任务微调的Wav2Vec2模型提取情感引导表征，结合卷积残差网络捕获情感特征，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有音频深度伪造检测方法主要依赖低层声学特征或预训练语音表征，忽视了高层情感线索的补充作用，而情感特征可能提供抗伪造的泛化信息。

Method: 使用情感识别任务微调的Wav2Vec2模型提取情感引导表征，设计基于卷积层和残差连接的专用特征提取器，从transformer层输出中捕获和精炼情感特征。

Result: 在ASVspoof2019LA和ASVspoof2021LA基准测试中达到最先进性能，在ASVspoof2021DF数据集上表现出强泛化能力。

Conclusion: 情感特征为音频反深度伪造提供了有效的补充信息，所提出的EmoAnti系统在检测性能和泛化能力方面均有显著提升。

Abstract: Audio deepfake is so sophisticated that the lack of effective detection
methods is fatal. While most detection systems primarily rely on low-level
acoustic features or pretrained speech representations, they frequently neglect
high-level emotional cues, which can offer complementary and potentially
anti-deepfake information to enhance generalization. In this work, we propose a
novel audio anti-deepfake system that utilizes emotional features (EmoAnti) by
exploiting a pretrained Wav2Vec2 (W2V2) model fine-tuned on emotion recognition
tasks, which derives emotion-guided representations, then designing a dedicated
feature extractor based on convolutional layers with residual connections to
effectively capture and refine emotional characteristics from the transformer
layers outputs. Experimental results show that our proposed architecture
achieves state-of-the-art performance on both the ASVspoof2019LA and
ASVspoof2021LA benchmarks, and demonstrates strong generalization on the
ASVspoof2021DF dataset. Our proposed approach's code is available at Anonymous
GitHub1.

</details>


### [89] [STASE: A spatialized text-to-audio synthesis engine for music generation](https://arxiv.org/abs/2509.11124)
*Tutti Chi,Letian Gao,Yixiao Zhang*

Main category: cs.SD

TL;DR: STASE是一个基于大语言模型的文本到空间音频生成系统，通过分离语义解释和物理渲染来实现用户可控的空间音频生成


<details>
  <summary>Details</summary>
Motivation: 现有文本到音频系统主要生成单声道或固定立体声，缺乏对空间属性的精确控制，而基于深度学习的空间化方法通常依赖潜在空间操作，限制了用户对空间感知关键心理声学参数的直接控制

Method: 使用大语言模型作为代理解释文本中的空间线索，通过两个主要路径处理提示：描述提示（直接映射显式空间信息）和抽象提示（使用RAG模块检索相关空间模板），并将语义解释与基于物理的空间渲染引擎解耦

Result: 提出了STASE系统框架，实现了可解释和用户可控的空间推理，能够处理显式和抽象的空间描述

Conclusion: STASE通过LLM和物理渲染引擎的解耦设计，为生成式空间音频提供了新的解决方案，但评估生成空间音频仍面临挑战

Abstract: While many text-to-audio systems produce monophonic or fixed-stereo outputs,
generating audio with user-defined spatial properties remains a challenge.
Existing deep learning-based spatialization methods often rely on latent-space
manipulations, which can limit direct control over psychoacoustic parameters
critical to spatial perception. To address this, we introduce STASE, a system
that leverages a Large Language Model (LLM) as an agent to interpret spatial
cues from text. A key feature of STASE is the decoupling of semantic
interpretation from a separate, physics-based spatial rendering engine, which
facilitates interpretable and user-controllable spatial reasoning. The LLM
processes prompts through two main pathways: (i) Description Prompts, for
direct mapping of explicit spatial information (e.g., "place the lead guitar at
45{\deg} azimuth, 10 m distance"), and (ii) Abstract Prompts, where a
Retrieval-Augmented Generation (RAG) module retrieves relevant spatial
templates to inform the rendering. This paper details the STASE workflow,
discusses implementation considerations, and highlights current challenges in
evaluating generative spatial audio.

</details>


### [90] [ENJ: Optimizing Noise with Genetic Algorithms to Jailbreak LSMs](https://arxiv.org/abs/2509.11128)
*Yibo Zhang,Liang Lin*

Main category: cs.SD

TL;DR: ENJ方法使用遗传算法将环境噪声转化为可优化的攻击载体，通过在噪声中融合恶意指令来劫持大型语音模型，人类听起来像无害噪声但模型会执行有害命令


<details>
  <summary>Details</summary>
Motivation: 大型语音模型安全风险日益突出，传统语音对抗攻击方法在有效性和隐蔽性之间难以平衡，需要开发更隐蔽有效的攻击方法

Method: 使用遗传算法进行种群初始化、交叉融合和概率变异操作，迭代演化一系列将恶意指令与背景噪声融合的音频样本

Result: 在多个主流语音模型上的实验表明，ENJ的攻击效果显著优于现有基线方法

Conclusion: 研究揭示了噪声在语音安全中的双重作用，为复杂声学环境下的模型安全防御提供了新的关键见解

Abstract: The widespread application of Large Speech Models (LSMs) has made their
security risks increasingly prominent. Traditional speech adversarial attack
methods face challenges in balancing effectiveness and stealth. This paper
proposes Evolutionary Noise Jailbreak (ENJ), which utilizes a genetic algorithm
to transform environmental noise from a passive interference into an actively
optimizable attack carrier for jailbreaking LSMs. Through operations such as
population initialization, crossover fusion, and probabilistic mutation, this
method iteratively evolves a series of audio samples that fuse malicious
instructions with background noise. These samples sound like harmless noise to
humans but can induce the model to parse and execute harmful commands.
Extensive experiments on multiple mainstream speech models show that ENJ's
attack effectiveness is significantly superior to existing baseline methods.
This research reveals the dual role of noise in speech security and provides
new critical insights for model security defense in complex acoustic
environments.

</details>


### [91] [An Entropy-Guided Curriculum Learning Strategy for Data-Efficient Acoustic Scene Classification under Domain Shift](https://arxiv.org/abs/2509.11168)
*Peihong Zhang,Yuxuan Liu,Zhixin Li,Rui Sang,Yiqiang Cai,Yizhou Tan,Shengchen Li*

Main category: cs.SD

TL;DR: 提出基于熵引导的课程学习策略，通过从高熵（设备无关）样本到低熵（设备特定）样本的渐进学习，解决数据高效声学场景分类中的域偏移问题，无需增加模型复杂度或推理开销。


<details>
  <summary>Details</summary>
Motivation: 声学场景分类在跨设备泛化方面面临挑战，特别是在标记数据有限的情况下。现有方法如数据增强和预训练模型已广泛应用，但训练策略优化这一无需增加架构复杂度或推理开销的补充路径尚未充分探索。

Method: 使用辅助域分类器估计每个训练样本的设备后验概率，计算香农熵作为域不变性的代理指标。基于熵值构建课程学习策略，从高熵（设备无关）样本开始，逐步加入低熵（设备特定）样本。

Result: 在多个DCASE 2024 ASC基准测试上的实验结果表明，该策略有效缓解了域偏移问题，特别是在有限标记数据条件下表现突出。

Conclusion: 该策略是架构无关的，不引入额外推理成本，可轻松集成到现有ASC基线中，为域偏移问题提供了实用解决方案。

Abstract: Acoustic Scene Classification (ASC) faces challenges in generalizing across
recording devices, particularly when labeled data is limited. The DCASE 2024
Challenge Task 1 highlights this issue by requiring models to learn from small
labeled subsets recorded on a few devices. These models need to then generalize
to recordings from previously unseen devices under strict complexity
constraints. While techniques such as data augmentation and the use of
pre-trained models are well-established for improving model generalization,
optimizing the training strategy represents a complementary yet less-explored
path that introduces no additional architectural complexity or inference
overhead. Among various training strategies, curriculum learning offers a
promising paradigm by structuring the learning process from easier to harder
examples. In this work, we propose an entropy-guided curriculum learning
strategy to address the domain shift problem in data-efficient ASC.
Specifically, we quantify the uncertainty of device domain predictions for each
training sample by computing the Shannon entropy of the device posterior
probabilities estimated by an auxiliary domain classifier. Using entropy as a
proxy for domain invariance, the curriculum begins with high-entropy samples
and gradually incorporates low-entropy, domain-specific ones to facilitate the
learning of generalizable representations. Experimental results on multiple
DCASE 2024 ASC baselines demonstrate that our strategy effectively mitigates
domain shift, particularly under limited labeled data conditions. Our strategy
is architecture-agnostic and introduces no additional inference cost, making it
easily integrable into existing ASC baselines and offering a practical solution
to domain shift.

</details>


### [92] [WeaveMuse: An Open Agentic System for Multimodal Music Understanding and Generation](https://arxiv.org/abs/2509.11183)
*Emmanouil Karystinaios*

Main category: cs.SD

TL;DR: WeaveMuse是一个多代理系统，用于音乐理解、符号作曲和音频合成，通过协调专业代理和工具来解决复杂的多模态音乐任务。


<details>
  <summary>Details</summary>
Motivation: 将代理式AI标准化为协调专业模型和工具解决复杂多模态任务的实用范式，旨在民主化、实现和普及音乐信息检索工具。

Method: 采用多代理系统架构，包括专业代理解释用户请求、推导机器可操作需求并验证输出，管理代理选择排序工具、协调用户交互和维护状态。系统支持本地部署或通过HFApi访问，具有可扩展性、约束模式、结构化解码和参数高效适配器。

Result: 构建了一个可扩展的框架，支持跨文本、符号记谱、可视化和音频的多模态交互，实现分析-合成-渲染循环，并处理跨格式约束。

Conclusion: WeaveMuse通过支持不同规模的开源模型、灵活内存管理和可重复部署路径，为音乐信息检索工具提供了民主化、可实施和可访问的解决方案。

Abstract: Agentic AI has been standardized in industry as a practical paradigm for
coordinating specialized models and tools to solve complex multimodal tasks. In
this work, we present WeaveMuse, a multi-agent system for music understanding,
symbolic composition, and audio synthesis. Each specialist agent interprets
user requests, derives machine-actionable requirements (modalities, formats,
constraints), and validates its own outputs, while a manager agent selects and
sequences tools, mediates user interaction, and maintains state across turns.
The system is extendable and deployable either locally, using quantization and
inference strategies to fit diverse hardware budgets, or via the HFApi to
preserve free community access to open models. Beyond out-of-the-box use, the
system emphasizes controllability and adaptation through constraint schemas,
structured decoding, policy-based inference, and parameter-efficient adapters
or distilled variants that tailor models to MIR tasks. A central design goal is
to facilitate intermodal interaction across text, symbolic notation and
visualization, and audio, enabling analysis-synthesis-render loops and
addressing cross-format constraints. The framework aims to democratize,
implement, and make accessible MIR tools by supporting interchangeable
open-source models of various sizes, flexible memory management, and
reproducible deployment paths.

</details>


### [93] [Revisiting Meter Tracking in Carnatic Music using Deep Learning Approaches](https://arxiv.org/abs/2509.11241)
*Satyajeet Prabhu*

Main category: cs.SD

TL;DR: 本研究评估了两种深度学习模型（TCN和Beat This!）在卡纳提克音乐节拍追踪任务上的表现，发现通过迁移学习可以显著提升性能，达到或超越传统DBN基准，证明了先进深度学习模型能够有效适应代表性不足的音乐传统。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型在西方音乐节拍追踪上表现出色，但在卡纳提克音乐等代表性不足的音乐传统中性能不佳。本研究旨在探索先进深度学习模型在卡纳提克音乐节拍追踪任务上的适应性和有效性。

Method: 使用Temporal Convolutional Network (TCN)和transformer-based的Beat This!模型，在CMR_f数据集上复现DBN基准的实验设置，评估了现成模型性能、微调策略和音乐知识参数的使用。

Result: 现成模型并不总是优于DBN基准，但通过迁移学习后性能显著提升，能够匹配或超越基准表现。

Conclusion: 先进的深度学习模型可以通过适当的适应策略有效应用于代表性不足的音乐传统，为构建更具包容性和广泛适用性的节拍追踪系统铺平道路。

Abstract: Beat and downbeat tracking, jointly referred to as Meter Tracking, is a
fundamental task in Music Information Retrieval (MIR). Deep learning models
have far surpassed traditional signal processing and classical machine learning
approaches in this domain, particularly for Western (Eurogenetic) genres, where
large annotated datasets are widely available. These systems, however, perform
less reliably on underrepresented musical traditions. Carnatic music, a rich
tradition from the Indian subcontinent, is renowned for its rhythmic intricacy
and unique metrical structures (t\=alas). The most notable prior work on meter
tracking in this context employed probabilistic Dynamic Bayesian Networks
(DBNs). The performance of state-of-the-art (SOTA) deep learning models on
Carnatic music, however, remains largely unexplored.
  In this study, we evaluate two models for meter tracking in Carnatic music:
the Temporal Convolutional Network (TCN), a lightweight architecture that has
been successfully adapted for Latin rhythms, and Beat This!, a
transformer-based model designed for broad stylistic coverage without the need
for post-processing. Replicating the experimental setup of the DBN baseline on
the Carnatic Music Rhythm (CMR$_f$) dataset, we systematically assess the
performance of these models in a directly comparable setting. We further
investigate adaptation strategies, including fine-tuning the models on Carnatic
data and the use of musically informed parameters. Results show that while
off-the-shelf models do not always outperform the DBN, their performance
improves substantially with transfer learning, matching or surpassing the
baseline. These findings indicate that SOTA deep learning models can be
effectively adapted to underrepresented traditions, paving the way for more
inclusive and broadly applicable meter tracking systems.

</details>


### [94] [FuseCodec: Semantic-Contextual Fusion and Supervision for Neural Codecs](https://arxiv.org/abs/2509.11425)
*Md Mubtasim Ahasan,Rafat Hasan Khan,Tasnim Mohiuddin,Aman Chadha,Tariq Iqbal,M Ashraful Amin,Amin Ahsan Ali,Md Mofijul Islam,A K M Mahbubur Rahman*

Main category: cs.SD

TL;DR: FuseCodec是一个统一的语音编码器，通过跨模态对齐和全局监督，整合声学、语义和上下文表示，在语音标记化和合成任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经编解码器主要捕获低层次声学特征，忽略了语音中的语义和上下文信息。虽然近期研究尝试引入自监督语音模型的语义表示或预训练语言模型的上下文表示，但在对齐和统一这些表示方面仍存在挑战。

Method: 提出三种互补技术：1)潜在表示融合，将语义和上下文特征直接整合到编码器潜在空间；2)全局语义-上下文监督，用全局池化和广播表示监督离散标记；3)时间对齐上下文监督，通过局部窗口动态匹配上下文和语音标记进行细粒度监督。

Result: 在LibriSpeech数据集上超越EnCodec、SpeechTokenizer和DAC，在转录准确性、感知质量、可懂度和说话人相似性方面达到最先进性能。还展示了在零样本语音合成中的适用性。

Conclusion: 研究证明了上下文和语义引导的标记化方法在语音标记化和下游任务中的有效性，为语音表示学习提供了新的统一框架。

Abstract: Speech tokenization enables discrete representation and facilitates speech
language modeling. However, existing neural codecs capture low-level acoustic
features, overlooking the semantic and contextual cues inherent to human
speech. While recent efforts introduced semantic representations from
self-supervised speech models or incorporated contextual representations from
pre-trained language models, challenges remain in aligning and unifying the
semantic and contextual representations. We introduce FuseCodec, which unifies
acoustic, semantic, and contextual representations through strong cross-modal
alignment and globally informed supervision. We propose three complementary
techniques: (i) Latent Representation Fusion, integrating semantic and
contextual features directly into the encoder latent space for robust and
unified representation learning; (ii) Global Semantic-Contextual Supervision,
supervising discrete tokens with globally pooled and broadcasted
representations to enhance temporal consistency and cross-modal alignment; and
(iii) Temporally Aligned Contextual Supervision, strengthening alignment by
dynamically matching contextual and speech tokens within a local window for
fine-grained token-level supervision. We further introduce FuseCodec-TTS,
demonstrating our methodology's applicability to zero-shot speech synthesis.
Empirically, FuseCodec achieves state-of-the-art performance in LibriSpeech,
surpassing EnCodec, SpeechTokenizer, and DAC in transcription accuracy,
perceptual quality, intelligibility, and speaker similarity. Results highlight
the effectiveness of contextually and semantically guided tokenization for
speech tokenization and downstream tasks. Code and pretrained models are
available at https://github.com/mubtasimahasan/FuseCodec.

</details>


### [95] [Acoustic Overspecification in Electronic Dance Music Taxonomy](https://arxiv.org/abs/2509.11474)
*Weilun Xu,Tianhao Dai,Oscar Goudet,Xiaoxuan Wang*

Main category: cs.SD

TL;DR: 本文提出了一种无监督方法来发现电子舞曲的自然声学结构，发现当前EDM分类体系存在约三分之一的过度指定问题


<details>
  <summary>Details</summary>
Motivation: 电子舞曲分类通常依赖行业定义的分类法，但这些子流派之间的声学基础不明确，现有方法假设预设标签的有效性而缺乏系统评估

Method: 结合新颖的基于tempogram的特征（捕捉EDM的分层节奏模式）和多标准特征选择的无监督方法，并与最先进的预训练音频嵌入（MERT和CLAP）进行比较验证

Result: 我们的特征空间和嵌入表示都收敛到19-23个自然声学家族，而预设分类有35个，表明当前EDM分类体系存在约三分之一的过度指定

Conclusion: 无监督方法揭示了EDM的自然声学结构，证明当前商业标签体系存在显著过度分类，为更合理的音乐分类提供了实证基础

Abstract: Electronic Dance Music (EDM) classification typically relies on
industry-defined taxonomies with numerous subgenres, yet the acoustic basis for
these distinctions remains unclear. Current approaches use supervised learning
with prescribed genre labels, assuming their validity without systematic
evaluation. In this paper, we propose an unsupervised approach to discover the
natural acoustic structure of EDM independent of commercial labels. Our method
combines novel tempogram-based features capturing EDM's layered rhythmic
patterns with multi-criteria feature selection. To validate that our findings
reflect genuine acoustic structure rather than methodological artifacts, we
compare our results against state-of-the-art pre-trained audio embeddings (MERT
and CLAP). Both our feature space and embedding representations converge to
19-23 natural acoustic families compared to the prescribed 35, providing
consistent evidence of significant overspecification in current EDM taxonomy by
approximately one-third.

</details>


### [96] [Scaling to Multimodal and Multichannel Heart Sound Classification: Fine-Tuning Wav2Vec 2.0 with Synthetic and Augmented Biosignals](https://arxiv.org/abs/2509.11606)
*Milan Marocchi,Matthew Fynn,Kayapanda Mandana,Yue Rong*

Main category: cs.SD

TL;DR: 该研究结合传统信号处理和去噪扩散模型，通过数据增强方法训练基于Wav2Vec 2.0的心脏声音分类器，在多种心脏声音数据集上实现了最先进的性能表现。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球主要死因，早期检测需求迫切。现有深度学习方法受限于同步和多通道数据集的稀缺性，需要开发有效的数据增强方法来提升模型性能。

Method: 结合传统信号处理和WaveGrad、DiffWave等去噪扩散模型创建增强数据集，用于微调基于Wav2Vec 2.0的分类器，处理多模态和多通道心脏声音数据。

Result: 在CinC 2016单通道PCG数据集上达到92.48%准确率；在同步PCG-ECG数据上达到93.14%准确率；在多通道PCG可穿戴背心数据集上达到77.13%准确率，各项指标均表现优异。

Conclusion: 基于transformer的模型在增强数据集支持下对心血管疾病检测非常有效，展示了在多模态和多通道心脏声音分类方面的巨大潜力。

Abstract: Cardiovascular diseases (CVDs) are the leading cause of death worldwide,
accounting for approximately 17.9 million deaths each year. Early detection is
critical, creating a demand for accurate and inexpensive pre-screening methods.
Deep learning has recently been applied to classify abnormal heart sounds
indicative of CVDs using synchronised phonocardiogram (PCG) and
electrocardiogram (ECG) signals, as well as multichannel PCG (mPCG). However,
state-of-the-art architectures remain underutilised due to the limited
availability of synchronised and multichannel datasets. Augmented datasets and
pre-trained models provide a pathway to overcome these limitations, enabling
transformer-based architectures to be trained effectively. This work combines
traditional signal processing with denoising diffusion models, WaveGrad and
DiffWave, to create an augmented dataset to fine-tune a Wav2Vec 2.0-based
classifier on multimodal and multichannel heart sound datasets. The approach
achieves state-of-the-art performance. On the Computing in Cardiology (CinC)
2016 dataset of single channel PCG, accuracy, unweighted average recall (UAR),
sensitivity, specificity and Matthew's correlation coefficient (MCC) reach
92.48\%, 93.05\%, 93.63\%, 92.48\%, 94.93\% and 0.8283, respectively. Using the
synchronised PCG and ECG signals of the training-a dataset from CinC, 93.14\%,
92.21\%, 94.35\%, 90.10\%, 95.12\% and 0.8380 are achieved for accuracy, UAR,
sensitivity, specificity and MCC, respectively. Using a wearable vest dataset
consisting of mPCG data, the model achieves 77.13\% accuracy, 74.25\% UAR,
86.47\% sensitivity, 62.04\% specificity, and 0.5082 MCC. These results
demonstrate the effectiveness of transformer-based models for CVD detection
when supported by augmented datasets, highlighting their potential to advance
multimodal and multichannel heart sound classification.

</details>


### [97] [Neural Audio Codecs for Prompt-Driven Universal Source Separation](https://arxiv.org/abs/2509.11717)
*Adhiraj Banerjee,Vipul Arora*

Main category: cs.SD

TL;DR: CodecSep是一个基于神经音频编解码器的高效文本驱动音频分离模型，相比AudioSep计算量减少54倍，在分离保真度上表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有文本引导音频分离模型（如AudioSep）计算量过大，不适合边缘设备部署，而现有的神经音频编解码器模型只能进行固定类别的分离。

Method: 结合DAC压缩技术和基于Transformer的掩码器，使用CLAP导出的FiLM参数进行调制，实现高效的文本驱动音频分离。

Result: 在六个开放域基准测试中，CodecSep在分离保真度（SI-SDR）上超越AudioSep，感知质量（ViSQOL）保持竞争力，计算量仅需1.35 GMACs，比AudioSep减少54倍。

Conclusion: CodecSep首次实现了基于神经音频编解码器的通用文本驱动分离，在保持完全比特流兼容性的同时显著降低了计算需求，适合边缘设备部署。

Abstract: Text-guided source separation supports flexible audio editing across media
and assistive applications, but existing models like AudioSep are too
compute-heavy for edge deployment. Neural audio codec (NAC) models such as
CodecFormer and SDCodec are compute-efficient but limited to fixed-class
separation. We introduce CodecSep, the first NAC-based model for on-device
universal, text-driven separation. CodecSep combines DAC compression with a
Transformer masker modulated by CLAP-derived FiLM parameters. Across six
open-domain benchmarks under matched training/prompt protocols,
\textbf{CodecSep} surpasses \textbf{AudioSep} in separation fidelity (SI-SDR)
while remaining competitive in perceptual quality (ViSQOL) and matching or
exceeding fixed-stem baselines (TDANet, CodecFormer, SDCodec). In code-stream
deployments, it needs just 1.35~GMACs end-to-end -- approximately $54\times$
less compute ($25\times$ architecture-only) than spectrogram-domain separators
like AudioSep -- while remaining fully bitstream-compatible.

</details>


### [98] [PoolingVQ: A VQVAE Variant for Reducing Audio Redundancy and Boosting Multi-Modal Fusion in Music Emotion Analysis](https://arxiv.org/abs/2509.11976)
*Dinghao Zou,Yicheng Gong,Xiaokang Li,Xin Cao,Sunbowen Lee*

Main category: cs.SD

TL;DR: 提出PoolingVQ方法，通过VQVAE和空间池化压缩音频特征序列以减少冗余，结合双阶段协同注意力机制融合音频和MIDI信息，在多模态音乐情感分析任务中取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 主流方法专注于复杂特征提取网络，但音频序列特征存在冗余，相比MIDI的紧凑表示，缩短音频序列长度可能有效提升任务性能

Method: 结合VQVAE和空间池化开发PoolingVQ方法，通过局部聚合直接压缩音频特征序列以减少冗余；设计双阶段协同注意力机制来融合音频和MIDI信息

Result: 在EMOPIA和VGMIDI公开数据集上的实验表明，该多模态框架实现了最先进的整体性能，PoolingVQ带来了一定改进

Conclusion: 通过压缩音频特征序列减少冗余，并结合有效的多模态融合策略，能够显著提升音乐情感分析任务的性能

Abstract: Multimodal music emotion analysis leverages audio and MIDI modalities to
enhance performance. While mainstream approaches focus on complex feature
extraction networks, we posit that shortening the length of audio sequence
features to mitigate redundancy, especially in contrast to MIDI's compact
representation, may effectively boost task performance. To achieve this, we
developed PoolingVQ by combining Vector Quantized Variational Autoencoder
(VQVAE) with spatial pooling, which directly compresses audio feature sequences
through local aggregation to reduce redundancy, then devised a two-stage
co-attention approach to fuse audio and MIDI information. Experimental results
on the public datasets EMOPIA and VGMIDI demonstrate that our multimodal
framework achieves state-of-the-art overall performance, with PoolingVQ
yielding some improvement.

</details>


### [99] [Improving Out-of-Domain Audio Deepfake Detection via Layer Selection and Fusion of SSL-Based Countermeasures](https://arxiv.org/abs/2509.12003)
*Pierre Serrano,Raphaël Duroselle,Florian Angulo,Jean-François Bonastre,Olivier Boeffard*

Main category: cs.SD

TL;DR: 该论文研究了基于冻结预训练自监督学习编码器的音频深度伪造检测系统，通过层分析和池化策略优化，发现选择最佳单层可减少80%参数且性能良好，同时多编码器融合提高了对域外攻击的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于冻结预训练SSL编码器的音频深度伪造检测系统虽然在结合加权池化方法时表现良好，但在面对域外条件时泛化能力仍然不足，需要研究如何提高系统对未知攻击的检测能力。

Method: 研究了6种不同的预训练SSL模型在4个测试语料库上的表现，进行了逐层分析确定贡献最大的层，比较了单层选择策略和MHFA自动选择策略，并进行了多编码器的分数级融合实验。

Result: 选择最佳单层的策略在减少80%系统参数的同时仍能获得良好性能；不同测试语料库和SSL模型间性能差异显著，表明编码器的预训练策略很重要；多编码器融合显著提高了对域外攻击的泛化能力。

Conclusion: 通过精心选择SSL编码器的特定层和使用多编码器融合策略，可以有效提高音频深度伪造检测系统在域外条件下的泛化性能，同时大幅减少模型参数。

Abstract: Audio deepfake detection systems based on frozen pre-trained self-supervised
learning (SSL) encoders show a high level of performance when combined with
layer-weighted pooling methods, such as multi-head factorized attentive pooling
(MHFA). However, they still struggle to generalize to out-of-domain (OOD)
conditions. We tackle this problem by studying the behavior of six different
pre-trained SSLs, on four different test corpora. We perform a layer-by-layer
analysis to determine which layers contribute most. Next, we study the pooling
head, comparing a strategy based on a single layer with automatic selection via
MHFA. We observed that selecting the best layer gave very good results, while
reducing system parameters by up to 80%. A wide variation in performance as a
function of test corpus and SSL model is also observed, showing that the
pre-training strategy of the encoder plays a role. Finally, score-level fusion
of several encoders improved generalization to OOD attacks.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [100] [Automated Radiology Report Generation Based on Topic-Keyword Semantic Guidance](https://arxiv.org/abs/2509.10873)
*Jing Xiao,Hongfei Liu,Ruiqi Dong,Jimin Liu,Haoyong Yu*

Main category: cs.MM

TL;DR: 提出TKSG框架，利用BiomedCLIP检索历史相似病例，通过主题词和关键词语义指导提升放射报告生成的准确性和相关性


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分利用历史放射报告知识，缺乏足够准确的先验信息，导致诊断效率低下，浪费医疗资源

Method: 使用BiomedCLIP检索相似病例，多模态检测主题词（疾病分类）和关键词（常见症状），构建主题向量指导全局解码，设计语义引导注意力模块优化局部解码

Result: 在IU X-Ray和MIMIC-CXR数据集上取得优异性能

Conclusion: TKSG框架通过有效利用历史报告知识，显著提升了放射报告生成的准确性和效率

Abstract: Automated radiology report generation is essential in clinical practice.
However, diagnosing radiological images typically requires physicians 5-10
minutes, resulting in a waste of valuable healthcare resources. Existing
studies have not fully leveraged knowledge from historical radiology reports,
lacking sufficient and accurate prior information. To address this, we propose
a Topic-Keyword Semantic Guidance (TKSG) framework. This framework uses
BiomedCLIP to accurately retrieve historical similar cases. Supported by
multimodal, TKSG accurately detects topic words (disease classifications) and
keywords (common symptoms) in diagnoses. The probabilities of topic terms are
aggregated into a topic vector, serving as global information to guide the
entire decoding process. Additionally, a semantic-guided attention module is
designed to refine local decoding with keyword content, ensuring report
accuracy and relevance. Experimental results show that our model achieves
excellent performance on both IU X-Ray and MIMIC-CXR datasets. The code is
available at https://github.com/SCNU203/TKSG.

</details>


### [101] [Nagare Media Ingest: A System for Multimedia Ingest Workflows](https://arxiv.org/abs/2509.11972)
*Matthias Neugebauer*

Main category: cs.MM

TL;DR: 本文介绍了nagare media ingest开源系统，该系统通过将多媒体摄取过程拆分为多个并发运行的组件，提供了比现有解决方案更大的灵活性。


<details>
  <summary>Details</summary>
Motivation: 随着云和边缘计算环境的普及，多媒体系统需要处理日益复杂的流媒体协议和用例，现有解决方案难以满足现代工作流程的需求。

Method: 设计了一个开源的多媒体摄取系统，将摄取过程的责任拆分为多个并发运行的组件，用户可以通过配置这些组件来实现特定的摄取工作流程。

Result: nagare media ingest系统提供了比传统解决方案更大的灵活性，允许用户根据具体用例选择合适的组件组合。

Conclusion: 通过组件化的设计方法，nagare media ingest能够更好地适应现代多媒体工作流程的复杂性，为多媒体数据摄取提供了更灵活的解决方案。

Abstract: Ingesting multimedia data is usually the first step of multimedia workflows.
For this purpose, various streaming protocols have been proposed for live and
file-based content. For instance, SRT, RIST, DASH-IF Live Media Ingest Protocol
and MOQT have been introduced in recent years. At the same time, the number of
use cases has only proliferated by the move to cloud- and edge-computing
environments. Multimedia systems now have to handle this complexity in order to
stay relevant for today's workflows.
  This technical report discusses implementation details of nagare media
ingest, an open source system for ingesting multimedia data into multimedia
workflows. In contrast to existing solutions, nagare media ingest splits up the
responsibilities of the ingest process. Users configure multiple concurrently
running components that work together to implement a particular ingest
workflow. As such, the design of nagare media ingest allows for great
flexibility as components can be selected to fit the desired use case.

</details>


### [102] [Results of the 2025 Video Browser Showdown](https://arxiv.org/abs/2509.12000)
*Luca Rossetto,Klaus Schoeffmann,Cathal Gurrin,Jakub Lokoč,Werner Bailer*

Main category: cs.MM

TL;DR: 第14届视频浏览器展示会结果报告


<details>
  <summary>Details</summary>
Motivation: 展示和评估最新的视频检索和浏览技术，促进多媒体信息检索领域的发展

Method: 通过竞赛形式，让各研究团队展示其视频浏览器系统在特定任务上的性能表现

Result: 报告了2025年1月8日在日本奈良举行的展示会结果，展示了当前视频检索技术的最新进展

Conclusion: 视频浏览器展示会为研究人员提供了交流平台，推动了视频检索技术的创新和发展

Abstract: This report presents the results of the 14th Video Browser Showdown, held at
the 2025 International Conference on Multimedia Modeling on the 8th of January
2025 in Nara, Japan.

</details>
